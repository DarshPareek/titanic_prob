{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('titanic/train.csv')\n",
    "test_data = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['People'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['People'] = test_data['SibSp'] + test_data['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch','Ticket', 'Cabin'])\n",
    "test_data = test_data.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch','Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'People'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mode()[0])\n",
    "test_data['Age'] = train_data['Age'].fillna(train_data['Age'].mode()[0])\n",
    "train_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\n",
    "test_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n",
    "test_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data, dtype='int')\n",
    "test_data = pd.get_dummies(test_data, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['Survived'])\n",
    "y_train = train_data['Survived'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(9,)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  for i in range(hp.Int('No. of Layers', min_value=1, max_value=11, step=1)):\n",
    "    model.add(keras.layers.Dense(units=hp.Int('n '+str(i), min_value = 32, max_value=512, step=32), activation='relu'))\n",
    "  dr = hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)\n",
    "  model.add(keras.layers.Dropout(dr))\n",
    "  model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.BinaryCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     directory='my_dir',\n",
    "                     factor = 7,\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 Complete [00h 00m 08s]\n",
      "val_accuracy: 0.832402229309082\n",
      "\n",
      "Best val_accuracy So Far: 0.8547486066818237\n",
      "Total elapsed time: 00h 05m 44s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 6, dropout was 0.1 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=35, validation_split=0.2, callbacks=[stop_early])\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('No. of Layers')}, dropout was {best_hps.get('dropout')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 0.6982 - accuracy: 0.6236 - val_loss: 0.6955 - val_accuracy: 0.6425\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6498 - accuracy: 0.6348 - val_loss: 0.6106 - val_accuracy: 0.6425\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6629 - val_loss: 0.5333 - val_accuracy: 0.7263\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6204 - accuracy: 0.6531 - val_loss: 0.5464 - val_accuracy: 0.7207\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6195 - accuracy: 0.6433 - val_loss: 0.5069 - val_accuracy: 0.7318\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.5937 - accuracy: 0.6728 - val_loss: 0.4905 - val_accuracy: 0.7374\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.5666 - accuracy: 0.7107 - val_loss: 0.4438 - val_accuracy: 0.7821\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5620 - accuracy: 0.7205 - val_loss: 0.4962 - val_accuracy: 0.7877\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.5549 - accuracy: 0.7444 - val_loss: 0.4208 - val_accuracy: 0.8324\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7725 - val_loss: 0.4113 - val_accuracy: 0.8268\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5085 - accuracy: 0.7711 - val_loss: 0.4604 - val_accuracy: 0.7989\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5653 - accuracy: 0.7402 - val_loss: 0.5055 - val_accuracy: 0.7989\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5042 - accuracy: 0.7739 - val_loss: 0.3984 - val_accuracy: 0.8101\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4840 - accuracy: 0.7865 - val_loss: 0.4017 - val_accuracy: 0.8324\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5272 - accuracy: 0.7640 - val_loss: 0.4163 - val_accuracy: 0.8268\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.7795 - val_loss: 0.4114 - val_accuracy: 0.8380\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.7823 - val_loss: 0.3815 - val_accuracy: 0.8156\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4720 - accuracy: 0.7879 - val_loss: 0.4427 - val_accuracy: 0.7877\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4796 - accuracy: 0.7865 - val_loss: 0.4113 - val_accuracy: 0.8212\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4686 - accuracy: 0.7879 - val_loss: 0.3894 - val_accuracy: 0.8212\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4625 - accuracy: 0.7935 - val_loss: 0.3681 - val_accuracy: 0.8436\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4891 - accuracy: 0.7781 - val_loss: 0.3823 - val_accuracy: 0.8380\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7865 - val_loss: 0.3767 - val_accuracy: 0.8324\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4625 - accuracy: 0.7865 - val_loss: 0.3913 - val_accuracy: 0.8436\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4636 - accuracy: 0.7963 - val_loss: 0.4889 - val_accuracy: 0.8212\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5069 - accuracy: 0.7640 - val_loss: 0.3872 - val_accuracy: 0.8380\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4537 - accuracy: 0.7921 - val_loss: 0.3880 - val_accuracy: 0.8045\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4518 - accuracy: 0.8020 - val_loss: 0.3718 - val_accuracy: 0.8212\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4446 - accuracy: 0.7907 - val_loss: 0.4306 - val_accuracy: 0.8547\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4756 - accuracy: 0.8062 - val_loss: 0.4115 - val_accuracy: 0.7933\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4767 - accuracy: 0.7978 - val_loss: 0.3856 - val_accuracy: 0.8380\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4520 - accuracy: 0.8006 - val_loss: 0.3632 - val_accuracy: 0.8492\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4555 - accuracy: 0.7963 - val_loss: 0.4425 - val_accuracy: 0.7933\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.7795 - val_loss: 0.3458 - val_accuracy: 0.8492\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4472 - accuracy: 0.7963 - val_loss: 0.3401 - val_accuracy: 0.8547\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4574 - accuracy: 0.8034 - val_loss: 0.3607 - val_accuracy: 0.8324\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.8034 - val_loss: 0.3662 - val_accuracy: 0.8659\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.7963 - val_loss: 0.3653 - val_accuracy: 0.8436\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4390 - accuracy: 0.8076 - val_loss: 0.3276 - val_accuracy: 0.8547\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8118 - val_loss: 0.3186 - val_accuracy: 0.8715\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7992 - val_loss: 0.3443 - val_accuracy: 0.8771\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8104 - val_loss: 0.3465 - val_accuracy: 0.8547\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4227 - accuracy: 0.8132 - val_loss: 0.3480 - val_accuracy: 0.8603\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8174 - val_loss: 0.3738 - val_accuracy: 0.8101\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7921 - val_loss: 0.3736 - val_accuracy: 0.8603\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7949 - val_loss: 0.3878 - val_accuracy: 0.8212\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4347 - accuracy: 0.8020 - val_loss: 0.3256 - val_accuracy: 0.8603\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8202 - val_loss: 0.3698 - val_accuracy: 0.8603\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4449 - accuracy: 0.7963 - val_loss: 0.3926 - val_accuracy: 0.8212\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4385 - accuracy: 0.8132 - val_loss: 0.3383 - val_accuracy: 0.8492\n",
      "Best epoch: 41\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41\n",
      "23/23 [==============================] - 1s 13ms/step - loss: 0.6453 - accuracy: 0.6517 - val_loss: 0.5490 - val_accuracy: 0.7207\n",
      "Epoch 2/41\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6517 - val_loss: 0.5556 - val_accuracy: 0.7374\n",
      "Epoch 3/41\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6281 - accuracy: 0.6756 - val_loss: 0.6319 - val_accuracy: 0.6425\n",
      "Epoch 4/41\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6285 - accuracy: 0.6573 - val_loss: 0.5246 - val_accuracy: 0.7263\n",
      "Epoch 5/41\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6071 - accuracy: 0.6756 - val_loss: 0.5393 - val_accuracy: 0.7095\n",
      "Epoch 6/41\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6460 - accuracy: 0.6264 - val_loss: 0.5915 - val_accuracy: 0.6760\n",
      "Epoch 7/41\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.6685 - val_loss: 0.5511 - val_accuracy: 0.7374\n",
      "Epoch 8/41\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 0.6531 - val_loss: 0.5401 - val_accuracy: 0.6425\n",
      "Epoch 9/41\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5659 - accuracy: 0.6812 - val_loss: 0.4502 - val_accuracy: 0.8045\n",
      "Epoch 10/41\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5911 - accuracy: 0.7051 - val_loss: 0.4695 - val_accuracy: 0.7765\n",
      "Epoch 11/41\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7458 - val_loss: 0.3986 - val_accuracy: 0.8268\n",
      "Epoch 12/41\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.5118 - accuracy: 0.7725 - val_loss: 0.4769 - val_accuracy: 0.7542\n",
      "Epoch 13/41\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.5293 - accuracy: 0.7697 - val_loss: 0.4496 - val_accuracy: 0.8045\n",
      "Epoch 14/41\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4988 - accuracy: 0.7753 - val_loss: 0.4166 - val_accuracy: 0.8324\n",
      "Epoch 15/41\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5103 - accuracy: 0.7767 - val_loss: 0.4111 - val_accuracy: 0.8212\n",
      "Epoch 16/41\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4907 - accuracy: 0.7823 - val_loss: 0.4326 - val_accuracy: 0.8156\n",
      "Epoch 17/41\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4975 - accuracy: 0.7851 - val_loss: 0.3796 - val_accuracy: 0.8324\n",
      "Epoch 18/41\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.8006 - val_loss: 0.4267 - val_accuracy: 0.8101\n",
      "Epoch 19/41\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4886 - accuracy: 0.7851 - val_loss: 0.4282 - val_accuracy: 0.8156\n",
      "Epoch 20/41\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.7893 - val_loss: 0.4029 - val_accuracy: 0.8324\n",
      "Epoch 21/41\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4986 - accuracy: 0.7739 - val_loss: 0.3989 - val_accuracy: 0.8492\n",
      "Epoch 22/41\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4721 - accuracy: 0.7921 - val_loss: 0.4108 - val_accuracy: 0.8101\n",
      "Epoch 23/41\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4704 - accuracy: 0.7963 - val_loss: 0.3981 - val_accuracy: 0.8324\n",
      "Epoch 24/41\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.7921 - val_loss: 0.3664 - val_accuracy: 0.8436\n",
      "Epoch 25/41\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4706 - accuracy: 0.7823 - val_loss: 0.3623 - val_accuracy: 0.8380\n",
      "Epoch 26/41\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5484 - accuracy: 0.7247 - val_loss: 0.4263 - val_accuracy: 0.8156\n",
      "Epoch 27/41\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4702 - accuracy: 0.7935 - val_loss: 0.3953 - val_accuracy: 0.8492\n",
      "Epoch 28/41\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4572 - accuracy: 0.8076 - val_loss: 0.3799 - val_accuracy: 0.8436\n",
      "Epoch 29/41\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4804 - accuracy: 0.8104 - val_loss: 0.4190 - val_accuracy: 0.7877\n",
      "Epoch 30/41\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4537 - accuracy: 0.7907 - val_loss: 0.3723 - val_accuracy: 0.8492\n",
      "Epoch 31/41\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4405 - accuracy: 0.8062 - val_loss: 0.3618 - val_accuracy: 0.8547\n",
      "Epoch 32/41\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4435 - accuracy: 0.8174 - val_loss: 0.3477 - val_accuracy: 0.8603\n",
      "Epoch 33/41\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4297 - accuracy: 0.8132 - val_loss: 0.3326 - val_accuracy: 0.8492\n",
      "Epoch 34/41\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4316 - accuracy: 0.7963 - val_loss: 0.3747 - val_accuracy: 0.8324\n",
      "Epoch 35/41\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4517 - accuracy: 0.7893 - val_loss: 0.3524 - val_accuracy: 0.8324\n",
      "Epoch 36/41\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4391 - accuracy: 0.8090 - val_loss: 0.3523 - val_accuracy: 0.8436\n",
      "Epoch 37/41\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4512 - accuracy: 0.7865 - val_loss: 0.3651 - val_accuracy: 0.8547\n",
      "Epoch 38/41\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4396 - accuracy: 0.8132 - val_loss: 0.3454 - val_accuracy: 0.8659\n",
      "Epoch 39/41\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8230 - val_loss: 0.3850 - val_accuracy: 0.8492\n",
      "Epoch 40/41\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4238 - accuracy: 0.8132 - val_loss: 0.3416 - val_accuracy: 0.8380\n",
      "Epoch 41/41\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4348 - accuracy: 0.8020 - val_loss: 0.3453 - val_accuracy: 0.8547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x78e7aa472e50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = hypermodel.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = np.round(predictions,0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('titanic/test.csv')\n",
    "# print(t[\"PassengerId\"].shape, survived.shape)\n",
    "answer = pd.DataFrame({\"PassengerId\" : t[\"PassengerId\"], \"Survived\":survived.ravel()})\n",
    "answer.to_csv('titanic/predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No. of Layers': 6,\n",
       " 'n 0': 64,\n",
       " 'dropout': 0.1,\n",
       " 'learning_rate': 0.001,\n",
       " 'n 1': 480,\n",
       " 'n 2': 128,\n",
       " 'n 3': 128,\n",
       " 'n 4': 384,\n",
       " 'n 5': 448,\n",
       " 'n 6': 32,\n",
       " 'n 7': 192,\n",
       " 'n 8': 96,\n",
       " 'n 9': 128,\n",
       " 'n 10': 224,\n",
       " 'tuner/epochs': 100,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 0,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow_decision_forests.keras import pd_dataframe_to_tf_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd_dataframe_to_tf_dataset(train_data, label='Survived')\n",
    "# test_ds = test_data.insert(column=\"Survived\",value=[0]*418, loc=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = pd_dataframe_to_tf_dataset(test_data, label='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmplnkxsq9h as temporary training directory\n",
      "Warning: Model constructor argument validation_split=0.2 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument validation_split=0.2 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.111907. Found 891 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-21 09:31:05.5436 UTC kernel.cc:1233] Loading model from path /tmp/tmplnkxsq9h/model/ with prefix 90256cc6f9df4912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.114095\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-21 09:31:05.5822 UTC decision_forest.cc:660] Model loaded with 300 root(s), 47030 node(s), and 9 input feature(s).\n",
      "[INFO 24-02-21 09:31:05.5822 UTC abstract_model.cc:1344] Engine \"RandomForestOptPred\" built\n",
      "[INFO 24-02-21 09:31:05.5823 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x78e76bf0e650>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tfdf.keras.RandomForestModel()\n",
    "model.fit(train_ds, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy without hyper-parameter tuning: 0.9046\n"
     ]
    }
   ],
   "source": [
    "model.compile([\"accuracy\"])\n",
    "test_accuracy = model.evaluate(train_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy without hyper-parameter tuning: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_decision_forests.component.tuner.tuner.SearchSpace at 0x78e764151010>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = tfdf.tuner.RandomSearch(num_trials=110)\n",
    "tuner.choice(\"min_examples\", [2, 5, 7, 10, 14, 21])\n",
    "tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
    "local_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\n",
    "local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8, 10, 12])\n",
    "global_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\n",
    "global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n",
    "tuner.choice(\"use_hessian_gain\", [True, False])\n",
    "tuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
    "tuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\n",
    "oblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\n",
    "oblique_space.choice(\"sparse_oblique_normalization\",\n",
    "                     [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\n",
    "oblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\n",
    "oblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp0pnh9t9n as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'Pclass': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'Age': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'Fare': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'People': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'Sex_female': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'Sex_male': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'Embarked_C': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>, 'Embarked_Q': <tf.Tensor 'data_7:0' shape=(None,) dtype=int64>, 'Embarked_S': <tf.Tensor 'data_8:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_9:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'Pclass': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Age': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Fare': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'People': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Sex_female': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'Sex_male': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'Embarked_C': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'Embarked_Q': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'Embarked_S': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>)}\n",
      "Training dataset read in 0:00:00.120736. Found 891 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-02-21 09:31:31.7283 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-21 09:31:31.7284 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-21 09:31:31.7284 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-21 09:31:31.8639 UTC kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-02-21 09:31:31.8639 UTC kernel.cc:772] Collect training examples\n",
      "[INFO 24-02-21 09:31:31.8639 UTC kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-02-21 09:31:31.8640 UTC kernel.cc:391] Number of batches: 1\n",
      "[INFO 24-02-21 09:31:31.8640 UTC kernel.cc:392] Number of examples: 891\n",
      "[INFO 24-02-21 09:31:31.8640 UTC kernel.cc:792] Training dataset:\n",
      "Number of records: 891\n",
      "Number of columns: 10\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 9 (90%)\n",
      "\tCATEGORICAL: 1 (10%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 9 (90%)\n",
      "\t0: \"Age\" NUMERICAL mean:28.567 min:0.42 max:80 sd:13.1922\n",
      "\t1: \"Embarked_C\" NUMERICAL mean:0.188552 min:0 max:1 sd:0.391152\n",
      "\t2: \"Embarked_Q\" NUMERICAL mean:0.0864198 min:0 max:1 sd:0.280983\n",
      "\t3: \"Embarked_S\" NUMERICAL mean:0.725028 min:0 max:1 sd:0.4465\n",
      "\t4: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n",
      "\t5: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n",
      "\t6: \"People\" NUMERICAL mean:1.9046 min:1 max:11 sd:1.61255\n",
      "\t7: \"Sex_female\" NUMERICAL mean:0.352413 min:0 max:1 sd:0.477722\n",
      "\t8: \"Sex_male\" NUMERICAL mean:0.647587 min:0 max:1 sd:0.477722\n",
      "\n",
      "CATEGORICAL: 1 (10%)\n",
      "\t9: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-02-21 09:31:31.8641 UTC kernel.cc:808] Configure learner\n",
      "[WARNING 24-02-21 09:31:31.8642 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-21 09:31:31.8642 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-21 09:31:31.8642 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-21 09:31:31.8642 UTC kernel.cc:822] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Embarked_C$\"\n",
      "features: \"^Embarked_Q$\"\n",
      "features: \"^Embarked_S$\"\n",
      "features: \"^Fare$\"\n",
      "features: \"^Pclass$\"\n",
      "features: \"^People$\"\n",
      "features: \"^Sex_female$\"\n",
      "features: \"^Sex_male$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "    features: \"^Age$\"\n",
      "    features: \"^Embarked_C$\"\n",
      "    features: \"^Embarked_Q$\"\n",
      "    features: \"^Embarked_S$\"\n",
      "    features: \"^Fare$\"\n",
      "    features: \"^Pclass$\"\n",
      "    features: \"^People$\"\n",
      "    features: \"^Sex_female$\"\n",
      "    features: \"^Sex_male$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: CLASSIFICATION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 6\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: -1\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      shrinkage: 0.1\n",
      "      loss: DEFAULT\n",
      "      validation_set_ratio: 0.1\n",
      "      validation_interval_in_trees: 1\n",
      "      early_stopping: VALIDATION_LOSS_INCREASE\n",
      "      early_stopping_num_trees_look_ahead: 30\n",
      "      l2_regularization: 0\n",
      "      lambda_loss: 1\n",
      "      mart {\n",
      "      }\n",
      "      adapt_subsample_for_maximum_training_duration: false\n",
      "      l1_regularization: 0\n",
      "      use_hessian_gain: false\n",
      "      l2_regularization_categorical: 1\n",
      "      stochastic_gradient_boosting {\n",
      "        ratio: 1\n",
      "      }\n",
      "      apply_link_function: true\n",
      "      compute_permutation_variable_importance: false\n",
      "      binary_focal_loss_options {\n",
      "        misprediction_exponent: 2\n",
      "        positive_sample_coefficient: 0.5\n",
      "      }\n",
      "      early_stopping_initial_iteration: 10\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 110\n",
      "    }\n",
      "  }\n",
      "  search_space {\n",
      "    fields {\n",
      "      name: \"min_examples\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: 2\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 5\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 7\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 10\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 14\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 21\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"categorical_algorithm\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"CART\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"RANDOM\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"growing_strategy\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"LOCAL\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"BEST_FIRST_GLOBAL\"\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"max_depth\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            integer: 3\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 4\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 5\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 6\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 8\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 10\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 12\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"LOCAL\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"max_num_nodes\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            integer: 16\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 32\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 64\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 128\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 256\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"BEST_FIRST_GLOBAL\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"use_hessian_gain\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"true\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"false\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"shrinkage\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          real: 0.02\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.05\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.1\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.15\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"num_candidate_attributes_ratio\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          real: 0.2\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.5\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.9\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"split_axis\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"AXIS_ALIGNED\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"SPARSE_OBLIQUE\"\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_normalization\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            categorical: \"NONE\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"STANDARD_DEVIATION\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"MIN_MAX\"\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_weights\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            categorical: \"BINARY\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"CONTINUOUS\"\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_num_projections_exponent\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            real: 1\n",
      "          }\n",
      "          possible_values {\n",
      "            real: 1.5\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-21 09:31:31.8645 UTC kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmp0pnh9t9n/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-02-21 09:31:31.8647 UTC kernel.cc:887] Train model\n",
      "[INFO 24-02-21 09:31:31.8648 UTC hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 2\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 7\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 14\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 21\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"LOCAL\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"BEST_FIRST_GLOBAL\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_depth\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 5\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 6\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 8\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 10\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 12\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"LOCAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_num_nodes\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 16\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 32\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 64\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 128\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 256\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"BEST_FIRST_GLOBAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"false\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.02\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.05\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.1\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.15\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.5\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.9\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_num_projections_exponent\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 1.5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-21 09:31:31.8649 UTC hyperparameters_optimizer.cc:500] Start local tuner with 16 thread(s)\n",
      "[INFO 24-02-21 09:31:31.8653 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:31.8653 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:31.8653 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:31.8653 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:31.8653 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:31.8653 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:31.8654 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:31.8654 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and [INFO[ 24-02-21 09:31:31.8654 UTC INFO9gradient_boosted_trees.cc feature(s). 24-02-21 09:31:31.8654 UTC gradient_boosted_trees.cc\n",
      "[INFO: 24-02-21 09:31:31.8654 UTC gradient_boosted_trees.cc:1261[591INFO] ]  24-02-21 09:31:31.8654 UTC gradient_boosted_trees.cc:1261] 818:818591] Default loss set to BINOMIAL_LOG_LIKELIHOODDefault loss set to  examples used for training and 73 examples used for validation\n",
      " examples used for training and 73 examples used for validation\n",
      "\n",
      "[INFOBINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-21 09:31:31.8654 UTC [[gradient_boosted_trees.ccINFO:INFO[INFO1218] Training gradient boosted tree on 891[[INFO[INFO 24-02-21 09:31:31.8655 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      " 24-02-21 09:31:31.8655 UTC gradient_boosted_trees.cc:591] Default loss set to INFOBINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-21 09:31:31.8655 UTC  example(s) and gradient_boosted_trees.cc9: feature(s).591] Default loss set to [\n",
      "INFO 24-02-21 09:31:31.8655 UTC  24-02-21 09:31:31.8655 UTC [gradient_boosted_trees.cc 24-02-21 09:31:31.8655 UTC INFOBINOMIAL_LOG_LIKELIHOODgradient_boosted_trees.cc: 24-02-21 09:31:31.8655 UTC gradient_boosted_trees.cc:\n",
      "591] gradient_boosted_trees.cc591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      ":[[591 24-02-21 09:31:31.8655 UTC gradient_boosted_trees.cc:Default loss set to BINOMIAL_LOG_LIKELIHOOD1218INFO] INFO 24-02-21 09:31:31.8655 UTC \n",
      "] Default loss set to BINOMIAL_LOG_LIKELIHOOD 24-02-21 09:31:31.8655 UTC \n",
      "gradient_boosted_trees.cc:1218Training gradient boosted tree on 891[:] Training gradient boosted tree on 891591[ example(s) and ] gradient_boosted_trees.ccDefault loss set to 9 feature(s).INFO example(s) and \n",
      "BINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-21 09:31:31.8656 UTC INFO[INFO 24-02-21 09:31:31.8656 UTC  24-02-21 09:31:31.8656 UTC [INFO 24-02-21 09:31:31.8656 UTC gradient_boosted_trees.cc9gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9gradient_boosted_trees.cc::1218] Training gradient boosted tree on 891 example(s) and :1218 feature(s).9 feature(s). feature(s).\n",
      "gradient_boosted_trees.cc\n",
      ":591] Default loss set to BINOMIAL_LOG_LIKELIHOOD[\n",
      "[] \n",
      "1218Training gradient boosted tree on 891 example(s) and INFO[INFO 24-02-21 09:31:31.8656 UTC gradient_boosted_trees.cc 24-02-21 09:31:31.8656 UTC 9gradient_boosted_trees.cc feature(s).] Training gradient boosted tree on 891 example(s) and 9\n",
      ":[INFO 24-02-21 09:31:31.8656 UTC INFO[ 24-02-21 09:31:31.8656 UTC 1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).gradient_boosted_trees.ccgradient_boosted_trees.ccINFO\n",
      ": 24-02-21 09:31:31.8657 UTC 591:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "] gradient_boosted_trees.cc:1261[] Default loss set to BINOMIAL_LOG_LIKELIHOOD818 examples used for training and 73 examples used for validation\n",
      "\n",
      "INFO[INFO 24-02-21 09:31:31.8657 UTC gradient_boosted_trees.cc:1218] [ 24-02-21 09:31:31.8657 UTC gradient_boosted_trees.ccTraining gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      ":1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFOINFO 24-02-21 09:31:31.8657 UTC gradient_boosted_trees.cc:1261] 818[ 24-02-21 09:31:31.8657 UTC  examples used for training and 73 examples used for validation\n",
      "gradient_boosted_trees.cc:INFO591] Default loss set to  24-02-21 09:31:31.8657 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and BINOMIAL_LOG_LIKELIHOOD\n",
      "73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.8657 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:31.8658 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.8658 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.8658 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.8658 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.8658 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[:1261] 818 examples used for training and 73[INFO examples used for validationINFO 24-02-21 09:31:31.8658 UTC  24-02-21 09:31:31.8658 UTC gradient_boosted_trees.cc:[1261] \n",
      "gradient_boosted_trees.ccINFO:1261]  24-02-21 09:31:31.8659 UTC 818 examples used for training and 73 examples used for validation\n",
      "gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.8659 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.8675 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284305 train-accuracy:0.612469 valid-loss:1.237372 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8677 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277369 train-accuracy:0.612469 valid-loss:1.239582 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8678 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.194743 train-accuracy:0.612469 valid-loss:1.158324 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8679 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315399 train-accuracy:0.612469 valid-loss:1.274949 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8679 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.170577 train-accuracy:0.612469 valid-loss:1.139671 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8681 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315816 train-accuracy:0.612469 valid-loss:1.273794 valid-accuracy:0.657534\n",
      "[INFO[INFO 24-02-21 09:31:31.8688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226758 train-accuracy:0.612469 valid-loss:1.193091 valid-accuracy:0.657534 24-02-21 09:31:31.8688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317194 train-accuracy:0.612469 valid-loss:1.275549 valid-accuracy:0.657534\n",
      "\n",
      "[INFO 24-02-21 09:31:31.8690 UTC gradient_boosted_trees.cc:1638] \tnum-trees:2 train-loss:1.225763 train-accuracy:0.612469 valid-loss:1.194371 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8695 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188267 train-accuracy:0.612469 valid-loss:1.149208 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8699 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243181 train-accuracy:0.612469 valid-loss:1.193485 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8700 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186980 train-accuracy:0.612469 valid-loss:1.152059 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8705 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240929 train-accuracy:0.612469 valid-loss:1.200175 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8708 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236005 train-accuracy:0.612469 valid-loss:1.200544 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8709 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226463 train-accuracy:0.612469 valid-loss:1.199126 valid-accuracy:0.657534\n",
      " feature(s).\n",
      "[INFO 24-02-21 09:31:31.8716 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.8734 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274205 train-accuracy:0.612469 valid-loss:1.241348 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.8746 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.212196 train-accuracy:0.612469 valid-loss:1.164358 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.9625 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597399\n",
      "[INFO 24-02-21 09:31:31.9626 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-21 09:31:31.9627 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.597399 valid-accuracy:0.904110\n",
      "[INFO 24-02-21 09:31:31.9634 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:31.9634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:31.9636 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.9647 UTC hyperparameters_optimizer.cc:582] [1/110] Score: -0.597399 / -0.597399 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-21 09:31:31.9659 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285802 train-accuracy:0.612469 valid-loss:1.245914 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:31.9826 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63361\n",
      "[INFO 24-02-21 09:31:31.9826 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-21 09:31:31.9829 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.633610 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:31.9836 UTC hyperparameters_optimizer.cc:582] [2/110] Score: -0.63361 / -0.597399 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-21 09:31:31.9846 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:31.9846 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:31.9848 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:31.9895 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.181472 train-accuracy:0.612469 valid-loss:1.141212 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.0362 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615036\n",
      "[INFO 24-02-21 09:31:32.0363 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.0370 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.615036 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:32.0378 UTC hyperparameters_optimizer.cc:582] [3/110] Score: -0.615036 / -0.597399 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-21 09:31:32.0389 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.0389 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.0391 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.0516 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.163251 train-accuracy:0.612469 valid-loss:1.141431 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.1631 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.616001\n",
      "[INFO 24-02-21 09:31:32.1631 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.1634 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.616001 valid-accuracy:0.904110\n",
      "[INFO 24-02-21 09:31:32.1637 UTC hyperparameters_optimizer.cc:582] [4/110] Score: -0.616001 / -0.597399 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.1681 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.1681 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.1683 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.1755 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61741\n",
      "[INFO 24-02-21 09:31:32.1756 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.1758 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.617410 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:32.1762 UTC hyperparameters_optimizer.cc:582] [5/110] Score: -0.61741 / -0.597399 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.1771 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.1771 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.1773 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.1788 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311915 train-accuracy:0.612469 valid-loss:1.273096 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.1886 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304683 train-accuracy:0.612469 valid-loss:1.273255 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.1958 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.575302\n",
      "[INFO 24-02-21 09:31:32.1959 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.1962 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.575302 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:32.1975 UTC hyperparameters_optimizer.cc:582] [6/110] Score: -0.575302 / -0.575302 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.1977 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.1980 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.1985 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.1997 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649223\n",
      "[INFO 24-02-21 09:31:32.1997 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.1998 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.649223 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.2000 UTC hyperparameters_optimizer.cc:582] [7/110] Score: -0.649223 / -0.575302 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.2003 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.2003 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.2005 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.2038 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177001 train-accuracy:0.612469 valid-loss:1.149981 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.2057 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232946 train-accuracy:0.612469 valid-loss:1.194721 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.2068 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640501\n",
      "[INFO 24-02-21 09:31:32.2068 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.2070 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.640501 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:32.2072 UTC hyperparameters_optimizer.cc:582] [8/110] Score: -0.640501 / -0.575302 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.2076 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.2076 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.2078 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.2086 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317307 train-accuracy:0.612469 valid-loss:1.276090 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.2593 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632296\n",
      "[INFO 24-02-21 09:31:32.2593 UTC gradient_boosted_trees.cc:271] Truncates the model to 113 tree(s) i.e. 113  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.2595 UTC gradient_boosted_trees.cc:334] Final model num-trees:113 valid-loss:0.632296 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:32.2602 UTC hyperparameters_optimizer.cc:582] [9/110] Score: -0.632296 / -0.575302 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.2616 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.2618 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.2623 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.2691 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.189766 train-accuracy:0.612469 valid-loss:1.141103 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.2806 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593443\n",
      "[INFO 24-02-21 09:31:32.2806 UTC gradient_boosted_trees.cc:271] Truncates the model to 174 tree(s) i.e. 174  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.2808 UTC gradient_boosted_trees.cc:334] Final model num-trees:174 valid-loss:0.593443 valid-accuracy:0.904110\n",
      "[INFO 24-02-21 09:31:32.2853 UTC hyperparameters_optimizer.cc:582] [10/110] Score: -0.593443 / -0.575302 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.2875 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.2875 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.2878 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.2887 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225315 train-accuracy:0.612469 valid-loss:1.190978 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.2888 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622671\n",
      "[INFO 24-02-21 09:31:32.2888 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.2889 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.622671 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.2892 UTC hyperparameters_optimizer.cc:582] [11/110] Score: -0.622671 / -0.575302 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.2899 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.2899 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.2901 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.2935 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.204425 train-accuracy:0.612469 valid-loss:1.186956 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.3165 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.555223\n",
      "[INFO 24-02-21 09:31:32.3165 UTC gradient_boosted_trees.cc:271] Truncates the model to 84 tree(s) i.e. 84  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.3166 UTC gradient_boosted_trees.cc:334] Final model num-trees:84 valid-loss:0.555223 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.3173 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.3173 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.3175 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.3190 UTC hyperparameters_optimizer.cc:582] [12/110] Score: -0.555223 / -0.555223 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.3221 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314188 train-accuracy:0.612469 valid-loss:1.273623 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.3854 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.596788\n",
      "[INFO 24-02-21 09:31:32.3854 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.3855 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.596788 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:32.3858 UTC hyperparameters_optimizer.cc:582] [13/110] Score: -0.596788 / -0.555223 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-21 09:31:32.3863 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.3863 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.3866 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.3881 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240699 train-accuracy:0.612469 valid-loss:1.201525 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.4207 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588391\n",
      "[INFO 24-02-21 09:31:32.4208 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.4209 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.588391 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.4213 UTC hyperparameters_optimizer.cc:582] [14/110] Score: -0.588391 / -0.555223 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.4219 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.4219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.4221 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.4255 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316350 train-accuracy:0.612469 valid-loss:1.276657 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.4677 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615455\n",
      "[INFO 24-02-21 09:31:32.4678 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.4678 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.615455 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.4682 UTC hyperparameters_optimizer.cc:582] [15/110] Score: -0.615455 / -0.555223 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.4686 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.4686 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.4689 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.4707 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.511879\n",
      "[INFO 24-02-21 09:31:32.4707 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.4709 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.511879 valid-accuracy:0.904110\n",
      "[INFO 24-02-21 09:31:32.4711 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287172 train-accuracy:0.612469 valid-loss:1.250164 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.4721 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.4721 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.4723 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.4751 UTC hyperparameters_optimizer.cc:582] [16/110] Score: -0.511879 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.4821 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312604 train-accuracy:0.612469 valid-loss:1.273894 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.4857 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.598598\n",
      "[INFO 24-02-21 09:31:32.4857 UTC gradient_boosted_trees.cc:271] Truncates the model to 247 tree(s) i.e. 247  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.4857 UTC gradient_boosted_trees.cc:334] Final model num-trees:247 valid-loss:0.598598 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.4860 UTC hyperparameters_optimizer.cc:582] [17/110] Score: -0.598598 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.4866 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.4866 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.4869 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.4892 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240259 train-accuracy:0.612469 valid-loss:1.200451 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.4963 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673177\n",
      "[INFO 24-02-21 09:31:32.4964 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.4971 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.673177 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:32.4981 UTC hyperparameters_optimizer.cc:582] [18/110] Score: -0.673177 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.5007 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.5007 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.5009 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.5043 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.267065 train-accuracy:0.612469 valid-loss:1.244269 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.5243 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650418\n",
      "[INFO 24-02-21 09:31:32.5243 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.5248 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.650418 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.5257 UTC hyperparameters_optimizer.cc:582] [19/110] Score: -0.650418 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.5271 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.5271 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.5272 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.5293 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.491973 train-accuracy:0.913203 valid-loss:0.602064 valid-accuracy:0.863014\n",
      "[INFO[INFO 24-02-21 09:31:32.5294 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.489406 train-accuracy:0.908313 valid-loss:0.622513 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.5294 UTC gradient_boosted_trees.cc:271] Truncates the model to 283 tree(s) i.e. 283  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.5294 UTC gradient_boosted_trees.cc:334] Final model num-trees:283 valid-loss:0.619180 valid-accuracy:0.863014\n",
      " 24-02-21 09:31:32.5293 UTC gradient_boosted_trees.cc:271] Truncates the model to 291 tree(s) i.e. 291  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.5303 UTC gradient_boosted_trees.cc:334] Final model num-trees:291 valid-loss:0.601437 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.5310 UTC hyperparameters_optimizer.cc:582] [20/110] Score: -0.61918 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.5317 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.5317 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.5321 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.5321 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.5323 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.5337 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275224 train-accuracy:0.612469 valid-loss:1.233402 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.5338 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.5347 UTC hyperparameters_optimizer.cc:582] [21/110] Score: -0.601437 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.5383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641731\n",
      "[INFO 24-02-21 09:31:32.5384 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.5385 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.641731 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:32.5389 UTC hyperparameters_optimizer.cc:582] [22/110] Score: -0.641731 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.5397 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.5397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.5399 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.5399 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285364 train-accuracy:0.612469 valid-loss:1.243724 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.5409 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315038 train-accuracy:0.612469 valid-loss:1.275353 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.5419 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283260 train-accuracy:0.612469 valid-loss:1.237579 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.5535 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.636208 train-accuracy:0.889976 valid-loss:0.632515 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:32.5535 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.5535 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.632515 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:32.5543 UTC hyperparameters_optimizer.cc:582] [23/110] Score: -0.632515 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.5545 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.5545 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.5547 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.5600 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.200526 train-accuracy:0.612469 valid-loss:1.154498 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.5942 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640183\n",
      "[INFO 24-02-21 09:31:32.5943 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.5955 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.640183 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.5970 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.5971 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.5973 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.5980 UTC hyperparameters_optimizer.cc:582] [24/110] Score: -0.640183 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.6002 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315471 train-accuracy:0.612469 valid-loss:1.274448 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.6542 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.610891\n",
      "[INFO 24-02-21 09:31:32.6542 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.6543 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.610891 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:32.6552 UTC hyperparameters_optimizer.cc:582] [25/110] Score: -0.610891 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.6558 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.6558 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.6561 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.6587 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223597 train-accuracy:0.612469 valid-loss:1.179838 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.6809 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.646031 train-accuracy:0.883863 valid-loss:0.621561 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.6810 UTC gradient_boosted_trees.cc:271] Truncates the model to 291 tree(s) i.e. 291  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.6810 UTC gradient_boosted_trees.cc:334] Final model num-trees:291 valid-loss:0.620361 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.6815 UTC hyperparameters_optimizer.cc:582] [26/110] Score: -0.620361 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.6828 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.6828 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.6830 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.6878 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315628 train-accuracy:0.612469 valid-loss:1.274406 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.7152 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626619\n",
      "[INFO 24-02-21 09:31:32.7152 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.7156 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.626619 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.7167 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.7167 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.7169 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.7177 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225315 train-accuracy:0.612469 valid-loss:1.185643 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.7215 UTC hyperparameters_optimizer.cc:582] [27/110] Score: -0.626619 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:32.7581 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621684\n",
      "[INFO 24-02-21 09:31:32.7582 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.7584 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.621684 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:32.7590 UTC hyperparameters_optimizer.cc:582] [28/110] Score: -0.621684 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.7601 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.7603 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.7608 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.7644 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221966 train-accuracy:0.612469 valid-loss:1.194927 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.8390 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643637\n",
      "[INFO 24-02-21 09:31:32.8390 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.8393 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.643637 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:32.8401 UTC hyperparameters_optimizer.cc:582] [29/110] Score: -0.643637 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.8403 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624303\n",
      "[INFO 24-02-21 09:31:32.8403 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.8404 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.624303 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:32.8412 UTC hyperparameters_optimizer.cc:582] [30/110] Score: -0.624303 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.8422 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.8422 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.8422 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.8422 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-21 09:31:32.8425 UTC gradient_boosted_trees.cc:1261] INFO818 24-02-21 09:31:32.8425 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      " examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.8449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313055 train-accuracy:0.612469 valid-loss:1.272387 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.8499 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65689\n",
      "[INFO 24-02-21 09:31:32.8499 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.8506 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.656890 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:32.8528 UTC hyperparameters_optimizer.cc:582] [31/110] Score: -0.65689 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.8541 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.8541 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.8557 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.8577 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294975 train-accuracy:0.612469 valid-loss:1.251589 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.8587 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.189835 train-accuracy:0.612469 valid-loss:1.149147 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.8595 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597298\n",
      "[INFO 24-02-21 09:31:32.8596 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.8597 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.597298 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:32.8598 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.560586\n",
      "[INFO 24-02-21 09:31:32.8598 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.8599 UTC hyperparameters_optimizer.cc:582] [32/110] Score: -0.597298 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.8599 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.560586 valid-accuracy:0.904110\n",
      "[INFO 24-02-21 09:31:32.8603 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.8603 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.8604 UTC hyperparameters_optimizer.cc:582] [33/110] Score: [-0.560586 / -0.511879 HParams: INFO 24-02-21 09:31:32.8604 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }[\n",
      "INFO 24-02-21 09:31:32.8606 UTC gradient_boosted_trees.cc[INFO 24-02-21 09:31:32.8606 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      ":1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.8609 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.8642 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245524 train-accuracy:0.612469 valid-loss:1.211040 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.8673 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.197776 train-accuracy:0.612469 valid-loss:1.156599 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:32.9839 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621127\n",
      "[INFO 24-02-21 09:31:32.9839 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-21 09:31:32.9842 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.621127 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:32.9850 UTC hyperparameters_optimizer.cc:582] [34/110] Score: -0.621127 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:32.9869 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:32.9869 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:32.9872 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:32.9902 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283905 train-accuracy:0.612469 valid-loss:1.245479 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.1336 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.502060 train-accuracy:0.910758 valid-loss:0.593983 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.1336 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.1336 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.593831 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.1351 UTC hyperparameters_optimizer.cc:582] [35/110] Score: -0.593831 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.1380 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.1380 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.1383 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.1439 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661942\n",
      "[INFO 24-02-21 09:31:33.1439 UTC gradient_boosted_trees.cc:271] Truncates the model to 189 tree(s) i.e. 189  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.1441 UTC gradient_boosted_trees.cc:334] Final model num-trees:189 valid-loss:0.661942 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.1449 UTC [INFO 24-02-21 09:31:33.1450 UTC hyperparameters_optimizer.cc:582] [36/110] Score: -0.661942 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177878 train-accuracy:0.612469 valid-loss:1.139203 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.1469 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.1469 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.1478 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.1563 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.216355 train-accuracy:0.612469 valid-loss:1.197360 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.1814 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636488\n",
      "[INFO 24-02-21 09:31:33.1815 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.1817 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.636488 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.1824 UTC hyperparameters_optimizer.cc:582] [37/110] Score: -0.636488 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.1837 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.1837 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.1840 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.1957 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.154426 train-accuracy:0.612469 valid-loss:1.145362 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.2130 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642812\n",
      "[INFO 24-02-21 09:31:33.2130 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.2135 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.642812 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.2147 UTC hyperparameters_optimizer.cc:582] [38/110] Score: -0.642812 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.2156 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.2156 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.2168 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.2222 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.174968 train-accuracy:0.612469 valid-loss:1.149178 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.2822 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640006\n",
      "[INFO 24-02-21 09:31:33.2822 UTC gradient_boosted_trees.cc:271] Truncates the model to 152 tree(s) i.e. 152  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.2825 UTC gradient_boosted_trees.cc:334] Final model num-trees:152 valid-loss:0.640006 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:33.2840 UTC hyperparameters_optimizer.cc:582] [39/110] Score: -0.640006 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.2844 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.2844 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.2844 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665798\n",
      "[INFO 24-02-21 09:31:33.2845 UTC gradient_boosted_trees.cc:271] Truncates the model to 211 tree(s) i.e. 211  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.2845 UTC gradient_boosted_trees.cc:334] Final model num-trees:211 valid-loss:0.665798 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.2846 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.2849 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.2850 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.2852 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.2886 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313121 train-accuracy:0.612469 valid-loss:1.272374 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.2914 UTC hyperparameters_optimizer.cc:582] [40/110] Score: -0.665798 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.2916 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312031 train-accuracy:0.612469 valid-loss:1.273948 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.2956 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653964\n",
      "[INFO 24-02-21 09:31:33.2956 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.2960 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.653964 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.2964 UTC hyperparameters_optimizer.cc:582] [41/110] Score: -0.653964 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.2971 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.2973 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.2977 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.3017 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287825 train-accuracy:0.612469 valid-loss:1.245016 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.3238 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629204\n",
      "[INFO 24-02-21 09:31:33.3238 UTC gradient_boosted_trees.cc:271] Truncates the model to 90 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.3239 UTC gradient_boosted_trees.cc:334] Final model num-trees:90 valid-loss:0.629204 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.3242 UTC hyperparameters_optimizer.cc:582] [42/110] Score: -0.629204 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.3244 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.3244 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.3249 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.3258 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.208598 train-accuracy:0.612469 valid-loss:1.168114 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.3800 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686709\n",
      "[INFO 24-02-21 09:31:33.3801 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.3801 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.686709 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.3802 UTC hyperparameters_optimizer.cc:582] [43/110] Score: -0.686709 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.3806 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.3806 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.3808 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-21 09:31:33.3864 UTC early_stopping.cc: 24-02-21 09:31:33.3864 UTC 53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233837 train-accuracy:0.612469 valid-loss:1.192736 valid-accuracy:0.657534\n",
      "0.581133\n",
      "[INFO 24-02-21 09:31:33.3864 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.3873 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.581133 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.3878 UTC hyperparameters_optimizer.cc:582] [44/110] Score: -0.581133 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.3884 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.3884 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.3886 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.3925 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284636 train-accuracy:0.612469 valid-loss:1.241099 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.4386 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603145\n",
      "[INFO 24-02-21 09:31:33.4386 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.4395 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.603145 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:33.4405 UTC hyperparameters_optimizer.cc:582] [45/110] Score: -0.603145 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.4441 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.4441 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.4443 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.4472 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278827 train-accuracy:0.612469 valid-loss:1.237987 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.4822 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653012\n",
      "[INFO 24-02-21 09:31:33.4822 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.4824 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.653012 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.4830 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.4830 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.4832 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.4847 UTC hyperparameters_optimizer.cc:582] [46/110] Score: -0.653012 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.4857 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184306 train-accuracy:0.612469 valid-loss:1.155036 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.5677 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.602047\n",
      "[INFO 24-02-21 09:31:33.5678 UTC gradient_boosted_trees.cc:271] Truncates the model to 161 tree(s) i.e. 161  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.5679 UTC gradient_boosted_trees.cc:334] Final model num-trees:161 valid-loss:0.602047 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.5686 UTC hyperparameters_optimizer.cc:582] [47/110] Score: -0.602047 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-21 09:31:33.5689 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63716\n",
      "[INFO 24-02-21 09:31:33.5689 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.5693 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.637160 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:33.5706 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.5707 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.5708 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.5717 UTC hyperparameters_optimizer.cc:582] [48/110] Score: -0.63716 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.5728 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313203 train-accuracy:0.612469 valid-loss:1.271798 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.5771 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.5771 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.5774 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.5792 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.318897 train-accuracy:0.612469 valid-loss:1.276344 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.6288 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.610887\n",
      "[INFO 24-02-21 09:31:33.6288 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.6291 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.610887 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:33.6299 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.6299 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.6301 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.6307 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225315 train-accuracy:0.612469 valid-loss:1.190978 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.6313 UTC hyperparameters_optimizer.cc:582] [49/110] Score: -0.610887 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.6909 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646619\n",
      "[INFO 24-02-21 09:31:33.6909 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.6914 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.646619 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:33.6935 UTC hyperparameters_optimizer.cc:582] [50/110] Score: -0.646619 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.6977 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.6977 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.6979 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.7025 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.199619 train-accuracy:0.612469 valid-loss:1.158496 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.7303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601467\n",
      "[INFO 24-02-21 09:31:33.7304 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.7305 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.601467 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.7318 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.7318 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.7321 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.7344 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224927 train-accuracy:0.612469 valid-loss:1.178658 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.7349 UTC hyperparameters_optimizer.cc:582] [51/110] Score: -0.601467 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.7464 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649389\n",
      "[INFO 24-02-21 09:31:33.7465 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.7470 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.649389 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:33.7472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603652\n",
      "[INFO 24-02-21 09:31:33.7472 UTC gradient_boosted_trees.cc:271] Truncates the model to 150 tree(s) i.e. 150  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.7473 UTC gradient_boosted_trees.cc:334] Final model num-trees:150 valid-loss:0.603652 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.7475 UTC hyperparameters_optimizer.cc:582] [52/110] Score: -0.603652 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.7476 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.7476 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.7479 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.7487 UTC [INFO 24-02-21 09:31:33.7487 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319558 train-accuracy:0.612469 valid-loss:1.279173 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.7514 UTC hyperparameters_optimizer.cc:582] [53/110] Score: -0.649389 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.7547 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.7555 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.7585 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275804 train-accuracy:0.612469 valid-loss:1.243060 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.7670 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667977\n",
      "[INFO 24-02-21 09:31:33.7671 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.7675 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.667977 valid-accuracy:0.835616\n",
      "[INFO 24-02-21 09:31:33.7680 UTC hyperparameters_optimizer.cc:582] [54/110] Score: -0.667977 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.7692 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.7692 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.7694 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.7759 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201277 train-accuracy:0.612469 valid-loss:1.166036 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.8691 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669982\n",
      "[INFO 24-02-21 09:31:33.8691 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.8693 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.669982 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.8702 UTC hyperparameters_optimizer.cc:582] [55/110] Score: -0.669982 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.8718 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.8718 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.8734 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.8835 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282797 train-accuracy:0.612469 valid-loss:1.248504 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.8983 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.442914 train-accuracy:0.920538 valid-loss:0.639183 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.8989 UTC gradient_boosted_trees.cc:271] Truncates the model to 292 tree(s) i.e. 292  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.8989 UTC gradient_boosted_trees.cc:334] Final model num-trees:292 valid-loss:0.636577 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:33.9004 UTC hyperparameters_optimizer.cc:582] [56/110] Score: -0.636577 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.9008 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.9009 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.9038 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.9070 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239956 train-accuracy:0.612469 valid-loss:1.199431 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.9246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663316\n",
      "[INFO 24-02-21 09:31:33.9246 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.9249 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.663316 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.9263 UTC hyperparameters_optimizer.cc:582] [57/110] Score: -0.663316 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.9267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.9267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.9269 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.9304 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.604757\n",
      "[INFO 24-02-21 09:31:33.9306 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.9308 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282842 train-accuracy:0.612469 valid-loss:1.243411 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.9309 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.604757 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:33.9312 UTC hyperparameters_optimizer.cc:582] [58/110] Score: -0.604757 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-21 09:31:33.9320 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.9322 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.9326 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.9337 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248502 train-accuracy:0.612469 valid-loss:1.207848 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.9692 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652525\n",
      "[INFO 24-02-21 09:31:33.9692 UTC gradient_boosted_trees.cc:271] Truncates the model to 80 tree(s) i.e. 80  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.9692 UTC gradient_boosted_trees.cc:334] Final model num-trees:80 valid-loss:0.652525 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:33.9696 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.9696 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.9699 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.9705 UTC hyperparameters_optimizer.cc:582] [59/110] Score: -0.652525 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:33.9798 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.746007 train-accuracy:0.856968 valid-loss:0.679974 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.9799 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-21 09:31:33.9799 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.679383 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:33.9802 UTC hyperparameters_optimizer.cc:582] [60/110] Score: -0.679383 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:33.9805 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310754 train-accuracy:0.612469 valid-loss:1.271414 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:33.9810 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:33.9810 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:33.9812 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:33.9880 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281616 train-accuracy:0.612469 valid-loss:1.240691 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.0076 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.591689\n",
      "[INFO 24-02-21 09:31:34.0077 UTC gradient_boosted_trees.cc:271] Truncates the model to 201 tree(s) i.e. 201  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.0079 UTC gradient_boosted_trees.cc:334] Final model num-trees:201 valid-loss:0.591689 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:34.0099 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.0099 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.0100 UTC hyperparameters_optimizer.cc:582] [61/110] Score: -0.591689 / -0.511879 HParams: [INFO 24-02-21 09:31:34.0101 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.0152 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315493 train-accuracy:0.612469 valid-loss:1.272668 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.0296 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643378\n",
      "[INFO 24-02-21 09:31:34.0296 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.0298 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.643378 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.0309 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.0309 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.0311 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.0317 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319330 train-accuracy:0.612469 valid-loss:1.278009 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.0347 UTC hyperparameters_optimizer.cc:582] [62/110] Score: -0.643378 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.0544 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645897\n",
      "[INFO 24-02-21 09:31:34.0544 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.0545 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.645897 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.0554 UTC hyperparameters_optimizer.cc:582] [63/110] Score: -0.645897 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.0561 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.0561 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.0563 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.0634 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284075 train-accuracy:0.612469 valid-loss:1.243870 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.1261 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625377\n",
      "[INFO 24-02-21 09:31:34.1261 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.1264 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.625377 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.1279 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.724232\n",
      "[INFO 24-02-21 09:31:34.1279 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.1293 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.724232 valid-accuracy:0.835616\n",
      "[INFO 24-02-21 09:31:34.1296 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.1297 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.1299 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.1300 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.553566\n",
      "[INFO 24-02-21 09:31:34.1300 UTC gradient_boosted_trees.cc:271] Truncates the model to 173 tree(s) i.e. 173  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.1301 UTC gradient_boosted_trees.cc:334] Final model num-trees:173 valid-loss:0.553566 valid-accuracy:0.917808\n",
      "[INFO 24-02-21 09:31:34.1311 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.1313 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.1314 UTC hyperparameters_optimizer.cc:582] [64/110] Score: -0.625377 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.1334 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.1347 UTC hyperparameters_optimizer.cc:582] [65/110] Score: -0.553566 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[[INFO 24-02-21 09:31:34.1373 UTC hyperparameters_optimizer.cc:582] [66/110] Score: -0.724232 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-21 09:31:34.1375 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282317 train-accuracy:0.612469 valid-loss:1.245270 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.1382 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314628 train-accuracy:0.612469 valid-loss:1.274074 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.1394 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.1394 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.1407 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.1457 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.450448 train-accuracy:0.916870 valid-loss:0.597053 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.1457 UTC gradient_boosted_trees.cc:271] Truncates the model to 297 tree(s) i.e. 297  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.1457 UTC gradient_boosted_trees.cc:334] Final model num-trees:297 valid-loss:0.596600 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.1458 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229968 train-accuracy:0.612469 valid-loss:1.191723 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.1489 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.1489 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.1490 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.1497 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647109\n",
      "[INFO 24-02-21 09:31:34.1498 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.1501 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.647109 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.1514 UTC hyperparameters_optimizer.cc:582] [67/110] Score: -0.5966 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.1515 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291655 train-accuracy:0.612469 valid-loss:1.249362 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.1519 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.1519 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.1521 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.1533 UTC hyperparameters_optimizer.cc:582] [68/110] Score: -0.647109 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.1589 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241093 train-accuracy:0.612469 valid-loss:1.199930 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.1694 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.585981\n",
      "[INFO 24-02-21 09:31:34.1695 UTC gradient_boosted_trees.cc:271] Truncates the model to 242 tree(s) i.e. 242  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.1696 UTC gradient_boosted_trees.cc:334] Final model num-trees:242 valid-loss:0.585981 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:34.1750 UTC hyperparameters_optimizer.cc:582] [69/110] Score: -0.585981 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.1755 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.1755 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.1770 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.1776 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.695188 train-accuracy:0.853301 valid-loss:0.682317 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.1776 UTC gradient_boosted_trees.cc:271] Truncates the model to 284 tree(s) i.e. 284  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.1776 UTC gradient_boosted_trees.cc:334] Final model num-trees:284 valid-loss:0.679649 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.1784 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.1784 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.1786 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.1790 UTC hyperparameters_optimizer.cc:582] [70/110] Score: -0.679649 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.1827 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.192897 train-accuracy:0.612469 valid-loss:1.149227 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.1913 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191019 train-accuracy:0.612469 valid-loss:1.161376 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.2095 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627266\n",
      "[INFO 24-02-21 09:31:34.2095 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.2098 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.627266 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:34.2107 UTC hyperparameters_optimizer.cc:582] [71/110] Score: -0.627266 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.2117 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.2117 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.2127 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.2144 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314633 train-accuracy:0.612469 valid-loss:1.273187 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.2568 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639127\n",
      "[INFO 24-02-21 09:31:34.2568 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.2570 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.639127 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.2576 UTC hyperparameters_optimizer.cc:582] [72/110] Score: -0.639127 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.2580 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.2580 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.2583 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.2600 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284261 train-accuracy:0.612469 valid-loss:1.237810 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.2900 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.725110 train-accuracy:0.847188 valid-loss:0.678996 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.2900 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.2900 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.678933 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.2904 UTC hyperparameters_optimizer.cc:582] [73/110] Score: -0.678933 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.2909 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.2909 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.2912 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.2931 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288744 train-accuracy:0.612469 valid-loss:1.248856 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.4088 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.525166 train-accuracy:0.903423 valid-loss:0.620403 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:34.4089 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.4089 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.620135 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:34.4099 UTC hyperparameters_optimizer.cc:582] [74/110] Score: -0.620135 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.4105 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.4105 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.4115 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.4129 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286798 train-accuracy:0.612469 valid-loss:1.242013 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.4259 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.532555\n",
      "[INFO 24-02-21 09:31:34.4260 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.4261 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.532555 valid-accuracy:0.904110\n",
      "[INFO 24-02-21 09:31:34.4280 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.4281 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.4283 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.4292 UTC hyperparameters_optimizer.cc:582] [75/110] Score: -0.532555 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.4314 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315485 train-accuracy:0.612469 valid-loss:1.274016 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.4786 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639816\n",
      "[INFO 24-02-21 09:31:34.4786 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.4788 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.639816 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.4792 UTC hyperparameters_optimizer.cc:582] [76/110] Score: -0.639816 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.4798 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.4798 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.4800 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.4823 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.185972 train-accuracy:0.612469 valid-loss:1.149275 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.5366 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617097\n",
      "[INFO 24-02-21 09:31:34.5367 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.5369 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.617097 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:34.5375 UTC hyperparameters_optimizer.cc:582] [77/110] Score: -0.617097 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.5414 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.5414 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.5418 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.5558 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.175158 train-accuracy:0.612469 valid-loss:1.145435 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.5565 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650035\n",
      "[INFO 24-02-21 09:31:34.5567 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.5568 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.650035 valid-accuracy:0.835616\n",
      "[INFO 24-02-21 09:31:34.5574 UTC hyperparameters_optimizer.cc:582] [78/110] Score: -0.650035 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.5580 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.5580 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.5582 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.5606 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226498 train-accuracy:0.612469 valid-loss:1.197031 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.5730 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636887\n",
      "[INFO 24-02-21 09:31:34.5730 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.5732 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.636887 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:34.5735 UTC hyperparameters_optimizer.cc:582] [79/110] Score: -0.636887 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.5742 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.5743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.5745 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.5763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245307 train-accuracy:0.612469 valid-loss:1.199261 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.5786 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644691\n",
      "[INFO 24-02-21 09:31:34.5786 UTC gradient_boosted_trees.cc:271] Truncates the model to 183 tree(s) i.e. 183  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.5788 UTC gradient_boosted_trees.cc:334] Final model num-trees:183 valid-loss:0.644691 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:34.5800 UTC hyperparameters_optimizer.cc:582] [80/110] Score: -0.644691 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.5801 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.5801 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.5811 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.5821 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317169 train-accuracy:0.612469 valid-loss:1.275751 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.5866 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.551145\n",
      "[INFO 24-02-21 09:31:34.5867 UTC gradient_boosted_trees.cc:271] Truncates the model to 173 tree(s) i.e. 173  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.5868 UTC gradient_boosted_trees.cc:334] Final model num-trees:173 valid-loss:0.551145 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:34.5886 UTC hyperparameters_optimizer.cc:582] [81/110] Score: -0.551145 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.5908 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.5908 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.5911 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.5956 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313810 train-accuracy:0.612469 valid-loss:1.272335 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.6065 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63372\n",
      "[INFO 24-02-21 09:31:34.6065 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.6068 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.633720 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.6078 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.6078 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.6081 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.6106 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315167 train-accuracy:0.612469 valid-loss:1.275631 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.6115 UTC hyperparameters_optimizer.cc:582] [82/110] Score: -0.63372 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.6449 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.586474\n",
      "[INFO 24-02-21 09:31:34.6449 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.6451 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.586474 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:34.6462 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.6462 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.6463 UTC hyperparameters_optimizer.cc:582] [83/110] Score: -0.586474 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.6475 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.6485 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319558 train-accuracy:0.612469 valid-loss:1.279173 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.6904 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.587314\n",
      "[INFO 24-02-21 09:31:34.6904 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.6906 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.587314 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:34.6913 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.6913 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.6947 UTC hyperparameters_optimizer.cc:582] [84/110] Score: -0.587314 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.6949 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.6964 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315644 train-accuracy:0.612469 valid-loss:1.272826 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.7534 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614419\n",
      "[INFO 24-02-21 09:31:34.7535 UTC gradient_boosted_trees.cc:271] Truncates the model to 168 tree(s) i.e. 168  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.7536 UTC gradient_boosted_trees.cc:334] Final model num-trees:168 valid-loss:0.614419 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:34.7549 UTC hyperparameters_optimizer.cc:582] [85/110] Score: -0.614419 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.7565 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.7565 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.7567 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.7618 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315557 train-accuracy:0.612469 valid-loss:1.273848 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.7898 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.59394\n",
      "[INFO 24-02-21 09:31:34.7899 UTC gradient_boosted_trees.cc:271] Truncates the model to 140 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.7901 UTC gradient_boosted_trees.cc:334] Final model num-trees:140 valid-loss:0.593940 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:34.7916 UTC hyperparameters_optimizer.cc:582] [86/110] Score: -0.59394 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.7948 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635216\n",
      "[INFO 24-02-21 09:31:34.7948 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO[INFO 24-02-21 09:31:34.7950 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.7951 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      " 24-02-21 09:31:34.7950 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.635216 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.7953 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.7961 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.7961 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.7963 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.7971 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201032 train-accuracy:0.612469 valid-loss:1.161634 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.7980 UTC hyperparameters_optimizer.cc:582] [87/110] Score: -0.635216 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.8038 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238652 train-accuracy:0.612469 valid-loss:1.194888 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.8472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666699\n",
      "[INFO 24-02-21 09:31:34.8472 UTC gradient_boosted_trees.cc:271] Truncates the model to 247 tree(s) i.e. 247  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.8473 UTC gradient_boosted_trees.cc:334] Final model num-trees:247 valid-loss:0.666699 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.8478 UTC hyperparameters_optimizer.cc:582] [88/110] Score: -0.666699 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.8483 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.8483 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.8488 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.8557 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226227 train-accuracy:0.612469 valid-loss:1.199288 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.8625 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.733831 train-accuracy:0.852078 valid-loss:0.691377 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.8631 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.8631 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.691082 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:34.8634 UTC hyperparameters_optimizer.cc:582] [89/110] Score: -0.691082 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:34.8638 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.8638 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.8641 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.8660 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233784 train-accuracy:0.612469 valid-loss:1.187967 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:34.9106 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651667\n",
      "[INFO 24-02-21 09:31:34.9106 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-21 09:31:34.9111 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.651667 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:34.9114 UTC hyperparameters_optimizer.cc:582] [90/110] Score: -0.651667 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:34.9124 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:34.9127 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:34.9132 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:34.9272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236306 train-accuracy:0.612469 valid-loss:1.193419 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:35.0380 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588235\n",
      "[INFO 24-02-21 09:31:35.0381 UTC gradient_boosted_trees.cc:271] Truncates the model to 102 tree(s) i.e. 102  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.0382 UTC gradient_boosted_trees.cc:334] Final model num-trees:102 valid-loss:0.588235 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.0387 UTC hyperparameters_optimizer.cc:582] [91/110] Score: -0.588235 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:35.0395 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:35.0395 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:35.0398 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:35.0464 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314994 train-accuracy:0.612469 valid-loss:1.273585 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:35.0595 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.541473\n",
      "[INFO 24-02-21 09:31:35.0596 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.0600 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.541473 valid-accuracy:0.904110\n",
      "[INFO 24-02-21 09:31:35.0608 UTC hyperparameters_optimizer.cc:582] [92/110] Score: -0.541473 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:35.0621 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:35.0621 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:35.0624 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:35.0648 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282252 train-accuracy:0.612469 valid-loss:1.235188 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:35.0755 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.486881 train-accuracy:0.914425 valid-loss:0.647843 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.0756 UTC gradient_boosted_trees.cc:271] Truncates the model to 284 tree(s) i.e. 284  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.0758 UTC gradient_boosted_trees.cc:334] Final model num-trees:284 valid-loss:0.642933 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.0775 UTC hyperparameters_optimizer.cc:582] [93/110] Score: -0.642933 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:35.0787 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.557290 train-accuracy:0.903423 valid-loss:0.603691 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.0787 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.0787 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.603638 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.0801 UTC hyperparameters_optimizer.cc:582] [94/110] Score: -0.603638 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:35.0807 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:35.0807 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:35.0810 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:35.0813 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.590453\n",
      "[INFO 24-02-21 09:31:35.0813 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.0814 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65122\n",
      "[INFO 24-02-21 09:31:35.0814 UTC gradient_boosted_trees.cc:271] Truncates the model to 100 tree(s) i.e. 100  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.0815 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.590453 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.0815 UTC gradient_boosted_trees.cc:334] Final model num-trees:100 valid-loss:0.651220 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:35.0817 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:31:35.0819 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:31:35.0821 UTC hyperparameters_optimizer.cc:582] [95/110] Score: -0.590453 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:35.0826 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:31:35.0828 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319075 train-accuracy:0.612469 valid-loss:1.277460 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:35.0860 UTC hyperparameters_optimizer.cc:582] [96/110] Score: -0.65122 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.0883 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314497 train-accuracy:0.612469 valid-loss:1.273761 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:31:35.1042 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.586526\n",
      "[INFO 24-02-21 09:31:35.1043 UTC gradient_boosted_trees.cc:271] Truncates the model to 100 tree(s) i.e. 100  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.1045 UTC gradient_boosted_trees.cc:334] Final model num-trees:100 valid-loss:0.586526 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:35.1070 UTC hyperparameters_optimizer.cc:582] [97/110] Score: -0.586526 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.1604 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.581113\n",
      "[INFO 24-02-21 09:31:35.1605 UTC gradient_boosted_trees.cc:271] Truncates the model to 210 tree(s) i.e. 210  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.1607 UTC gradient_boosted_trees.cc:334] Final model num-trees:210 valid-loss:0.581113 valid-accuracy:0.904110\n",
      "[INFO 24-02-21 09:31:35.1643 UTC hyperparameters_optimizer.cc:582] [98/110] Score: -0.581113 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.1715 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640531\n",
      "[INFO 24-02-21 09:31:35.1715 UTC gradient_boosted_trees.cc:271] Truncates the model to 204 tree(s) i.e. 204  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.1716 UTC gradient_boosted_trees.cc:334] Final model num-trees:204 valid-loss:0.640531 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.1731 UTC hyperparameters_optimizer.cc:582] [99/110] Score: -0.640531 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:35.2080 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649522\n",
      "[INFO 24-02-21 09:31:35.2080 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.2082 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.649522 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:35.2088 UTC hyperparameters_optimizer.cc:582] [100/110] Score: -0.649522 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.3002 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658538\n",
      "[INFO 24-02-21 09:31:35.3003 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.3004 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.658538 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:35.3012 UTC hyperparameters_optimizer.cc:582] [101/110] Score: -0.658538 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.3061 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658414\n",
      "[INFO 24-02-21 09:31:35.3061 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.3062 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.658414 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.3079 UTC hyperparameters_optimizer.cc:582] [102/110] Score: -0.658414 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.4418 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629076\n",
      "[INFO 24-02-21 09:31:35.4418 UTC gradient_boosted_trees.cc:271] Truncates the model to 191 tree(s) i.e. 191  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.4419 UTC gradient_boosted_trees.cc:334] Final model num-trees:191 valid-loss:0.629076 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:35.4431 UTC hyperparameters_optimizer.cc:582] [103/110] Score: -0.629076 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.4711 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.707491 train-accuracy:0.861858 valid-loss:0.684214 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.4711 UTC gradient_boosted_trees.cc:271] Truncates the model to 283 tree(s) i.e. 283  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.4711 UTC gradient_boosted_trees.cc:334] Final model num-trees:283 valid-loss:0.683857 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.4714 UTC hyperparameters_optimizer.cc:582] [104/110] Score: -0.683857 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.4734 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634467\n",
      "[INFO 24-02-21 09:31:35.4734 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.4735 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.634467 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:35.4738 UTC hyperparameters_optimizer.cc:582] [105/110] Score: -0.634467 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.5015 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593423\n",
      "[INFO 24-02-21 09:31:35.5015 UTC gradient_boosted_trees.cc:271] Truncates the model to 167 tree(s) i.e. 167  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.5017 UTC gradient_boosted_trees.cc:334] Final model num-trees:167 valid-loss:0.593423 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:31:35.5032 UTC hyperparameters_optimizer.cc:582] [106/110] Score: -0.593423 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:31:35.7055 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652275\n",
      "[INFO 24-02-21 09:31:35.7055 UTC gradient_boosted_trees.cc:271] Truncates the model to 204 tree(s) i.e. 204  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.7056 UTC gradient_boosted_trees.cc:334] Final model num-trees:204 valid-loss:0.652275 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.7066 UTC hyperparameters_optimizer.cc:582] [107/110] Score: -0.652275 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.8503 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647156\n",
      "[INFO 24-02-21 09:31:35.8503 UTC gradient_boosted_trees.cc:271] Truncates the model to 134 tree(s) i.e. 134  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.8508 UTC gradient_boosted_trees.cc:334] Final model num-trees:134 valid-loss:0.647156 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:31:35.8541 UTC hyperparameters_optimizer.cc:582] [108/110] Score: -0.647156 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:35.8744 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663695\n",
      "[INFO 24-02-21 09:31:35.8744 UTC gradient_boosted_trees.cc:271] Truncates the model to 177 tree(s) i.e. 177  iteration(s).\n",
      "[INFO 24-02-21 09:31:35.8745 UTC gradient_boosted_trees.cc:334] Final model num-trees:177 valid-loss:0.663695 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:31:35.8752 UTC hyperparameters_optimizer.cc:582] [109/110] Score: -0.663695 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:36.0468 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601666\n",
      "[INFO 24-02-21 09:31:36.0468 UTC gradient_boosted_trees.cc:271] Truncates the model to 201 tree(s) i.e. 201  iteration(s).\n",
      "[INFO 24-02-21 09:31:36.0470 UTC gradient_boosted_trees.cc:334] Final model num-trees:201 valid-loss:0.601666 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:31:36.0482 UTC hyperparameters_optimizer.cc:582] [110/110] Score: -0.601666 / -0.511879 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-21 09:31:36.0518 UTC hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 5\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  value {\n",
      "    categorical: \"RANDOM\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  value {\n",
      "    categorical: \"LOCAL\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  value {\n",
      "    integer: 8\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  value {\n",
      "    categorical: \"true\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  value {\n",
      "    real: 0.15\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  value {\n",
      "    real: 0.2\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  value {\n",
      "    categorical: \"SPARSE_OBLIQUE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_normalization\"\n",
      "  value {\n",
      "    categorical: \"NONE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_weights\"\n",
      "  value {\n",
      "    categorical: \"CONTINUOUS\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_num_projections_exponent\"\n",
      "  value {\n",
      "    real: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-21 09:31:36.0523 UTC kernel.cc:919] Export model in log directory: /tmp/tmp0pnh9t9n with prefix a549c13402c54112\n",
      "[INFO 24-02-21 09:31:36.0543 UTC kernel.cc:937] Save model in resources\n",
      "[INFO 24-02-21 09:31:36.0564 UTC abstract_model.cc:881] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 0.511879\n",
      "\n",
      "Accuracy: 0.90411  CI95[W][0 1]\n",
      "ErrorRate: : 0.0958904\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42   6\n",
      "2   1  24\n",
      "Total: 73\n",
      "\n",
      "\n",
      "[INFO 24-02-21 09:31:36.0598 UTC kernel.cc:1233] Loading model from path /tmp/tmp0pnh9t9n/model/ with prefix a549c13402c54112\n",
      "[INFO 24-02-21 09:31:36.0642 UTC decision_forest.cc:660] Model loaded with 54 root(s), 4112 node(s), and 9 input feature(s).\n",
      "[INFO 24-02-21 09:31:36.0643 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-02-21 09:31:36.0643 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:04.204566\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x78e764586c90>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "tuned_model.fit(train_ds, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the TF-DF hyper-parameter tuner: 0.9675\n"
     ]
    }
   ],
   "source": [
    "tuned_model.compile([\"accuracy\"])\n",
    "tuned_test_accuracy = tuned_model.evaluate(train_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy with the TF-DF hyper-parameter tuner: {tuned_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpsby758fw as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'Pclass': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'Age': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'Fare': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'People': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'Sex_female': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'Sex_male': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'Embarked_C': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>, 'Embarked_Q': <tf.Tensor 'data_7:0' shape=(None,) dtype=int64>, 'Embarked_S': <tf.Tensor 'data_8:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_9:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'Pclass': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Age': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Fare': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'People': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Sex_female': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'Sex_male': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'Embarked_C': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'Embarked_Q': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'Embarked_S': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>)}\n",
      "Training dataset read in 0:00:00.113219. Found 891 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-02-21 09:33:15.3498 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-21 09:33:15.3498 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-21 09:33:15.3498 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-21 09:33:15.4768 UTC kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-02-21 09:33:15.4768 UTC kernel.cc:772] Collect training examples\n",
      "[INFO 24-02-21 09:33:15.4768 UTC kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-02-21 09:33:15.4768 UTC kernel.cc:391] Number of batches: 1\n",
      "[INFO 24-02-21 09:33:15.4768 UTC kernel.cc:392] Number of examples: 891\n",
      "[INFO 24-02-21 09:33:15.4769 UTC kernel.cc:792] Training dataset:\n",
      "Number of records: 891\n",
      "Number of columns: 10\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 9 (90%)\n",
      "\tCATEGORICAL: 1 (10%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 9 (90%)\n",
      "\t0: \"Age\" NUMERICAL mean:28.567 min:0.42 max:80 sd:13.1922\n",
      "\t1: \"Embarked_C\" NUMERICAL mean:0.188552 min:0 max:1 sd:0.391152\n",
      "\t2: \"Embarked_Q\" NUMERICAL mean:0.0864198 min:0 max:1 sd:0.280983\n",
      "\t3: \"Embarked_S\" NUMERICAL mean:0.725028 min:0 max:1 sd:0.4465\n",
      "\t4: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n",
      "\t5: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n",
      "\t6: \"People\" NUMERICAL mean:1.9046 min:1 max:11 sd:1.61255\n",
      "\t7: \"Sex_female\" NUMERICAL mean:0.352413 min:0 max:1 sd:0.477722\n",
      "\t8: \"Sex_male\" NUMERICAL mean:0.647587 min:0 max:1 sd:0.477722\n",
      "\n",
      "CATEGORICAL: 1 (10%)\n",
      "\t9: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-02-21 09:33:15.4769 UTC kernel.cc:808] Configure learner\n",
      "[WARNING 24-02-21 09:33:15.4770 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-21 09:33:15.4770 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-21 09:33:15.4770 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-21 09:33:15.4771 UTC kernel.cc:822] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Embarked_C$\"\n",
      "features: \"^Embarked_Q$\"\n",
      "features: \"^Embarked_S$\"\n",
      "features: \"^Fare$\"\n",
      "features: \"^Pclass$\"\n",
      "features: \"^People$\"\n",
      "features: \"^Sex_female$\"\n",
      "features: \"^Sex_male$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "    features: \"^Age$\"\n",
      "    features: \"^Embarked_C$\"\n",
      "    features: \"^Embarked_Q$\"\n",
      "    features: \"^Embarked_S$\"\n",
      "    features: \"^Fare$\"\n",
      "    features: \"^Pclass$\"\n",
      "    features: \"^People$\"\n",
      "    features: \"^Sex_female$\"\n",
      "    features: \"^Sex_male$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: CLASSIFICATION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 6\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: -1\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      shrinkage: 0.1\n",
      "      loss: DEFAULT\n",
      "      validation_set_ratio: 0.1\n",
      "      validation_interval_in_trees: 1\n",
      "      early_stopping: VALIDATION_LOSS_INCREASE\n",
      "      early_stopping_num_trees_look_ahead: 30\n",
      "      l2_regularization: 0\n",
      "      lambda_loss: 1\n",
      "      mart {\n",
      "      }\n",
      "      adapt_subsample_for_maximum_training_duration: false\n",
      "      l1_regularization: 0\n",
      "      use_hessian_gain: false\n",
      "      l2_regularization_categorical: 1\n",
      "      stochastic_gradient_boosting {\n",
      "        ratio: 1\n",
      "      }\n",
      "      apply_link_function: true\n",
      "      compute_permutation_variable_importance: false\n",
      "      binary_focal_loss_options {\n",
      "        misprediction_exponent: 2\n",
      "        positive_sample_coefficient: 0.5\n",
      "      }\n",
      "      early_stopping_initial_iteration: 10\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 50\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "  predefined_search_space {\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-21 09:33:15.4771 UTC kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmpsby758fw/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-02-21 09:33:15.4772 UTC kernel.cc:887] Train model\n",
      "[INFO 24-02-21 09:33:15.4774 UTC hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_projection_density_factor\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"LOCAL\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"BEST_FIRST_GLOBAL\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_num_nodes\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 16\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 32\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 64\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 128\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 256\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 512\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"BEST_FIRST_GLOBAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_depth\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 6\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 8\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"LOCAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sampling_method\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"subsample\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 0.6\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 0.8\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 0.9\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"RANDOM\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.02\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.05\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 7\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 20\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"false\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.5\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.9\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-21 09:33:15.4775 UTC hyperparameters_optimizer.cc:500] Start local tuner with 16 thread(s)\n",
      "[INFO[INFO 24-02-21 09:33:15.4788 UTC gradient_boosted_trees.cc: 24-02-21 09:33:15.4788 UTC gradient_boosted_trees.cc:591591] ] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-21 09:33:15.4788 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 24-02-21 09:33:15.4788 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and  example(s) and 9 feature(s).\n",
      "9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4789 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4789 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4789 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4789 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4789 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4790 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-21 09:33:15.4790 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and  24-02-21 09:33:15.4790 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4790 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4791 UTC gradient_boosted_trees.cc:[INFO591] Default loss set to  24-02-21 09:33:15.4791 UTC BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[ 24-02-21 09:33:15.4791 UTC gradient_boosted_trees.ccgradient_boosted_trees.ccINFO:1218] Training gradient boosted tree on 891 24-02-21 09:33:15.4791 UTC :1261] 818 examples used for training and 73 examples used for validation\n",
      " example(s) and 9 feature(s).\n",
      "gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4791 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4791 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-21 09:33:15.4792 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and  24-02-21 09:33:15.4792 UTC 73 examples used for validation\n",
      "gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-21 09:33:15.4792 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on  24-02-21 09:33:15.4792 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4792 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4792 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4793 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4793 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[[INFOINFO 24-02-21 09:33:15.4793 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD 24-02-21 09:33:15.4793 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4793 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "\n",
      "[INFO[INFO 24-02-21 09:33:15.4793 UTC gradient_boosted_trees.cc:1261 24-02-21 09:33:15.4793 UTC gradient_boosted_trees.cc:1218] 818 examples used for training and 73 examples used for validation\n",
      "] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4794 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4796 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4796 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4797 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4816 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4816 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4817 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4817 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4819 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4819 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4819 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4819 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4819 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:15.4820 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:15.4821 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4822 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:15.4859 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316985 train-accuracy:0.612469 valid-loss:1.274556 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4875 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247455 train-accuracy:0.612469 valid-loss:1.198044 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4879 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293382 train-accuracy:0.612469 valid-loss:1.252779 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4888 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244565 train-accuracy:0.612469 valid-loss:1.206217 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4913 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313858 train-accuracy:0.612469 valid-loss:1.272100 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4916 UTC gradient_boosted_trees.cc:1638] \tnum-trees:2 train-loss:1.297618 train-accuracy:0.612469 valid-loss:1.256489 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4927 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280658 train-accuracy:0.612469 valid-loss:1.247397 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4950 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239858 train-accuracy:0.612469 valid-loss:1.194932 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4953 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280485 train-accuracy:0.612469 valid-loss:1.242568 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4965 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238336 train-accuracy:0.612469 valid-loss:1.196547 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4969 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282139 train-accuracy:0.612469 valid-loss:1.244676 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.4989 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311745 train-accuracy:0.612469 valid-loss:1.272557 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.5040 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282137 train-accuracy:0.612469 valid-loss:1.244571 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.5043 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315485 train-accuracy:0.612469 valid-loss:1.273895 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.5062 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232506 train-accuracy:0.612469 valid-loss:1.204161 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.5080 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.216131 train-accuracy:0.612469 valid-loss:1.186216 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:15.5177 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235894 train-accuracy:0.612469 valid-loss:1.206082 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:16.2961 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.612295\n",
      "[INFO 24-02-21 09:33:16.2961 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-21 09:33:16.2963 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.612295 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:33:16.2970 UTC hyperparameters_optimizer.cc:582] [1/50] Score: -0.612295 / -0.612295 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:16.2973 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:16.2974 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:16.2975 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:16.3083 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314637 train-accuracy:0.612469 valid-loss:1.273489 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:16.3880 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624062\n",
      "[INFO 24-02-21 09:33:16.3880 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-21 09:33:16.3881 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.624062 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:16.3883 UTC hyperparameters_optimizer.cc:582] [2/50] Score: -0.624062 / -0.612295 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:16.3890 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:16.3890 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:16.3893 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:16.4063 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277922 train-accuracy:0.612469 valid-loss:1.248156 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:16.6823 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.596004\n",
      "[INFO 24-02-21 09:33:16.6823 UTC gradient_boosted_trees.cc:271] Truncates the model to 173 tree(s) i.e. 173  iteration(s).\n",
      "[INFO 24-02-21 09:33:16.6824 UTC gradient_boosted_trees.cc:334] Final model num-trees:173 valid-loss:0.596004 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:16.6833 UTC hyperparameters_optimizer.cc:582] [3/50] Score: -0.596004 / -0.596004 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:16.6837 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:16.6837 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:16.6840 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:16.7094 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309232 train-accuracy:0.612469 valid-loss:1.273213 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:16.8636 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593863\n",
      "[INFO 24-02-21 09:33:16.8636 UTC gradient_boosted_trees.cc:271] Truncates the model to 99 tree(s) i.e. 99  iteration(s).\n",
      "[INFO 24-02-21 09:33:16.8639 UTC gradient_boosted_trees.cc:334] Final model num-trees:99 valid-loss:0.593863 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:16.8654 UTC hyperparameters_optimizer.cc:582] [4/50] Score: -0.593863 / -0.593863 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:16.8655 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:16.8655 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:16.8657 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:16.8726 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.318063 train-accuracy:0.612469 valid-loss:1.278844 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:16.9154 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666358\n",
      "[INFO 24-02-21 09:33:16.9154 UTC gradient_boosted_trees.cc:271] Truncates the model to 197 tree(s) i.e. 197  iteration(s).\n",
      "[INFO 24-02-21 09:33:16.9155 UTC gradient_boosted_trees.cc:334] Final model num-trees:197 valid-loss:0.666358 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:16.9164 UTC hyperparameters_optimizer.cc:582] [5/50] Score: -0.666358 / -0.593863 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:16.9181 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:16.9181 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:16.9182 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:16.9259 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319159 train-accuracy:0.612469 valid-loss:1.278546 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:17.0792 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645618\n",
      "[INFO 24-02-21 09:33:17.0792 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-21 09:33:17.0794 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.645618 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:17.0805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:17.0805 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:17.0807 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:17.0813 UTC hyperparameters_optimizer.cc:582] [6/50] Score: -0.645618 / -0.593863 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:17.0939 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313727 train-accuracy:0.612469 valid-loss:1.273497 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:17.1105 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650377\n",
      "[INFO 24-02-21 09:33:17.1105 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-21 09:33:17.1107 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.650377 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:17.1118 UTC hyperparameters_optimizer.cc:582] [7/50] Score: -0.650377 / -0.593863 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:17.1131 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:17.1131 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:17.1133 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:17.1285 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232927 train-accuracy:0.612469 valid-loss:1.212309 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:17.2039 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.575025\n",
      "[INFO 24-02-21 09:33:17.2039 UTC gradient_boosted_trees.cc:271] Truncates the model to 93 tree(s) i.e. 93  iteration(s).\n",
      "[INFO 24-02-21 09:33:17.2041 UTC gradient_boosted_trees.cc:334] Final model num-trees:93 valid-loss:0.575025 valid-accuracy:0.904110\n",
      "[[INFO 24-02-21 09:33:17.2063 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:17.2066 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:17.2070 UTC gradient_boosted_trees.cc:1261] 818INFO 24-02-21 09:33:17.2072 UTC  examples used for training and 73 examples used for validation\n",
      "hyperparameters_optimizer.cc:582] [8/50] Score: -0.575025 / -0.575025 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:17.2252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227712 train-accuracy:0.612469 valid-loss:1.212989 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:17.8289 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63752\n",
      "[INFO 24-02-21 09:33:17.8290 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-21 09:33:17.8292 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.637520 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:33:17.8298 UTC hyperparameters_optimizer.cc:582] [9/50] Score: -0.63752 / -0.575025 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:17.8306 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:17.8306 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:17.8309 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:17.8538 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276003 train-accuracy:0.612469 valid-loss:1.238004 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:17.9102 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661122\n",
      "[INFO 24-02-21 09:33:17.9102 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-21 09:33:17.9104 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.661122 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:17.9111 UTC hyperparameters_optimizer.cc:582] [10/50] Score: -0.661122 / -0.575025 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:17.9123 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:17.9123 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:17.9127 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:17.9359 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312925 train-accuracy:0.612469 valid-loss:1.276873 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:17.9399 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669595\n",
      "[INFO 24-02-21 09:33:17.9400 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-21 09:33:17.9401 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.669595 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:17.9405 UTC hyperparameters_optimizer.cc:582] [11/50] Score: -0.669595 / -0.575025 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:17.9413 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:17.9413 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:17.9415 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:17.9620 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312659 train-accuracy:0.612469 valid-loss:1.273163 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:18.0064 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635356\n",
      "[INFO 24-02-21 09:33:18.0064 UTC gradient_boosted_trees.cc:271] Truncates the model to 81 tree(s) i.e. 81  iteration(s).\n",
      "[INFO 24-02-21 09:33:18.0065 UTC gradient_boosted_trees.cc:334] Final model num-trees:81 valid-loss:0.635356 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:18.0069 UTC hyperparameters_optimizer.cc:582] [12/50] Score: -0.635356 / -0.575025 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:18.0077 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:18.0077 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:18.0078 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:18.0315 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310614 train-accuracy:0.612469 valid-loss:1.272857 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:18.0518 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667936\n",
      "[INFO 24-02-21 09:33:18.0519 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-21 09:33:18.0522 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.667936 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:18.0532 UTC hyperparameters_optimizer.cc:582] [13/50] Score: -0.667936 / -0.575025 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:18.0548 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:18.0552 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:18.0557 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:18.0626 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.256799 train-accuracy:0.612469 valid-loss:1.211400 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:18.1272 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657365\n",
      "[INFO 24-02-21 09:33:18.1272 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-21 09:33:18.1276 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.657365 valid-accuracy:0.849315\n",
      "[[INFO 24-02-21 09:33:18.1283 UTC hyperparameters_optimizer.cc:582] [14/50] Score: -0.657365 / -0.575025 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "INFO 24-02-21 09:33:18.1287 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:18.1287 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:18.1292 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:18.1446 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226912 train-accuracy:0.612469 valid-loss:1.199930 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:18.1831 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638175\n",
      "[INFO 24-02-21 09:33:18.1831 UTC gradient_boosted_trees.cc:271] Truncates the model to 85 tree(s) i.e. 85  iteration(s).\n",
      "[INFO 24-02-21 09:33:18.1833 UTC gradient_boosted_trees.cc:334] Final model num-trees:85 valid-loss:0.638175 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:18.1844 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:18.1844 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:18.1844 UTC hyperparameters_optimizer.cc:582] [15/50] Score: -0.638175 / -0.575025 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:18.1851 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:18.2061 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277880 train-accuracy:0.612469 valid-loss:1.235134 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:18.3434 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.563229\n",
      "[INFO 24-02-21 09:33:18.3435 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-21 09:33:18.3439 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.563229 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:18.3462 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:18.3462 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:18.3463 UTC hyperparameters_optimizer.cc:582] [16/50] Score: -0.563229 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:18.3465 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:18.3589 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293082 train-accuracy:0.612469 valid-loss:1.249056 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:18.7966 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637325\n",
      "[INFO 24-02-21 09:33:18.7966 UTC gradient_boosted_trees.cc:271] Truncates the model to 249 tree(s) i.e. 249  iteration(s).\n",
      "[INFO 24-02-21 09:33:18.7968 UTC gradient_boosted_trees.cc:334] Final model num-trees:249 valid-loss:0.637325 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:18.7974 UTC hyperparameters_optimizer.cc:582] [17/50] Score: -0.637325 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:18.7985 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:18.7986 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:18.7989 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:18.8185 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314080 train-accuracy:0.612469 valid-loss:1.273716 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:18.8225 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644034\n",
      "[INFO 24-02-21 09:33:18.8225 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-21 09:33:18.8226 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.644034 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:18.8230 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:18.8231 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:18.8233 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:18.8281 UTC hyperparameters_optimizer.cc:582] [18/50] Score: -0.644034 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:18.8446 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285782 train-accuracy:0.612469 valid-loss:1.243165 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:18.9792 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638633\n",
      "[INFO 24-02-21 09:33:18.9792 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-21 09:33:18.9795 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.638633 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:33:18.9799 UTC hyperparameters_optimizer.cc:582] [19/50] Score: -0.638633 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:18.9807 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:18.9807 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:18.9810 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:18.9996 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313683 train-accuracy:0.612469 valid-loss:1.272872 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:19.0142 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652696\n",
      "[INFO 24-02-21 09:33:19.0143 UTC gradient_boosted_trees.cc:271] Truncates the model to 154 tree(s) i.e. 154  iteration(s).\n",
      "[INFO 24-02-21 09:33:19.0145 UTC gradient_boosted_trees.cc:334] Final model num-trees:154 valid-loss:0.652696 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:19.0161 UTC hyperparameters_optimizer.cc:582] [20/50] Score: -0.652696 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:19.0202 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:19.0203 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:19.0205 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:19.0383 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227521 train-accuracy:0.612469 valid-loss:1.188364 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:19.1400 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653986\n",
      "[INFO 24-02-21 09:33:19.1401 UTC gradient_boosted_trees.cc:271] Truncates the model to 228 tree(s) i.e. 228  iteration(s).\n",
      "[INFO 24-02-21 09:33:19.1403 UTC gradient_boosted_trees.cc:334] Final model num-trees:228 valid-loss:0.653986 valid-accuracy:0.835616\n",
      "[INFO 24-02-21 09:33:19.1419 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:19.1420 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:19.1423 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:19.1480 UTC hyperparameters_optimizer.cc:582] [21/50] Score: -0.653986 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:19.1648 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235366 train-accuracy:0.612469 valid-loss:1.197124 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:19.1947 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.374502 train-accuracy:0.942543 valid-loss:0.563830 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:33:19.1948 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-21 09:33:19.1948 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.563830 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:33:19.1973 UTC hyperparameters_optimizer.cc:582] [22/50] Score: -0.56383 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:19.1975 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:19.1975 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:19.1991 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:19.2005 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314505 train-accuracy:0.612469 valid-loss:1.274422 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:19.4429 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.677318 train-accuracy:0.863081 valid-loss:0.660778 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:19.4429 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-21 09:33:19.4429 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.660778 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:19.4433 UTC hyperparameters_optimizer.cc:582] [23/50] Score: -0.660778 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:19.4441 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:19.4442 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:19.4443 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:19.4494 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.258824 train-accuracy:0.612469 valid-loss:1.214804 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:19.4701 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.484679 train-accuracy:0.914425 valid-loss:0.609105 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:33:19.4701 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-21 09:33:19.4701 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.608657 valid-accuracy:0.890411\n",
      "[[INFO 24-02-21 09:33:19.4725 UTC hyperparameters_optimizer.cc:582] [24/50] Score: -0.608657INFO 24-02-21 09:33:19.4727 UTC  / -0.563229gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:19.4741 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:19.4755 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:19.4909 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314636 train-accuracy:0.612469 valid-loss:1.275429 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.0165 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655586\n",
      "[INFO 24-02-21 09:33:20.0165 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.0166 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.655586 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:20.0170 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.0170 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.0173 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.0207 UTC hyperparameters_optimizer.cc:582] [25/50] Score: -0.655586 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:20.0222 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.256352 train-accuracy:0.612469 valid-loss:1.217104 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.0784 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633835\n",
      "[INFO 24-02-21 09:33:20.0784 UTC gradient_boosted_trees.cc:271] Truncates the model to 56 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.0787 UTC gradient_boosted_trees.cc:334] Final model num-trees:56 valid-loss:0.633835 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:20.0799 UTC hyperparameters_optimizer.cc:582] [26/50] Score: -0.633835 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:20.0809 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.0811 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.0816 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.0982 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285856 train-accuracy:0.612469 valid-loss:1.247042 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.2921 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647659\n",
      "[INFO 24-02-21 09:33:20.2921 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.2923 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.647659 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:20.2925 UTC hyperparameters_optimizer.cc:582] [27/50] Score: -0.647659 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:20.2931 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.2931 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.2933 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.3056 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.417044 train-accuracy:0.932763 valid-loss:0.575927 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:20.3056 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.3056 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.575927 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:20.3068 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232952 train-accuracy:0.612469 valid-loss:1.198210 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.3070 UTC hyperparameters_optimizer.cc:582] [28/50] Score: -0.575927 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:20.3074 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.3074 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.3085 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.3263 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222314 train-accuracy:0.612469 valid-loss:1.184476 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.4656 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658651\n",
      "[INFO 24-02-21 09:33:20.4657 UTC gradient_boosted_trees.cc:271] Truncates the model to 160 tree(s) i.e. 160  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.4659 UTC gradient_boosted_trees.cc:334] Final model num-trees:160 valid-loss:0.658651 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:20.4679 UTC hyperparameters_optimizer.cc:582] [29/50] Score: -0.658651 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:20.4687 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.4687 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.4701 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.4918 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280949 train-accuracy:0.612469 valid-loss:1.245230 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.5841 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.595518\n",
      "[INFO 24-02-21 09:33:20.5900 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.5933 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.595518 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:20.5943 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.5943 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.5945 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.5947 UTC hyperparameters_optimizer.cc:582] [30/50] Score: -0.595518 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:20.6052 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.258274 train-accuracy:0.612469 valid-loss:1.202960 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.8209 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.424540 train-accuracy:0.930318 valid-loss:0.661877 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:20.8209 UTC gradient_boosted_trees.cc:271] Truncates the model to 295 tree(s) i.e. 295  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.8209 UTC gradient_boosted_trees.cc:334] Final model num-trees:295 valid-loss:0.660749 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:20.8228 UTC hyperparameters_optimizer.cc:582] [31/50] Score: -0.660749 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:20.8269 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.8270 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.8272 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.8354 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320585 train-accuracy:0.612469 valid-loss:1.278842 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.9007 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.583161\n",
      "[INFO 24-02-21 09:33:20.9008 UTC gradient_boosted_trees.cc:271] Truncates the model to 96 tree(s) i.e. 96  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.9010 UTC gradient_boosted_trees.cc:334] Final model num-trees:96 valid-loss:0.583161 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:20.9037 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.9038 UTC hyperparameters_optimizer.cc:582] [32/50] Score: -0.583161 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:20.9039 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.9043 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61505\n",
      "[INFO 24-02-21 09:33:20.9044 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-21 09:33:20.9044 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.615050 valid-accuracy:0.835616\n",
      "[INFO 24-02-21 09:33:20.9048 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:20.9048 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:20.9049 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.9049 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:20.9080 UTC hyperparameters_optimizer.cc:582] [33/50] Score: -0.61505 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:20.9211 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285087 train-accuracy:0.612469 valid-loss:1.243585 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:20.9228 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313275 train-accuracy:0.612469 valid-loss:1.273596 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:21.1799 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675103\n",
      "[INFO 24-02-21 09:33:21.1799 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-21 09:33:21.1801 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.675103 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:21.1806 UTC hyperparameters_optimizer.cc:582] [34/50] Score: -0.675103 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:21.1808 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-21 09:33:21.1809 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-21 09:33:21.1811 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-21 09:33:21.1932 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286201 train-accuracy:0.612469 valid-loss:1.243237 valid-accuracy:0.657534\n",
      "[INFO 24-02-21 09:33:21.4237 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651572\n",
      "[INFO 24-02-21 09:33:21.4239 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-21 09:33:21.4241 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.651572 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:21.4253 UTC hyperparameters_optimizer.cc:582] [35/50] Score: -0.651572 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:21.6555 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630914\n",
      "[INFO 24-02-21 09:33:21.6555 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-21 09:33:21.6557 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.630914 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:21.6561 UTC hyperparameters_optimizer.cc:582] [36/50] Score: -0.630914 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:21.7866 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675125\n",
      "[INFO 24-02-21 09:33:21.7867 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-21 09:33:21.7868 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.675125 valid-accuracy:0.835616\n",
      "[INFO 24-02-21 09:33:21.7875 UTC hyperparameters_optimizer.cc:582] [37/50] Score: -0.675125 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:21.8825 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650544\n",
      "[INFO 24-02-21 09:33:21.8825 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-21 09:33:21.8826 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.650544 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:33:21.8834 UTC hyperparameters_optimizer.cc:582] [38/50] Score: -0.650544 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:21.9716 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641562\n",
      "[INFO 24-02-21 09:33:21.9716 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-21 09:33:21.9717 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.641562 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:21.9719 UTC hyperparameters_optimizer.cc:582] [39/50] Score: -0.641562 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:21.9822 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.352415 train-accuracy:0.953545 valid-loss:0.590116 valid-accuracy:0.849315\n",
      "[INFO 24-02-21 09:33:21.9822 UTC gradient_boosted_trees.cc:271] Truncates the model to 271 tree(s) i.e. 271  iteration(s).\n",
      "[INFO 24-02-21 09:33:21.9822 UTC gradient_boosted_trees.cc:334] Final model num-trees:271 valid-loss:0.582610 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:21.9827 UTC hyperparameters_optimizer.cc:582] [40/50] Score: -0.58261 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:22.2833 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654342\n",
      "[INFO 24-02-21 09:33:22.2833 UTC gradient_boosted_trees.cc:271] Truncates the model to 163 tree(s) i.e. 163  iteration(s).\n",
      "[INFO 24-02-21 09:33:22.2835 UTC gradient_boosted_trees.cc:334] Final model num-trees:163 valid-loss:0.654342 valid-accuracy:0.835616\n",
      "[INFO 24-02-21 09:33:22.2850 UTC hyperparameters_optimizer.cc:582] [41/50] Score: -0.654342 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:22.3720 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606897\n",
      "[INFO 24-02-21 09:33:22.3720 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-21 09:33:22.3722 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.606897 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:22.3729 UTC hyperparameters_optimizer.cc:582] [42/50] Score: -0.606897 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:22.8429 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.710138 train-accuracy:0.849633 valid-loss:0.673913 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:22.8429 UTC gradient_boosted_trees.cc:271] Truncates the model to 297 tree(s) i.e. 297  iteration(s).\n",
      "[INFO 24-02-21 09:33:22.8429 UTC gradient_boosted_trees.cc:334] Final model num-trees:297 valid-loss:0.673910 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:22.8433 UTC hyperparameters_optimizer.cc:582] [43/50] Score: -0.67391 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:22.9745 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634165\n",
      "[INFO 24-02-21 09:33:22.9745 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-21 09:33:22.9746 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.634165 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:22.9749 UTC hyperparameters_optimizer.cc:582] [44/50] Score: -0.634165 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:22.9885 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62861\n",
      "[INFO 24-02-21 09:33:22.9885 UTC gradient_boosted_trees.cc:271] Truncates the model to 169 tree(s) i.e. 169  iteration(s).\n",
      "[INFO 24-02-21 09:33:22.9887 UTC gradient_boosted_trees.cc:334] Final model num-trees:169 valid-loss:0.628610 valid-accuracy:0.863014\n",
      "[INFO 24-02-21 09:33:22.9904 UTC hyperparameters_optimizer.cc:582] [45/50] Score: -0.62861 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-21 09:33:23.0235 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619811\n",
      "[INFO 24-02-21 09:33:23.0235 UTC gradient_boosted_trees.cc:271] Truncates the model to 142 tree(s) i.e. 142  iteration(s).\n",
      "[INFO 24-02-21 09:33:23.0236 UTC gradient_boosted_trees.cc:334] Final model num-trees:142 valid-loss:0.619811 valid-accuracy:0.890411\n",
      "[INFO 24-02-21 09:33:23.0243 UTC hyperparameters_optimizer.cc:582] [46/50] Score: -0.619811 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-21 09:33:23.0863 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623406\n",
      "[INFO 24-02-21 09:33:23.0863 UTC gradient_boosted_trees.cc:271] Truncates the model to 191 tree(s) i.e. 191  iteration(s).\n",
      "[INFO 24-02-21 09:33:23.0864 UTC gradient_boosted_trees.cc:334] Final model num-trees:191 valid-loss:0.623406 valid-accuracy:0.835616\n",
      "[INFO 24-02-21 09:33:23.0874 UTC hyperparameters_optimizer.cc:582] [47/50] Score: -0.623406 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:23.2484 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654517\n",
      "[INFO 24-02-21 09:33:23.2484 UTC gradient_boosted_trees.cc:271] Truncates the model to 161 tree(s) i.e. 161  iteration(s).\n",
      "[INFO 24-02-21 09:33:23.2486 UTC gradient_boosted_trees.cc:334] Final model num-trees:161 valid-loss:0.654517 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:23.2498 UTC hyperparameters_optimizer.cc:582] [48/50] Score: -0.654517 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:23.3149 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614801\n",
      "[INFO 24-02-21 09:33:23.3149 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-21 09:33:23.3150 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.614801 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:23.3159 UTC hyperparameters_optimizer.cc:582] [49/50] Score: -0.614801 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-21 09:33:23.8655 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.390381 train-accuracy:0.941320 valid-loss:0.607084 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:23.8655 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-21 09:33:23.8656 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.606500 valid-accuracy:0.876712\n",
      "[INFO 24-02-21 09:33:23.8669 UTC hyperparameters_optimizer.cc:582] [50/50] Score: -0.6065 / -0.563229 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-21 09:33:23.8713 UTC hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  value {\n",
      "    categorical: \"SPARSE_OBLIQUE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_projection_density_factor\"\n",
      "  value {\n",
      "    real: 3\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_normalization\"\n",
      "  value {\n",
      "    categorical: \"NONE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_weights\"\n",
      "  value {\n",
      "    categorical: \"BINARY\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  value {\n",
      "    categorical: \"RANDOM\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  value {\n",
      "    categorical: \"LOCAL\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  value {\n",
      "    integer: 8\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sampling_method\"\n",
      "  value {\n",
      "    categorical: \"RANDOM\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"subsample\"\n",
      "  value {\n",
      "    real: 1\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  value {\n",
      "    real: 0.1\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 5\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  value {\n",
      "    categorical: \"false\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  value {\n",
      "    real: 0.5\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-21 09:33:23.8716 UTC kernel.cc:919] Export model in log directory: /tmp/tmpsby758fw with prefix dbd50fce34f54395\n",
      "[INFO 24-02-21 09:33:23.8736 UTC kernel.cc:937] Save model in resources\n",
      "[INFO 24-02-21 09:33:23.8752 UTC abstract_model.cc:881] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 0.563229\n",
      "\n",
      "Accuracy: 0.876712  CI95[W][0 1]\n",
      "ErrorRate: : 0.123288\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41   7\n",
      "2   2  23\n",
      "Total: 73\n",
      "\n",
      "\n",
      "[INFO 24-02-21 09:33:23.8806 UTC kernel.cc:1233] Loading model from path /tmp/tmpsby758fw/model/ with prefix dbd50fce34f54395\n",
      "[INFO 24-02-21 09:33:23.8885 UTC decision_forest.cc:660] Model loaded with 63 root(s), 4559 node(s), and 9 input feature(s).\n",
      "[INFO 24-02-21 09:33:23.8886 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-02-21 09:33:23.8886 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:08.415172\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x78e69cf05290>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner2 = tfdf.tuner.RandomSearch(num_trials=50, use_predefined_hps=True)\n",
    "\n",
    "# Define and train the model.\n",
    "tuned_model2 = tfdf.keras.GradientBoostedTreesModel(tuner=tuner2)\n",
    "tuned_model2.fit(train_ds, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x78e7643b72e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x78e7643b72e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the TF-DF hyper-parameter tuner: 0.9675\n"
     ]
    }
   ],
   "source": [
    "tuned_model2.compile([\"accuracy\"])\n",
    "tuned_test_accuracy2 = tuned_model2.evaluate(train_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy with the TF-DF hyper-parameter tuner: {tuned_test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x78e7643b7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x78e7643b7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_rfm = tuned_model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame({\"PassengerId\" : t[\"PassengerId\"], \"Survived\":np.round(predictions_rfm,0).astype('int').ravel()})\n",
    "answer.to_csv('titanic/predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1 (1.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (9):\n",
      "\tAge\n",
      "\tEmbarked_C\n",
      "\tEmbarked_Q\n",
      "\tEmbarked_S\n",
      "\tFare\n",
      "\tPclass\n",
      "\tPeople\n",
      "\tSex_female\n",
      "\tSex_male\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.        \"Age\"  0.404580 ################\n",
      "    2.       \"Fare\"  0.214968 ####\n",
      "    3. \"Embarked_C\"  0.203683 ###\n",
      "    4. \"Embarked_Q\"  0.184145 ##\n",
      "    5.     \"Pclass\"  0.184070 ##\n",
      "    6. \"Sex_female\"  0.179725 #\n",
      "    7. \"Embarked_S\"  0.179184 #\n",
      "    8.     \"People\"  0.152488 \n",
      "    9.   \"Sex_male\"  0.147862 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.        \"Age\" 19.000000 ################\n",
      "    2. \"Sex_female\" 11.000000 ########\n",
      "    3. \"Embarked_C\"  6.000000 ####\n",
      "    4. \"Embarked_Q\"  6.000000 ####\n",
      "    5.       \"Fare\"  6.000000 ####\n",
      "    6.     \"Pclass\"  3.000000 #\n",
      "    7. \"Embarked_S\"  1.000000 \n",
      "    8.     \"People\"  1.000000 \n",
      "    9.   \"Sex_male\"  1.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.        \"Age\" 1000.000000 ################\n",
      "    2.       \"Fare\" 307.000000 ####\n",
      "    3. \"Embarked_C\" 247.000000 ###\n",
      "    4. \"Embarked_Q\" 184.000000 ##\n",
      "    5. \"Embarked_S\" 134.000000 ##\n",
      "    6.     \"Pclass\" 81.000000 #\n",
      "    7.     \"People\" 52.000000 \n",
      "    8. \"Sex_female\" 19.000000 \n",
      "    9.   \"Sex_male\"  5.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.        \"Age\" 801212.279997 ################\n",
      "    2. \"Sex_female\" 487794.243801 #########\n",
      "    3. \"Embarked_C\" 461887.785836 #########\n",
      "    4.       \"Fare\" 372637.277779 #######\n",
      "    5.     \"Pclass\" 249363.819905 ####\n",
      "    6. \"Embarked_Q\" 173466.219301 ###\n",
      "    7. \"Embarked_S\" 99479.444228 #\n",
      "    8.   \"Sex_male\" 76579.019610 #\n",
      "    9.     \"People\" 17511.542227 \n",
      "\n",
      "\n",
      "Hyperparameter optimizer:\n",
      "\n",
      "Best parameters: min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1\n",
      "Num steps: 110\n",
      "Best score: -0.511879\n",
      "\n",
      "Step #0 score:-0.597399 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #1 score:-0.633610 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #2 score:-0.615036 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #3 score:-0.616001 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #4 score:-0.617410 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #5 score:-0.575302 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #6 score:-0.649223 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #7 score:-0.640501 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #8 score:-0.632296 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #9 score:-0.593443 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #10 score:-0.622671 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #11 score:-0.555223 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #12 score:-0.596788 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #13 score:-0.588391 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #14 score:-0.615455 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #15 score:-0.511879 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #16 score:-0.598598 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #17 score:-0.673177 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #18 score:-0.650418 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #19 score:-0.619180 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #20 score:-0.601437 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #21 score:-0.641731 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #22 score:-0.632515 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #23 score:-0.640183 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #24 score:-0.610891 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #25 score:-0.620361 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #26 score:-0.626619 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #27 score:-0.621684 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #28 score:-0.643637 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #29 score:-0.624303 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #30 score:-0.656890 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #31 score:-0.597298 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #32 score:-0.560586 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #33 score:-0.621127 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #34 score:-0.593831 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #35 score:-0.661942 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #36 score:-0.636488 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #37 score:-0.642812 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #38 score:-0.640006 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #39 score:-0.665798 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #40 score:-0.653964 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #41 score:-0.629204 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #42 score:-0.686709 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #43 score:-0.581133 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #44 score:-0.603145 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #45 score:-0.653012 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #46 score:-0.602047 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #47 score:-0.637160 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #48 score:-0.610887 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #49 score:-0.646619 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #50 score:-0.601467 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #51 score:-0.603652 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #52 score:-0.649389 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #53 score:-0.667977 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #54 score:-0.669982 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #55 score:-0.636577 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #56 score:-0.663316 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #57 score:-0.604757 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #58 score:-0.652525 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #59 score:-0.679383 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #60 score:-0.591689 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #61 score:-0.643378 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #62 score:-0.645897 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #63 score:-0.625377 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #64 score:-0.553566 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #65 score:-0.724232 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #66 score:-0.596600 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #67 score:-0.647109 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #68 score:-0.585981 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #69 score:-0.679649 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #70 score:-0.627266 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #71 score:-0.639127 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #72 score:-0.678933 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #73 score:-0.620135 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #74 score:-0.532555 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #75 score:-0.639816 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #76 score:-0.617097 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #77 score:-0.650035 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #78 score:-0.636887 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #79 score:-0.644691 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #80 score:-0.551145 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #81 score:-0.633720 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #82 score:-0.586474 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #83 score:-0.587314 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #84 score:-0.614419 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #85 score:-0.593940 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #86 score:-0.635216 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #87 score:-0.666699 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #88 score:-0.691082 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #89 score:-0.651667 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #90 score:-0.588235 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #91 score:-0.541473 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #92 score:-0.642933 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #93 score:-0.603638 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #94 score:-0.590453 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #95 score:-0.651220 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #96 score:-0.586526 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #97 score:-0.581113 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #98 score:-0.640531 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #99 score:-0.649522 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #100 score:-0.658538 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #101 score:-0.658414 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #102 score:-0.629076 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #103 score:-0.683857 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #104 score:-0.634467 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #105 score:-0.593423 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #106 score:-0.652275 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #107 score:-0.647156 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #108 score:-0.663695 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #109 score:-0.601666 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 0.511879\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 54\n",
      "Total number of nodes: 4112\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 54 Average: 76.1481 StdDev: 25.8331\n",
      "Min: 25 Max: 125 Ignored: 0\n",
      "----------------------------------------------\n",
      "[  25,  30) 5   9.26%   9.26% ######\n",
      "[  30,  35) 1   1.85%  11.11% #\n",
      "[  35,  40) 3   5.56%  16.67% ####\n",
      "[  40,  45) 0   0.00%  16.67%\n",
      "[  45,  50) 0   0.00%  16.67%\n",
      "[  50,  55) 4   7.41%  24.07% #####\n",
      "[  55,  60) 0   0.00%  24.07%\n",
      "[  60,  65) 2   3.70%  27.78% ###\n",
      "[  65,  70) 4   7.41%  35.19% #####\n",
      "[  70,  75) 2   3.70%  38.89% ###\n",
      "[  75,  80) 6  11.11%  50.00% ########\n",
      "[  80,  85) 3   5.56%  55.56% ####\n",
      "[  85,  90) 4   7.41%  62.96% #####\n",
      "[  90,  95) 6  11.11%  74.07% ########\n",
      "[  95, 100) 8  14.81%  88.89% ##########\n",
      "[ 100, 105) 0   0.00%  88.89%\n",
      "[ 105, 110) 3   5.56%  94.44% ####\n",
      "[ 110, 115) 0   0.00%  94.44%\n",
      "[ 115, 120) 1   1.85%  96.30% #\n",
      "[ 120, 125] 2   3.70% 100.00% ###\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 2083 Average: 5.9952 StdDev: 1.25981\n",
      "Min: 1 Max: 7 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)    4   0.19%   0.19%\n",
      "[ 2, 3)   20   0.96%   1.15%\n",
      "[ 3, 4)   76   3.65%   4.80% #\n",
      "[ 4, 5)  210  10.08%  14.88% ##\n",
      "[ 5, 6)  312  14.98%  29.86% ###\n",
      "[ 6, 7)  411  19.73%  49.59% ####\n",
      "[ 7, 7] 1050  50.41% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 2083 Average: 21.206 StdDev: 59.3398\n",
      "Min: 5 Max: 722 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   5,  40) 1883  90.40%  90.40% ##########\n",
      "[  40,  76)  103   4.94%  95.34% #\n",
      "[  76, 112)   27   1.30%  96.64%\n",
      "[ 112, 148)   15   0.72%  97.36%\n",
      "[ 148, 184)   11   0.53%  97.89%\n",
      "[ 184, 220)   10   0.48%  98.37%\n",
      "[ 220, 256)    5   0.24%  98.61%\n",
      "[ 256, 292)    2   0.10%  98.70%\n",
      "[ 292, 328)    7   0.34%  99.04%\n",
      "[ 328, 364)    2   0.10%  99.14%\n",
      "[ 364, 399)    2   0.10%  99.23%\n",
      "[ 399, 435)    4   0.19%  99.42%\n",
      "[ 435, 471)    0   0.00%  99.42%\n",
      "[ 471, 507)    2   0.10%  99.52%\n",
      "[ 507, 543)    2   0.10%  99.62%\n",
      "[ 543, 579)    3   0.14%  99.76%\n",
      "[ 579, 615)    0   0.00%  99.76%\n",
      "[ 615, 651)    2   0.10%  99.86%\n",
      "[ 651, 687)    1   0.05%  99.90%\n",
      "[ 687, 722]    2   0.10% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t1000 : Age [NUMERICAL]\n",
      "\t307 : Fare [NUMERICAL]\n",
      "\t247 : Embarked_C [NUMERICAL]\n",
      "\t184 : Embarked_Q [NUMERICAL]\n",
      "\t134 : Embarked_S [NUMERICAL]\n",
      "\t81 : Pclass [NUMERICAL]\n",
      "\t52 : People [NUMERICAL]\n",
      "\t19 : Sex_female [NUMERICAL]\n",
      "\t5 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t19 : Age [NUMERICAL]\n",
      "\t11 : Sex_female [NUMERICAL]\n",
      "\t6 : Fare [NUMERICAL]\n",
      "\t6 : Embarked_Q [NUMERICAL]\n",
      "\t6 : Embarked_C [NUMERICAL]\n",
      "\t3 : Pclass [NUMERICAL]\n",
      "\t1 : Sex_male [NUMERICAL]\n",
      "\t1 : People [NUMERICAL]\n",
      "\t1 : Embarked_S [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t66 : Age [NUMERICAL]\n",
      "\t21 : Fare [NUMERICAL]\n",
      "\t17 : Pclass [NUMERICAL]\n",
      "\t17 : Embarked_C [NUMERICAL]\n",
      "\t13 : Embarked_S [NUMERICAL]\n",
      "\t12 : Sex_female [NUMERICAL]\n",
      "\t10 : Embarked_Q [NUMERICAL]\n",
      "\t1 : Sex_male [NUMERICAL]\n",
      "\t1 : People [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t150 : Age [NUMERICAL]\n",
      "\t50 : Fare [NUMERICAL]\n",
      "\t45 : Embarked_C [NUMERICAL]\n",
      "\t28 : Embarked_S [NUMERICAL]\n",
      "\t27 : Pclass [NUMERICAL]\n",
      "\t26 : Embarked_Q [NUMERICAL]\n",
      "\t12 : Sex_female [NUMERICAL]\n",
      "\t7 : People [NUMERICAL]\n",
      "\t1 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t303 : Age [NUMERICAL]\n",
      "\t90 : Fare [NUMERICAL]\n",
      "\t81 : Embarked_C [NUMERICAL]\n",
      "\t52 : Embarked_S [NUMERICAL]\n",
      "\t52 : Embarked_Q [NUMERICAL]\n",
      "\t37 : Pclass [NUMERICAL]\n",
      "\t17 : People [NUMERICAL]\n",
      "\t13 : Sex_female [NUMERICAL]\n",
      "\t1 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t735 : Age [NUMERICAL]\n",
      "\t216 : Fare [NUMERICAL]\n",
      "\t188 : Embarked_C [NUMERICAL]\n",
      "\t132 : Embarked_Q [NUMERICAL]\n",
      "\t109 : Embarked_S [NUMERICAL]\n",
      "\t66 : Pclass [NUMERICAL]\n",
      "\t39 : People [NUMERICAL]\n",
      "\t16 : Sex_female [NUMERICAL]\n",
      "\t3 : Sex_male [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t2029 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t54 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t158 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t346 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t646 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t1504 : ObliqueCondition\n",
      "\n",
      "Training logs:\n",
      "Number of iteration to final model: 54\n",
      "\tIter:1 train-loss:1.177001 valid-loss:1.149981  train-accuracy:0.612469 valid-accuracy:0.657534\n",
      "\tIter:2 train-loss:1.062041 valid-loss:1.044482  train-accuracy:0.823961 valid-accuracy:0.821918\n",
      "\tIter:3 train-loss:0.967821 valid-loss:0.950645  train-accuracy:0.855746 valid-accuracy:0.863014\n",
      "\tIter:4 train-loss:0.888189 valid-loss:0.879084  train-accuracy:0.875306 valid-accuracy:0.890411\n",
      "\tIter:5 train-loss:0.826687 valid-loss:0.834131  train-accuracy:0.885086 valid-accuracy:0.890411\n",
      "\tIter:6 train-loss:0.769459 valid-loss:0.784646  train-accuracy:0.892421 valid-accuracy:0.890411\n",
      "\tIter:16 train-loss:0.491624 valid-loss:0.625313  train-accuracy:0.921760 valid-accuracy:0.863014\n",
      "\tIter:26 train-loss:0.392094 valid-loss:0.593853  train-accuracy:0.943765 valid-accuracy:0.863014\n",
      "\tIter:36 train-loss:0.323112 valid-loss:0.550139  train-accuracy:0.957213 valid-accuracy:0.876712\n",
      "\tIter:46 train-loss:0.269714 valid-loss:0.548402  train-accuracy:0.968215 valid-accuracy:0.890411\n",
      "\tIter:56 train-loss:0.226420 valid-loss:0.532888  train-accuracy:0.974328 valid-accuracy:0.890411\n",
      "\tIter:66 train-loss:0.189519 valid-loss:0.568572  train-accuracy:0.977995 valid-accuracy:0.876712\n",
      "\tIter:76 train-loss:0.164596 valid-loss:0.575260  train-accuracy:0.977995 valid-accuracy:0.904110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
