{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('titanic/train.csv')\n",
    "test_data = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['People'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['People'] = test_data['SibSp'] + test_data['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Size'] = train_data['Name'] .apply(lambda x : len(x))\n",
    "test_data['Size'] = test_data['Name'] .apply(lambda x : len(x))\n",
    "train_data = train_data.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch','Ticket', 'Cabin'])\n",
    "test_data = test_data.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch','Ticket', 'Cabin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Fare', 'Embarked',\n",
       "       'People', 'Size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mode()[0])\n",
    "test_data['Age'] = train_data['Age'].fillna(train_data['Age'].mode()[0])\n",
    "train_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\n",
    "test_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n",
    "test_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data, dtype='int')\n",
    "test_data = pd.get_dummies(test_data, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['Survived'])\n",
    "y_train = train_data['Survived'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Age', 'Fare', 'People', 'Sex_female', 'Sex_male',\n",
       "       'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(9,)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  for i in range(hp.Int('No. of Layers', min_value=1, max_value=7, step=1)):\n",
    "    model.add(keras.layers.Dense(units=hp.Int('n '+str(i), min_value = 32, max_value=512, step=32), activation='relu'))\n",
    "  dr = hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)\n",
    "  model.add(keras.layers.Dropout(dr))\n",
    "  model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.BinaryCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     directory='my_dir',\n",
    "                     factor = 70,\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.832402229309082\n",
      "\n",
      "Best val_accuracy So Far: 0.8603351712226868\n",
      "Total elapsed time: 00h 03m 48s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 1, dropout was 0.2 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=35, validation_split=0.2, callbacks=[stop_early])\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('No. of Layers')}, dropout was {best_hps.get('dropout')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1.2316 - accuracy: 0.6278 - val_loss: 0.9785 - val_accuracy: 0.6369\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9133 - accuracy: 0.6910 - val_loss: 0.4241 - val_accuracy: 0.8268\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.7402 - val_loss: 0.5204 - val_accuracy: 0.7765\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.7360 - val_loss: 0.4575 - val_accuracy: 0.7877\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7556 - val_loss: 0.3902 - val_accuracy: 0.8101\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7570 - val_loss: 0.5214 - val_accuracy: 0.7877\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7711 - val_loss: 0.5281 - val_accuracy: 0.8045\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.7514 - val_loss: 0.5048 - val_accuracy: 0.7933\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6124 - accuracy: 0.7374 - val_loss: 0.4021 - val_accuracy: 0.8045\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7767 - val_loss: 0.3806 - val_accuracy: 0.7933\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7865 - val_loss: 0.3852 - val_accuracy: 0.8212\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7837 - val_loss: 0.5087 - val_accuracy: 0.7989\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7725 - val_loss: 0.4628 - val_accuracy: 0.8045\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4945 - accuracy: 0.7851 - val_loss: 0.3706 - val_accuracy: 0.8436\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7626 - val_loss: 0.3963 - val_accuracy: 0.8268\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7739 - val_loss: 0.3758 - val_accuracy: 0.8156\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7865 - val_loss: 0.3741 - val_accuracy: 0.8603\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8034 - val_loss: 0.3562 - val_accuracy: 0.8547\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7978 - val_loss: 0.3694 - val_accuracy: 0.8492\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.8020 - val_loss: 0.4284 - val_accuracy: 0.8212\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7851 - val_loss: 0.3615 - val_accuracy: 0.8492\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7921 - val_loss: 0.4025 - val_accuracy: 0.8324\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7711 - val_loss: 0.3587 - val_accuracy: 0.8492\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7767 - val_loss: 0.3853 - val_accuracy: 0.8492\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7865 - val_loss: 0.3694 - val_accuracy: 0.8603\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7809 - val_loss: 0.3541 - val_accuracy: 0.8380\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.8034 - val_loss: 0.3681 - val_accuracy: 0.8603\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7879 - val_loss: 0.3746 - val_accuracy: 0.8547\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.8006 - val_loss: 0.4063 - val_accuracy: 0.8436\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.8006 - val_loss: 0.3698 - val_accuracy: 0.8492\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8076 - val_loss: 0.3518 - val_accuracy: 0.8603\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7865 - val_loss: 0.3615 - val_accuracy: 0.8547\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7935 - val_loss: 0.3551 - val_accuracy: 0.8547\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4509 - accuracy: 0.8048 - val_loss: 0.3676 - val_accuracy: 0.8436\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7767 - val_loss: 0.3694 - val_accuracy: 0.8436\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7992 - val_loss: 0.3544 - val_accuracy: 0.8603\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7907 - val_loss: 0.3396 - val_accuracy: 0.8603\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7992 - val_loss: 0.3537 - val_accuracy: 0.8603\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.3802 - val_accuracy: 0.8603\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.3627 - val_accuracy: 0.8603\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.7851 - val_loss: 0.4045 - val_accuracy: 0.8436\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.8034 - val_loss: 0.3507 - val_accuracy: 0.8436\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.8118 - val_loss: 0.4401 - val_accuracy: 0.8436\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4916 - accuracy: 0.7837 - val_loss: 0.4167 - val_accuracy: 0.8268\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7992 - val_loss: 0.3539 - val_accuracy: 0.8492\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7893 - val_loss: 0.3518 - val_accuracy: 0.8547\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7865 - val_loss: 0.3635 - val_accuracy: 0.8492\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7949 - val_loss: 0.3858 - val_accuracy: 0.8547\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7851 - val_loss: 0.3641 - val_accuracy: 0.8492\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7907 - val_loss: 0.3424 - val_accuracy: 0.8547\n",
      "Best epoch: 17\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1.5876 - accuracy: 0.6222 - val_loss: 0.5021 - val_accuracy: 0.7765\n",
      "Epoch 2/17\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.7121 - val_loss: 0.4236 - val_accuracy: 0.7821\n",
      "Epoch 3/17\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.6507 - accuracy: 0.7430 - val_loss: 0.3967 - val_accuracy: 0.8268\n",
      "Epoch 4/17\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7640 - val_loss: 0.3993 - val_accuracy: 0.8101\n",
      "Epoch 5/17\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6305 - accuracy: 0.7486 - val_loss: 0.6687 - val_accuracy: 0.7151\n",
      "Epoch 6/17\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.7069 - accuracy: 0.7163 - val_loss: 0.5554 - val_accuracy: 0.7654\n",
      "Epoch 7/17\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.7360 - val_loss: 0.4917 - val_accuracy: 0.7654\n",
      "Epoch 8/17\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.7444 - val_loss: 0.4784 - val_accuracy: 0.8156\n",
      "Epoch 9/17\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7879 - val_loss: 0.4205 - val_accuracy: 0.8156\n",
      "Epoch 10/17\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.7963 - val_loss: 0.5235 - val_accuracy: 0.7877\n",
      "Epoch 11/17\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7823 - val_loss: 0.4258 - val_accuracy: 0.8268\n",
      "Epoch 12/17\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7781 - val_loss: 0.4177 - val_accuracy: 0.8212\n",
      "Epoch 13/17\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7851 - val_loss: 0.3939 - val_accuracy: 0.7933\n",
      "Epoch 14/17\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7879 - val_loss: 0.4200 - val_accuracy: 0.8101\n",
      "Epoch 15/17\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7795 - val_loss: 0.3803 - val_accuracy: 0.8324\n",
      "Epoch 16/17\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7893 - val_loss: 0.3950 - val_accuracy: 0.7933\n",
      "Epoch 17/17\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7626 - val_loss: 0.3916 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x704ac0bf6a50>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71559626], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = F1Score()\n",
    "y_true = y_train[:178].to_numpy().reshape(178,1)\n",
    "y_pred = np.round(hypermodel.predict(X_train[:178])).astype('int')\n",
    "m.update_state(y_true, y_pred)\n",
    "res = m.result()\n",
    "res.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 734us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = hypermodel.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = np.round(predictions,0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('titanic/test.csv')\n",
    "# print(t[\"PassengerId\"].shape, survived.shape)\n",
    "answer = pd.DataFrame({\"PassengerId\" : t[\"PassengerId\"], \"Survived\":survived.ravel()})\n",
    "answer.to_csv('titanic/predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No. of Layers': 6,\n",
       " 'n 0': 64,\n",
       " 'dropout': 0.1,\n",
       " 'learning_rate': 0.001,\n",
       " 'n 1': 480,\n",
       " 'n 2': 128,\n",
       " 'n 3': 128,\n",
       " 'n 4': 384,\n",
       " 'n 5': 448,\n",
       " 'n 6': 32,\n",
       " 'n 7': 192,\n",
       " 'n 8': 96,\n",
       " 'n 9': 128,\n",
       " 'n 10': 224,\n",
       " 'tuner/epochs': 100,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 0,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow_decision_forests.keras import pd_dataframe_to_tf_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert Survived, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_71033/4090388752.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_dataframe_to_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m418\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5141\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5142\u001b[0m             )\n\u001b[1;32m   5143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5144\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5145\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5147\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5148\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert Survived, already exists"
     ]
    }
   ],
   "source": [
    "train_ds = pd_dataframe_to_tf_dataset(train_data, label='Survived')\n",
    "# test_ds = test_data.insert(column=\"Survived\",value=[0]*418, loc=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>People</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age     Fare  People  Sex_female  Sex_male  Embarked_C  \\\n",
       "0         3  22.0   7.2500       1           0         1           0   \n",
       "1         3  38.0  71.2833       2           1         0           1   \n",
       "2         2  26.0   7.9250       1           0         1           0   \n",
       "3         3  35.0  53.1000       1           0         1           0   \n",
       "4         3  35.0   8.0500       3           1         0           0   \n",
       "..      ...   ...      ...     ...         ...       ...         ...   \n",
       "413       3  24.0   0.0000       1           0         1           0   \n",
       "414       1  44.0   7.9250       1           1         0           0   \n",
       "415       3  24.0   8.0500       1           0         1           0   \n",
       "416       3  34.0  32.5000       1           0         1           0   \n",
       "417       3  18.0  13.0000       3           0         1           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  Survived  \n",
       "0             0           1         0  \n",
       "1             0           0         0  \n",
       "2             0           1         0  \n",
       "3             0           1         0  \n",
       "4             0           1         0  \n",
       "..          ...         ...       ...  \n",
       "413           0           1         0  \n",
       "414           0           1         0  \n",
       "415           0           1         0  \n",
       "416           0           1         0  \n",
       "417           0           1         0  \n",
       "\n",
       "[418 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds = pd_dataframe_to_tf_dataset(train_data[:178], label='Survived')\n",
    "test_ds = pd_dataframe_to_tf_dataset(test_data, label='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp8emijaf_ as temporary training directory\n",
      "Warning: Model constructor argument validation_split=0.2 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument validation_split=0.2 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.110156. Found 713 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.085700\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-22 06:48:38.1120 UTC kernel.cc:1233] Loading model from path /tmp/tmp8emijaf_/model/ with prefix cce4213c9f9e4ee2\n",
      "[INFO 24-02-22 06:48:38.1404 UTC decision_forest.cc:660] Model loaded with 300 root(s), 37318 node(s), and 9 input feature(s).\n",
      "[INFO 24-02-22 06:48:38.1404 UTC abstract_model.cc:1344] Engine \"RandomForestOptPred\" built\n",
      "[INFO 24-02-22 06:48:38.1404 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x704bdc60b950>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tfdf.keras.RandomForestModel()\n",
    "model.fit(train_ds, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy without hyper-parameter tuning: 0.8202\n"
     ]
    }
   ],
   "source": [
    "model.compile([\"accuracy\"])\n",
    "test_accuracy = model.evaluate(test_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy without hyper-parameter tuning: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_decision_forests.component.tuner.tuner.SearchSpace at 0x704bc47d3e90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = tfdf.tuner.RandomSearch(num_trials=1100)\n",
    "tuner.choice(\"min_examples\", [2, 5, 7, 10, 14, 21])\n",
    "tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
    "local_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\n",
    "local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8, 10, 12, 14])\n",
    "global_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\n",
    "global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256, 512])\n",
    "tuner.choice(\"use_hessian_gain\", [True, False])\n",
    "tuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30])\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
    "tuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\n",
    "oblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\n",
    "oblique_space.choice(\"sparse_oblique_normalization\",\n",
    "                     [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\n",
    "oblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\n",
    "oblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5, 2.0, 2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp67f8kk_x as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'Pclass': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'Age': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'Fare': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'People': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'Sex_female': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'Sex_male': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'Embarked_C': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>, 'Embarked_Q': <tf.Tensor 'data_7:0' shape=(None,) dtype=int64>, 'Embarked_S': <tf.Tensor 'data_8:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_9:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'Pclass': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Age': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Fare': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'People': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Sex_female': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'Sex_male': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'Embarked_C': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'Embarked_Q': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'Embarked_S': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>)}\n",
      "Training dataset read in 0:00:00.116031. Found 891 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-02-22 06:52:12.5711 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:52:12.5711 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:52:12.5711 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-22 06:52:12.7017 UTC kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-02-22 06:52:12.7017 UTC kernel.cc:772] Collect training examples\n",
      "[INFO 24-02-22 06:52:12.7017 UTC kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-02-22 06:52:12.7018 UTC kernel.cc:391] Number of batches: 1\n",
      "[INFO 24-02-22 06:52:12.7018 UTC kernel.cc:392] Number of examples: 891\n",
      "[INFO 24-02-22 06:52:12.7018 UTC kernel.cc:792] Training dataset:\n",
      "Number of records: 891\n",
      "Number of columns: 10\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 9 (90%)\n",
      "\tCATEGORICAL: 1 (10%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 9 (90%)\n",
      "\t0: \"Age\" NUMERICAL mean:28.567 min:0.42 max:80 sd:13.1922\n",
      "\t1: \"Embarked_C\" NUMERICAL mean:0.188552 min:0 max:1 sd:0.391152\n",
      "\t2: \"Embarked_Q\" NUMERICAL mean:0.0864198 min:0 max:1 sd:0.280983\n",
      "\t3: \"Embarked_S\" NUMERICAL mean:0.725028 min:0 max:1 sd:0.4465\n",
      "\t4: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n",
      "\t5: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n",
      "\t6: \"People\" NUMERICAL mean:1.9046 min:1 max:11 sd:1.61255\n",
      "\t7: \"Sex_female\" NUMERICAL mean:0.352413 min:0 max:1 sd:0.477722\n",
      "\t8: \"Sex_male\" NUMERICAL mean:0.647587 min:0 max:1 sd:0.477722\n",
      "\n",
      "CATEGORICAL: 1 (10%)\n",
      "\t9: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-02-22 06:52:12.7018 UTC kernel.cc:808] Configure learner\n",
      "[WARNING 24-02-22 06:52:12.7020 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:52:12.7020 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:52:12.7020 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-22 06:52:12.7020 UTC kernel.cc:822] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Embarked_C$\"\n",
      "features: \"^Embarked_Q$\"\n",
      "features: \"^Embarked_S$\"\n",
      "features: \"^Fare$\"\n",
      "features: \"^Pclass$\"\n",
      "features: \"^People$\"\n",
      "features: \"^Sex_female$\"\n",
      "features: \"^Sex_male$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "    features: \"^Age$\"\n",
      "    features: \"^Embarked_C$\"\n",
      "    features: \"^Embarked_Q$\"\n",
      "    features: \"^Embarked_S$\"\n",
      "    features: \"^Fare$\"\n",
      "    features: \"^Pclass$\"\n",
      "    features: \"^People$\"\n",
      "    features: \"^Sex_female$\"\n",
      "    features: \"^Sex_male$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: CLASSIFICATION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 6\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: -1\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      shrinkage: 0.1\n",
      "      loss: DEFAULT\n",
      "      validation_set_ratio: 0.1\n",
      "      validation_interval_in_trees: 1\n",
      "      early_stopping: VALIDATION_LOSS_INCREASE\n",
      "      early_stopping_num_trees_look_ahead: 30\n",
      "      l2_regularization: 0\n",
      "      lambda_loss: 1\n",
      "      mart {\n",
      "      }\n",
      "      adapt_subsample_for_maximum_training_duration: false\n",
      "      l1_regularization: 0\n",
      "      use_hessian_gain: false\n",
      "      l2_regularization_categorical: 1\n",
      "      stochastic_gradient_boosting {\n",
      "        ratio: 1\n",
      "      }\n",
      "      apply_link_function: true\n",
      "      compute_permutation_variable_importance: false\n",
      "      binary_focal_loss_options {\n",
      "        misprediction_exponent: 2\n",
      "        positive_sample_coefficient: 0.5\n",
      "      }\n",
      "      early_stopping_initial_iteration: 10\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 1100\n",
      "    }\n",
      "  }\n",
      "  search_space {\n",
      "    fields {\n",
      "      name: \"min_examples\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: 2\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 5\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 7\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 10\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 14\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 21\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"categorical_algorithm\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"CART\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"RANDOM\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"growing_strategy\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"LOCAL\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"BEST_FIRST_GLOBAL\"\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"max_depth\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            integer: 3\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 4\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 5\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 6\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 8\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 10\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 12\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 14\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"LOCAL\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"max_num_nodes\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            integer: 16\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 32\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 64\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 128\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 256\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 512\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"BEST_FIRST_GLOBAL\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"use_hessian_gain\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"true\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"false\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"shrinkage\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          real: 0.02\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.05\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.1\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.15\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.2\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.25\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.3\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"num_candidate_attributes_ratio\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          real: 0.2\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.5\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.9\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"split_axis\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"AXIS_ALIGNED\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"SPARSE_OBLIQUE\"\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_normalization\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            categorical: \"NONE\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"STANDARD_DEVIATION\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"MIN_MAX\"\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_weights\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            categorical: \"BINARY\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"CONTINUOUS\"\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_num_projections_exponent\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            real: 1\n",
      "          }\n",
      "          possible_values {\n",
      "            real: 1.5\n",
      "          }\n",
      "          possible_values {\n",
      "            real: 2\n",
      "          }\n",
      "          possible_values {\n",
      "            real: 2.5\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:52:12.7021 UTC kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmp67f8kk_x/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-02-22 06:52:12.7024 UTC kernel.cc:887] Train model\n",
      "[INFO 24-02-22 06:52:12.7026 UTC hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 2\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 7\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 14\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 21\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"LOCAL\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"BEST_FIRST_GLOBAL\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_depth\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 5\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 6\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 8\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 10\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 12\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 14\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"LOCAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_num_nodes\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 16\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 32\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 64\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 128\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 256\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 512\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"BEST_FIRST_GLOBAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"false\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.02\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.05\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.1\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.15\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.25\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.3\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.5\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.9\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_num_projections_exponent\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 1.5\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2.5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:52:12.7027 UTC hyperparameters_optimizer.cc:500] Start local tuner with 16 thread(s)\n",
      "[INFO[INFO 24-02-22 06:52:12.7040 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD 24-02-22 06:52:12.7040 UTC \n",
      "gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:12.7040 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[[INFOINFO 24-02-22 06:52:12.7040 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and [INFO9 feature(s).\n",
      " 24-02-22 06:52:12.7040 UTC  24-02-22 06:52:12.7040 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:12.7041 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:12.7041 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:12.7041 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:12.7041 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:12.7042 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:12.7042 UTC gradient_boosted_trees.cc:1218[INFO] Training gradient boosted tree on 891 24-02-22 06:52:12.7042 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD example(s) and 9 feature(s).\n",
      "\n",
      "[INFO 24-02-22 06:52:12.7042 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO[INFO 24-02-22 06:52:12.7042 UTC gradient_boosted_trees.cc:591]  24-02-22 06:52:12.7042 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " examples used for validation\n",
      "[INFO 24-02-22 06:52:12.7042 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO[INFO 24-02-22 06:52:12.7042 UTC gradient_boosted_trees.cc:[ 24-02-22 06:52:12.7043 UTC gradient_boosted_trees.cc:591INFO591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "]  24-02-22 06:52:12.7043 UTC gradient_boosted_trees.cc:Default loss set to [[BINOMIAL_LOG_LIKELIHOODINFO\n",
      "[[INFOINFO1261] 818 24-02-22 06:52:12.7043 UTC  24-02-22 06:52:12.7043 UTC  examples used for training and 73 examples used for validationINFO 24-02-22 06:52:12.7043 UTC gradient_boosted_trees.ccgradient_boosted_trees.cc 24-02-22 06:52:12.7043 UTC \n",
      "gradient_boosted_trees.cc::1261] 818 examples used for training and :gradient_boosted_trees.cc591] Default loss set to BINOMIAL_LOG_LIKELIHOOD121873: examples used for validation\n",
      "] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-22 06:52:12.7043 UTC gradient_boosted_trees.ccINFO1218] Training gradient boosted tree on 891 example(s) and 9[ 24-02-22 06:52:12.7044 UTC [ feature(s).INFO\n",
      "INFO 24-02-22 06:52:12.7044 UTC gradient_boosted_trees.ccgradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD:1261] 818 24-02-22 06:52:12.7044 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " examples used for training and [INFO73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.7044 UTC :[INFO 24-02-22 06:52:12.7044 UTC 1261] [gradient_boosted_trees.ccINFO 24-02-22 06:52:12.7044 UTC :gradient_boosted_trees.cc\n",
      " 24-02-22 06:52:12.7044 UTC 1261gradient_boosted_trees.cc:1261] 818[INFO examples used for training and \n",
      " 24-02-22 06:52:12.7044 UTC :1218] [gradient_boosted_trees.cc:gradient_boosted_trees.ccTraining gradient boosted tree on :1218] Training gradient boosted tree on 818891 examples used for training and  example(s) and 973 feature(s).INFO] 591 24-02-22 06:52:12.7045 UTC gradient_boosted_trees.cc[:891\n",
      "INFO] Default loss set to  examples used for validation example(s) and  24-02-22 06:52:12.7045 UTC \n",
      "591[73gradient_boosted_trees.cc examples used for validation818INFO] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "\n",
      "[INFO 24-02-22 06:52:12.7045 UTC gradient_boosted_trees.cc:1218:BINOMIAL_LOG_LIKELIHOOD9\n",
      "1218] Training gradient boosted tree on  feature(s).\n",
      " 24-02-22 06:52:12.7045 UTC 891 examples used for training and ] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "73 examples used for validation[gradient_boosted_trees.cc:1261] 818 examples used for training and 73 example(s) and [INFO[INFO examples used for validation 24-02-22 06:52:12.7045 UTC \n",
      "9 feature(s).\n",
      " 24-02-22 06:52:12.7045 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-22 06:52:12.7046 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      " 24-02-22 06:52:12.7046 UTC gradient_boosted_trees.ccgradient_boosted_trees.cc:1261] 818 examples used for training and 73:1261] 818 examples used for training and 73 examples used for validation\n",
      " examples used for validation\n",
      "[INFO 24-02-22 06:52:12.7046 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.7047 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.7047 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.7047 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.7047 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "INFO 24-02-22 06:52:12.7049 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:12.7051 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.7066 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.164205 train-accuracy:0.612469 valid-loss:1.133167 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.7066 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190321 train-accuracy:0.612469 valid-loss:1.132398 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.7069 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315816 train-accuracy:0.612469 valid-loss:1.273794 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.7079 UTC gradient_boosted_trees.cc:1638] \tnum-trees:2 train-loss:1.039638 train-accuracy:0.839853 valid-loss:1.017572 valid-accuracy:0.890411\n",
      "\n",
      "[INFO 24-02-22 06:52:12.7098 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314193 train-accuracy:0.612469 valid-loss:1.272817 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.7098 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.075505 train-accuracy:0.804401 valid-loss:1.040988 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:12.7108 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.065701 train-accuracy:0.832518 valid-loss:1.041587 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:12.7163 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.100601 train-accuracy:0.827628 valid-loss:1.066768 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:12.7166 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.095281 train-accuracy:0.817848 valid-loss:1.067494 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:12.7180 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.018021 train-accuracy:0.869193 valid-loss:1.042523 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:12.7183 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.052283 train-accuracy:0.819071 valid-loss:1.042057 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:12.7198 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182365 train-accuracy:0.612469 valid-loss:1.149245 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.7225 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289999 train-accuracy:0.612469 valid-loss:1.244988 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.7266 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159043 train-accuracy:0.612469 valid-loss:1.141635 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.7294 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121196 train-accuracy:0.808068 valid-loss:1.056015 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:12.7778 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.128867 train-accuracy:0.786064 valid-loss:1.097591 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:52:12.7855 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209427 train-accuracy:0.612469 valid-loss:1.185846 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.8152 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645815\n",
      "[INFO 24-02-22 06:52:12.8152 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:52:12.8173 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.645815 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:12.8186 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:12.8186 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:12.8187 UTC hyperparameters_optimizer.cc:582] [1/1100] Score: -0.645815 / -0.645815 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:12.8189 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.8221 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226706 train-accuracy:0.612469 valid-loss:1.203646 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.8651 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599763\n",
      "[INFO 24-02-22 06:52:12.8657 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:52:12.8663 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.599763 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:12.8699 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.585609\n",
      "[INFO 24-02-22 06:52:12.8699 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:52:12.8701 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.585609 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:12.8708 UTC hyperparameters_optimizer.cc:582] [2/1100] Score: -0.585609 / -0.585609 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:12.8717 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:12.8717 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:12.8721 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.8726 UTC hyperparameters_optimizer.cc:582] [3/1100] Score: -0.599763 / -0.585609 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:12.8739 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:12.8739 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:12.8741 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.8845 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.56893\n",
      "[INFO 24-02-22 06:52:12.8845 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:52:12.8846 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.568930 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:12.8853 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:12.8853 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:12.8853 UTC hyperparameters_optimizer.cc:582] [4/1100] Score: -0.56893 / -0.56893 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:12.8870 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:12.8942 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085730 train-accuracy:0.833741 valid-loss:1.059826 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:12.9180 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276242 train-accuracy:0.612469 valid-loss:1.246026 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:12.9549 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.049212 train-accuracy:0.834963 valid-loss:1.034807 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:13.0229 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634661\n",
      "[INFO 24-02-22 06:52:13.0229 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.0231 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.634661 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.0236 UTC hyperparameters_optimizer.cc:582] [5/1100] Score: -0.634661 / -0.56893 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:13.0249 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.0249 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.0254 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.0590 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.253455 train-accuracy:0.612469 valid-loss:1.238585 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.2508 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615607\n",
      "[INFO 24-02-22 06:52:13.2508 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.2512 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.615607 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.2525 UTC hyperparameters_optimizer.cc:582] [6/1100] Score: -0.615607 / -0.56893 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:13.2550 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.2550 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.2553 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.3041 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.131184 train-accuracy:0.773839 valid-loss:1.127911 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:52:13.3849 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.491973 train-accuracy:0.913203 valid-loss:0.602064 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.3850 UTC gradient_boosted_trees.cc:271] Truncates the model to 291 tree(s) i.e. 291  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.3850 UTC gradient_boosted_trees.cc:334] Final model num-trees:291 valid-loss:0.601437 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.3870 UTC hyperparameters_optimizer.cc:582] [7/1100] Score: -0.601437 / -0.56893 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:13.3914 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.3914 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.3917 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.4014 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.073011 train-accuracy:0.831296 valid-loss:1.039561 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:13.4058 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664715\n",
      "[INFO 24-02-22 06:52:13.4058 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.4062 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.664715 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.4064 UTC hyperparameters_optimizer.cc:582] [8/1100] Score: -0.664715 / -0.56893 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:13.4074 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.4075 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.4077 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.4120 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287825 train-accuracy:0.612469 valid-loss:1.245016 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.5693 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.714605\n",
      "[INFO 24-02-22 06:52:13.5694 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.5700 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.714605 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.5704 UTC hyperparameters_optimizer.cc:582] [9/1100] Score: -0.714605 / -0.56893 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:13.5721 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.5721 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.5723 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.5776 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.068169 train-accuracy:0.823961 valid-loss:1.014039 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.5913 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629326\n",
      "[INFO 24-02-22 06:52:13.5914 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.5915 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.629326 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:13.5919 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.5919 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.5921 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.5953 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.134896 train-accuracy:0.799511 valid-loss:1.085033 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:13.5954 UTC hyperparameters_optimizer.cc:582] [10/1100] Score: -0.629326 / -0.56893 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:13.6141 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643946\n",
      "[INFO 24-02-22 06:52:13.6141 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.6145 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.643946 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:13.6148 UTC hyperparameters_optimizer.cc:582] [11/1100] Score: -0.643946 / -0.56893 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:13.6154 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.6154 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.6156 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.6259 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.503908\n",
      "[INFO 24-02-22 06:52:13.6259 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.6261 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.503908 valid-accuracy:0.890411\n",
      "[[INFOINFO 24-02-22 06:52:13.6267 UTC hyperparameters_optimizer.cc 24-02-22 06:52:13.6267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      ":582] [12[INFO/1100] Score:  24-02-22 06:52:13.6267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9-0.503908 / -0.503908 HParams:  feature(s).\n",
      "fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:13.6269 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.6272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.143591 train-accuracy:0.612469 valid-loss:1.137907 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.6397 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653731\n",
      "[INFO 24-02-22 06:52:13.6397 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:13.6406 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:13.6406 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.653731 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.6410 UTC hyperparameters_optimizer.cc:582] [13/1100] Score: -0.653731 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:13.6420 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.6420 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.6425 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.6437 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.197199 train-accuracy:0.612469 valid-loss:1.159089 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.6667 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285439 train-accuracy:0.612469 valid-loss:1.246917 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.7141 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677357\n",
      "[INFO 24-02-22 06:52:13.7142 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.7143 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.677357 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:13.7145 UTC hyperparameters_optimizer.cc:582] [14/1100] Score: -0.677357 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:13.7156 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.7162 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.7167 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.7308 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313806 train-accuracy:0.612469 valid-loss:1.274964 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.7878 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676131\n",
      "[INFO 24-02-22 06:52:13.7878 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.7881 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.676131 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.7883 UTC hyperparameters_optimizer.cc:582] [15/1100] Score: -0.676131 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:13.7897 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.7920 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.7923 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.7945 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241570 train-accuracy:0.612469 valid-loss:1.208747 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.9256 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.586386\n",
      "[INFO 24-02-22 06:52:13.9256 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.9256 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.586386 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:13.9258 UTC hyperparameters_optimizer.cc:582] [16/1100] Score: -0.586386 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:13.9262 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.9262 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.9265 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.9490 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593186\n",
      "[INFO 24-02-22 06:52:13.9491 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.9494 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.593186 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:13.9499 UTC hyperparameters_optimizer.cc:582] [17/1100] Score: -0.593186 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:13.9506 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.9506 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.9509 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:13.9570 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275165 train-accuracy:0.612469 valid-loss:1.245438 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.9571 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186774 train-accuracy:0.612469 valid-loss:1.144765 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:13.9909 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617288\n",
      "[INFO 24-02-22 06:52:13.9929 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:52:13.9930 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.617288 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:13.9934 UTC hyperparameters_optimizer.cc:582] [18/1100] Score: -0.617288 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:13.9936 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:13.9936 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:13.9939 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.0019 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191036 train-accuracy:0.612469 valid-loss:1.183483 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:14.1021 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63702\n",
      "[INFO 24-02-22 06:52:14.1022 UTC gradient_boosted_trees.cc:271] Truncates the model to 203 tree(s) i.e. 203  iteration(s).\n",
      "[INFO 24-02-22 06:52:14.1023 UTC gradient_boosted_trees.cc:334] Final model num-trees:203 valid-loss:0.637020 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:14.1037 UTC hyperparameters_optimizer.cc:582] [19/1100] Score: -0.63702 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:14.1042 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:14.1043 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:14.1062 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.1398 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.136112 train-accuracy:0.612469 valid-loss:1.149606 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:14.1999 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606755\n",
      "[INFO 24-02-22 06:52:14.2012 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:14.2019 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.606755 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:14.2025 UTC hyperparameters_optimizer.cc:582] [20/1100] Score: -0.606755 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:14.2036 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:14.2036 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:14.2041 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.2097 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.566428\n",
      "[INFO 24-02-22 06:52:14.2097 UTC gradient_boosted_trees.cc:271] Truncates the model to 203 tree(s) i.e. 203  iteration(s).\n",
      "[INFO 24-02-22 06:52:14.2098 UTC gradient_boosted_trees.cc:334] Final model num-trees:203 valid-loss:0.566428 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:14.2105 UTC hyperparameters_optimizer.cc:582] [21/1100] Score: -0.566428 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:14.2117 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:14.2119 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:14.2122 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.2276 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229481 train-accuracy:0.612469 valid-loss:1.193106 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:14.2594 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313035 train-accuracy:0.612469 valid-loss:1.273130 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:14.2647 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64275\n",
      "[INFO 24-02-22 06:52:14.2647 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:14.2656 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.642750 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:14.2663 UTC hyperparameters_optimizer.cc:582] [22/1100] Score: -0.64275 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:14.2675 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:14.2675 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:14.2685 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.2705 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233949 train-accuracy:0.612469 valid-loss:1.184032 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:14.4793 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.60253\n",
      "[INFO 24-02-22 06:52:14.4794 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:52:14.4798 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.602530 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:14.4807 UTC hyperparameters_optimizer.cc:582] [23/1100] Score: -0.60253 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:14.4811 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:14.4811 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:14.4815 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.4910 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.078383 train-accuracy:0.795844 valid-loss:1.037319 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:14.4981 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6314\n",
      "[INFO 24-02-22 06:52:14.4982 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:52:14.4984 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.631400 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:14.4990 UTC hyperparameters_optimizer.cc:582] [24/1100] Score: -0.6314 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:14.5005 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:14.5007 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:14.5011 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.5032 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315471 train-accuracy:0.612469 valid-loss:1.274448 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:14.5212 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.618578\n",
      "[INFO 24-02-22 06:52:14.5212 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:52:14.5243 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.618578 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:14.5258 UTC hyperparameters_optimizer.cc:582] [25/1100] Score: -0.618578 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:14.5324 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:14.5325 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:14.5334 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.5463 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.099886 train-accuracy:0.842298 valid-loss:1.059202 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:14.8730 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.693484\n",
      "[INFO 24-02-22 06:52:14.8730 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:14.8733 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.693484 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 06:52:14.8746 UTC hyperparameters_optimizer.cc:582] [26/1100] Score: -0.693484 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:52:14.8750 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:14.8750 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:14.8754 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:14.9272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281634 train-accuracy:0.612469 valid-loss:1.247485 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:15.1317 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.502060 train-accuracy:0.910758 valid-loss:0.593983 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:15.1317 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.1317 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.593831 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:15.1335 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.1335 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.1337 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.1355 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.147898 train-accuracy:0.784841 valid-loss:1.084295 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:15.1387 UTC hyperparameters_optimizer.cc:582] [27/1100] Score: -0.593831 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:15.2734 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662786\n",
      "[INFO 24-02-22 06:52:15.2734 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.2736 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.662786 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:15.2737 UTC hyperparameters_optimizer.cc:582] [28/1100] Score: -0.662786 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:15.2741 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.2742 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.2745 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.2773 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.169833 train-accuracy:0.612469 valid-loss:1.149661 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:15.3124 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.58492\n",
      "[INFO 24-02-22 06:52:15.3125 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.3127 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.584920 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:15.3129 UTC hyperparameters_optimizer.cc:582] [29/1100] Score: -0.58492 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:15.3132 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.3132 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.3134 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.3551 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588046\n",
      "[INFO 24-02-22 06:52:15.3551 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.3553 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.588046 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:15.3559 UTC hyperparameters_optimizer.cc:582] [30/1100] Score: -0.588046 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:15.3570 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.3570 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.3572 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.3598 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313055 train-accuracy:0.612469 valid-loss:1.272387 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:15.3678 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063719 train-accuracy:0.832518 valid-loss:1.033268 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:15.4813 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639925\n",
      "[INFO 24-02-22 06:52:15.4814 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.4816 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.639925 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:15.4822 UTC hyperparameters_optimizer.cc:582] [31/1100] Score: -0.639925 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:15.4828 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.4828 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.4834 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.4888 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.254090 train-accuracy:0.612469 valid-loss:1.202201 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:15.5376 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.559566\n",
      "[INFO 24-02-22 06:52:15.5376 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.5379 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.559566 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:15.5383 UTC hyperparameters_optimizer.cc:582] [32/1100] Score: -0.559566 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:15.5398 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.5398 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.5400 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.5678 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.613429\n",
      "[INFO 24-02-22 06:52:15.5678 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.5679 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.613429 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:15.5682 UTC hyperparameters_optimizer.cc:582] [33/1100] Score: -0.613429 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:15.5690 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.5690 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.5692 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.5934 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094939 train-accuracy:0.814181 valid-loss:1.087596 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:52:15.5969 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196391 train-accuracy:0.612469 valid-loss:1.154914 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:15.6400 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643561\n",
      "[INFO 24-02-22 06:52:15.6400 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.6404 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.643561 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:15.6414 UTC hyperparameters_optimizer.cc:582] [34/1100] Score: -0.643561 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:15.6426 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.6426 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.6436 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.6461 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235209 train-accuracy:0.612469 valid-loss:1.199373 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:15.7468 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640006\n",
      "[INFO 24-02-22 06:52:15.7469 UTC gradient_boosted_trees.cc:271] Truncates the model to 152 tree(s) i.e. 152  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.7471 UTC gradient_boosted_trees.cc:334] Final model num-trees:152 valid-loss:0.640006 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:15.7489 UTC hyperparameters_optimizer.cc:582] [35/1100] Score: -0.640006 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:15.7517 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.7517 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.7519 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.7644 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631039\n",
      "[INFO 24-02-22 06:52:15.7644 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.7646 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.631039 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:15.7652 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.7652 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.7654 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.7687 UTC hyperparameters_optimizer.cc:582] [36/1100] Score: -0.631039 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:15.7693 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103147 train-accuracy:0.819071 valid-loss:1.125643 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:15.8073 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.032754 train-accuracy:0.864303 valid-loss:1.028699 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:15.8847 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66127\n",
      "[INFO 24-02-22 06:52:15.8848 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.8856 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.661270 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:15.8864 UTC hyperparameters_optimizer.cc:582] [37/1100] Score: -0.66127 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:15.8878 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.8878 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.8886 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.9518 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640317\n",
      "[INFO 24-02-22 06:52:15.9519 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.9541 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.640317 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:15.9547 UTC hyperparameters_optimizer.cc:582] [38/1100] Score: -0.640317 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:15.9580 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.9591 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.9593 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.9870 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.998630 train-accuracy:0.849633 valid-loss:1.020043 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:15.9893 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666041\n",
      "[INFO 24-02-22 06:52:15.9893 UTC gradient_boosted_trees.cc:271] Truncates the model to 157 tree(s) i.e. 157  iteration(s).\n",
      "[INFO 24-02-22 06:52:15.9895 UTC gradient_boosted_trees.cc:334] Final model num-trees:157 valid-loss:0.666041 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:15.9907 UTC hyperparameters_optimizer.cc:582] [39/1100] Score: -0.666041 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:15.9929 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:15.9929 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:15.9931 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:15.9981 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313121 train-accuracy:0.612469 valid-loss:1.272374 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:16.0097 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.027505 train-accuracy:0.856968 valid-loss:0.973444 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:16.3189 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.598319\n",
      "[INFO 24-02-22 06:52:16.3189 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:52:16.3191 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.598319 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:16.3193 UTC hyperparameters_optimizer.cc:582] [40/1100] Score: -0.598319 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:16.3199 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:16.3199 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:16.3201 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:16.3606 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646619\n",
      "[INFO 24-02-22 06:52:16.3607 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-22 06:52:16.3610 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.646619 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 06:52:16.3638 UTC hyperparameters_optimizer.cc:582] [41/1100] Score: -0.646619 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "INFO 24-02-22 06:52:16.3651 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:16.3651 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:16.3667 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:16.3943 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240193 train-accuracy:0.612469 valid-loss:1.194980 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:16.4038 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.271080 train-accuracy:0.612469 valid-loss:1.231129 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:16.6388 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649778\n",
      "[INFO 24-02-22 06:52:16.6388 UTC gradient_boosted_trees.cc:271] Truncates the model to 169 tree(s) i.e. 169  iteration(s).\n",
      "[INFO 24-02-22 06:52:16.6389 UTC gradient_boosted_trees.cc:334] Final model num-trees:169 valid-loss:0.649778 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:16.6394 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:16.6394 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:16.6395 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:16.6405 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.135750 train-accuracy:0.799511 valid-loss:1.095354 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:16.6420 UTC hyperparameters_optimizer.cc:582] [42/1100] Score: -0.649778 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:16.7148 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662044\n",
      "[INFO 24-02-22 06:52:16.7148 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:52:16.7149 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.662044 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:16.7151 UTC hyperparameters_optimizer.cc:582] [43/1100] Score: -0.662044 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:16.7156 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:16.7157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:16.7160 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:16.7366 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.192772 train-accuracy:0.612469 valid-loss:1.167074 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:16.8601 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.612097\n",
      "[INFO 24-02-22 06:52:16.8601 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:16.8605 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.612097 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:16.8609 UTC hyperparameters_optimizer.cc:582] [44/1100] Score: -0.612097 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:16.8628 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:16.8628 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:16.8644 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:16.9054 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.178297 train-accuracy:0.612469 valid-loss:1.144813 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:17.0012 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666539\n",
      "[INFO 24-02-22 06:52:17.0013 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:52:17.0016 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.666539 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:17.0030 UTC hyperparameters_optimizer.cc:582] [45/1100] Score: -0.666539 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:17.0055 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.0058 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.0062 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.0160 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284358 train-accuracy:0.612469 valid-loss:1.243270 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:17.5622 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.766761\n",
      "[INFO 24-02-22 06:52:17.5622 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:52:17.5641 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.766761 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:17.5698 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.5699 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.5701 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.5720 UTC hyperparameters_optimizer.cc:582] [46/1100] Score: -0.766761 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:17.5926 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288142 train-accuracy:0.612469 valid-loss:1.241258 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:17.6547 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.620427\n",
      "[INFO 24-02-22 06:52:17.6547 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:52:17.6548 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.620427 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:17.6551 UTC hyperparameters_optimizer.cc:582] [47/1100] Score: -0.620427 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:17.6572 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.6579 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.6581 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.6622 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.715716\n",
      "[INFO 24-02-22 06:52:17.6622 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:17.6629 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:17.6629 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.715716 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:17.6632 UTC hyperparameters_optimizer.cc:582] [48/1100] Score: -0.715716 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:17.6639 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.6639 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.6642 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.6666 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232870 train-accuracy:0.612469 valid-loss:1.192181 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:17.6693 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.980769 train-accuracy:0.911980 valid-loss:1.091928 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:52:17.7186 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664302\n",
      "[INFO 24-02-22 06:52:17.7188 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:52:17.7190 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.664302 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:17.7195 UTC hyperparameters_optimizer.cc:582] [49/1100] Score: -0.664302 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:17.7198 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.7198 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.7201 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.7231 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227738 train-accuracy:0.612469 valid-loss:1.191486 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:17.7498 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664295\n",
      "[INFO 24-02-22 06:52:17.7498 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:52:17.7502 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.664295 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:17.7508 UTC hyperparameters_optimizer.cc:582] [50/1100] Score: -0.664295 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:17.7515 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.7515 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.7519 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.7635 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114722 train-accuracy:0.800734 valid-loss:1.075823 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:17.7920 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.608074\n",
      "[INFO 24-02-22 06:52:17.7920 UTC gradient_boosted_trees.cc:271] Truncates the model to 85 tree(s) i.e. 85  iteration(s).\n",
      "[INFO 24-02-22 06:52:17.7922 UTC gradient_boosted_trees.cc:334] Final model num-trees:85 valid-loss:0.608074 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:17.7930 UTC hyperparameters_optimizer.cc:582] [51/1100] Score: -0.608074 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:17.7934 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.7934 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.7941 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.8093 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.160492 train-accuracy:0.790954 valid-loss:1.105157 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:17.8645 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651693\n",
      "[INFO 24-02-22 06:52:17.8645 UTC gradient_boosted_trees.cc:271] Truncates the model to 79 tree(s) i.e. 79  iteration(s).\n",
      "[INFO 24-02-22 06:52:17.8648 UTC gradient_boosted_trees.cc:334] Final model num-trees:79 valid-loss:0.651693 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:17.8655 UTC hyperparameters_optimizer.cc:582] [52/1100] Score: -0.651693 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:17.8673 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.8673 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.8675 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.8683 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296600 train-accuracy:0.612469 valid-loss:1.257550 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:17.9596 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.805334\n",
      "[INFO 24-02-22 06:52:17.9596 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:17.9614 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:17.9614 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.805334 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:17.9627 UTC hyperparameters_optimizer.cc:582] [53/1100] Score: -0.805334 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:17.9657 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:17.9658 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:17.9660 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:17.9748 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219116 train-accuracy:0.612469 valid-loss:1.183481 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.0964 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.633798 train-accuracy:0.886308 valid-loss:0.640271 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:18.0964 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.0964 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.640271 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:18.0968 UTC hyperparameters_optimizer.cc:582] [54/1100] Score: -0.640271 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:18.0986 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.0987 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.1009 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.1046 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.089277 train-accuracy:0.784841 valid-loss:1.059138 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:18.1066 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676364\n",
      "[INFO 24-02-22 06:52:18.1066 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:18.1068 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:18.1068 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.676364 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:18.1073 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.1073 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.1075 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.1080 UTC hyperparameters_optimizer.cc:582] [55/1100] Score: -0.676364 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:18.1303 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180787 train-accuracy:0.612469 valid-loss:1.161048 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.1696 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.58998\n",
      "[INFO 24-02-22 06:52:18.1700 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.1702 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.589980 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:18.1703 UTC hyperparameters_optimizer.cc:582] [56/1100] Score: -0.58998 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:18.1716 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.1719 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.1721 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.1829 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142705 train-accuracy:0.751834 valid-loss:1.100336 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:52:18.2868 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.552127\n",
      "[INFO 24-02-22 06:52:18.2869 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.2871 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.552127 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:18.2885 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.2885 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.2887 UTC hyperparameters_optimizer.cc:582] [57/1100] Score: [INFO-0.552127 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      " 24-02-22 06:52:18.2892 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.3013 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228917 train-accuracy:0.612469 valid-loss:1.191074 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.4611 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603467\n",
      "[INFO 24-02-22 06:52:18.4611 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.4613 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.603467 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:18.4615 UTC hyperparameters_optimizer.cc:582] [58/1100] Score: -0.603467 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:18.4617 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.4618 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.4620 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.4632 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.171017 train-accuracy:0.799511 valid-loss:1.130619 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:18.4760 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.7172\n",
      "[INFO 24-02-22 06:52:18.4760 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.4763 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.717200 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:18.4767 UTC hyperparameters_optimizer.cc:582] [59/1100] Score: -0.7172 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:18.4770 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.4770 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.4772 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.5570 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606969\n",
      "[INFO 24-02-22 06:52:18.5570 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.5571 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.606969 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:18.5574 UTC hyperparameters_optimizer.cc:582] [60/1100] Score: -0.606969 / -0.503908 HParams: [INFOfields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      " 24-02-22 06:52:18.5575 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.5575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.5578 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.5658 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651592\n",
      "[INFO 24-02-22 06:52:18.5659 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.5660 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.651592 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:18.5663 UTC hyperparameters_optimizer.cc:582] [61/1100] Score: -0.651592 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:18.5670 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.5672 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.5675 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.5737 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314937 train-accuracy:0.612469 valid-loss:1.272088 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.5743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.264878 train-accuracy:0.612469 valid-loss:1.230927 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.5777 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223015 train-accuracy:0.612469 valid-loss:1.198105 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.5993 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638965\n",
      "[INFO 24-02-22 06:52:18.5993 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.5997 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.638965 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:18.6007 UTC hyperparameters_optimizer.cc:582] [62/1100] Score: -0.638965 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:18.6032 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.6032 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.6035 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.6060 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296041 train-accuracy:0.612469 valid-loss:1.254616 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.7164 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.598334\n",
      "[INFO 24-02-22 06:52:18.7164 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.7165 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.598334 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:18.7169 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.7169 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.7171 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.7187 UTC hyperparameters_optimizer.cc:582] [63/1100] Score: -0.598334 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:18.7349 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277388 train-accuracy:0.612469 valid-loss:1.246263 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.8333 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.612763 train-accuracy:0.877751 valid-loss:0.629838 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:18.8333 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.8333 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.629838 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:18.8336 UTC hyperparameters_optimizer.cc:582] [64/1100] Score: -0.629838 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:18.8345 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.8346 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.8349 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.8352 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646786\n",
      "[INFO 24-02-22 06:52:18.8353 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:52:18.8355 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.646786 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:18.8361 UTC hyperparameters_optimizer.cc:582] [65/1100] Score: -0.646786 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:18.8375 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:18.8376 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:18.8378 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:18.8442 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180871 train-accuracy:0.612469 valid-loss:1.166882 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:18.8866 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312635 train-accuracy:0.612469 valid-loss:1.271768 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:19.0027 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641507\n",
      "[INFO 24-02-22 06:52:19.0028 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:52:19.0031 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.641507 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:19.0043 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:19.0044 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:19.0045 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:19.0094 UTC hyperparameters_optimizer.cc:582] [66/1100] Score: -0.641507 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:19.0105 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188565 train-accuracy:0.612469 valid-loss:1.160161 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:19.0275 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.60253\n",
      "[INFO 24-02-22 06:52:19.0276 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:52:19.0277 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.602530 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:19.0281 UTC hyperparameters_optimizer.cc:582] [67/1100] Score: -0.60253 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:19.0285 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:19.0286 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:19.0288 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:19.0518 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.198827 train-accuracy:0.612469 valid-loss:1.160411 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:19.1404 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.559765\n",
      "[INFO 24-02-22 06:52:19.1404 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:52:19.1406 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.559765 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:19.1408 UTC hyperparameters_optimizer.cc:582] [68/1100] Score: -0.559765 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:19.1413 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:19.1413 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:19.1416 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:19.1917 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182719 train-accuracy:0.612469 valid-loss:1.162290 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:19.3453 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679317\n",
      "[INFO 24-02-22 06:52:19.3453 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:52:19.3464 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.679317 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:19.3467 UTC hyperparameters_optimizer.cc:582] [69/1100] Score: -0.679317 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:19.3475 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:19.3475 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:19.3477 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:19.3526 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.057740 train-accuracy:0.847188 valid-loss:1.022583 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:19.5508 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.554702\n",
      "[INFO 24-02-22 06:52:19.5508 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:52:19.5511 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.554702 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:19.5558 UTC hyperparameters_optimizer.cc:582] [70/1100] Score: -0.554702 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:19.5568 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:19.5569 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:19.5576 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:19.6017 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.093098 train-accuracy:0.814181 valid-loss:1.050298 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:19.6226 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643361\n",
      "[INFO 24-02-22 06:52:19.6226 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:52:19.6228 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.643361 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:19.6231 UTC hyperparameters_optimizer.cc:582] [71/1100] Score: -0.643361 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:19.6236 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:19.6236 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:19.6252 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:19.6300 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284475 train-accuracy:0.612469 valid-loss:1.242730 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:19.6316 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686589\n",
      "[INFO 24-02-22 06:52:19.6316 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:52:19.6318 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.686589 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:19.6325 UTC hyperparameters_optimizer.cc:582] [72/1100] Score: -0.686589 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:19.6334 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:19.6334 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:19.6336 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:19.6408 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184039 train-accuracy:0.612469 valid-loss:1.145816 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:19.7895 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627231\n",
      "[INFO 24-02-22 06:52:19.7895 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:52:19.7897 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.627231 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:19.7902 UTC hyperparameters_optimizer.cc:582] [73/1100] Score: -0.627231 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:19.7911 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:19.7913 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:19.7916 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:19.7972 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238975 train-accuracy:0.612469 valid-loss:1.201793 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.0778 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.596326\n",
      "[INFO 24-02-22 06:52:20.0778 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.0781 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.596326 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:20.0792 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.0792 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.0794 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.0810 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240844 train-accuracy:0.612469 valid-loss:1.192641 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.0820 UTC hyperparameters_optimizer.cc:582] [74/1100] Score: -0.596326 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:20.1242 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.561884\n",
      "[INFO 24-02-22 06:52:20.1243 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.1245 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.561884 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:20.1249 UTC hyperparameters_optimizer.cc:582] [75/1100] Score: -0.561884 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:20.1267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.1284 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.1291 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.1310 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286573 train-accuracy:0.612469 valid-loss:1.244857 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.1898 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656476\n",
      "[INFO 24-02-22 06:52:20.1899 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.1901 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.656476 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:20.1914 UTC hyperparameters_optimizer.cc:582] [76/1100] Score: -0.656476 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:20.1934 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.1937 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.1939 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.1976 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.061146 train-accuracy:0.817848 valid-loss:1.029980 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:20.2743 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662947\n",
      "[INFO 24-02-22 06:52:20.2752 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:20.2753 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:20.2753 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.662947 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:20.2755 UTC hyperparameters_optimizer.cc:582] [77/1100] Score: -0.662947 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:20.2759 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.2759 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.2761 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.2936 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.021994 train-accuracy:0.877751 valid-loss:0.998170 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:20.3156 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.579348\n",
      "[INFO 24-02-22 06:52:20.3156 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.3157 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.579348 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:20.3163 UTC hyperparameters_optimizer.cc:582] [78/1100] Score: -0.579348 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:20.3175 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.3175 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.3178 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.3201 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641401\n",
      "[INFO 24-02-22 06:52:20.3202 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.3204 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.641401 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:20.3210 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.3210 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.3211 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.3231 UTC hyperparameters_optimizer.cc:582] [79/1100] Score: -0.641401 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:20.3278 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201509 train-accuracy:0.612469 valid-loss:1.166813 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.3282 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176903 train-accuracy:0.612469 valid-loss:1.145917 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.4007 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599048\n",
      "[INFO 24-02-22 06:52:20.4007 UTC gradient_boosted_trees.cc:271] Truncates the model to 261 tree(s) i.e. 261  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.4008 UTC gradient_boosted_trees.cc:334] Final model num-trees:261 valid-loss:0.599048 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:20.4026 UTC hyperparameters_optimizer.cc:582] [80/1100] Score: -0.599048 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:20.4032 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.4032 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.4056 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636102\n",
      "[INFO 24-02-22 06:52:20.4057 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.4057 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.4058 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.636102 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:20.4068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.4068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.4069 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317169 train-accuracy:0.612469 valid-loss:1.275751 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.4070 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.4087 UTC hyperparameters_optimizer.cc:582] [81/1100] Score: -0.636102 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:20.4203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640009\n",
      "[INFO 24-02-22 06:52:20.4203 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.4211 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.640009 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:20.4222 UTC hyperparameters_optimizer.cc:582] [82/1100] Score: -0.640009 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO[INFO 24-02-22 06:52:20.4239 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282673 train-accuracy:0.612469 valid-loss:1.242140 valid-accuracy:0.657534\n",
      " 24-02-22 06:52:20.4239 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.4239 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.4241 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.4262 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315167 train-accuracy:0.612469 valid-loss:1.275631 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.5095 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588897\n",
      "[INFO 24-02-22 06:52:20.5096 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.5097 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.588897 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:20.5103 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.5103 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.5105 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.5120 UTC hyperparameters_optimizer.cc:582] [83/1100] Score: -0.588897 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:20.5136 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317792 train-accuracy:0.612469 valid-loss:1.275756 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.6892 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.711419\n",
      "[INFO 24-02-22 06:52:20.6892 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:20.6899 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:20.6899 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.711419 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:20.6906 UTC hyperparameters_optimizer.cc:582] [84/1100] Score: -0.711419 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:20.6921 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.6921 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.6924 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.6975 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316014 train-accuracy:0.612469 valid-loss:1.274073 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.7936 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666699\n",
      "[INFO 24-02-22 06:52:20.7936 UTC gradient_boosted_trees.cc:271] Truncates the model to 247 tree(s) i.e. 247  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.7936 UTC gradient_boosted_trees.cc:334] Final model num-trees:247 valid-loss:0.666699 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:20.7942 UTC hyperparameters_optimizer.cc:582] [85/1100] Score: -0.666699 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:20.7948 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.7948 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.7957 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.8182 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282163 train-accuracy:0.612469 valid-loss:1.248354 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:20.9203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655131\n",
      "[INFO 24-02-22 06:52:20.9204 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.9205 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.655131 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:20.9206 UTC hyperparameters_optimizer.cc:582] [86/1100] Score: -0.655131 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:20.9210 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.9210 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.9212 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.9278 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.069783 train-accuracy:0.836186 valid-loss:1.030265 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:20.9419 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640531\n",
      "[INFO 24-02-22 06:52:20.9424 UTC gradient_boosted_trees.cc:271] Truncates the model to 204 tree(s) i.e. 204  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.9426 UTC gradient_boosted_trees.cc:334] Final model num-trees:204 valid-loss:0.640531 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:20.9436 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638013\n",
      "[INFO 24-02-22 06:52:20.9436 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:52:20.9442 UTC hyperparameters_optimizer.cc:582] [87/1100] Score: -0.640531 / -0.503908 HParams: [INFOfields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      " 24-02-22 06:52:20.9443 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.638013 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:20.9453 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.9453 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.9456 UTC hyperparameters_optimizer.cc:582] [88/1100] Score: [-0.638013 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:52:20.9465 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.9503 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.9503 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.9505 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.9561 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681733\n",
      "[INFO 24-02-22 06:52:20.9561 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:20.9564 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:20.9564 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.681733 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:20.9570 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:20.9571 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:20.9573 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:20.9587 UTC hyperparameters_optimizer.cc:582] [89/1100] Score: -0.681733 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:20.9593 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.101836 train-accuracy:0.799511 valid-loss:1.050739 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:20.9818 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.065789 train-accuracy:0.814181 valid-loss:1.085611 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:20.9996 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188072 train-accuracy:0.612469 valid-loss:1.135707 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:21.0334 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.587596\n",
      "[INFO 24-02-22 06:52:21.0334 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:52:21.0335 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.587596 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:21.0340 UTC hyperparameters_optimizer.cc:582] [90/1100] Score: -0.587596 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:21.0344 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:21.0344 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:21.0345 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:21.0517 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.149878 train-accuracy:0.756724 valid-loss:1.123264 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:52:21.0762 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.579884\n",
      "[INFO 24-02-22 06:52:21.0762 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:52:21.0765 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.579884 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:21.0768 UTC hyperparameters_optimizer.cc:582] [91/1100] Score: -0.579884 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:21.0775 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:21.0775 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:21.0777 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:21.1233 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311993 train-accuracy:0.612469 valid-loss:1.273615 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:21.2031 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647353\n",
      "[INFO 24-02-22 06:52:21.2031 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:21.2033 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:21.2033 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.647353 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:21.2036 UTC hyperparameters_optimizer.cc:582] [92/1100] Score: -0.647353 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:21.2040 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:21.2040 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:21.2042 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:21.2068 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282252 train-accuracy:0.612469 valid-loss:1.235188 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:21.4400 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.636474 train-accuracy:0.877751 valid-loss:0.656947 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:21.4401 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:21.4401 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.656947 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:21.4407 UTC hyperparameters_optimizer.cc:582] [93/1100] Score: -0.656947 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:21.4418 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:21.4418 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:21.4420 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:21.4494 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290253 train-accuracy:0.612469 valid-loss:1.247102 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:21.4804 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.610321\n",
      "[INFO 24-02-22 06:52:21.4804 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:21.4806 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:21.4806 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.610321 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:21.4810 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:21.4810 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:21.4811 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:21.4820 UTC hyperparameters_optimizer.cc:582] [94/1100] Score: -0.610321 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:21.5274 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285172 train-accuracy:0.612469 valid-loss:1.245924 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:21.7054 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593423\n",
      "[INFO 24-02-22 06:52:21.7054 UTC gradient_boosted_trees.cc:271] Truncates the model to 167 tree(s) i.e. 167  iteration(s).\n",
      "[INFO 24-02-22 06:52:21.7056 UTC gradient_boosted_trees.cc:334] Final model num-trees:167 valid-loss:0.593423 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:21.7070 UTC hyperparameters_optimizer.cc:582] [95/1100] Score: -0.593423 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:21.7077 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:21.7078 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:21.7091 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:21.7910 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207092 train-accuracy:0.612469 valid-loss:1.180801 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:21.9475 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605527\n",
      "[INFO 24-02-22 06:52:21.9475 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:52:21.9477 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.605527 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:21.9480 UTC hyperparameters_optimizer.cc:582] [96/1100] Score: -0.605527 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:21.9487 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:21.9487 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:21.9490 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:21.9512 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152901 train-accuracy:0.732274 valid-loss:1.106582 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:52:21.9967 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624682\n",
      "[INFO 24-02-22 06:52:21.9967 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:21.9971 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:21.9972 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.624682 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:21.9980 UTC hyperparameters_optimizer.cc:582] [97/1100] Score: -0.624682 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:21.9989 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:21.9989 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:21.9991 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:22.0260 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.527791 train-accuracy:0.905868 valid-loss:0.598807 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:22.0260 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:22.0260 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.598807 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:22.0274 UTC hyperparameters_optimizer.cc:582] [98/1100] Score: -0.598807 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:22.0299 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:22.0301 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:22.0306 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:22.0392 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671101\n",
      "[INFO 24-02-22 06:52:22.0393 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:22.0395 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.671101 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:22.0401 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:22.0401 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:22.0403 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:22.0427 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.093093 train-accuracy:0.799511 valid-loss:1.059912 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:22.0455 UTC hyperparameters_optimizer.cc:582] [99/1100] Score: -0.671101 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:22.0488 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239214 train-accuracy:0.612469 valid-loss:1.200153 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:22.0562 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.057835 train-accuracy:0.841076 valid-loss:1.110262 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:22.1672 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603022\n",
      "[INFO 24-02-22 06:52:22.1672 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:22.1674 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.603022 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:22.1678 UTC hyperparameters_optimizer.cc:582] [100/1100] Score: -0.603022 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:22.1686 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:22.1687 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:22.1691 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:22.1712 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315785 train-accuracy:0.612469 valid-loss:1.275142 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:22.4062 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637813\n",
      "[INFO 24-02-22 06:52:22.4062 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-22 06:52:22.4064 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.637813 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:22.4070 UTC hyperparameters_optimizer.cc:582] [101/1100] Score: -0.637813 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:22.4078 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:22.4078 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:22.4082 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:22.4385 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.164286 train-accuracy:0.612469 valid-loss:1.158946 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:22.5706 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677585\n",
      "[INFO 24-02-22 06:52:22.5707 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:52:22.5707 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.677585 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:22.5710 UTC hyperparameters_optimizer.cc:582] [102/1100] Score: -0.677585 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:22.5732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:22.5734 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:22.5736 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:22.6167 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237836 train-accuracy:0.612469 valid-loss:1.197012 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:22.7816 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.505954 train-accuracy:0.907090 valid-loss:0.595298 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:22.7816 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:22.7816 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.595298 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:22.7833 UTC hyperparameters_optimizer.cc:582] [103/1100] Score: -0.595298 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:22.7869 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:22.7869 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:22.7871 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:22.7893 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229626 train-accuracy:0.612469 valid-loss:1.192820 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:22.9404 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656367\n",
      "[INFO 24-02-22 06:52:22.9404 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:52:22.9407 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.656367 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:22.9416 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:22.9416 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:22.9418 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:22.9437 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286573 train-accuracy:0.612469 valid-loss:1.244857 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:22.9453 UTC hyperparameters_optimizer.cc:582] [104/1100] Score: -0.656367 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:23.0545 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.575557\n",
      "[INFO 24-02-22 06:52:23.0545 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.0546 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.575557 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:23.0555 UTC hyperparameters_optimizer.cc:582] [105/1100] Score: -0.575557 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:23.0567 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.0567 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.0569 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.0601 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313639 train-accuracy:0.612469 valid-loss:1.275170 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:23.1993 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684891\n",
      "[INFO 24-02-22 06:52:23.1994 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.1997 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.684891 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:23.2000 UTC hyperparameters_optimizer.cc:582] [106/1100] Score: -0.684891 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:23.2009 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.2009 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.2013 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.2030 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.098556 train-accuracy:0.784841 valid-loss:1.039178 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:23.2221 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640009\n",
      "[INFO 24-02-22 06:52:23.2221 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.2223 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.640009 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:23.2230 UTC hyperparameters_optimizer.cc:582] [107/1100] Score: -0.640009 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:23.2235 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.2235 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.2243 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.2271 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248129 train-accuracy:0.612469 valid-loss:1.203281 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:23.3025 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661047\n",
      "[INFO 24-02-22 06:52:23.3027 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.3042 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.661047 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:23.3062 UTC hyperparameters_optimizer.cc:582] [108/1100] Score: -0.661047 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:23.3082 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.3083 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.3086 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.3428 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.571258\n",
      "[INFO 24-02-22 06:52:23.3428 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.3429 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.571258 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:23.3431 UTC hyperparameters_optimizer.cc:582] [109/1100] Score: -0.571258 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:23.3436 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.3436 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.3439 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.3467 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315873 train-accuracy:0.612469 valid-loss:1.274487 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:23.3559 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236489 train-accuracy:0.612469 valid-loss:1.203695 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:23.4636 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631749\n",
      "[INFO 24-02-22 06:52:23.4636 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.4637 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.631749 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:23.4645 UTC hyperparameters_optimizer.cc:582] [110/1100] Score: -0.631749 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:23.4661 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.4664 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.4668 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.4790 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.212586 train-accuracy:0.612469 valid-loss:1.186428 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:23.5036 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.610419 train-accuracy:0.887531 valid-loss:0.645773 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:23.5037 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.5037 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.645773 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:23.5051 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.5051 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.5053 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.5063 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.136466 train-accuracy:0.798289 valid-loss:1.094303 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:23.5088 UTC hyperparameters_optimizer.cc:582] [111/1100] Score: -0.645773 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:23.6066 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.549677\n",
      "[INFO 24-02-22 06:52:23.6066 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.6067 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.549677 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:23.6071 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.6071 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.6073 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.6087 UTC hyperparameters_optimizer.cc:582] [112/1100] Score: -0.549677 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:23.6195 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.582806\n",
      "[INFO 24-02-22 06:52:23.6196 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.6198 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.582806 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:23.6203 UTC hyperparameters_optimizer.cc:582] [113/1100] Score: -0.582806 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:23.6214 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.6216 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.6219 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.6282 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.089459 train-accuracy:0.817848 valid-loss:1.061566 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:23.6411 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.938526 train-accuracy:0.916870 valid-loss:1.037766 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:23.8383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669472\n",
      "[INFO 24-02-22 06:52:23.8383 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.8387 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.669472 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:23.8397 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.8397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.8399 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.8420 UTC hyperparameters_optimizer.cc:582] [114/1100] Score: -0.669472 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:23.8527 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314713 train-accuracy:0.612469 valid-loss:1.275085 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:23.8966 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6399\n",
      "[INFO 24-02-22 06:52:23.8967 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:23.8969 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.639900 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:23.8971 UTC hyperparameters_optimizer.cc:582] [115/1100] Score: -0.6399 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:23.8984 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:23.8984 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:23.8987 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:23.9483 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221959 train-accuracy:0.612469 valid-loss:1.187046 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:24.2299 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.564717\n",
      "[INFO 24-02-22 06:52:24.2301 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:52:24.2305 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.564717 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:24.2310 UTC hyperparameters_optimizer.cc:582] [116/1100] Score: -0.564717 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:24.2319 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:24.2320 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:24.2324 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:24.2517 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225914 train-accuracy:0.612469 valid-loss:1.200500 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:24.7340 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629376\n",
      "[INFO 24-02-22 06:52:24.7340 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:52:24.7341 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.629376 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:24.7345 UTC hyperparameters_optimizer.cc:582] [117/1100] Score: -0.629376 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:24.7349 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:24.7349 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:24.7353 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:24.7756 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65802\n",
      "[INFO 24-02-22 06:52:24.7756 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:52:24.7757 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.658020 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:24.7760 UTC hyperparameters_optimizer.cc:582] [118/1100] Score: -0.65802 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:24.7766 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:24.7766 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:24.7769 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:24.7784 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289056 train-accuracy:0.612469 valid-loss:1.250027 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:24.8227 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.220351 train-accuracy:0.612469 valid-loss:1.189451 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:24.8997 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627014\n",
      "[INFO 24-02-22 06:52:24.8997 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:52:24.8998 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.627014 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:24.9005 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:24.9005 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:24.9007 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:24.9020 UTC hyperparameters_optimizer.cc:582] [119/1100] Score: -0.627014 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:24.9081 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190120 train-accuracy:0.777506 valid-loss:1.123604 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:24.9804 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61353\n",
      "[INFO 24-02-22 06:52:24.9805 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:52:24.9808 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.613530 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:24.9828 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:24.9828 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:24.9831 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:24.9841 UTC hyperparameters_optimizer.cc:582] [120/1100] Score: -0.61353 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:25.0290 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079692 train-accuracy:0.811736 valid-loss:1.042342 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:25.3126 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.822489\n",
      "[INFO 24-02-22 06:52:25.3126 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:25.3135 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:25.3136 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.822489 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:25.3152 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:25.3152 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:25.3153 UTC hyperparameters_optimizer.cc:582] [121/1100] Score: -0.822489 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:25.3160 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:25.3352 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.032177 train-accuracy:0.852078 valid-loss:0.984284 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:25.4459 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.581505\n",
      "[INFO 24-02-22 06:52:25.4459 UTC gradient_boosted_trees.cc:271] Truncates the model to 85 tree(s) i.e. 85  iteration(s).\n",
      "[INFO 24-02-22 06:52:25.4465 UTC gradient_boosted_trees.cc:334] Final model num-trees:85 valid-loss:0.581505 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:25.4485 UTC hyperparameters_optimizer.cc:582] [122/1100] Score: -0.581505 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:25.4516 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:25.4516 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:25.4517 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:25.4672 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224793 train-accuracy:0.612469 valid-loss:1.179132 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:25.4962 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.620094\n",
      "[INFO 24-02-22 06:52:25.4963 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:52:25.4963 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.620094 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:25.4965 UTC hyperparameters_optimizer.cc:582] [123/1100] Score: -0.620094 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:25.4968 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:25.4968 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:25.4971 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:25.5151 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313396 train-accuracy:0.612469 valid-loss:1.273092 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:25.5789 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652279\n",
      "[INFO 24-02-22 06:52:25.5789 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:52:25.5794 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.652279 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:25.5800 UTC hyperparameters_optimizer.cc:582] [124/1100] Score: -0.652279 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:25.5810 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:25.5810 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:25.5812 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:25.6021 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.175104 train-accuracy:0.612469 valid-loss:1.155296 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:26.1050 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655113\n",
      "[INFO 24-02-22 06:52:26.1051 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.1059 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.655113 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:26.1073 UTC hyperparameters_optimizer.cc:582] [125/1100] Score: -0.655113 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:26.1086 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.1086 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.1113 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.1504 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312715 train-accuracy:0.612469 valid-loss:1.271527 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:26.3562 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.55349\n",
      "[INFO 24-02-22 06:52:26.3562 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.3564 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.553490 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:52:26.3567 UTC hyperparameters_optimizer.cc:582] [126/1100] Score: -0.55349 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:26.3574 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.3574 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.3577 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.3603 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.120118 train-accuracy:0.768949 valid-loss:1.089012 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:26.4308 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642726\n",
      "[INFO 24-02-22 06:52:26.4308 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.4310 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.642726 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:26.4323 UTC hyperparameters_optimizer.cc:582] [127/1100] Score: -0.642726 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:26.4347 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.4348 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.4350 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.4405 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112110 train-accuracy:0.781174 valid-loss:1.090371 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:52:26.5053 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626014\n",
      "[INFO 24-02-22 06:52:26.5053 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.5060 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.626014 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:26.5070 UTC hyperparameters_optimizer.cc:582] [128/1100] Score: -0.626014 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:26.5082 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.5082 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.5086 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.5198 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.990442 train-accuracy:0.872861 valid-loss:1.008714 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:26.5538 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671986\n",
      "[INFO 24-02-22 06:52:26.5538 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.5542 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.671986 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:26.5553 UTC hyperparameters_optimizer.cc:582] [129/1100] Score: -0.671986 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:26.5557 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.5557 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.5562 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.5584 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233056 train-accuracy:0.612469 valid-loss:1.180107 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:26.6262 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639237\n",
      "[INFO 24-02-22 06:52:26.6262 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.6264 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.639237 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:26.6268 UTC hyperparameters_optimizer.cc:582] [130/1100] Score: -0.639237 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:26.6275 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.6276 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.6279 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.6605 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248214 train-accuracy:0.612469 valid-loss:1.194917 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:26.6893 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646227\n",
      "[INFO 24-02-22 06:52:26.6893 UTC gradient_boosted_trees.cc:271] Truncates the model to 189 tree(s) i.e. 189  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.6895 UTC gradient_boosted_trees.cc:334] Final model num-trees:189 valid-loss:0.646227 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:26.6906 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.6906 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.6908 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.6920 UTC hyperparameters_optimizer.cc:582] [131/1100] Score: -0.646227 / -0.503908 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:26.7479 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311962 train-accuracy:0.612469 valid-loss:1.272337 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:26.8701 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.484448\n",
      "[INFO 24-02-22 06:52:26.8711 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.8713 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.484448 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:26.8718 UTC hyperparameters_optimizer.cc:582] [132/1100] Score: -0.484448 / -0.484448 HParams: [INFO 24-02-22 06:52:26.8719 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:26.8719 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.8721 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.9451 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236838 train-accuracy:0.612469 valid-loss:1.195902 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:26.9487 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6267\n",
      "[INFO 24-02-22 06:52:26.9487 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.9487 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.626700 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:26.9490 UTC hyperparameters_optimizer.cc:582] [133/1100] Score: -0.6267 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:26.9493 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.9493 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.9496 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:26.9627 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627543\n",
      "[INFO 24-02-22 06:52:26.9627 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:52:26.9629 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.627543 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:26.9633 UTC hyperparameters_optimizer.cc:582] [134/1100] Score: -0.627543 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:26.9635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:26.9635 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:26.9637 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.0043 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.134799 train-accuracy:0.786064 valid-loss:1.082870 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:27.0473 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642666\n",
      "[INFO 24-02-22 06:52:27.0474 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.0475 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.642666 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:27.0476 UTC hyperparameters_optimizer.cc:582] [135/1100] Score: -0.642666 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:27.0480 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.0480 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.0482 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.0494 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680645\n",
      "[INFO 24-02-22 06:52:27.0495 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:27.0503 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:27.0503 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.680645 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:27.0506 UTC hyperparameters_optimizer.cc:582] [136/1100] Score: -0.680645 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:27.0515 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.0515 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.0519 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.0735 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224646 train-accuracy:0.612469 valid-loss:1.187241 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:27.1085 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159745 train-accuracy:0.612469 valid-loss:1.141938 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:27.1386 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.108111 train-accuracy:0.799511 valid-loss:1.081834 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:27.2033 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633698\n",
      "[INFO 24-02-22 06:52:27.2033 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.2036 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.633698 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:27.2039 UTC hyperparameters_optimizer.cc:582] [137/1100] Score: -0.633698 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:27.2056 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.2058 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.2061 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.2136 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.087355 train-accuracy:0.815403 valid-loss:1.040962 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:27.2241 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614333\n",
      "[INFO 24-02-22 06:52:27.2242 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.2243 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.614333 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:27.2247 UTC hyperparameters_optimizer.cc:582] [138/1100] Score: -0.614333 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:27.2252 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.2253 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.2255 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.3398 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.027400 train-accuracy:0.860636 valid-loss:1.051705 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:27.4783 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597476\n",
      "[INFO 24-02-22 06:52:27.4785 UTC gradient_boosted_trees.cc:271] Truncates the model to 200 tree(s) i.e. 200  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.4788 UTC gradient_boosted_trees.cc:334] Final model num-trees:200 valid-loss:0.597476 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:27.4805 UTC hyperparameters_optimizer.cc:582] [139/1100] Score: -0.597476 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:27.4847 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.4849 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.4853 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.594182\n",
      "[INFO 24-02-22 06:52:27.4854 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.4854 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.4854 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.594182 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:27.4858 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.4859 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.4861 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.4886 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229850 train-accuracy:0.612469 valid-loss:1.190243 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:27.4887 UTC hyperparameters_optimizer.cc:582] [140/1100] Score: -0.594182 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:27.4919 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283393 train-accuracy:0.612469 valid-loss:1.241838 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:27.5436 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619649\n",
      "[INFO 24-02-22 06:52:27.5438 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.5441 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.619649 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:27.5446 UTC hyperparameters_optimizer.cc:582] [141/1100] Score: -0.619649 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:27.5452 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.5453 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.5455 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.5695 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.163179 train-accuracy:0.797066 valid-loss:1.110233 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:27.6268 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631588\n",
      "[INFO 24-02-22 06:52:27.6269 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.6271 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.631588 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:27.6276 UTC hyperparameters_optimizer.cc:582] [142/1100] Score: -0.631588 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:27.6322 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.6322 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.6324 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.6346 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227917 train-accuracy:0.612469 valid-loss:1.183747 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:27.7685 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634664\n",
      "[INFO 24-02-22 06:52:27.7686 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.7690 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.634664 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:27.7695 UTC hyperparameters_optimizer.cc:582] [143/1100] Score: -0.634664 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:27.7714 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.7716 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.7718 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.8021 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.140911 train-accuracy:0.816626 valid-loss:1.090411 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:27.8384 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655209\n",
      "[INFO 24-02-22 06:52:27.8384 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      "[INFO 24-02-22 06:52:27.8386 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.655209 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:27.8394 UTC hyperparameters_optimizer.cc:582] [144/1100] Score: -0.655209 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:27.8403 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:27.8403 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:27.8406 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:27.9002 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.147740 train-accuracy:0.612469 valid-loss:1.135246 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:28.3821 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653877\n",
      "[INFO 24-02-22 06:52:28.3821 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:52:28.3823 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.653877 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:28.3826 UTC hyperparameters_optimizer.cc:582] [145/1100] Score: -0.653877 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:28.3831 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:28.3831 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:28.3836 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:28.3869 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.137680 train-accuracy:0.806846 valid-loss:1.116412 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:28.3938 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627401\n",
      "[INFO 24-02-22 06:52:28.3938 UTC gradient_boosted_trees.cc:271] Truncates the model to 110 tree(s) i.e. 110  iteration(s).\n",
      "[INFO 24-02-22 06:52:28.3940 UTC gradient_boosted_trees.cc:334] Final model num-trees:110 valid-loss:0.627401 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:28.3958 UTC hyperparameters_optimizer.cc:582] [146/1100] Score: -0.627401 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:28.3971 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:28.3971 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:28.3974 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:28.3988 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291914 train-accuracy:0.612469 valid-loss:1.251837 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:28.5231 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.598999\n",
      "[INFO 24-02-22 06:52:28.5231 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:52:28.5233 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.598999 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:28.5236 UTC hyperparameters_optimizer.cc:582] [147/1100] Score: -0.598999 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:28.5242 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:28.5242 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:28.5244 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:28.5323 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092989 train-accuracy:0.832518 valid-loss:1.054227 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:28.8026 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.507576 train-accuracy:0.915648 valid-loss:0.622344 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:28.8026 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:28.8026 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.622344 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:28.8033 UTC hyperparameters_optimizer.cc:582] [148/1100] Score: -0.622344 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:28.8046 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:28.8047 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:28.8049 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:28.8588 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.139529 train-accuracy:0.771394 valid-loss:1.096960 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:52:28.8649 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63044\n",
      "[INFO 24-02-22 06:52:28.8649 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:52:28.8651 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.630440 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:28.8653 UTC hyperparameters_optimizer.cc:582] [149/1100] Score: -0.63044 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:28.8660 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:28.8660 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:28.8662 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:28.8834 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283267 train-accuracy:0.612469 valid-loss:1.244910 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:29.0592 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663697\n",
      "[INFO 24-02-22 06:52:29.0592 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:52:29.0594 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.663697 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:29.0595 UTC hyperparameters_optimizer.cc:582] [150/1100] Score: -0.663697 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:29.0601 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:29.0601 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:29.0603 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:29.0867 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152187 train-accuracy:0.779951 valid-loss:1.111623 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:29.1007 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690625\n",
      "[INFO 24-02-22 06:52:29.1007 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:29.1009 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.690625 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:29.1010 UTC hyperparameters_optimizer.cc:582] [151/1100] Score: -0.690625 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:29.1016 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:29.1017 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:29.1020 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:29.1162 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.074569 train-accuracy:0.812958 valid-loss:1.044712 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:29.4060 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633112\n",
      "[INFO 24-02-22 06:52:29.4060 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:52:29.4061 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.633112 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:29.4063 UTC hyperparameters_optimizer.cc:582] [152/1100] Score: -0.633112 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:29.4067 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:29.4067 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:29.4070 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:29.4095 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191022 train-accuracy:0.612469 valid-loss:1.151426 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:29.5287 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622736\n",
      "[INFO 24-02-22 06:52:29.5289 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:29.5292 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.622736 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:29.5296 UTC hyperparameters_optimizer.cc:582] [153/1100] Score: -0.622736 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:29.5305 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:29.5306 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:29.5308 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:29.5400 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644741\n",
      "[INFO 24-02-22 06:52:29.5401 UTC gradient_boosted_trees.cc:271] Truncates the model to 203 tree(s) i.e. 203  iteration(s).\n",
      "[INFO 24-02-22 06:52:29.5403 UTC gradient_boosted_trees.cc:334] Final model num-trees:203 valid-loss:0.644741 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:29.5417 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159815 train-accuracy:0.612469 valid-loss:1.114686 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:29.5420 UTC hyperparameters_optimizer.cc:582] [154/1100] Score: -0.644741 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:29.5426 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:29.5426 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:29.5449 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:29.6020 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070446 train-accuracy:0.833741 valid-loss:1.056351 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:29.7139 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684591\n",
      "[INFO 24-02-22 06:52:29.7139 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:29.7141 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:29.7141 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.684591 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:29.7142 UTC hyperparameters_optimizer.cc:582] [155/1100] Score: -0.684591 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:29.7145 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:29.7145 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:29.7148 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:29.7238 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304222 train-accuracy:0.612469 valid-loss:1.270168 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:29.7751 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62803\n",
      "[INFO 24-02-22 06:52:29.7751 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:52:29.7753 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.628030 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:29.7766 UTC hyperparameters_optimizer.cc:582] [156/1100] Score: -0.62803 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:29.7783 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:29.7784 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:29.7786 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:29.8341 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.074598 train-accuracy:0.852078 valid-loss:1.042424 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:29.8651 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665994\n",
      "[INFO 24-02-22 06:52:29.8651 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:52:29.8652 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.665994 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:29.8655 UTC hyperparameters_optimizer.cc:582] [157/1100] Score: -0.665994 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:29.8659 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:29.8659 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:29.8662 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:29.8676 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286593 train-accuracy:0.612469 valid-loss:1.241458 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:30.1944 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66968\n",
      "[INFO 24-02-22 06:52:30.1945 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.1951 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.669680 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:30.1960 UTC hyperparameters_optimizer.cc:582] [158/1100] Score: -0.66968 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:30.1974 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.591658\n",
      "[INFO 24-02-22 06:52:30.1974 UTC gradient_boosted_trees.cc:271] Truncates the model to 182 tree(s) i.e. 182  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.1975 UTC gradient_boosted_trees.cc:334] Final model num-trees:182 valid-loss:0.591658 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:30.1980 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.1980 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.1983 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.1983 UTC hyperparameters_optimizer.cc:582] [159/1100] Score: -0.591658 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:30.2002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.2004 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.2007 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.2010 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.051514 train-accuracy:0.831296 valid-loss:1.007601 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:30.2510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234649 train-accuracy:0.612469 valid-loss:1.205510 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:30.3099 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645021\n",
      "[INFO 24-02-22 06:52:30.3102 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:30.3106 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:30.3106 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.645021 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:30.3110 UTC hyperparameters_optimizer.cc:582] [160/1100] Score: -0.645021 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:30.3119 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.3122 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.3127 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.3478 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130488 train-accuracy:0.778729 valid-loss:1.092155 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:30.3992 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615304\n",
      "[INFO 24-02-22 06:52:30.3992 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.3994 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.615304 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:30.3999 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.3999 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.4001 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.4021 UTC hyperparameters_optimizer.cc:582] [161/1100] Score: -0.615304 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:30.4123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.039638 train-accuracy:0.839853 valid-loss:1.022283 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:30.4620 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665059\n",
      "[INFO 24-02-22 06:52:30.4620 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.4621 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.665059 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:30.4624 UTC hyperparameters_optimizer.cc:582] [162/1100] Score: -0.665059 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:30.4628 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.4629 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.4632 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.4704 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230207 train-accuracy:0.612469 valid-loss:1.200669 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:30.6387 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674371\n",
      "[INFO 24-02-22 06:52:30.6387 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.6391 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.674371 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:30.6396 UTC hyperparameters_optimizer.cc:582] [163/1100] Score: -0.674371 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:30.6408 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.6408 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.6411 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.6556 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.061535 train-accuracy:0.821516 valid-loss:1.027643 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:30.6902 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682262\n",
      "[INFO 24-02-22 06:52:30.6902 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.6913 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.682262 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:30.6984 UTC hyperparameters_optimizer.cc:582] [164/1100] Score: -0.682262 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:30.7127 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.7128 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.7131 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.7493 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286558 train-accuracy:0.612469 valid-loss:1.244134 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:30.7718 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.700419\n",
      "[INFO 24-02-22 06:52:30.7718 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.7722 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.700419 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:30.7726 UTC hyperparameters_optimizer.cc:582] [165/1100] Score: -0.700419 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:30.7735 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.7735 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.7738 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.7797 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278910 train-accuracy:0.612469 valid-loss:1.242487 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:30.8077 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.607977\n",
      "[INFO 24-02-22 06:52:30.8081 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.8095 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.607977 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:30.8103 UTC hyperparameters_optimizer.cc:582] [166/1100] Score: -0.607977 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:30.8119 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.8119 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.8121 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.8158 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278847 train-accuracy:0.612469 valid-loss:1.242114 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:30.9475 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621692\n",
      "[INFO 24-02-22 06:52:30.9475 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:52:30.9477 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.621692 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:30.9482 UTC hyperparameters_optimizer.cc:582] [167/1100] Score: -0.621692 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:30.9488 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:30.9488 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:30.9491 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:30.9554 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233990 train-accuracy:0.612469 valid-loss:1.190513 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:31.0407 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662283\n",
      "[INFO 24-02-22 06:52:31.0408 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:52:31.0411 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.662283 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:31.0419 UTC hyperparameters_optimizer.cc:582] [168/1100] Score: -0.662283 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:31.0426 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:31.0426 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:31.0434 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:31.0930 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102483 train-accuracy:0.816626 valid-loss:1.100178 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:31.1481 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648901\n",
      "[INFO 24-02-22 06:52:31.1481 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:52:31.1484 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.648901 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:31.1492 UTC hyperparameters_optimizer.cc:582] [169/1100] Score: -0.648901 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:31.1515 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:31.1534 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:31.1537 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:31.2072 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309754 train-accuracy:0.612469 valid-loss:1.269595 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:31.3077 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677989\n",
      "[INFO 24-02-22 06:52:31.3078 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:52:31.3080 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.677989 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:31.3086 UTC hyperparameters_optimizer.cc:582] [170/1100] Score: -0.677989 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:31.3099 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:31.3100 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:31.3102 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:31.3174 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283097 train-accuracy:0.612469 valid-loss:1.243554 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:31.4275 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.595065\n",
      "[INFO 24-02-22 06:52:31.4276 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:52:31.4277 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.595065 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:31.4289 UTC gradient_boosted_trees.cc[INFO 24-02-22 06:52:31.4289 UTC hyperparameters_optimizer.cc:582] [171:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:31.4290 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "/1100] Score: -0.595065 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:31.4303 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:31.4462 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.251857 train-accuracy:0.612469 valid-loss:1.196193 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:31.8232 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649326\n",
      "[INFO 24-02-22 06:52:31.8233 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:52:31.8234 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.649326 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:31.8243 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:31.8243 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:31.8245 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:31.8253 UTC hyperparameters_optimizer.cc:582] [172/1100] Score: -0.649326 / -0.484448 HParams: [INFO 24-02-22 06:52:31.8254 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225080 train-accuracy:0.612469 valid-loss:1.184543 valid-accuracy:0.657534\n",
      "fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:31.8388 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622477\n",
      "[INFO 24-02-22 06:52:31.8388 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:52:31.8390 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.622477 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:31.8395 UTC hyperparameters_optimizer.cc:582] [173/1100] Score: -0.622477 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:31.8400 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:31.8400 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:31.8404 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:31.8474 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090872 train-accuracy:0.827628 valid-loss:1.067991 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:31.8597 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663058\n",
      "[INFO 24-02-22 06:52:31.8597 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:31.8600 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.663058 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:31.8607 UTC hyperparameters_optimizer.cc:582] [174/1100] Score: -0.663058 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:31.8615 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:31.8617 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:31.8619 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:31.8644 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.069407 train-accuracy:0.815403 valid-loss:1.036986 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:31.9479 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643666\n",
      "[INFO 24-02-22 06:52:31.9479 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:52:31.9480 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.643666 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:31.9482 UTC hyperparameters_optimizer.cc:582] [175/1100] Score: -0.643666 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:31.9487 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:31.9487 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:31.9489 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:31.9523 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317904 train-accuracy:0.612469 valid-loss:1.275185 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:32.0062 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676862\n",
      "[INFO 24-02-22 06:52:32.0063 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.0064 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.676862 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:32.0068 UTC hyperparameters_optimizer.cc:582] [176/1100] Score: -0.676862 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:32.0075 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.0075 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.0078 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.0121 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.052165 train-accuracy:0.830073 valid-loss:1.052134 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:32.0222 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64435\n",
      "[INFO 24-02-22 06:52:32.0222 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:32.0223 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:32.0224 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.644350 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:32.0228 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.0228 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.0230 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.0253 UTC hyperparameters_optimizer.cc:582] [177/1100] Score: -0.64435 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:32.0546 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248214 train-accuracy:0.612469 valid-loss:1.194917 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:32.0929 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623624\n",
      "[INFO 24-02-22 06:52:32.0930 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.0932 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.623624 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:32.0941 UTC hyperparameters_optimizer.cc:582] [178/1100] Score: -0.623624 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:32.0945 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.0945 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.0949 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.0998 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146546 train-accuracy:0.782396 valid-loss:1.111780 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:32.1143 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675383\n",
      "[INFO 24-02-22 06:52:32.1143 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.1145 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.675383 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:32.1146 UTC hyperparameters_optimizer.cc:582] [179/1100] Score: -0.675383 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:32.1152 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.1152 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.1155 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.1219 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155574 train-accuracy:0.612469 valid-loss:1.154717 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:32.1591 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.584911\n",
      "[INFO 24-02-22 06:52:32.1594 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.1610 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.584911 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:32.1641 UTC hyperparameters_optimizer.cc:582] [180/1100] Score: -0.584911 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:32.1652 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.1652 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.1657 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.1907 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651041\n",
      "[INFO 24-02-22 06:52:32.1908 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.1915 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.651041 valid-accuracy:0.863014\n",
      "[[INFO 24-02-22 06:52:32.1933 UTC hyperparameters_optimizer.cc:582] [181/1100] Score: -0.651041 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "INFO 24-02-22 06:52:32.1938 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.1938 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.1943 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.1964 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157931 train-accuracy:0.743276 valid-loss:1.122237 valid-accuracy:0.712329\n",
      "[INFO 24-02-22 06:52:32.2274 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.145249 train-accuracy:0.742054 valid-loss:1.088221 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:32.2970 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624666\n",
      "[INFO 24-02-22 06:52:32.2970 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.2972 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.624666 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 06:52:32.2979 UTC hyperparameters_optimizer.cc:582] [182/1100] Score: -0.624666 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "INFO 24-02-22 06:52:32.2980 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.2980 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.2983 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.2986 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.543816\n",
      "[INFO 24-02-22 06:52:32.2986 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.2989 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.543816 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:32.2993 UTC hyperparameters_optimizer.cc:582] [183/1100] Score: -0.543816 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:32.3001 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.3001 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.3004 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.3045 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.198555 train-accuracy:0.612469 valid-loss:1.161182 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:32.3653 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646839\n",
      "[INFO 24-02-22 06:52:32.3653 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.3655 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.646839 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:32.3661 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.3661 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.3663 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.3687 UTC hyperparameters_optimizer.cc:582] [184/1100] Score: -0.646839 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:32.3832 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234470 train-accuracy:0.612469 valid-loss:1.202474 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:32.3904 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.560026\n",
      "[INFO 24-02-22 06:52:32.3904 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.3905 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.560026 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:32.3909 UTC hyperparameters_optimizer.cc:582] [185/1100] Score: -0.560026 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:32.3916 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.3916 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.3918 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.3977 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188732 train-accuracy:0.612469 valid-loss:1.161251 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:32.4500 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.120760 train-accuracy:0.784841 valid-loss:1.101223 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:52:32.5725 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.586447\n",
      "[INFO 24-02-22 06:52:32.5726 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:32.5729 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:32.5730 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.586447 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:32.5735 UTC hyperparameters_optimizer.cc:582] [186/1100] Score: -0.586447 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:32.5740 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.5742 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.5745 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.5898 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096894 train-accuracy:0.814181 valid-loss:1.064519 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:32.9128 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653785\n",
      "[INFO 24-02-22 06:52:32.9128 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.9130 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.653785 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:32.9134 UTC hyperparameters_optimizer.cc:582] [187/1100] Score: -0.653785 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:32.9135 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.9135 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.9138 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.9148 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103610 train-accuracy:0.798289 valid-loss:1.061187 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:32.9398 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.624044 train-accuracy:0.880196 valid-loss:0.630360 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:32.9398 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.9398 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.629333 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:32.9404 UTC hyperparameters_optimizer.cc:582] [188/1100] Score: -0.629333 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:32.9407 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.9407 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.9414 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.9618 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309497 train-accuracy:0.612469 valid-loss:1.272176 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:32.9701 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.576655\n",
      "[INFO 24-02-22 06:52:32.9701 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:52:32.9702 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.576655 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:32.9709 UTC hyperparameters_optimizer.cc:582] [189/1100] Score: -0.576655 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:32.9719 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:32.9720 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:32.9722 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:32.9875 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257585 train-accuracy:0.612469 valid-loss:1.216943 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:33.2313 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649184\n",
      "[INFO 24-02-22 06:52:33.2313 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.2318 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.649184 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:33.2339 UTC hyperparameters_optimizer.cc:582] [190/1100] Score: -0.649184 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:33.2370 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.2390 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.2393 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.2434 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227624 train-accuracy:0.612469 valid-loss:1.192501 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:33.4419 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639879\n",
      "[INFO 24-02-22 06:52:33.4420 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.4423 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.639879 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:33.4433 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.4433 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.4435 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.4460 UTC hyperparameters_optimizer.cc:582] [191/1100] Score: -0.639879 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:33.4778 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634097\n",
      "[INFO 24-02-22 06:52:33.4779 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.4783 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.634097 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:33.4794 UTC hyperparameters_optimizer.cc:582] [192/1100] Score: -0.634097 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:33.4807 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.4809 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.4812 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.4833 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063207 train-accuracy:0.826406 valid-loss:1.010794 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:33.5022 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151687 train-accuracy:0.767726 valid-loss:1.115998 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:52:33.5858 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638393\n",
      "[INFO 24-02-22 06:52:33.5858 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.5861 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.638393 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:33.5864 UTC hyperparameters_optimizer.cc:582] [193/1100] Score: -0.638393 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:33.5874 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.5874 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.5878 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.5903 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.140486 train-accuracy:0.798289 valid-loss:1.087194 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:33.6328 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634816\n",
      "[INFO 24-02-22 06:52:33.6328 UTC gradient_boosted_trees.cc:271] Truncates the model to 150 tree(s) i.e. 150  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.6329 UTC gradient_boosted_trees.cc:334] Final model num-trees:150 valid-loss:0.634816 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:33.6341 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.6341 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.6343 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.6353 UTC hyperparameters_optimizer.cc:582] [194/1100] Score: -0.634816 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:33.7072 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102483 train-accuracy:0.816626 valid-loss:1.100178 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:33.7147 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619892\n",
      "[INFO 24-02-22 06:52:33.7148 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.7149 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.619892 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:33.7152 UTC hyperparameters_optimizer.cc:582] [195/1100] Score: -0.619892 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:33.7158 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.7158 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.7160 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.7178 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235987 train-accuracy:0.612469 valid-loss:1.183496 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:33.7476 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.576481\n",
      "[INFO 24-02-22 06:52:33.7478 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.7481 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.576481 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:33.7488 UTC hyperparameters_optimizer.cc:582] [196/1100] Score: -0.576481 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:33.7492 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.7509 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.7511 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.7589 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.097460 train-accuracy:0.811736 valid-loss:1.076761 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:33.7830 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.556867\n",
      "[INFO 24-02-22 06:52:33.7830 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.7832 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.556867 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:33.7836 UTC hyperparameters_optimizer.cc:582] [197/1100] Score: -0.556867 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:33.7840 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.7840 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.7845 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.7867 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102358 train-accuracy:0.795844 valid-loss:1.065848 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:33.8819 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6243\n",
      "[INFO 24-02-22 06:52:33.8819 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.8821 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.624300 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:33.8828 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-22 06:52:33.8828 UTC hyperparameters_optimizer.cc:582] [198/1100] Score: -0.6243 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      " 24-02-22 06:52:33.8828 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.8838 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.9378 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.170652 train-accuracy:0.612469 valid-loss:1.156128 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:33.9741 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605375\n",
      "[INFO 24-02-22 06:52:33.9742 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.9744 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.605375 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:33.9751 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.9751 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.9760 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.9761 UTC hyperparameters_optimizer.cc:582] [199/1100] Score: -0.605375 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:33.9834 UTC gradient_boosted_trees.cc:[INFO1636] \tnum-trees:1 train-loss:1.198729 train-accuracy:0.612469 valid-loss:1.177023 valid-accuracy:0.657534\n",
      " 24-02-22 06:52:33.9842 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.570653\n",
      "[INFO 24-02-22 06:52:33.9856 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.9866 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.570653 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:33.9876 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.9876 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:33.9877 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:33.9885 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159729 train-accuracy:0.784841 valid-loss:1.104714 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:33.9920 UTC hyperparameters_optimizer.cc:582] [200/1100] Score: -0.570653 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:33.9973 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621858\n",
      "[INFO 24-02-22 06:52:33.9974 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:33.9981 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.621858 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:33.9988 UTC hyperparameters_optimizer.cc:582] [201/1100] Score: -0.621858 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:33.9999 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:33.9999 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:34.0004 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:34.0424 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.260840 train-accuracy:0.612469 valid-loss:1.240243 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:34.1159 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631691\n",
      "[INFO 24-02-22 06:52:34.1160 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:52:34.1160 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.631691 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:34.1174 UTC hyperparameters_optimizer.cc:582] [202/1100] Score: -0.631691 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:34.1179 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:34.1179 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:34.1186 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:34.1402 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257585 train-accuracy:0.612469 valid-loss:1.216943 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:34.2417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637541\n",
      "[INFO 24-02-22 06:52:34.2417 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 06:52:34.2417 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.637541 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:34.2420 UTC hyperparameters_optimizer.cc:582] [203/1100] Score: -0.637541 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:34.2425 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:34.2425 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:34.2448 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:34.2619 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315007 train-accuracy:0.612469 valid-loss:1.274747 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:34.2736 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634937\n",
      "[INFO 24-02-22 06:52:34.2736 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:34.2749 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.634937 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:34.2767 UTC hyperparameters_optimizer.cc:582] [204/1100] Score: -0.634937 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:34.2786 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:34.2786 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:34.2788 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:34.2912 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279254 train-accuracy:0.612469 valid-loss:1.236507 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:34.5615 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601864\n",
      "[INFO 24-02-22 06:52:34.5615 UTC gradient_boosted_trees.cc:271] Truncates the model to 84 tree(s) i.e. 84  iteration(s).\n",
      "[INFO 24-02-22 06:52:34.5617 UTC gradient_boosted_trees.cc:334] Final model num-trees:84 valid-loss:0.601864 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:34.5633 UTC hyperparameters_optimizer.cc:582] [205/1100] Score: -0.601864 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:34.5649 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:34.5649 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:34.5651 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:34.5668 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.062843 train-accuracy:0.856968 valid-loss:1.009514 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:34.6870 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683953\n",
      "[INFO 24-02-22 06:52:34.6871 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:52:34.6872 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.683953 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:34.6874 UTC hyperparameters_optimizer.cc:582] [206/1100] Score: -0.683953 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:34.6881 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:34.6881 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:34.6883 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:34.7062 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312349 train-accuracy:0.612469 valid-loss:1.272286 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:34.7983 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642792\n",
      "[INFO 24-02-22 06:52:34.7983 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:52:34.7985 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.642792 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:34.7987 UTC hyperparameters_optimizer.cc:582] [207/1100] Score: -0.642792 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:34.7991 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:34.7991 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:34.7993 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:34.8963 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.210984 train-accuracy:0.612469 valid-loss:1.176949 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:35.1488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638097\n",
      "[INFO 24-02-22 06:52:35.1488 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:52:35.1489 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.638097 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:35.1492 UTC hyperparameters_optimizer.cc:582] [208/1100] Score: -0.638097 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:35.1497 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:35.1498 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:35.1500 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:35.1524 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237759 train-accuracy:0.612469 valid-loss:1.194881 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:35.3918 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.590543\n",
      "[INFO 24-02-22 06:52:35.3919 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:52:35.3921 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.590543 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:35.3930 UTC hyperparameters_optimizer.cc:582] [209/1100] Score: -0.590543 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:35.3949 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:35.3949 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:35.3952 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:35.4124 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223015 train-accuracy:0.612469 valid-loss:1.198105 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:35.8605 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646519\n",
      "[INFO 24-02-22 06:52:35.8606 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:35.8607 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.646519 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:35.8611 UTC hyperparameters_optimizer.cc:582] [210/1100] Score: -0.646519 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:35.8616 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:35.8617 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:35.8620 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:35.8642 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157161 train-accuracy:0.784841 valid-loss:1.117567 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:35.9831 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676301\n",
      "[INFO 24-02-22 06:52:35.9831 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:35.9834 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.676301 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:35.9837 UTC hyperparameters_optimizer.cc:582] [211/1100] Score: -0.676301 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:35.9842 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:35.9843 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:35.9847 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:35.9897 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121386 train-accuracy:0.789731 valid-loss:1.078852 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:36.0160 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634097\n",
      "[INFO 24-02-22 06:52:36.0161 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.0165 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.634097 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:36.0172 UTC hyperparameters_optimizer.cc:582] [212/1100] Score: -0.634097 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:36.0179 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.0179 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.0182 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.0199 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.604342\n",
      "[INFO 24-02-22 06:52:36.0201 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.0203 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.604342 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:36.0206 UTC hyperparameters_optimizer.cc:582] [213/1100] Score: -0.604342 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:36.0210 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.0211 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.0215 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.0241 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092846 train-accuracy:0.822738 valid-loss:1.075629 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:36.0275 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.145010 train-accuracy:0.783619 valid-loss:1.109858 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:36.0294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609086\n",
      "[INFO 24-02-22 06:52:36.0295 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.0297 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.609086 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:36.0302 UTC hyperparameters_optimizer.cc:582] [214/1100] Score: -0.609086 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:36.0307 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.0307 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.0313 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.0749 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.100133 train-accuracy:0.805623 valid-loss:1.058472 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:36.1438 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640701\n",
      "[INFO 24-02-22 06:52:36.1439 UTC gradient_boosted_trees.cc:271] Truncates the model to 102 tree(s) i.e. 102  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.1440 UTC gradient_boosted_trees.cc:334] Final model num-trees:102 valid-loss:0.640701 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:36.1446 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.1446 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.1448 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.1453 UTC hyperparameters_optimizer.cc:582] [215/1100] Score: -0.640701 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:36.1583 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661219\n",
      "[INFO 24-02-22 06:52:36.1583 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.1587 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.661219 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:36.1611 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.1611 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.1614 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.1620 UTC hyperparameters_optimizer.cc:582] [216/1100] Score: -0.661219 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:36.1642 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231636 train-accuracy:0.612469 valid-loss:1.201255 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:36.1651 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241109 train-accuracy:0.612469 valid-loss:1.206834 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:36.3139 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690635\n",
      "[INFO 24-02-22 06:52:36.3139 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.3140 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.690635 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:36.3146 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.3146 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.3154 UTC hyperparameters_optimizer.cc:582] [217/1100] Score: -0.690635 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:36.3170 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.3209 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.139269 train-accuracy:0.770171 valid-loss:1.088426 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:36.3689 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643361\n",
      "[INFO 24-02-22 06:52:36.3689 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.3692 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.643361 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:36.3696 UTC hyperparameters_optimizer.cc:582] [218/1100] Score: -0.643361 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:36.3705 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.3705 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.3707 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.4077 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593643\n",
      "[INFO 24-02-22 06:52:36.4077 UTC gradient_boosted_trees.cc:271] Truncates the model to 78 tree(s) i.e. 78  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.4079 UTC gradient_boosted_trees.cc:334] Final model num-trees:78 valid-loss:0.593643 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:36.4086 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.4086 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.4089 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.4122 UTC hyperparameters_optimizer.cc:582] [219/1100] Score: -0.593643 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:36.4139 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.306886 train-accuracy:0.612469 valid-loss:1.267699 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:36.4245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653081\n",
      "[INFO 24-02-22 06:52:36.4246 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.4248 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315345 train-accuracy:0.612469 valid-loss:1.273349 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:36.4249 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.653081 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:36.4252 UTC hyperparameters_optimizer.cc:582] [220/1100] Score: -0.653081 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:36.4259 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.4259 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.4262 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.4848 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186039 train-accuracy:0.612469 valid-loss:1.144359 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:36.5100 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638097\n",
      "[INFO 24-02-22 06:52:36.5100 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.5101 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.638097 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:36.5104 UTC hyperparameters_optimizer.cc:582] [221/1100] Score: -0.638097 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:36.5117 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.5117 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.5120 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.5256 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.067461 train-accuracy:0.894866 valid-loss:1.109769 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:36.6416 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619375\n",
      "[INFO 24-02-22 06:52:36.6416 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.6431 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.619375 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:36.6533 UTC hyperparameters_optimizer.cc:582] [222/1100] Score: -0.619375 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:36.6596 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.6597 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.6599 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.6624 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.54815\n",
      "[INFO 24-02-22 06:52:36.6625 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:52:36.6627 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.548150 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:36.6635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:36.6635 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:36.6637 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:36.6654 UTC hyperparameters_optimizer.cc:582] [223/1100] Score: -0.54815 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:36.6902 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.041041 train-accuracy:0.837408 valid-loss:1.024407 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:36.7006 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187568 train-accuracy:0.612469 valid-loss:1.140934 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:37.0032 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635861\n",
      "[INFO 24-02-22 06:52:37.0032 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.0036 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.635861 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:37.0042 UTC hyperparameters_optimizer.cc:582] [224/1100] Score: -0.635861 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:37.0047 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.0047 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.0050 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.0114 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151585 train-accuracy:0.749389 valid-loss:1.125946 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:52:37.1294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.581865\n",
      "[INFO 24-02-22 06:52:37.1294 UTC gradient_boosted_trees.cc:271] Truncates the model to 140 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.1296 UTC gradient_boosted_trees.cc:334] Final model num-trees:140 valid-loss:0.581865 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:37.1302 UTC hyperparameters_optimizer.cc:582] [225/1100] Score: -0.581865 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:37.1312 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.1314 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.1319 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.1562 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184766 train-accuracy:0.612469 valid-loss:1.147686 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:37.3123 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.705775\n",
      "[INFO 24-02-22 06:52:37.3124 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.3141 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.705775 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:37.3152 UTC hyperparameters_optimizer.cc:582] [226/1100] Score: -0.705775 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:37.3192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.3192 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.3197 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.3437 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090131 train-accuracy:0.812958 valid-loss:1.036691 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:37.3921 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.561038\n",
      "[INFO 24-02-22 06:52:37.3921 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.3923 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.561038 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:37.3926 UTC hyperparameters_optimizer.cc:582] [227/1100] Score: -0.561038 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:37.3958 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.3960 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.3962 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.3974 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.169577 train-accuracy:0.726161 valid-loss:1.122915 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:52:37.4173 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640669\n",
      "[INFO 24-02-22 06:52:37.4174 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.4175 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.640669 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:37.4192 UTC hyperparameters_optimizer.cc:582] [228/1100] Score: -0.640669 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:37.4200 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.4201 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.4204 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.4682 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103146 train-accuracy:0.612469 valid-loss:1.148262 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:37.4721 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645628\n",
      "[INFO 24-02-22 06:52:37.4723 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.4724 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.645628 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:37.4727 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.4728 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.4730 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.4757 UTC hyperparameters_optimizer.cc:582] [229/1100] Score: -0.645628 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:37.5665 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.981332 train-accuracy:0.889976 valid-loss:1.034290 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:37.6464 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6201\n",
      "[INFO 24-02-22 06:52:37.6464 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.6466 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.620100 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:37.6480 UTC hyperparameters_optimizer.cc:582] [230/1100] Score: -0.6201 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:37.6482 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.6483 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.6484 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.7713 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.984469 train-accuracy:0.933985 valid-loss:1.096705 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:37.8557 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664239\n",
      "[INFO 24-02-22 06:52:37.8558 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.8560 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.664239 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:37.8578 UTC hyperparameters_optimizer.cc:582] [231/1100] Score: -0.664239 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:37.8624 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.8624 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.8628 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.8648 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.110875 train-accuracy:0.797066 valid-loss:1.067801 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:37.9226 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.56709\n",
      "[INFO 24-02-22 06:52:37.9227 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:52:37.9229 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.567090 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:37.9234 UTC hyperparameters_optimizer.cc:582] [232/1100] Score: -0.56709 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:37.9240 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:37.9240 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:37.9243 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:37.9272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296466 train-accuracy:0.612469 valid-loss:1.253541 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:38.0343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647355\n",
      "[INFO 24-02-22 06:52:38.0343 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.0345 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.647355 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:38.0351 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.0351 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.0355 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.0380 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090999 train-accuracy:0.808068 valid-loss:1.056373 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:38.0387 UTC hyperparameters_optimizer.cc:582] [233/1100] Score: -0.647355 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:38.1499 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.704299\n",
      "[INFO 24-02-22 06:52:38.1499 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.1518 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.704299 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:38.1545 UTC hyperparameters_optimizer.cc:582] [234/1100] Score: -0.704299 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:38.1618 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.1620 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.1623 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.1650 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283905 train-accuracy:0.612469 valid-loss:1.245479 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:38.1992 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668482\n",
      "[INFO 24-02-22 06:52:38.1992 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.1996 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.668482 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:38.1999 UTC hyperparameters_optimizer.cc:582] [235/1100] Score: -0.668482 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:38.2008 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.2010 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.2013 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.2039 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313188 train-accuracy:0.612469 valid-loss:1.271887 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:38.3991 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636488\n",
      "[INFO 24-02-22 06:52:38.4004 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.4008 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.636488 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:38.4015 UTC hyperparameters_optimizer.cc:582] [236/1100] Score: -0.636488 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:38.4047 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.4047 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.4049 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.4146 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.051761 train-accuracy:0.823961 valid-loss:1.054982 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:38.5957 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599953\n",
      "[INFO 24-02-22 06:52:38.5957 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.5958 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.599953 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:38.5961 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.5961 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.5963 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.5987 UTC hyperparameters_optimizer.cc:582] [237/1100] Score: -0.599953 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:38.6297 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.116081 train-accuracy:0.612469 valid-loss:1.139489 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:38.6631 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639398\n",
      "[INFO 24-02-22 06:52:38.6633 UTC gradient_boosted_trees.cc:271] Truncates the model to 158 tree(s) i.e. 158  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.6638 UTC gradient_boosted_trees.cc:334] Final model num-trees:158 valid-loss:0.639398 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:38.6697 UTC early_stopping.cc:[INFO 24-02-22 06:52:38.6698 UTC hyperparameters_optimizer.cc:582] [238/1100] Score: -0.639398 / -0.484448 HParams: 53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632438\n",
      "[INFOfields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      " 24-02-22 06:52:38.6699 UTC gradient_boosted_trees.cc:271] Truncates the model to 270 tree(s) i.e. 270  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.6699 UTC gradient_boosted_trees.cc:334] Final model num-trees:270 valid-loss:0.632438 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:38.6704 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.6704 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.6704 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.6704 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.6706 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.6719 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.6746 UTC hyperparameters_optimizer.cc:582] [239/1100] Score: -0.632438 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO[INFO 24-02-22 06:52:38.6842 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313634 train-accuracy:0.612469 valid-loss:1.270482 valid-accuracy:0.657534\n",
      " 24-02-22 06:52:38.6844 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.197719 train-accuracy:0.612469 valid-loss:1.160383 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:38.8463 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.553541\n",
      "[INFO 24-02-22 06:52:38.8463 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.8466 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.553541 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:38.8478 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.8481 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.8486 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.8520 UTC hyperparameters_optimizer.cc:582] [240/1100] Score: -0.553541 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:38.9515 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649065\n",
      "[INFO 24-02-22 06:52:38.9516 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.9521 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.649065 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:38.9528 UTC hyperparameters_optimizer.cc:582] [241/1100] Score: -0.649065 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:38.9535 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.9536 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.9539 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.9551 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207848 train-accuracy:0.612469 valid-loss:1.166010 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:38.9664 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.308255 train-accuracy:0.612469 valid-loss:1.272066 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:38.9899 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.575577\n",
      "[INFO 24-02-22 06:52:38.9899 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:38.9901 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.575577 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:38.9903 UTC hyperparameters_optimizer.cc:582] [242/1100] Score: -0.575577 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:38.9907 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:38.9907 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:38.9910 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:38.9924 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.161347 train-accuracy:0.731051 valid-loss:1.131231 valid-accuracy:0.712329\n",
      "[INFO 24-02-22 06:52:39.1099 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.547343\n",
      "[INFO 24-02-22 06:52:39.1100 UTC gradient_boosted_trees.cc:271] Truncates the model to 215 tree(s) i.e. 215  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.1100 UTC gradient_boosted_trees.cc:334] Final model num-trees:215 valid-loss:0.547343 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:52:39.1105 UTC hyperparameters_optimizer.cc:582] [243/1100] Score: -0.547343 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:39.1115 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.1115 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.1119 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.1128 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.259946 train-accuracy:0.612469 valid-loss:1.219631 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:39.1326 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.548625\n",
      "[INFO 24-02-22 06:52:39.1327 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.1328 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.548625 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:39.1333 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.1333 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.1335 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.1353 UTC hyperparameters_optimizer.cc:582] [244/1100] Score: -0.548625 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:39.1428 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313271 train-accuracy:0.612469 valid-loss:1.274862 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:39.2475 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630608\n",
      "[INFO 24-02-22 06:52:39.2476 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.2476 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.630608 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:39.2479 UTC hyperparameters_optimizer.cc:582] [245/1100] Score: -0.630608 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:39.2485 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.2486 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.2490 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.2509 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.602836\n",
      "[INFO 24-02-22 06:52:39.2509 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.2511 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.602836 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:39.2518 UTC hyperparameters_optimizer.cc:582] [246/1100] Score: -0.602836 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:39.2530 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.2531 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.2535 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.2605 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153855 train-accuracy:0.787286 valid-loss:1.106332 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:52:39.2607 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278267 train-accuracy:0.612469 valid-loss:1.240491 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:39.3332 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650486\n",
      "[INFO 24-02-22 06:52:39.3332 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.3333 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.650486 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:39.3339 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.3339 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.3340 UTC hyperparameters_optimizer.cc:582] [247/1100] Score: -0.650486 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:39.3343 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.3911 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312261 train-accuracy:0.612469 valid-loss:1.273091 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:39.4198 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.716784\n",
      "[INFO 24-02-22 06:52:39.4198 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.4204 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.716784 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:39.4212 UTC hyperparameters_optimizer.cc:582] [248/1100] Score: -0.716784 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:39.4230 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.4230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.4233 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.4912 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283156 train-accuracy:0.612469 valid-loss:1.240811 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:39.7960 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.425146 train-accuracy:0.922983 valid-loss:0.587780 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:39.7960 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.7960 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.587780 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:39.7977 UTC hyperparameters_optimizer.cc:582] [249/1100] Score: -0.58778 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:39.8004 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.8005 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.8009 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.8198 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.051665 train-accuracy:0.827628 valid-loss:1.029522 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:39.8356 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.576442\n",
      "[INFO 24-02-22 06:52:39.8356 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.8358 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.576442 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:39.8365 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.8365 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.8368 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.8387 UTC hyperparameters_optimizer.cc:582] [250/1100] Score: -0.576442 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:39.8466 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.716255\n",
      "[INFO 24-02-22 06:52:39.8467 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.8484 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.716255 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:39.8492 UTC hyperparameters_optimizer.cc:582] [251/1100] Score: -0.716255 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:39.8517 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65789\n",
      "[INFO 24-02-22 06:52:39.8517 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:52:39.8521 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.657890 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:39.8524 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.8524 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.8536 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.8544 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.8544 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.8546 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.8561 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.042430 train-accuracy:0.841076 valid-loss:1.033871 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:39.8587 UTC hyperparameters_optimizer.cc:582] [252/1100] Score: -0.65789 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:39.8698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201220 train-accuracy:0.612469 valid-loss:1.143978 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:39.9159 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.113568 train-accuracy:0.799511 valid-loss:1.065076 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:39.9543 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64303\n",
      "[INFO 24-02-22 06:52:39.9543 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:39.9545 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:39.9545 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.643030 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:39.9547 UTC hyperparameters_optimizer.cc:582] [253/1100] Score: -0.64303 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:39.9551 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:39.9551 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:39.9553 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:39.9602 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227359 train-accuracy:0.612469 valid-loss:1.187809 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:40.0328 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.577275\n",
      "[INFO 24-02-22 06:52:40.0328 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 24-02-22 06:52:40.0330 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.577275 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:40.0338 UTC hyperparameters_optimizer.cc:582] [254/1100] Score: -0.577275 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:40.0349 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.0349 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.0358 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.0377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.057056 train-accuracy:0.832518 valid-loss:0.971974 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:40.2393 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.730107\n",
      "[INFO 24-02-22 06:52:40.2393 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:40.2405 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:40.2405 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.730107 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:40.2421 UTC hyperparameters_optimizer.cc:582] [255/1100] Score: -0.730107 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:40.2423 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.525454\n",
      "[INFO 24-02-22 06:52:40.2423 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:52:40.2455 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.525454 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:40.2466 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.2466 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.2468 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.2482 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.2491 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.2493 UTC hyperparameters_optimizer.cc:582] [256/1100] Score: -0.525454 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:40.2494 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.2536 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132178 train-accuracy:0.778729 valid-loss:1.092296 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:40.2655 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233960 train-accuracy:0.612469 valid-loss:1.198490 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:40.3916 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.574905\n",
      "[INFO 24-02-22 06:52:40.3917 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:52:40.3918 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.574905 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:40.3931 UTC hyperparameters_optimizer.cc:582] [257/1100] Score: -0.574905 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:40.3956 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.3963 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.3965 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.3985 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.198030 train-accuracy:0.612469 valid-loss:1.166131 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:40.5555 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.611073\n",
      "[INFO 24-02-22 06:52:40.5555 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:52:40.5556 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.611073 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:40.5559 UTC hyperparameters_optimizer.cc:582] [258/1100] Score: -0.611073 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:40.5589 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.5590 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.5592 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.5973 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275486 train-accuracy:0.612469 valid-loss:1.241826 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:40.6354 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.566698\n",
      "[INFO 24-02-22 06:52:40.6356 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:52:40.6358 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.566698 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:40.6365 UTC hyperparameters_optimizer.cc:582] [259/1100] Score: -0.566698 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:40.6401 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.6401 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.6404 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.7486 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.273811 train-accuracy:0.612469 valid-loss:1.241495 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:40.8516 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655736\n",
      "[INFO 24-02-22 06:52:40.8517 UTC gradient_boosted_trees.cc:271] Truncates the model to 153 tree(s) i.e. 153  iteration(s).\n",
      "[INFO 24-02-22 06:52:40.8520 UTC gradient_boosted_trees.cc:334] Final model num-trees:153 valid-loss:0.655736 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:40.8545 UTC hyperparameters_optimizer.cc:582] [260/1100] Score: -0.655736 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:40.8586 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.8589 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.8592 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.8620 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290536 train-accuracy:0.612469 valid-loss:1.247462 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:40.9774 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646468\n",
      "[INFO 24-02-22 06:52:40.9774 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:52:40.9777 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.646468 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:40.9785 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.9786 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.9789 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.9806 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635395\n",
      "[INFO 24-02-22 06:52:40.9806 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:52:40.9807 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.635395 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:40.9813 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:40.9813 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:40.9815 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:40.9820 UTC hyperparameters_optimizer.cc:582] [261/1100] Score: -0.646468 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:40.9825 UTC hyperparameters_optimizer.cc:582] [262/1100] Score: -0.635395 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:41.0146 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.078789 train-accuracy:0.827628 valid-loss:1.008086 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:41.0206 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.074925 train-accuracy:0.815403 valid-loss:1.052210 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:41.0313 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655862\n",
      "[INFO 24-02-22 06:52:41.0313 UTC gradient_boosted_trees.cc:271] Truncates the model to 145 tree(s) i.e. 145  iteration(s).\n",
      "[INFO 24-02-22 06:52:41.0317 UTC gradient_boosted_trees.cc:334] Final model num-trees:145 valid-loss:0.655862 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:41.0336 UTC hyperparameters_optimizer.cc:582] [263/1100] Score: -0.655862 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:41.0375 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:41.0375 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:41.0378 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:41.0424 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.038623 train-accuracy:0.856968 valid-loss:1.029385 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:41.1203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617232\n",
      "[INFO 24-02-22 06:52:41.1203 UTC gradient_boosted_trees.cc:271] Truncates the model to 195 tree(s) i.e. 195  iteration(s).\n",
      "[INFO 24-02-22 06:52:41.1206 UTC gradient_boosted_trees.cc:334] Final model num-trees:195 valid-loss:0.617232 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:41.1232 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:41.1232 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:41.1234 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:41.1253 UTC hyperparameters_optimizer.cc:582] [264/1100] Score: -0.617232 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:41.1540 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291646 train-accuracy:0.612469 valid-loss:1.250734 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:41.2712 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648661\n",
      "[INFO 24-02-22 06:52:41.2712 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:52:41.2721 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.648661 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:41.2727 UTC hyperparameters_optimizer.cc:582] [265/1100] Score: -0.648661 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:41.2741 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:41.2741 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:41.2747 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:41.2929 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276707 train-accuracy:0.612469 valid-loss:1.244168 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:41.4397 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601573\n",
      "[INFO 24-02-22 06:52:41.4422 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:52:41.4424 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.601573 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:41.4430 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:41.4431 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:41.4432 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:41.4434 UTC hyperparameters_optimizer.cc:582] [266/1100] Score: -0.601573 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:41.4468 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224758 train-accuracy:0.612469 valid-loss:1.188162 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:41.4999 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638922\n",
      "[INFO 24-02-22 06:52:41.4999 UTC gradient_boosted_trees.cc:271] Truncates the model to 222 tree(s) i.e. 222  iteration(s).\n",
      "[INFO 24-02-22 06:52:41.5001 UTC gradient_boosted_trees.cc:334] Final model num-trees:222 valid-loss:0.638922 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:41.5027 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:41.5027 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:41.5030 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:41.5061 UTC hyperparameters_optimizer.cc:582] [267/1100] Score: -0.638922 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:41.5102 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060876 train-accuracy:0.836186 valid-loss:1.021777 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:41.5793 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686185\n",
      "[INFO 24-02-22 06:52:41.5793 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:52:41.5796 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.686185 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:41.5804 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:41.5804 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:41.5806 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:41.5855 UTC hyperparameters_optimizer.cc:582] [268/1100] Score: -0.686185 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:41.5889 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313990 train-accuracy:0.612469 valid-loss:1.272889 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:41.6831 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.449844 train-accuracy:0.924205 valid-loss:0.572759 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:41.6832 UTC gradient_boosted_trees.cc:271] Truncates the model to 287 tree(s) i.e. 287  iteration(s).\n",
      "[INFO 24-02-22 06:52:41.6832 UTC gradient_boosted_trees.cc:334] Final model num-trees:287 valid-loss:0.571873 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:41.6840 UTC hyperparameters_optimizer.cc:582] [269/1100] Score: -0.571873 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:41.6857 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:41.6857 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:41.6860 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:41.6890 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184124 train-accuracy:0.612469 valid-loss:1.147953 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:41.7431 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.600764\n",
      "[INFO 24-02-22 06:52:41.7443 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:52:41.7444 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.600764 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:41.7448 UTC hyperparameters_optimizer.cc:582] [270/1100] Score: -0.600764 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:41.7453 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:41.7453 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:41.7479 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:41.7558 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083037 train-accuracy:0.833741 valid-loss:1.062042 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:42.0004 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660915\n",
      "[INFO 24-02-22 06:52:42.0014 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:42.0017 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:42.0017 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.660915 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:42.0020 UTC hyperparameters_optimizer.cc:582] [271/1100] Score: -0.660915 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:42.0024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.589818\n",
      "[INFO 24-02-22 06:52:42.0025 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:52:42.0026 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:42.0026 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:42.0026 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.589818 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:42.0028 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:42.0031 UTC hyperparameters_optimizer.cc:582] [272/1100] Score: -0.589818 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:42.0038 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:42.0038 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:42.0041 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:42.0101 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241286 train-accuracy:0.612469 valid-loss:1.197954 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:42.0232 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121785 train-accuracy:0.800734 valid-loss:1.121075 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:42.0391 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.749716\n",
      "[INFO 24-02-22 06:52:42.0391 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:42.0396 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.749716 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:42.0406 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:42.0408 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:42.0411 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:42.0420 UTC hyperparameters_optimizer.cc:582] [273/1100] Score: -0.749716 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:42.0430 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315546 train-accuracy:0.612469 valid-loss:1.274705 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:42.3932 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651127\n",
      "[INFO 24-02-22 06:52:42.3932 UTC gradient_boosted_trees.cc:271] Truncates the model to 160 tree(s) i.e. 160  iteration(s).\n",
      "[INFO 24-02-22 06:52:42.3933 UTC gradient_boosted_trees.cc:334] Final model num-trees:160 valid-loss:0.651127 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:42.3940 UTC hyperparameters_optimizer.cc:582] [274/1100] Score: -0.651127 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:42.3946 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:42.3946 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:42.3954 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:42.4265 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274925 train-accuracy:0.612469 valid-loss:1.240368 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:42.4365 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622065\n",
      "[INFO 24-02-22 06:52:42.4366 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:52:42.4368 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.622065 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:42.4373 UTC hyperparameters_optimizer.cc:582] [275/1100] Score: -0.622065 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:42.4379 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:42.4380 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:42.4382 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:42.4611 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313694 train-accuracy:0.612469 valid-loss:1.275437 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:42.6101 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654726\n",
      "[INFO 24-02-22 06:52:42.6102 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:52:42.6103 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.654726 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:42.6107 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:42.6107 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:42.6109 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:42.6121 UTC hyperparameters_optimizer.cc:582] [276/1100] Score: -0.654726 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:42.6381 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.170748 train-accuracy:0.612469 valid-loss:1.145764 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:42.7090 UTC gradient_boosted_trees.cc:1638] \tnum-trees:39 train-loss:0.080990 train-accuracy:0.980440 valid-loss:1.346523 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:42.9280 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.847052\n",
      "[INFO 24-02-22 06:52:42.9280 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:42.9295 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:42.9295 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.847052 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:42.9304 UTC hyperparameters_optimizer.cc:582] [277/1100] Score: -0.847052 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:42.9325 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:42.9325 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:42.9328 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:42.9396 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315317 train-accuracy:0.612469 valid-loss:1.274285 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:42.9751 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649589\n",
      "[INFO 24-02-22 06:52:42.9751 UTC gradient_boosted_trees.cc:271] Truncates the model to 174 tree(s) i.e. 174  iteration(s).\n",
      "[INFO 24-02-22 06:52:42.9754 UTC gradient_boosted_trees.cc:334] Final model num-trees:174 valid-loss:0.649589 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:42.9761 UTC hyperparameters_optimizer.cc:582] [278/1100] Score: -0.649589 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:42.9765 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:42.9765 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:42.9767 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:42.9806 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176294 train-accuracy:0.612469 valid-loss:1.139967 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:43.1744 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624791\n",
      "[INFO 24-02-22 06:52:43.1745 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:52:43.1747 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.624791 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:43.1753 UTC hyperparameters_optimizer.cc:582] [279/1100] Score: -0.624791 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:43.1763 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:43.1764 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:43.1766 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:43.1872 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619533\n",
      "[INFO 24-02-22 06:52:43.1872 UTC gradient_boosted_trees.cc:271] Truncates the model to 209 tree(s) i.e. 209  iteration(s).\n",
      "[INFO 24-02-22 06:52:43.1876 UTC gradient_boosted_trees.cc:334] Final model num-trees:209 valid-loss:0.619533 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:43.1905 UTC hyperparameters_optimizer.cc:582] [280/1100] Score: -0.619533 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:43.1943 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:43.1945 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:43.1947 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:43.1985 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.167918 train-accuracy:0.612469 valid-loss:1.155999 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:43.2062 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.218319 train-accuracy:0.612469 valid-loss:1.191955 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:43.2378 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640886\n",
      "[INFO 24-02-22 06:52:43.2379 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:52:43.2381 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.640886 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:43.2386 UTC hyperparameters_optimizer.cc:582] [281/1100] Score: -0.640886 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:43.2394 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:43.2394 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:43.2396 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:43.2426 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280828 train-accuracy:0.612469 valid-loss:1.243046 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:43.2460 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643775\n",
      "[INFO 24-02-22 06:52:43.2460 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:52:43.2462 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.643775 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:43.2468 UTC hyperparameters_optimizer.cc:582] [282/1100] Score: -0.643775 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:43.2478 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:43.2478 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:43.2480 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:43.2506 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132015 train-accuracy:0.815403 valid-loss:1.085689 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:43.3437 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685192\n",
      "[INFO 24-02-22 06:52:43.3438 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:52:43.3440 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.685192 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:43.3445 UTC hyperparameters_optimizer.cc:582] [283/1100] Score: -0.685192 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:43.3450 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:43.3451 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:43.3454 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:43.3556 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681752\n",
      "[INFO 24-02-22 06:52:43.3556 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:43.3561 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.681752 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:43.3564 UTC hyperparameters_optimizer.cc:582] [284/1100] Score: -0.681752 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:43.3575 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:43.3575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:43.3578 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:43.3700 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.046293 train-accuracy:0.842298 valid-loss:1.030040 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:43.3882 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.988641 train-accuracy:0.891198 valid-loss:1.004745 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:43.5342 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629114\n",
      "[INFO 24-02-22 06:52:43.5343 UTC gradient_boosted_trees.cc:271] Truncates the model to 80 tree(s) i.e. 80  iteration(s).\n",
      "[INFO 24-02-22 06:52:43.5347 UTC gradient_boosted_trees.cc:334] Final model num-trees:80 valid-loss:0.629114 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:43.5363 UTC hyperparameters_optimizer.cc:582] [285/1100] Score: -0.629114 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:43.5381 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:43.5381 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:43.5384 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:43.5478 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.206133 train-accuracy:0.612469 valid-loss:1.152097 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:43.8741 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648945\n",
      "[INFO 24-02-22 06:52:43.8741 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:52:43.8744 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.648945 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:43.8751 UTC hyperparameters_optimizer.cc:582] [286/1100] Score: -0.648945 / -0.484448 HParams: [INFO 24-02-22 06:52:43.8756 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:43.8756 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:43.8760 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:43.8804 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092251 train-accuracy:0.812958 valid-loss:1.062496 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:44.0349 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646662\n",
      "[INFO 24-02-22 06:52:44.0349 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.0353 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.646662 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:44.0356 UTC hyperparameters_optimizer.cc:582] [287/1100] Score: -0.646662 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:44.0365 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.0366 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.0369 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.0410 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632866\n",
      "[INFO 24-02-22 06:52:44.0411 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.0413 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.632866 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:44.0417 UTC hyperparameters_optimizer.cc:582] [288/1100] Score: -0.632866 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:44.0428 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.0429 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.0430 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.0497 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.173890 train-accuracy:0.612469 valid-loss:1.171449 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:44.0566 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063050 train-accuracy:0.852078 valid-loss:1.076076 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:44.0930 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633866\n",
      "[INFO 24-02-22 06:52:44.0930 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.0933 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.633866 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:44.0943 UTC hyperparameters_optimizer.cc:582] [289/1100] Score: -0.633866 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:44.0950 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.0951 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.0954 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.1409 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130108 train-accuracy:0.792176 valid-loss:1.098854 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:44.1529 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636323\n",
      "[INFO 24-02-22 06:52:44.1529 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.1530 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.636323 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:44.1532 UTC hyperparameters_optimizer.cc:582] [290/1100] Score: -0.636323 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:44.1537 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.1537 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.1540 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.1559 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284378 train-accuracy:0.612469 valid-loss:1.243530 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:44.1715 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642619\n",
      "[INFO 24-02-22 06:52:44.1716 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.1723 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.642619 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:44.1729 UTC hyperparameters_optimizer.cc:582] [291/1100] Score: -0.642619 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:44.1732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.1732 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.1734 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.1890 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114911 train-accuracy:0.799511 valid-loss:1.074299 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:44.3205 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647414\n",
      "[INFO 24-02-22 06:52:44.3206 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.3213 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.647414 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:44.3222 UTC hyperparameters_optimizer.cc:582] [292/1100] Score: -0.647414 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:44.3233 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.3233 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.3235 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.3630 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61021\n",
      "[INFO 24-02-22 06:52:44.3631 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.3633 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.610210 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:44.3638 UTC hyperparameters_optimizer.cc:582] [293/1100] Score: -0.61021 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:44.3644 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.3644 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.3646 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.3667 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.140671 train-accuracy:0.804401 valid-loss:1.081380 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:44.3936 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.030961 train-accuracy:0.822738 valid-loss:1.038861 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:44.4078 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660354\n",
      "[INFO 24-02-22 06:52:44.4078 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.4087 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.660354 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:44.4098 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.4098 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.4100 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.4121 UTC hyperparameters_optimizer.cc:582] [294/1100] Score: -0.660354 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:44.4163 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187494 train-accuracy:0.612469 valid-loss:1.156045 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:44.6286 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699986\n",
      "[INFO 24-02-22 06:52:44.6286 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:44.6291 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:44.6291 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.699986 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:44.6296 UTC hyperparameters_optimizer.cc:582] [295/1100] Score: -0.699986 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:44.6312 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.6312 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.6326 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.6557 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.108883 train-accuracy:0.784841 valid-loss:1.100377 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:44.6696 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.551815\n",
      "[INFO 24-02-22 06:52:44.6697 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.6698 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.551815 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:44.6702 UTC hyperparameters_optimizer.cc:582] [296/1100] Score: -0.551815 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:44.6709 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.6709 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.6712 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.6735 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315480 train-accuracy:0.612469 valid-loss:1.273775 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:44.7554 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63649\n",
      "[INFO 24-02-22 06:52:44.7554 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.7556 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.636490 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:44.7566 UTC hyperparameters_optimizer.cc:582] [297/1100] Score: -0.63649 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:44.7575 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.7575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.7576 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:44.7587 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626416\n",
      "[INFO 24-02-22 06:52:44.7587 UTC gradient_boosted_trees.cc:271] Truncates the model to 257 tree(s) i.e. 257  iteration(s).\n",
      "[INFO 24-02-22 06:52:44.7590 UTC gradient_boosted_trees.cc:334] Final model num-trees:257 valid-loss:0.626416 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:44.7604 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.189548 train-accuracy:0.612469 valid-loss:1.154894 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:44.7615 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:44.7615 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:44.7617 UTC hyperparameters_optimizer.cc:582] [INFO 24-02-22 06:52:44.7617 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[298/1100] Score: -0.626416 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:44.7843 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266785 train-accuracy:0.612469 valid-loss:1.230380 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.0184 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.571546\n",
      "[INFO 24-02-22 06:52:45.0219 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.0221 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.571546 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:45.0225 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.0225 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.0227 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.0248 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241270 train-accuracy:0.612469 valid-loss:1.206233 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.0254 UTC hyperparameters_optimizer.cc:582] [299/1100] Score: -0.571546 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:45.0433 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655346\n",
      "[INFO 24-02-22 06:52:45.0434 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.0439 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.655346 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:45.0455 UTC hyperparameters_optimizer.cc:582] [300/1100] Score: -0.655346 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:45.0481 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.0483 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.0488 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.0846 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.270577 train-accuracy:0.612469 valid-loss:1.246549 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.1385 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.739866\n",
      "[INFO 24-02-22 06:52:45.1386 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.1390 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.739866 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:45.1393 UTC hyperparameters_optimizer.cc:582] [301/1100] Score: -0.739866 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:45.1400 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.1400 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.1404 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.1890 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277113 train-accuracy:0.612469 valid-loss:1.241307 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.2220 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.60142\n",
      "[INFO 24-02-22 06:52:45.2220 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.2223 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.601420 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:45.2233 UTC hyperparameters_optimizer.cc:582] [302/1100] Score: -0.60142 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:45.2254 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.2254 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.2256 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.2285 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.067668 train-accuracy:0.814181 valid-loss:1.041996 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:45.2308 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614684\n",
      "[INFO 24-02-22 06:52:45.2308 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.2309 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.614684 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:45.2317 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.2318 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.2320 UTC hyperparameters_optimizer.cc:582] [303/1100] Score: -0.614684 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:45.2321 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.2359 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292592 train-accuracy:0.612469 valid-loss:1.247424 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.2696 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.507365 train-accuracy:0.919315 valid-loss:0.604948 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:45.2696 UTC gradient_boosted_trees.cc:271] Truncates the model to 289 tree(s) i.e. 289  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.2697 UTC gradient_boosted_trees.cc:334] Final model num-trees:289 valid-loss:0.602668 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:45.2713 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.2713 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.2716 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.2720 UTC hyperparameters_optimizer.cc:582] [304/1100] Score: -0.602668 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:45.4092 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.254608 train-accuracy:0.612469 valid-loss:1.230161 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.4302 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.613454\n",
      "[INFO 24-02-22 06:52:45.4303 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.4305 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.613454 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:45.4317 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.4317 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.4319 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.4320 UTC hyperparameters_optimizer.cc:582] [305/1100] Score: -0.613454 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:45.4348 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239986 train-accuracy:0.612469 valid-loss:1.202857 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.5902 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645295\n",
      "[INFO 24-02-22 06:52:45.5902 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.5903 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.645295 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:45.5906 UTC hyperparameters_optimizer.cc:582] [306/1100] Score: -0.645295 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:45.5912 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.5912 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.5925 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.6360 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.175416 train-accuracy:0.612469 valid-loss:1.138909 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.9074 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674591\n",
      "[INFO 24-02-22 06:52:45.9074 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.9082 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.674591 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:45.9099 UTC hyperparameters_optimizer.cc:582] [307/1100] Score: -0.674591 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:45.9112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.9112 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.9126 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:45.9227 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305754 train-accuracy:0.612469 valid-loss:1.271287 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:45.9967 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644853\n",
      "[INFO 24-02-22 06:52:45.9967 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:45.9970 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.644853 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:45.9974 UTC hyperparameters_optimizer.cc:582] [308/1100] Score: -0.644853 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:45.9987 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:45.9989 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:45.9991 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.0068 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.214522 train-accuracy:0.612469 valid-loss:1.195807 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.1188 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588574\n",
      "[INFO 24-02-22 06:52:46.1188 UTC gradient_boosted_trees.cc:271] Truncates the model to 253 tree(s) i.e. 253  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.1188 UTC gradient_boosted_trees.cc:334] Final model num-trees:253 valid-loss:0.588574 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:46.1193 UTC hyperparameters_optimizer.cc:582] [309/1100] Score: -0.588574 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:46.1196 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.1196 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.1201 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.1253 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315215 train-accuracy:0.612469 valid-loss:1.273733 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.2808 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637641\n",
      "[INFO 24-02-22 06:52:46.2809 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.2810 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.637641 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:46.2812 UTC hyperparameters_optimizer.cc:582] [310/1100] Score: -0.637641 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:46.2817 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.2817 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.2822 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.3235 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314063 train-accuracy:0.612469 valid-loss:1.273074 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.3905 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648206\n",
      "[INFO 24-02-22 06:52:46.3906 UTC gradient_boosted_trees.cc:271] Truncates the model to 173 tree(s) i.e. 173  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.3908 UTC gradient_boosted_trees.cc:334] Final model num-trees:173 valid-loss:0.648206 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:46.3922 UTC hyperparameters_optimizer.cc:582] [311/1100] Score: -0.648206 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:46.3956 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.3959 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.3962 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.4023 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.220053 train-accuracy:0.612469 valid-loss:1.205711 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.4234 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68281\n",
      "[INFO 24-02-22 06:52:46.4234 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.4246 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.682810 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:46.4269 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.4282 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.4284 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.4320 UTC hyperparameters_optimizer.cc:582] [312/1100] Score: -0.68281 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:46.4357 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229134 train-accuracy:0.612469 valid-loss:1.197853 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.6270 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624847\n",
      "[INFO 24-02-22 06:52:46.6270 UTC gradient_boosted_trees.cc:271] Truncates the model to 90 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.6273 UTC gradient_boosted_trees.cc:334] Final model num-trees:90 valid-loss:0.624847 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:46.6331 UTC hyperparameters_optimizer.cc:582] [313/1100] Score: -0.624847 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:46.6337 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.6337 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.6348 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.6410 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314491 train-accuracy:0.612469 valid-loss:1.275567 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.7611 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676403\n",
      "[INFO 24-02-22 06:52:46.7614 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.7618 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.676403 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:46.7627 UTC hyperparameters_optimizer.cc:582] [314/1100] Score: -0.676403 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:46.7637 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.7638 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.7642 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.7650 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225315 train-accuracy:0.612469 valid-loss:1.190978 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.8293 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597307\n",
      "[INFO 24-02-22 06:52:46.8294 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.8304 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.597307 valid-accuracy:0.904110\n",
      "[INFO[INFO 24-02-22 06:52:46.8330 UTC hyperparameters_optimizer.cc:582] [315/1100] Score: -0.597307 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      " 24-02-22 06:52:46.8330 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.8331 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.8346 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.8369 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225315 train-accuracy:0.612469 valid-loss:1.190978 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.8545 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632512\n",
      "[INFO 24-02-22 06:52:46.8545 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.8549 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.632512 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:46.8559 UTC hyperparameters_optimizer.cc:582] [316/1100] Score: -0.632512 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:46.8565 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.8565 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.8567 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.8619 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151853 train-accuracy:0.733496 valid-loss:1.117814 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:52:46.8960 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621407\n",
      "[INFO 24-02-22 06:52:46.8961 UTC gradient_boosted_trees.cc:271] Truncates the model to 161 tree(s) i.e. 161  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.8961 UTC gradient_boosted_trees.cc:334] Final model num-trees:161 valid-loss:0.621407 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:46.8964 UTC hyperparameters_optimizer.cc:582] [317/1100] Score: -0.621407 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:46.8971 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.8971 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.8973 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.8996 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180217 train-accuracy:0.612469 valid-loss:1.142852 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.9214 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619798\n",
      "[INFO 24-02-22 06:52:46.9215 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.9218 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.619798 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:46.9259 UTC hyperparameters_optimizer.cc:582] [318/1100] Score: -0.619798 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:46.9263 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.9263 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.9266 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.9492 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635511\n",
      "[INFO 24-02-22 06:52:46.9515 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:52:46.9516 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.635511 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:46.9519 UTC hyperparameters_optimizer.cc:582] [319/1100] Score: -0.635511 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:46.9523 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:46.9524 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:46.9526 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:46.9618 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311131 train-accuracy:0.612469 valid-loss:1.270226 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:46.9764 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312593 train-accuracy:0.612469 valid-loss:1.272154 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:47.0427 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658055\n",
      "[INFO 24-02-22 06:52:47.0427 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:47.0432 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.658055 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:47.0448 UTC hyperparameters_optimizer.cc:582] [320/1100] Score: -0.658055 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:47.0468 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:47.0468 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:47.0470 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:47.1206 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.195493 train-accuracy:0.612469 valid-loss:1.152677 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:47.6467 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670339\n",
      "[INFO 24-02-22 06:52:47.6468 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:52:47.6471 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.670339 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:47.6473 UTC hyperparameters_optimizer.cc:582] [321/1100] Score: -0.670339 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:47.6478 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:47.6478 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:47.6481 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:47.6538 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.107359 train-accuracy:0.821516 valid-loss:1.063441 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:47.7681 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64197\n",
      "[INFO 24-02-22 06:52:47.7681 UTC gradient_boosted_trees.cc:271] Truncates the model to 214 tree(s) i.e. 214  iteration(s).\n",
      "[INFO 24-02-22 06:52:47.7682 UTC gradient_boosted_trees.cc:334] Final model num-trees:214 valid-loss:0.641970 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:47.7694 UTC hyperparameters_optimizer.cc:582] [322/1100] Score: -0.64197 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:47.7701 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:47.7701 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:47.7709 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:47.7733 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281307 train-accuracy:0.612469 valid-loss:1.238596 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.0086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.581195\n",
      "[INFO 24-02-22 06:52:48.0086 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.0091 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.581195 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:48.0095 UTC hyperparameters_optimizer.cc:582] [323/1100] Score: -0.581195 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:48.0109 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.0109 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.0111 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.0138 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.208053 train-accuracy:0.612469 valid-loss:1.161483 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.0184 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643179\n",
      "[INFO 24-02-22 06:52:48.0185 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.0188 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.643179 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:48.0197 UTC hyperparameters_optimizer.cc:582] [324/1100] Score: -0.643179 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:48.0212 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.0213 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.0216 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.0327 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.111622 train-accuracy:0.799511 valid-loss:1.089183 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:48.0803 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643617\n",
      "[INFO 24-02-22 06:52:48.0803 UTC gradient_boosted_trees.cc:271] Truncates the model to 214 tree(s) i.e. 214  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.0805 UTC gradient_boosted_trees.cc:334] Final model num-trees:214 valid-loss:0.643617 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:48.0824 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.0825 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.0826 UTC hyperparameters_optimizer.cc:582] [325/1100] Score: -0.643617 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:48.0861 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.1099 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311762 train-accuracy:0.612469 valid-loss:1.273844 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.1184 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.721029\n",
      "[INFO 24-02-22 06:52:48.1185 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:52:48.1192 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:52:48.1193 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.721029 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:48.1204 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.1205 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.1208 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[[INFO 24-02-22 06:52:48.1233 UTC hyperparameters_optimizer.cc:582] [326/1100] Score: -0.721029 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 06:52:48.1238 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283420 train-accuracy:0.612469 valid-loss:1.241651 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.1959 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665115\n",
      "[INFO 24-02-22 06:52:48.1959 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.1964 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.665115 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:48.1979 UTC hyperparameters_optimizer.cc:582] [327/1100] Score: -0.665115 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:48.2016 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.2016 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.2019 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.2081 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.118751 train-accuracy:0.811736 valid-loss:1.083073 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:48.3540 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66077\n",
      "[INFO 24-02-22 06:52:48.3541 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.3543 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.660770 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:48.3555 UTC hyperparameters_optimizer.cc:582] [328/1100] Score: -0.66077 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:48.3569 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.3569 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.3571 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.3715 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.585931\n",
      "[INFO 24-02-22 06:52:48.3715 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.3716 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.585931 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:48.3721 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.3721 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.3723 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.3754 UTC hyperparameters_optimizer.cc:582] [329/1100] Score: -0.585931 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:48.3866 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186661 train-accuracy:0.612469 valid-loss:1.157884 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.4117 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226258 train-accuracy:0.612469 valid-loss:1.189857 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.6015 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681982\n",
      "[INFO 24-02-22 06:52:48.6016 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.6023 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.681982 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:48.6029 UTC hyperparameters_optimizer.cc:582] [330/1100] Score: -0.681982 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:48.6035 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.6036 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.6039 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.6097 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283339 train-accuracy:0.612469 valid-loss:1.240677 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.6878 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669408\n",
      "[INFO 24-02-22 06:52:48.6879 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.6880 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.669408 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:48.6882 UTC hyperparameters_optimizer.cc:582] [331/1100] Score: -0.669408 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:48.6887 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.6888 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.6889 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.6919 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162544 train-accuracy:0.612469 valid-loss:1.131559 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.8929 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.600919\n",
      "[INFO 24-02-22 06:52:48.8941 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.8946 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.600919 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:48.8953 UTC hyperparameters_optimizer.cc:582] [332/1100] Score: -0.600919 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:48.8979 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.8979 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.8981 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.9273 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678578\n",
      "[INFO 24-02-22 06:52:48.9273 UTC gradient_boosted_trees.cc:271] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "[INFO 24-02-22 06:52:48.9287 UTC gradient_boosted_trees.cc:334] Final model num-trees:116 valid-loss:0.678578 valid-accuracy:0.849315\n",
      "[[INFO 24-02-22 06:52:48.9393 UTC hyperparameters_optimizer.cc:582] [333/1100] Score: -0.678578 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:52:48.9453 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:48.9570 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:48.9573 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:48.9585 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290888 train-accuracy:0.612469 valid-loss:1.249509 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:48.9854 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.206688 train-accuracy:0.612469 valid-loss:1.178095 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:49.1597 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606689\n",
      "[INFO 24-02-22 06:52:49.1597 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 06:52:49.1598 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.606689 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:49.1602 UTC hyperparameters_optimizer.cc:582] [334/1100] Score: -0.606689 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:49.1625 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:49.1626 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:49.1628 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:49.1663 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.115177 train-accuracy:0.812958 valid-loss:1.102666 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:49.1908 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661819\n",
      "[INFO 24-02-22 06:52:49.1908 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:49.1910 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.661819 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:49.1912 UTC hyperparameters_optimizer.cc:582] [335/1100] Score: -0.661819 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:49.1931 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:49.1931 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:49.1934 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:49.1994 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282305 train-accuracy:0.612469 valid-loss:1.245003 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:49.2294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597063\n",
      "[INFO 24-02-22 06:52:49.2308 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:52:49.2310 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.597063 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:49.2318 UTC hyperparameters_optimizer.cc:582] [336/1100] Score: -0.597063 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:49.2347 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:49.2347 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:49.2349 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:49.2787 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603301\n",
      "[INFO 24-02-22 06:52:49.2787 UTC gradient_boosted_trees.cc:271] Truncates the model to 209 tree(s) i.e. 209  iteration(s).\n",
      "[INFO 24-02-22 06:52:49.2788 UTC gradient_boosted_trees.cc:334] Final model num-trees:209 valid-loss:0.603301 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:49.2793 UTC hyperparameters_optimizer.cc:582] [337/1100] Score: -0.603301 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:49.2803 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:49.2803 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:49.2806 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:49.2905 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.093954 train-accuracy:0.809291 valid-loss:1.065633 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:49.3481 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.100983 train-accuracy:0.805623 valid-loss:1.056027 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:49.4128 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.607654\n",
      "[INFO 24-02-22 06:52:49.4128 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:52:49.4129 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.607654 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:49.4142 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:49.4142 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:49.4145 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:49.4173 UTC hyperparameters_optimizer.cc:582] [338/1100] Score: -0.607654 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:49.4667 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.178297 train-accuracy:0.612469 valid-loss:1.144813 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:49.7709 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660747\n",
      "[INFO 24-02-22 06:52:49.7709 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 06:52:49.7712 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.660747 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:49.7719 UTC hyperparameters_optimizer.cc:582] [339/1100] Score: -0.660747 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:49.7736 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:49.7736 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:49.7738 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:49.7757 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287201 train-accuracy:0.612469 valid-loss:1.247207 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:49.8935 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673941\n",
      "[INFO 24-02-22 06:52:49.8935 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-22 06:52:49.8939 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.673941 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:49.8950 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:49.8950 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:49.8952 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:49.8955 UTC hyperparameters_optimizer.cc:582] [340/1100] Score: -0.673941 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:49.9123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.042856 train-accuracy:0.834963 valid-loss:1.027909 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:49.9229 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.591906\n",
      "[INFO 24-02-22 06:52:49.9230 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 06:52:49.9233 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.591906 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:49.9242 UTC hyperparameters_optimizer.cc:582] [341/1100] Score: -0.591906 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:49.9261 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:49.9262 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:49.9265 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:49.9321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240293 train-accuracy:0.612469 valid-loss:1.196974 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:50.3700 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639281\n",
      "[INFO 24-02-22 06:52:50.3700 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:52:50.3702 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.639281 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:50.3709 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:50.3709 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:50.3711 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:50.3720 UTC hyperparameters_optimizer.cc:582] [342/1100] Score: -0.639281 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:50.3743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.173701 train-accuracy:0.612469 valid-loss:1.152043 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:50.5240 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66036\n",
      "[INFO 24-02-22 06:52:50.5241 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:52:50.5247 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.660360 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:50.5253 UTC hyperparameters_optimizer.cc:582] [343/1100] Score: -0.66036 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:50.5269 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:50.5269 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:50.5272 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:50.5419 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315089 train-accuracy:0.612469 valid-loss:1.273227 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:50.6524 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597921\n",
      "[INFO 24-02-22 06:52:50.6525 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:52:50.6528 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.597921 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:50.6535 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:50.6536 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:50.6537 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:50.6547 UTC hyperparameters_optimizer.cc:582] [344/[INFO1100] Score:  24-02-22 06:52:50.6547 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103610 train-accuracy:0.798289 valid-loss:1.061187 valid-accuracy:0.808219\n",
      "-0.597921 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:50.7689 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.508148\n",
      "[INFO 24-02-22 06:52:50.7693 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:52:50.7694 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.508148 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:50.7700 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:50.7700 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:50.7702 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:50.7702 UTC hyperparameters_optimizer.cc:582] [345/1100] Score: -0.508148 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:50.7723 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243493 train-accuracy:0.612469 valid-loss:1.206354 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:50.8284 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603391\n",
      "[INFO 24-02-22 06:52:50.8285 UTC gradient_boosted_trees.cc:271] Truncates the model to 168 tree(s) i.e. 168  iteration(s).\n",
      "[INFO 24-02-22 06:52:50.8286 UTC gradient_boosted_trees.cc:334] Final model num-trees:168 valid-loss:0.603391 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:50.8298 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:50.8298 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:50.8300 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:50.8320 UTC hyperparameters_optimizer.cc:582] [346/1100] Score: -0.603391 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:50.8329 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063207 train-accuracy:0.826406 valid-loss:1.010794 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:50.8409 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623886\n",
      "[INFO 24-02-22 06:52:50.8409 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:52:50.8411 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.623886 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:50.8415 UTC hyperparameters_optimizer.cc:582] [347/1100] Score: -0.623886 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:50.8421 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:50.8421 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:50.8423 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:50.8905 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.125363 train-accuracy:0.825183 valid-loss:1.086953 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:50.9208 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632352\n",
      "[INFO 24-02-22 06:52:50.9209 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 06:52:50.9212 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.632352 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:50.9252 UTC hyperparameters_optimizer.cc:582] [348/1100] Score: -0.632352 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:50.9265 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:50.9268 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:50.9286 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:50.9412 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638393\n",
      "[INFO 24-02-22 06:52:50.9413 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:52:50.9416 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.638393 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:50.9426 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:50.9427 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:50.9431 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:50.9449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.088130 train-accuracy:0.808068 valid-loss:1.054906 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:50.9487 UTC hyperparameters_optimizer.cc:582] [349/1100] Score: -0.638393 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:50.9524 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313011 train-accuracy:0.612469 valid-loss:1.271220 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:51.0609 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.56106\n",
      "[INFO 24-02-22 06:52:51.0615 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:52:51.0635 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.561060 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:51.0651 UTC hyperparameters_optimizer.cc:582] [350/1100] Score: -0.56106 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:51.0676 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:51.0681 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:51.0683 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:51.0845 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286376 train-accuracy:0.612469 valid-loss:1.244270 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:51.1380 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644097\n",
      "[INFO 24-02-22 06:52:51.1381 UTC gradient_boosted_trees.cc:271] Truncates the model to 167 tree(s) i.e. 167  iteration(s).\n",
      "[INFO 24-02-22 06:52:51.1382 UTC gradient_boosted_trees.cc:334] Final model num-trees:167 valid-loss:0.644097 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:51.1431 UTC hyperparameters_optimizer.cc:582] [351/1100] Score: -0.644097 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:51.1437 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:51.1437 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:51.1488 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:51.1716 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156901 train-accuracy:0.750611 valid-loss:1.120914 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:51.6326 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660188\n",
      "[INFO 24-02-22 06:52:51.6326 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 06:52:51.6329 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.660188 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:51.6350 UTC hyperparameters_optimizer.cc:582] [352/1100] Score: -0.660188 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:51.6384 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:51.6384 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:51.6386 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:51.6664 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642909\n",
      "[INFO 24-02-22 06:52:51.6664 UTC gradient_boosted_trees.cc:271] Truncates the model to 189 tree(s) i.e. 189  iteration(s).\n",
      "[INFO 24-02-22 06:52:51.6670 UTC gradient_boosted_trees.cc:334] Final model num-trees:189 valid-loss:0.642909 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:51.6700 UTC hyperparameters_optimizer.cc:582] [353/1100] Score: -0.642909 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:51.6733 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:51.6736 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:51.6748 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:51.6926 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277874 train-accuracy:0.612469 valid-loss:1.239951 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:51.7137 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282745 train-accuracy:0.612469 valid-loss:1.244109 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:52.0996 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691353\n",
      "[INFO 24-02-22 06:52:52.0997 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:52:52.0998 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.691353 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:52.1000 UTC hyperparameters_optimizer.cc:582] [354/1100] Score: -0.691353 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:52.1005 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:52.1005 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:52.1007 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:52.1029 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314696 train-accuracy:0.612469 valid-loss:1.275497 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:52.3212 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619076\n",
      "[INFO 24-02-22 06:52:52.3213 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:52:52.3215 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.619076 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:52.3219 UTC hyperparameters_optimizer.cc:582] [355/1100] Score: -0.619076 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:52.3227 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:52.3228 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:52.3233 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:52.3854 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.212333 train-accuracy:0.612469 valid-loss:1.189938 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:52.4071 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666967\n",
      "[INFO 24-02-22 06:52:52.4071 UTC gradient_boosted_trees.cc:271] Truncates the model to 133 tree(s) i.e. 133  iteration(s).\n",
      "[INFO 24-02-22 06:52:52.4073 UTC gradient_boosted_trees.cc:334] Final model num-trees:133 valid-loss:0.666967 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:52.4096 UTC hyperparameters_optimizer.cc:582] [356/1100] Score: -0.666967 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:52.4100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:52.4101 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:52.4111 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:52.4191 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.140458 train-accuracy:0.815403 valid-loss:1.097437 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:52.7763 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601603\n",
      "[INFO 24-02-22 06:52:52.7764 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:52.7767 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.601603 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:52.7772 UTC hyperparameters_optimizer.cc:582] [357/1100] Score: -0.601603 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:52.7778 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:52.7780 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:52.7785 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:52.7915 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639534\n",
      "[INFO 24-02-22 06:52:52.7916 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:52.7919 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.639534 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:52.7922 UTC hyperparameters_optimizer.cc:582] [358/1100] Score: -0.639534 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:52.7927 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:52.7928 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:52.7930 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:52.7977 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094497 train-accuracy:0.798289 valid-loss:1.062943 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:52.8368 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084510 train-accuracy:0.823961 valid-loss:1.055907 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:52.9631 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640095\n",
      "[INFO 24-02-22 06:52:52.9631 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:52.9638 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.640095 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:52.9645 UTC hyperparameters_optimizer.cc:582] [359/1100] Score: -0.640095 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:52.9651 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:52.9652 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:52.9654 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:52.9814 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309497 train-accuracy:0.612469 valid-loss:1.272176 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:53.0820 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.58921\n",
      "[INFO 24-02-22 06:52:53.0821 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:52:53.0824 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.589210 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:53.0827 UTC hyperparameters_optimizer.cc:582] [360/1100] Score: -0.58921 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:53.0847 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:53.0847 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:53.0849 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:53.0879 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666243\n",
      "[INFO 24-02-22 06:52:53.0879 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:52:53.0880 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.666243 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:53.0885 UTC hyperparameters_optimizer.cc:582] [361/1100] Score: -0.666243 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:53.0894 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:53.0894 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:53.0897 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:53.1059 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156699 train-accuracy:0.789731 valid-loss:1.117319 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:53.1062 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.100803 train-accuracy:0.794621 valid-loss:1.068665 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:53.3272 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593871\n",
      "[INFO 24-02-22 06:52:53.3272 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:52:53.3274 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.593871 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:53.3279 UTC hyperparameters_optimizer.cc:582] [362/1100] Score: -0.593871 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:53.3284 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:53.3284 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:53.3286 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:53.3493 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311165 train-accuracy:0.612469 valid-loss:1.270723 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:53.6170 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588897\n",
      "[INFO 24-02-22 06:52:53.6171 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:52:53.6173 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.588897 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:53.6179 UTC hyperparameters_optimizer.cc:582] [363/1100] Score: -0.588897 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:53.6189 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:53.6190 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:53.6192 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:53.6262 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.147689 train-accuracy:0.756724 valid-loss:1.109441 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:52:53.8790 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599618\n",
      "[INFO 24-02-22 06:52:53.8791 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:52:53.8792 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.599618 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:53.8798 UTC hyperparameters_optimizer.cc:582] [364/1100] Score: -0.599618 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:53.8808 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:53.8808 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:53.8811 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:53.8848 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.212267 train-accuracy:0.612469 valid-loss:1.168145 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:53.9834 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.610989\n",
      "[INFO 24-02-22 06:52:53.9835 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:53.9836 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.610989 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:53.9838 UTC hyperparameters_optimizer.cc:582] [365/1100] Score: -0.610989 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:53.9851 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:53.9852 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:53.9854 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:53.9878 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232172 train-accuracy:0.612469 valid-loss:1.194339 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:54.0173 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660734\n",
      "[INFO 24-02-22 06:52:54.0174 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:52:54.0175 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.660734 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:54.0178 UTC hyperparameters_optimizer.cc:582] [366/1100] Score: -0.660734 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:54.0183 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:54.0183 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:54.0185 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:54.0299 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236708 train-accuracy:0.612469 valid-loss:1.203876 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:54.2790 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.571491\n",
      "[INFO 24-02-22 06:52:54.2791 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:52:54.2793 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.571491 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:54.2799 UTC hyperparameters_optimizer.cc:582] [367/1100] Score: -0.571491 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:54.2805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:54.2805 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:54.2811 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:54.3403 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237005 train-accuracy:0.612469 valid-loss:1.194575 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:54.3617 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.611401\n",
      "[INFO 24-02-22 06:52:54.3618 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:52:54.3618 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.611401 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:54.3621 UTC hyperparameters_optimizer.cc:582] [368/1100] Score: -0.611401 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:54.3626 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:54.3626 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:54.3629 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:54.3682 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.124875 train-accuracy:0.815403 valid-loss:1.094010 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:54.5180 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656066\n",
      "[INFO 24-02-22 06:52:54.5184 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:52:54.5187 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.656066 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:54.5190 UTC hyperparameters_optimizer.cc:582] [369/1100] Score: -0.656066 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:54.5197 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:54.5197 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:54.5200 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:54.5279 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287990 train-accuracy:0.612469 valid-loss:1.243949 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:54.7756 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645746\n",
      "[INFO 24-02-22 06:52:54.7757 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:52:54.7759 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.645746 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:54.7761 UTC hyperparameters_optimizer.cc:582] [370/1100] Score: -0.645746 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:54.7771 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:54.7772 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:54.7779 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:54.7971 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121692 train-accuracy:0.790954 valid-loss:1.101305 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:52:55.3526 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.459543 train-accuracy:0.919315 valid-loss:0.583639 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:55.3527 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:52:55.3527 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.582241 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:55.3544 UTC hyperparameters_optimizer.cc:582] [371/1100] Score: -0.582241 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:55.3546 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:55.3547 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:55.3565 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:55.3624 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314312 train-accuracy:0.612469 valid-loss:1.273884 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:55.5581 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657438\n",
      "[INFO 24-02-22 06:52:55.5582 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:52:55.5584 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.657438 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:55.5591 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:55.5591 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:55.5593 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:55.5595 UTC hyperparameters_optimizer.cc:582] [372/1100] Score: -0.657438 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:55.5647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177722 train-accuracy:0.612469 valid-loss:1.139205 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:55.6133 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603737\n",
      "[INFO 24-02-22 06:52:55.6134 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:52:55.6136 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.603737 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:55.6143 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:55.6143 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:55.6145 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:55.6154 UTC hyperparameters_optimizer.cc:582] [373/1100] Score: -0.603737 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:55.6201 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241288 train-accuracy:0.612469 valid-loss:1.200857 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:55.7479 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601927\n",
      "[INFO 24-02-22 06:52:55.7480 UTC gradient_boosted_trees.cc:271] Truncates the model to 188 tree(s) i.e. 188  iteration(s).\n",
      "[INFO 24-02-22 06:52:55.7481 UTC gradient_boosted_trees.cc:334] Final model num-trees:188 valid-loss:0.601927 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:55.7495 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:55.7496 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:55.7498 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:55.7521 UTC hyperparameters_optimizer.cc:582] [374/1100] Score: -0.601927 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:55.7977 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.616415\n",
      "[INFO 24-02-22 06:52:55.7977 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-22 06:52:55.7992 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.616415 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:55.8009 UTC hyperparameters_optimizer.cc:582] [375/1100] Score: -0.616415 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:52:55.8012 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:55.8013 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:55.8024 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:55.8085 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.137444 train-accuracy:0.794621 valid-loss:1.123634 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:52:55.8232 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196285 train-accuracy:0.612469 valid-loss:1.149821 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:55.9180 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661219\n",
      "[INFO 24-02-22 06:52:55.9180 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:52:55.9184 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.661219 valid-accuracy:0.849315\n",
      "[[INFO 24-02-22 06:52:55.9205 UTC hyperparameters_optimizer.cc:582] [376/1100] Score: -0.661219 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 06:52:55.9217 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:55.9217 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:55.9232 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:55.9400 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311859 train-accuracy:0.612469 valid-loss:1.273870 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:56.2517 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.574196\n",
      "[INFO 24-02-22 06:52:56.2518 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:52:56.2518 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.574196 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:56.2522 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:56.2522 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:56.2524 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:56.2536 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291059 train-accuracy:0.612469 valid-loss:1.249887 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:56.2553 UTC hyperparameters_optimizer.cc:582] [377/1100] Score: -0.574196 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:56.3146 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615418\n",
      "[INFO 24-02-22 06:52:56.3147 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:52:56.3148 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.615418 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:56.3151 UTC hyperparameters_optimizer.cc:582] [378/1100] Score: -0.615418 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:56.3156 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:56.3156 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:56.3158 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:56.4194 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.931934 train-accuracy:0.920538 valid-loss:1.015764 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:56.6074 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.480360 train-accuracy:0.913203 valid-loss:0.570568 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:56.6075 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 06:52:56.6075 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.567367 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:56.6082 UTC hyperparameters_optimizer.cc:582] [379/1100] Score: -0.567367 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:56.6088 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:56.6088 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:56.6095 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:56.6138 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.123036 train-accuracy:0.775061 valid-loss:1.062937 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:56.7514 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659832\n",
      "[INFO 24-02-22 06:52:56.7514 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:52:56.7518 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.659832 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:56.7523 UTC hyperparameters_optimizer.cc:582] [380/1100] Score: -0.659832 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:56.7540 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:56.7540 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:56.7542 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:56.7734 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.057955 train-accuracy:0.839853 valid-loss:1.059179 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:56.8570 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622333\n",
      "[INFO 24-02-22 06:52:56.8571 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:56.8583 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.622333 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:56.8663 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:56.8663 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:56.8665 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:56.8666 UTC hyperparameters_optimizer.cc:582] [381/1100] Score: -0.622333 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:56.9142 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626599\n",
      "[INFO 24-02-22 06:52:56.9142 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:52:56.9143 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.626599 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:56.9147 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:56.9148 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:56.9150 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:56.9158 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.119457 train-accuracy:0.820293 valid-loss:1.071153 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:52:56.9165 UTC hyperparameters_optimizer.cc:582] [382/1100] Score: -0.626599 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:56.9220 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.136861 train-accuracy:0.806846 valid-loss:1.119136 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:56.9530 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639241\n",
      "[INFO 24-02-22 06:52:56.9531 UTC gradient_boosted_trees.cc:271] Truncates the model to 223 tree(s) i.e. 223  iteration(s).\n",
      "[INFO 24-02-22 06:52:56.9532 UTC gradient_boosted_trees.cc:334] Final model num-trees:223 valid-loss:0.639241 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:56.9554 UTC hyperparameters_optimizer.cc:582] [383/1100] Score: -0.639241 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:56.9587 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:56.9587 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:56.9603 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.0203 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311327 train-accuracy:0.612469 valid-loss:1.268522 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:57.2483 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662834\n",
      "[INFO 24-02-22 06:52:57.2483 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.2486 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.662834 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:57.2501 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.2501 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.2503 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.2520 UTC hyperparameters_optimizer.cc:582] [384/1100] Score: -0.662834 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:57.2538 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641816\n",
      "[INFO 24-02-22 06:52:57.2539 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.2541 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.641816 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:57.2548 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.2548 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.2550 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.2573 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246697 train-accuracy:0.612469 valid-loss:1.198592 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:57.2577 UTC hyperparameters_optimizer.cc:582] [385/1100] Score: -0.641816 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:57.2590 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294012 train-accuracy:0.612469 valid-loss:1.246234 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:57.4357 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63003\n",
      "[INFO 24-02-22 06:52:57.4358 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.4364 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.630030 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:57.4416 UTC hyperparameters_optimizer.cc:582] [386/1100] Score: -0.63003 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:57.4541 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.4543 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.4546 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.4653 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311840 train-accuracy:0.612469 valid-loss:1.274240 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:57.5046 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615004\n",
      "[INFO 24-02-22 06:52:57.5046 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.5048 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.615004 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:57.5055 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.5055 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.5058 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.5082 UTC hyperparameters_optimizer.cc:582] [387/1100] Score: -0.615004 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:57.5127 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237045 train-accuracy:0.612469 valid-loss:1.200568 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:57.6682 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649211\n",
      "[INFO 24-02-22 06:52:57.6705 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.6707 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.649211 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:57.6709 UTC hyperparameters_optimizer.cc:582] [388/1100] Score: -0.649211 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:57.6723 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.6723 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.6726 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.6801 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.212009 train-accuracy:0.612469 valid-loss:1.168431 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:57.6858 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646081\n",
      "[INFO 24-02-22 06:52:57.6858 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.6861 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.646081 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:57.6863 UTC hyperparameters_optimizer.cc:582] [389/1100] Score: -0.646081 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:57.6871 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.6872 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.6876 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.6896 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240098 train-accuracy:0.612469 valid-loss:1.209500 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:57.8448 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.308004 train-accuracy:0.959658 valid-loss:0.601009 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:57.8449 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.8449 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.600869 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:57.8479 UTC hyperparameters_optimizer.cc:582] [390/1100] Score: -0.600869 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:57.8557 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.8558 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.8560 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.8561 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651144\n",
      "[INFO 24-02-22 06:52:57.8561 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.8568 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.651144 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:57.8587 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.8587 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.8589 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.8615 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.100554 train-accuracy:0.810513 valid-loss:1.079295 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:52:57.8620 UTC hyperparameters_optimizer.cc:582] [391/1100] Score: -0.651144 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:57.8663 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632075\n",
      "[INFO 24-02-22 06:52:57.8663 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:52:57.8683 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.632075 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:57.8695 UTC hyperparameters_optimizer.cc:582] [392/1100] Score: -0.632075 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:57.8700 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:57.8700 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:57.8704 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:57.8756 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.194521 train-accuracy:0.612469 valid-loss:1.180063 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:57.9339 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.991010 train-accuracy:0.888753 valid-loss:1.008975 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:58.0256 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617728\n",
      "[INFO 24-02-22 06:52:58.0256 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.0257 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.617728 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:58.0259 UTC hyperparameters_optimizer.cc:582] [393/1100] Score: -0.617728 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:58.0265 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.0267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.0269 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.0937 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.039493 train-accuracy:0.841076 valid-loss:1.031607 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:58.0993 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614473\n",
      "[INFO 24-02-22 06:52:58.0994 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.0998 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.614473 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:58.1007 UTC hyperparameters_optimizer.cc:582] [394/1100] Score: -0.614473 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:58.1011 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.1011 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.1016 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.1320 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652409\n",
      "[INFO 24-02-22 06:52:58.1320 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.1322 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.652409 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:58.1328 UTC hyperparameters_optimizer.cc:582] [395/1100] Score: -0.652409 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:58.1331 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.1331 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.1334 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.1403 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314884 train-accuracy:0.612469 valid-loss:1.272310 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:58.1499 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665398\n",
      "[INFO 24-02-22 06:52:58.1500 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.1510 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.665398 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:58.1521 UTC hyperparameters_optimizer.cc:582] [396/1100] Score: -0.665398 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:58.1553 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.1553 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.1555 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.1563 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319109 train-accuracy:0.612469 valid-loss:1.277920 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:58.1588 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227802 train-accuracy:0.612469 valid-loss:1.183388 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:58.2589 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.710151\n",
      "[INFO 24-02-22 06:52:58.2590 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.2611 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.710151 valid-accuracy:0.863014\n",
      "[[INFO 24-02-22 06:52:58.2673 UTC hyperparameters_optimizer.cc:582] [397/1100] Score: -0.710151 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 06:52:58.2696 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.2696 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.2727 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.2837 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156003 train-accuracy:0.724939 valid-loss:1.104059 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:52:58.3116 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.618336\n",
      "[INFO 24-02-22 06:52:58.3116 UTC gradient_boosted_trees.cc:271] Truncates the model to 190 tree(s) i.e. 190  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.3119 UTC gradient_boosted_trees.cc:334] Final model num-trees:190 valid-loss:0.618336 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:58.3154 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.3154 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.3158 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.3187 UTC hyperparameters_optimizer.cc:582] [398/1100] Score: -0.618336 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:58.3661 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315302 train-accuracy:0.612469 valid-loss:1.273581 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:58.4250 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.722702 train-accuracy:0.848411 valid-loss:0.678976 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:58.4250 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.4250 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.678976 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:58.4255 UTC hyperparameters_optimizer.cc:582] [399/1100] Score: -0.678976 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:58.4258 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.4259 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.4264 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.4344 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310895 train-accuracy:0.612469 valid-loss:1.270481 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:58.6607 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623125\n",
      "[INFO 24-02-22 06:52:58.6607 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.6610 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.623125 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:58.6616 UTC hyperparameters_optimizer.cc:582] [400/1100] Score: -0.623125 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:58.6627 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.6627 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.6629 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.6645 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.118059 train-accuracy:0.801956 valid-loss:1.059123 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:52:58.8132 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660087\n",
      "[INFO 24-02-22 06:52:58.8133 UTC gradient_boosted_trees.cc:271] Truncates the model to 195 tree(s) i.e. 195  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.8133 UTC gradient_boosted_trees.cc:334] Final model num-trees:195 valid-loss:0.660087 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:58.8136 UTC hyperparameters_optimizer.cc:582] [401/1100] Score: -0.660087 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:58.8143 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.8146 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.8151 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.8184 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312835 train-accuracy:0.612469 valid-loss:1.271485 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:58.8903 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637671\n",
      "[INFO 24-02-22 06:52:58.8903 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.8906 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.637671 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:52:58.8925 UTC hyperparameters_optimizer.cc:582] [402/1100] Score: -0.637671 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:58.8955 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.8955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.8957 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.9066 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.52347\n",
      "[INFO 24-02-22 06:52:58.9066 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.9069 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.523470 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:52:58.9079 UTC hyperparameters_optimizer.cc:582] [403/1100] Score: -0.52347 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:58.9092 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.9093 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.9097 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:58.9119 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156989 train-accuracy:0.746944 valid-loss:1.130168 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:52:58.9210 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.086433 train-accuracy:0.800734 valid-loss:1.049446 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:58.9540 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634506\n",
      "[INFO 24-02-22 06:52:58.9541 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:52:58.9543 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.634506 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:58.9547 UTC hyperparameters_optimizer.cc:582] [404/1100] Score: -0.634506 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:58.9554 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:58.9554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:58.9557 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:59.0801 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.267164 train-accuracy:0.612469 valid-loss:1.238463 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:59.1516 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.569205\n",
      "[INFO 24-02-22 06:52:59.1517 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:52:59.1518 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.569205 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:59.1532 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:59.1532 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:59.1534 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:59.1553 UTC hyperparameters_optimizer.cc:582] [405/1100] Score: -0.569205 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:59.1583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.206178 train-accuracy:0.612469 valid-loss:1.159781 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:59.1710 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.592396\n",
      "[INFO 24-02-22 06:52:59.1711 UTC gradient_boosted_trees.cc:271] Truncates the model to 225 tree(s) i.e. 225  iteration(s).\n",
      "[INFO 24-02-22 06:52:59.1713 UTC gradient_boosted_trees.cc:334] Final model num-trees:225 valid-loss:0.592396 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:59.1725 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609601\n",
      "[INFO 24-02-22 06:52:59.1725 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:52:59.1726 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.609601 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:59.1728 UTC hyperparameters_optimizer.cc:582] [406/1100] Score: -0.592396 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:59.1730 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:59.1731 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:59.1732 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:59.1741 UTC hyperparameters_optimizer.cc:582] [407/1100] Score: -0.609601 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:52:59.1762 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:59.1762 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:59.1766 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:59.1793 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313358 train-accuracy:0.612469 valid-loss:1.274471 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:59.2008 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.072667 train-accuracy:0.798289 valid-loss:1.053906 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:52:59.4716 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629034\n",
      "[INFO 24-02-22 06:52:59.4716 UTC gradient_boosted_trees.cc:271] Truncates the model to 171 tree(s) i.e. 171  iteration(s).\n",
      "[INFO 24-02-22 06:52:59.4718 UTC gradient_boosted_trees.cc:334] Final model num-trees:171 valid-loss:0.629034 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:59.4738 UTC hyperparameters_optimizer.cc:582] [408/1100] Score: -0.629034 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:52:59.4808 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:59.4809 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:59.4811 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:59.4847 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278250 train-accuracy:0.612469 valid-loss:1.246174 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:52:59.7443 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.582871\n",
      "[INFO 24-02-22 06:52:59.7443 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-22 06:52:59.7446 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.582871 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:59.7455 UTC hyperparameters_optimizer.cc:582] [409/1100] Score: -0.582871 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:52:59.7473 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:59.7474 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:59.7476 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:59.7517 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.118514 train-accuracy:0.803178 valid-loss:1.080320 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:52:59.8982 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.561494\n",
      "[INFO 24-02-22 06:52:59.8982 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 06:52:59.8984 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.561494 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:52:59.8991 UTC hyperparameters_optimizer.cc:582] [410/1100] Score: -0.561494 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:59.9004 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:59.9004 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:59.9006 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:59.9018 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177592 train-accuracy:0.707824 valid-loss:1.137357 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:52:59.9632 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614571\n",
      "[INFO 24-02-22 06:52:59.9635 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:52:59.9636 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.614571 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:52:59.9639 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:52:59.9639 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:52:59.9641 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:52:59.9653 UTC hyperparameters_optimizer.cc:582] [411/1100] Score: -0.614571 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:52:59.9778 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239499 train-accuracy:0.612469 valid-loss:1.197999 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:00.0431 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637383\n",
      "[INFO 24-02-22 06:53:00.0431 UTC gradient_boosted_trees.cc:271] Truncates the model to 105 tree(s) i.e. 105  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.0433 UTC gradient_boosted_trees.cc:334] Final model num-trees:105 valid-loss:0.637383 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:00.0446 UTC hyperparameters_optimizer.cc:582] [412/1100] Score: -0.637383 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:00.0452 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.0452 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.0464 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:00.0926 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621387\n",
      "[INFO 24-02-22 06:53:00.0926 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.0927 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.621387 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:00.0929 UTC hyperparameters_optimizer.cc:582] [413/1100] Score: -0.621387 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:00.0937 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.0938 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.0941 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:00.1056 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.197954 train-accuracy:0.612469 valid-loss:1.153321 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:00.1105 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.046686 train-accuracy:0.836186 valid-loss:1.039360 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:00.1167 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.398199 train-accuracy:0.943765 valid-loss:0.613285 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:00.1167 UTC gradient_boosted_trees.cc:271] Truncates the model to 290 tree(s) i.e. 290  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.1168 UTC gradient_boosted_trees.cc:334] Final model num-trees:290 valid-loss:0.610151 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:00.1184 UTC hyperparameters_optimizer.cc:582] [414/1100] Score: -0.610151 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:00.1190 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.1190 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.1205 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:00.1700 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640554\n",
      "[INFO 24-02-22 06:53:00.1700 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.1703 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.640554 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:00.1708 UTC hyperparameters_optimizer.cc:582] [415/1100] Score: -0.640554 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:00.1713 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.1713 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.1715 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:00.1800 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207245 train-accuracy:0.612469 valid-loss:1.161104 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:00.2116 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.308161 train-accuracy:0.612469 valid-loss:1.269641 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:00.2441 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.271008 train-accuracy:0.966993 valid-loss:0.597362 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:00.2441 UTC gradient_boosted_trees.cc:271] Truncates the model to 291 tree(s) i.e. 291  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.2442 UTC gradient_boosted_trees.cc:334] Final model num-trees:291 valid-loss:0.596103 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:00.2484 UTC hyperparameters_optimizer.cc:582] [416/1100] Score: -0.596103 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:00.2516 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.2516 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.2518 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:00.3463 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.585172\n",
      "[INFO 24-02-22 06:53:00.3463 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.3466 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.585172 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:00.3473 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.3473 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.3475 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:00.3553 UTC hyperparameters_optimizer.cc:582] [417/1100] Score: -0.585172 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:00.3575 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.133995 train-accuracy:0.612469 valid-loss:1.140349 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:00.3596 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.986392 train-accuracy:0.876528 valid-loss:1.067140 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:00.4016 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631661\n",
      "[INFO 24-02-22 06:53:00.4016 UTC gradient_boosted_trees.cc:271] Truncates the model to 169 tree(s) i.e. 169  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.4022 UTC gradient_boosted_trees.cc:334] Final model num-trees:169 valid-loss:0.631661 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:00.4052 UTC hyperparameters_optimizer.cc:582] [418/1100] Score: -0.631661 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:00.4112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.4114 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.4117 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:00.4245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661939\n",
      "[INFO 24-02-22 06:53:00.4245 UTC gradient_boosted_trees.cc:271] Truncates the model to 145 tree(s) i.e. 145  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.4250 UTC gradient_boosted_trees.cc:334] Final model num-trees:145 valid-loss:0.661939 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:00.4269 UTC hyperparameters_optimizer.cc:582] [419/1100] Score: -0.661939 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:00.4273 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.4273 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.4302 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:00.4339 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281511 train-accuracy:0.612469 valid-loss:1.242851 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:00.5193 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281075 train-accuracy:0.612469 valid-loss:1.243858 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:00.9767 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81764\n",
      "[INFO 24-02-22 06:53:00.9768 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:00.9776 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.817640 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:00.9782 UTC hyperparameters_optimizer.cc:582] [420/1100] Score: -0.81764 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:00.9809 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:00.9810 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:00.9812 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:01.0023 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313208 train-accuracy:0.612469 valid-loss:1.272814 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:01.2069 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631426\n",
      "[INFO 24-02-22 06:53:01.2070 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 06:53:01.2071 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.631426 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:01.2074 UTC hyperparameters_optimizer.cc:582] [421/1100] Score: -0.631426 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:01.2081 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:01.2081 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:01.2084 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:01.2173 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692347\n",
      "[INFO 24-02-22 06:53:01.2173 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:01.2178 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:01.2181 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.692347 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:01.2188 UTC hyperparameters_optimizer.cc:582] [422/1100] Score: -0.692347 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:01.2195 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:01.2197 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:01.2201 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:01.2221 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281897 train-accuracy:0.612469 valid-loss:1.242155 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:01.2384 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283704 train-accuracy:0.612469 valid-loss:1.244602 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:01.3057 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621795\n",
      "[INFO 24-02-22 06:53:01.3057 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:53:01.3058 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.621795 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:01.3063 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:01.3063 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:01.3066 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:01.3087 UTC hyperparameters_optimizer.cc:582] [423/1100] Score: -0.621795 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:01.3633 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224459 train-accuracy:0.612469 valid-loss:1.181652 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:01.4443 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615357\n",
      "[INFO 24-02-22 06:53:01.4444 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:53:01.4445 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.615357 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:01.4449 UTC hyperparameters_optimizer.cc:582] [424/1100] Score: -0.615357 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:01.4458 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:01.4458 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:01.4461 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:01.4622 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295575 train-accuracy:0.612469 valid-loss:1.250218 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:01.6637 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.764579\n",
      "[INFO 24-02-22 06:53:01.6637 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:01.6650 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.764579 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:01.6667 UTC hyperparameters_optimizer.cc:582] [425/1100] Score: -0.764579 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:01.6696 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:01.6698 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:01.6700 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:01.6782 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102276 train-accuracy:0.784841 valid-loss:1.058230 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:01.8632 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.618467\n",
      "[INFO 24-02-22 06:53:01.8632 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:01.8634 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.618467 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:01.8637 UTC hyperparameters_optimizer.cc:582] [426/1100] Score: -0.618467 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:01.8640 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:01.8640 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:01.8644 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:01.8692 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201783 train-accuracy:0.612469 valid-loss:1.172441 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:01.9318 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673177\n",
      "[INFO 24-02-22 06:53:01.9319 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:53:01.9329 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.673177 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:01.9334 UTC hyperparameters_optimizer.cc:582] [427/1100] Score: -0.673177 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:01.9342 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:01.9342 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:01.9344 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:02.0244 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309276 train-accuracy:0.612469 valid-loss:1.272954 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:02.0266 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664885\n",
      "[INFO 24-02-22 06:53:02.0266 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:53:02.0269 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.664885 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:02.0277 UTC hyperparameters_optimizer.cc:582] [428/1100] Score: -0.664885 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:02.0282 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:02.0282 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:02.0287 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:02.0481 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222467 train-accuracy:0.612469 valid-loss:1.191578 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:02.3195 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597427\n",
      "[INFO 24-02-22 06:53:02.3195 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:53:02.3196 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.597427 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:02.3199 UTC hyperparameters_optimizer.cc:582] [429/1100] Score: -0.597427 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:02.3203 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:02.3203 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:02.3206 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:02.3305 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241046 train-accuracy:0.612469 valid-loss:1.205361 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:02.7882 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634404\n",
      "[INFO 24-02-22 06:53:02.7882 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 06:53:02.7884 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.634404 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:02.7895 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:02.7895 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:02.7897 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:02.7920 UTC hyperparameters_optimizer.cc:582] [430/1100] Score: -0.634404 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:02.7990 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289876 train-accuracy:0.612469 valid-loss:1.245383 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:02.8454 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.708706\n",
      "[INFO 24-02-22 06:53:02.8455 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:53:02.8457 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.708706 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:02.8460 UTC hyperparameters_optimizer.cc:582] [431/1100] Score: -0.708706 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:02.8467 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:02.8469 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:02.8474 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:02.8794 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121785 train-accuracy:0.800734 valid-loss:1.121075 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:03.0763 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636596\n",
      "[INFO 24-02-22 06:53:03.0763 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:03.0766 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.636596 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:03.0776 UTC hyperparameters_optimizer.cc:582] [432/1100] Score: -0.636596 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:03.0783 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:03.0783 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:03.0786 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:03.0863 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.195367 train-accuracy:0.612469 valid-loss:1.149119 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:03.1643 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.56989\n",
      "[INFO 24-02-22 06:53:03.1643 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 06:53:03.1645 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.569890 valid-accuracy:0.904110\n",
      "[[INFO 24-02-22 06:53:03.1662 UTC hyperparameters_optimizer.cc:582] [433/1100] Score: -0.56989 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:53:03.1668 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:03.1668 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:03.1673 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:03.2302 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.106854 train-accuracy:0.830073 valid-loss:1.096761 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:03.5325 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599368\n",
      "[INFO 24-02-22 06:53:03.5325 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:53:03.5327 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.599368 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:03.5330 UTC hyperparameters_optimizer.cc:582] [434/1100] Score: -0.599368 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:03.5337 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:03.5340 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:03.5343 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:03.5464 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314024 train-accuracy:0.612469 valid-loss:1.273414 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:03.7779 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.499510 train-accuracy:0.909535 valid-loss:0.598749 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:03.7779 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:53:03.7780 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.598749 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:03.7797 UTC hyperparameters_optimizer.cc:582] [435/1100] Score: -0.598749 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:03.7820 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:03.7820 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:03.7823 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:03.7931 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241743 train-accuracy:0.612469 valid-loss:1.204710 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:03.9463 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606046\n",
      "[INFO 24-02-22 06:53:03.9463 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 06:53:03.9465 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.606046 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:03.9480 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:03.9480 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:03.9482 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:03.9487 UTC hyperparameters_optimizer.cc:582] [436/1100] Score: -0.606046 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:04.0135 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.071168 train-accuracy:0.821516 valid-loss:1.031351 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:04.0268 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641375\n",
      "[INFO 24-02-22 06:53:04.0268 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.0269 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.641375 valid-accuracy:0.849315\n",
      "[[INFO 24-02-22 06:53:04.0275 UTC hyperparameters_optimizer.cc:582] [437/1100] Score: -0.641375 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 06:53:04.0278 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.0278 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.0282 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.0303 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.082842 train-accuracy:0.804401 valid-loss:1.063985 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:04.1544 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.577672\n",
      "[INFO 24-02-22 06:53:04.1544 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.1546 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.577672 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:04.1555 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.1555 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.1558 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.1587 UTC hyperparameters_optimizer.cc:582] [438/1100] Score: -0.577672 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:04.2210 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653734\n",
      "[INFO 24-02-22 06:53:04.2211 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.2213 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.653734 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:04.2216 UTC hyperparameters_optimizer.cc:582] [439/1100] Score: -0.653734 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO[INFO 24-02-22 06:53:04.2235 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.108865 train-accuracy:0.819071 valid-loss:1.077129 valid-accuracy:0.808219\n",
      " 24-02-22 06:53:04.2253 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.2253 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.2255 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.2280 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.119669 train-accuracy:0.794621 valid-loss:1.104012 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:04.3317 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.575536\n",
      "[INFO 24-02-22 06:53:04.3317 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.3318 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.575536 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:04.3324 UTC hyperparameters_optimizer.cc:582] [440/1100] Score: -0.575536 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:04.3335 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.3336 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.3338 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.3392 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155679 train-accuracy:0.777506 valid-loss:1.093022 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:04.3740 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638409\n",
      "[INFO 24-02-22 06:53:04.3740 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.3750 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.638409 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:04.3755 UTC hyperparameters_optimizer.cc:582] [441/1100] Score: -0.638409 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:04.3774 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.3775 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.3778 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.3865 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.204442 train-accuracy:0.612469 valid-loss:1.156524 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:04.4016 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640886\n",
      "[INFO 24-02-22 06:53:04.4016 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.4019 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.640886 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:04.4024 UTC hyperparameters_optimizer.cc:582] [442/1100] Score: -0.640886 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:04.4033 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.4034 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.4041 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.4123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094208 train-accuracy:0.810513 valid-loss:1.068660 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:04.6965 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.567182\n",
      "[INFO 24-02-22 06:53:04.6965 UTC gradient_boosted_trees.cc:271] Truncates the model to 142 tree(s) i.e. 142  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.6966 UTC gradient_boosted_trees.cc:334] Final model num-trees:142 valid-loss:0.567182 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:04.6977 UTC hyperparameters_optimizer.cc:582] [443/1100] Score: -0.567182 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:04.6981 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.6981 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.6998 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.7014 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.203011 train-accuracy:0.612469 valid-loss:1.165899 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:04.7434 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643922\n",
      "[INFO 24-02-22 06:53:04.7434 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.7435 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.643922 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:04.7439 UTC hyperparameters_optimizer.cc:582] [444/1100] Score: -0.643922 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:04.7447 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.7447 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.7449 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.7976 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629708\n",
      "[INFO 24-02-22 06:53:04.7979 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.7981 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.629708 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:04.7983 UTC hyperparameters_optimizer.cc:582] [445/1100] Score: -0.629708 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:04.8014 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.8029 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.8031 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.8252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312094 train-accuracy:0.612469 valid-loss:1.273532 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:04.8411 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617541\n",
      "[INFO 24-02-22 06:53:04.8411 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 06:53:04.8412 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.617541 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:04.8414 UTC hyperparameters_optimizer.cc:582] [446/1100] Score: -0.617541 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:04.8418 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:04.8419 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:04.8420 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:04.8440 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285449 train-accuracy:0.612469 valid-loss:1.251458 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:04.8632 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312673 train-accuracy:0.612469 valid-loss:1.272290 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:05.0847 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65345\n",
      "[INFO 24-02-22 06:53:05.0849 UTC gradient_boosted_trees.cc:271] Truncates the model to 90 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 24-02-22 06:53:05.0852 UTC gradient_boosted_trees.cc:334] Final model num-trees:90 valid-loss:0.653450 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:05.0862 UTC hyperparameters_optimizer.cc:582] [447/1100] Score: -0.65345 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:05.0877 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:05.0877 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:05.0879 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:05.1094 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121838 train-accuracy:0.799511 valid-loss:1.117590 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:05.7235 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.580403\n",
      "[INFO 24-02-22 06:53:05.7235 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-22 06:53:05.7236 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.580403 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:05.7241 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:05.7241 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:05.7243 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:05.7253 UTC hyperparameters_optimizer.cc:582] [448/1100] Score: -0.580403 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:05.7269 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285192 train-accuracy:0.612469 valid-loss:1.243748 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:05.8098 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638751\n",
      "[INFO 24-02-22 06:53:05.8098 UTC gradient_boosted_trees.cc:271] Truncates the model to 206 tree(s) i.e. 206  iteration(s).\n",
      "[INFO 24-02-22 06:53:05.8099 UTC gradient_boosted_trees.cc:334] Final model num-trees:206 valid-loss:0.638751 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:05.8101 UTC hyperparameters_optimizer.cc:582] [449/1100] Score: -0.638751 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:05.8104 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:05.8104 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:05.8106 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:05.8263 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.057454 train-accuracy:0.821516 valid-loss:1.026983 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:05.8876 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683639\n",
      "[INFO 24-02-22 06:53:05.8877 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:05.8883 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.683639 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:05.8891 UTC hyperparameters_optimizer.cc:582] [450/1100] Score: -0.683639 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:05.8909 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:05.8909 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:05.8911 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:05.8975 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227202 train-accuracy:0.612469 valid-loss:1.200222 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:05.9712 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639249\n",
      "[INFO 24-02-22 06:53:05.9745 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:53:05.9748 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.639249 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:05.9755 UTC hyperparameters_optimizer.cc:582] [451/1100] Score: -0.639249 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:05.9761 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:05.9761 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:05.9767 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:05.9849 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283313 train-accuracy:0.612469 valid-loss:1.245107 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:06.0275 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67814\n",
      "[INFO 24-02-22 06:53:06.0276 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.0279 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.678140 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:06.0284 UTC hyperparameters_optimizer.cc:582] [452/1100] Score: -0.67814 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:06.0290 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.0290 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.0293 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.0768 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657731\n",
      "[INFO 24-02-22 06:53:06.0769 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.0772 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.657731 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:06.0775 UTC hyperparameters_optimizer.cc:582] [453/1100] Score: -0.657731 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:06.0784 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.0784 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.0786 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.0811 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.042430 train-accuracy:0.841076 valid-loss:1.033871 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:06.1436 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.044266 train-accuracy:0.849633 valid-loss:1.052248 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:06.1776 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64303\n",
      "[INFO 24-02-22 06:53:06.1776 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:06.1779 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:06.1779 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.643030 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:06.1781 UTC hyperparameters_optimizer.cc:582] [454/1100] Score: -0.64303 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:06.1788 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.1789 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.1791 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.1800 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319558 train-accuracy:0.612469 valid-loss:1.279173 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:06.2527 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667432\n",
      "[INFO 24-02-22 06:53:06.2528 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.2531 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.667432 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:06.2537 UTC hyperparameters_optimizer.cc:582] [455/1100] Score: -0.667432 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:06.2589 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.2589 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.2591 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.2637 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.161512 train-accuracy:0.748166 valid-loss:1.128068 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:53:06.3417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.600541\n",
      "[INFO 24-02-22 06:53:06.3417 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.3418 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.600541 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:06.3420 UTC hyperparameters_optimizer.cc:582] [456/1100] Score: -0.600541 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:06.3425 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.3425 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.3445 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.3486 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282098 train-accuracy:0.612469 valid-loss:1.239884 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:06.3902 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.744502 train-accuracy:0.855746 valid-loss:0.673468 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:06.3902 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.3903 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.673468 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:06.3907 UTC hyperparameters_optimizer.cc:582] [457/1100] Score: -0.673468 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:06.3918 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.3919 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.3923 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.3997 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284395 train-accuracy:0.612469 valid-loss:1.242448 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:06.5197 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.608508\n",
      "[INFO 24-02-22 06:53:06.5197 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.5199 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.608508 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:06.5204 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.5204 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.5206 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.5220 UTC hyperparameters_optimizer.cc:582] [458/1100] Score: -0.608508 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:06.5238 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291993 train-accuracy:0.612469 valid-loss:1.249082 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:06.6753 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648956\n",
      "[INFO 24-02-22 06:53:06.6753 UTC gradient_boosted_trees.cc:271] Truncates the model to 110 tree(s) i.e. 110  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.6762 UTC gradient_boosted_trees.cc:334] Final model num-trees:110 valid-loss:0.648956 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:06.6773 UTC hyperparameters_optimizer.cc:582] [459/1100] Score: -0.648956 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:06.6791 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.6793 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.6796 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.6822 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235352 train-accuracy:0.612469 valid-loss:1.206283 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:06.7440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61662\n",
      "[INFO 24-02-22 06:53:06.7441 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.7444 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.616620 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:06.7454 UTC hyperparameters_optimizer.cc:582] [460/1100] Score: -0.61662 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:06.7472 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.7474 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.7477 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.7678 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236045 train-accuracy:0.612469 valid-loss:1.191788 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:06.8332 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642907\n",
      "[INFO 24-02-22 06:53:06.8332 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.8334 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.642907 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:06.8347 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.8347 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.8349 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.8387 UTC hyperparameters_optimizer.cc:582] [461/1100] Score: -0.642907 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:06.8496 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096135 train-accuracy:0.844743 valid-loss:1.060510 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:06.8692 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637673\n",
      "[INFO 24-02-22 06:53:06.8693 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.8695 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.637673 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:06.8699 UTC hyperparameters_optimizer.cc:582] [462/1100] Score: -0.637673 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:06.8704 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.8705 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.8708 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.8848 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103721 train-accuracy:0.826406 valid-loss:1.070458 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:06.9381 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658727\n",
      "[INFO 24-02-22 06:53:06.9381 UTC gradient_boosted_trees.cc:271] Truncates the model to 97 tree(s) i.e. 97  iteration(s).\n",
      "[INFO 24-02-22 06:53:06.9382 UTC gradient_boosted_trees.cc:334] Final model num-trees:97 valid-loss:0.658727 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:06.9385 UTC hyperparameters_optimizer.cc:582] [463/1100] Score: -0.658727 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:06.9394 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:06.9394 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:06.9396 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:06.9404 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162135 train-accuracy:0.784841 valid-loss:1.132935 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:07.0119 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.587321\n",
      "[INFO 24-02-22 06:53:07.0120 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.0155 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.587321 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:07.0159 UTC hyperparameters_optimizer.cc:582] [464/1100] Score: -0.587321 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:07.0164 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.0164 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.0168 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.0216 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288206 train-accuracy:0.612469 valid-loss:1.248483 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:07.0345 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682391\n",
      "[INFO 24-02-22 06:53:07.0347 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.0349 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.682391 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:07.0351 UTC hyperparameters_optimizer.cc:582] [465/1100] Score: -0.682391 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:07.0355 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.0355 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.0358 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.0382 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063544 train-accuracy:0.823961 valid-loss:1.009754 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:07.1567 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621788\n",
      "[INFO 24-02-22 06:53:07.1567 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.1570 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.621788 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:07.1573 UTC hyperparameters_optimizer.cc:582] [466/1100] Score: -0.621788 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:07.1580 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.1581 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.1605 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.1767 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.192181 train-accuracy:0.612469 valid-loss:1.148009 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:07.2721 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.343510 train-accuracy:0.957213 valid-loss:0.609951 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:07.2721 UTC gradient_boosted_trees.cc:271] Truncates the model to 292 tree(s) i.e. 292  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.2721 UTC gradient_boosted_trees.cc:334] Final model num-trees:292 valid-loss:0.608194 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:07.2755 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.2755 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.2757 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.2787 UTC hyperparameters_optimizer.cc:582] [467/1100] Score: -0.608194 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:07.2957 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279573 train-accuracy:0.612469 valid-loss:1.240951 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:07.5190 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.611209\n",
      "[INFO 24-02-22 06:53:07.5190 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.5194 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.611209 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:07.5198 UTC hyperparameters_optimizer.cc:582] [468/1100] Score: -0.611209 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:07.5206 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.5206 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.5210 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.5321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.992231 train-accuracy:0.871638 valid-loss:1.017002 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:07.5773 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655213\n",
      "[INFO 24-02-22 06:53:07.5774 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.5775 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.655213 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:07.5780 UTC hyperparameters_optimizer.cc:582] [469/1100] Score: -0.655213 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:07.5791 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.5792 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.5794 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.5859 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239996 train-accuracy:0.612469 valid-loss:1.197918 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:07.5992 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636416\n",
      "[INFO 24-02-22 06:53:07.5992 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.5994 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.636416 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:07.5998 UTC hyperparameters_optimizer.cc:582] [470/1100] Score: -0.636416 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:07.6003 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.6003 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.6005 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.6019 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.040037 train-accuracy:0.833741 valid-loss:1.027259 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:07.6383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655561\n",
      "[INFO 24-02-22 06:53:07.6384 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.6388 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.655561 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:07.6401 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.6402 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.6404 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.6420 UTC hyperparameters_optimizer.cc:582] [471/1100] Score: -0.655561 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:07.6473 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619365\n",
      "[INFO 24-02-22 06:53:07.6473 UTC gradient_boosted_trees.cc:271] Truncates the model to 177 tree(s) i.e. 177  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.6476 UTC gradient_boosted_trees.cc:334] Final model num-trees:177 valid-loss:0.619365 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:07.6528 UTC hyperparameters_optimizer.cc:582] [472/1100] Score: -0.619365 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:07.6533 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.6533 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.6540 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.6548 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.185463 train-accuracy:0.612469 valid-loss:1.138529 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:07.6613 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157044 train-accuracy:0.756724 valid-loss:1.120204 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:53:07.9440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597554\n",
      "[INFO 24-02-22 06:53:07.9440 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:53:07.9443 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.597554 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:07.9448 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:07.9449 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:07.9450 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:07.9487 UTC hyperparameters_optimizer.cc:582] [473/1100] Score: -0.597554 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:07.9959 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.055006 train-accuracy:0.826406 valid-loss:1.030581 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:08.0055 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648704\n",
      "[INFO 24-02-22 06:53:08.0056 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:08.0064 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:08.0064 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.648704 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:08.0071 UTC hyperparameters_optimizer.cc:582] [474/1100] Score: -0.648704 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:08.0085 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.0085 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.0089 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.0151 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085542 train-accuracy:0.823961 valid-loss:1.100802 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:08.1193 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634986\n",
      "[INFO 24-02-22 06:53:08.1193 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.1194 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.634986 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:08.1199 UTC hyperparameters_optimizer.cc:582] [475/1100] Score: -0.634986 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:08.1206 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.1206 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.1208 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.1951 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094423 train-accuracy:0.809291 valid-loss:1.053383 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:08.2262 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64955\n",
      "[INFO 24-02-22 06:53:08.2262 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.2264 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.649550 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:08.2266 UTC hyperparameters_optimizer.cc:582] [476/1100] Score: -0.64955 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:08.2273 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.2273 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.2277 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.2300 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.143124 train-accuracy:0.788509 valid-loss:1.093568 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:08.3566 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.572552\n",
      "[INFO 24-02-22 06:53:08.3566 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.3568 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.572552 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:08.3575 UTC hyperparameters_optimizer.cc:582] [477/1100] Score: -0.572552 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:08.3586 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.3587 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.3588 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.702981\n",
      "[INFO[INFO 24-02-22 06:53:08.3589 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      " 24-02-22 06:53:08.3588 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.3594 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.702981 valid-accuracy:0.835616\n",
      "[[INFO 24-02-22 06:53:08.3601 UTC hyperparameters_optimizer.cc:582] [478/1100] Score: -0.702981 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:53:08.3603 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.3603 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.3610 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.3643 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151005 train-accuracy:0.751834 valid-loss:1.131782 valid-accuracy:0.726027\n",
      "[INFO 24-02-22 06:53:08.3763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083672 train-accuracy:0.823961 valid-loss:1.039801 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:08.4449 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.517357\n",
      "[INFO 24-02-22 06:53:08.4449 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.4452 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.517357 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:08.4461 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.4461 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.4463 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.4476 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315461 train-accuracy:0.612469 valid-loss:1.272817 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:08.4487 UTC hyperparameters_optimizer.cc:582] [479/1100] Score: -0.517357 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:08.5855 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61479\n",
      "[INFO 24-02-22 06:53:08.5855 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.5859 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.614790 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:08.5866 UTC hyperparameters_optimizer.cc:582] [480/1100] Score: -0.61479 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:08.5874 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.5876 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.5882 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.5966 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.078319 train-accuracy:0.820293 valid-loss:1.072838 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:08.6538 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.566319\n",
      "[INFO 24-02-22 06:53:08.6538 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.6541 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.566319 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:08.6546 UTC hyperparameters_optimizer.cc:582] [481/1100] Score: -0.566319 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:08.6555 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.6556 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.6559 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.6624 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.260943 train-accuracy:0.612469 valid-loss:1.239495 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:08.7672 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659726\n",
      "[INFO 24-02-22 06:53:08.7672 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.7675 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.659726 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:08.7691 UTC hyperparameters_optimizer.cc:582] [482/1100] Score: -0.659726 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:08.7695 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.7695 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.7697 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.7803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305659 train-accuracy:0.612469 valid-loss:1.270607 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:08.8911 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.515623 train-accuracy:0.909535 valid-loss:0.600724 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:08.8911 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:53:08.8911 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.600724 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:08.8925 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:08.8926 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:08.8927 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:08.8955 UTC hyperparameters_optimizer.cc:582] [483/1100] Score: -0.600724 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:08.9479 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277105 train-accuracy:0.612469 valid-loss:1.238890 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:09.0472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.604731\n",
      "[INFO 24-02-22 06:53:09.0473 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.0475 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.604731 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:09.0479 UTC hyperparameters_optimizer.cc:582] [484/1100] Score: -0.604731 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:09.0490 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.0491 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.0515 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.0545 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313255 train-accuracy:0.612469 valid-loss:1.270231 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:09.2144 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656628\n",
      "[INFO 24-02-22 06:53:09.2145 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.2150 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.656628 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:09.2164 UTC hyperparameters_optimizer.cc:582] [485/1100] Score: -0.656628 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:09.2169 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.2169 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.2194 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.2216 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.179685 train-accuracy:0.612469 valid-loss:1.130666 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:09.3678 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601433\n",
      "[INFO 24-02-22 06:53:09.3678 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.3682 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.601433 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:09.3687 UTC hyperparameters_optimizer.cc:582] [486/1100] Score: -0.601433 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:09.3691 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.3691 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.3693 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.3717 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.097156 train-accuracy:0.792176 valid-loss:1.043985 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:09.4099 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.618026\n",
      "[INFO 24-02-22 06:53:09.4099 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.4101 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.618026 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:09.4104 UTC hyperparameters_optimizer.cc:582] [487/1100] Score: -0.618026 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:09.4112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.4112 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.4115 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.4134 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243062 train-accuracy:0.612469 valid-loss:1.204149 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:09.4432 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690008\n",
      "[INFO 24-02-22 06:53:09.4433 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.4449 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.690008 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:09.4494 UTC hyperparameters_optimizer.cc:582] [488/1100] Score: -0.690008 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:09.4573 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.4574 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.4577 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.4614 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090078 train-accuracy:0.817848 valid-loss:1.065738 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:09.5917 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.535468\n",
      "[INFO 24-02-22 06:53:09.5917 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.5919 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.535468 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:09.5923 UTC hyperparameters_optimizer.cc:582] [489/1100] Score: -0.535468 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:09.5929 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.5929 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.5932 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.6403 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.575657\n",
      "[INFO 24-02-22 06:53:09.6404 UTC gradient_boosted_trees.cc:271] Truncates the model to 88 tree(s) i.e. 88  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.6406 UTC gradient_boosted_trees.cc:334] Final model num-trees:88 valid-loss:0.575657 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:09.6411 UTC hyperparameters_optimizer.cc:582] [490/1100] Score: -0.575657 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:09.6422 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.6422 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.6424 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.6431 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224470 train-accuracy:0.612469 valid-loss:1.180450 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:09.6443 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.116716 train-accuracy:0.784841 valid-loss:1.079455 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:09.6959 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.547564\n",
      "[INFO 24-02-22 06:53:09.6960 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.6963 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.547564 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:09.6971 UTC hyperparameters_optimizer.cc:582] [491/1100] Score: -0.547564 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:09.6988 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.6989 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.6993 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.7005 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.258916 train-accuracy:0.612469 valid-loss:1.211833 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:09.7797 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62514\n",
      "[INFO 24-02-22 06:53:09.7797 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.7798 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.625140 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:09.7800 UTC hyperparameters_optimizer.cc:582] [492/1100] Score: -0.62514 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:09.7806 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.7806 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.7808 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.7876 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665489\n",
      "[INFO 24-02-22 06:53:09.7883 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.7884 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.665489 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:09.7885 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232946 train-accuracy:0.612469 valid-loss:1.194721 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:09.7886 UTC hyperparameters_optimizer.cc:582] [493/1100] Score: -0.665489 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:09.7890 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.7890 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.7892 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.8547 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.199854 train-accuracy:0.612469 valid-loss:1.176986 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:09.8877 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.591289\n",
      "[INFO 24-02-22 06:53:09.8877 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.8879 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.591289 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:09.8887 UTC hyperparameters_optimizer.cc:582] [494/1100] Score: -0.591289 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:09.8902 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.8903 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.8905 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.8975 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.072825 train-accuracy:0.819071 valid-loss:1.044568 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:09.9444 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621864\n",
      "[INFO 24-02-22 06:53:09.9444 UTC gradient_boosted_trees.cc:271] Truncates the model to 268 tree(s) i.e. 268  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.9447 UTC gradient_boosted_trees.cc:334] Final model num-trees:268 valid-loss:0.621864 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:09.9496 UTC hyperparameters_optimizer.cc:582] [495/1100] Score: -0.621864 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:09.9568 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:09.9568 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:09.9571 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:09.9932 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.714661\n",
      "[INFO 24-02-22 06:53:09.9935 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:53:09.9944 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.714661 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:10.0048 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:10.0048 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:10.0050 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:10.0120 UTC hyperparameters_optimizer.cc:582] [496/1100] Score: -0.714661 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:10.0154 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282608 train-accuracy:0.612469 valid-loss:1.246338 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:10.0335 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680486\n",
      "[INFO 24-02-22 06:53:10.0336 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:53:10.0357 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.680486 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:10.0456 UTC hyperparameters_optimizer.cc:582] [497/1100] Score: -0.680486 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:10.0499 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:10.0500 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:10.0591 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:10.0681 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.042633 train-accuracy:0.838631 valid-loss:1.020416 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:10.0799 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.009763 train-accuracy:0.869193 valid-loss:1.018621 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:10.2351 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640995\n",
      "[INFO 24-02-22 06:53:10.2351 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:10.2353 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.640995 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:10.2357 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:10.2357 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:10.2359 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:10.2387 UTC hyperparameters_optimizer.cc:582] [498/1100] Score: -0.640995 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:10.2956 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.088321 train-accuracy:0.830073 valid-loss:1.046161 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:10.3124 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.60444\n",
      "[INFO 24-02-22 06:53:10.3124 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:53:10.3126 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.604440 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:10.3130 UTC hyperparameters_optimizer.cc:582] [499/1100] Score: -0.60444 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:10.3141 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:10.3141 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:10.3143 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:10.3346 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238502 train-accuracy:0.612469 valid-loss:1.194397 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:10.4481 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624447\n",
      "[INFO 24-02-22 06:53:10.4481 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:10.4486 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:10.4486 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.624447 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:10.4491 UTC hyperparameters_optimizer.cc:582] [500/1100] Score: -0.624447 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:10.4496 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:10.4497 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:10.4501 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:10.4550 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.069407 train-accuracy:0.815403 valid-loss:1.036986 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:10.5673 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676862\n",
      "[INFO 24-02-22 06:53:10.5673 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:53:10.5675 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.676862 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:10.5677 UTC hyperparameters_optimizer.cc:582] [501/1100] Score: -0.676862 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:10.5684 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:10.5684 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:10.5687 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:10.6329 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.033919 train-accuracy:0.836186 valid-loss:0.984510 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:10.7433 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.591978\n",
      "[INFO 24-02-22 06:53:10.7433 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:10.7434 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.591978 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:10.7437 UTC hyperparameters_optimizer.cc:582] [502/1100] Score: -0.591978 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:10.7439 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:10.7439 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:10.7442 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:10.7518 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.147654 train-accuracy:0.799511 valid-loss:1.104105 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:11.0081 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605113\n",
      "[INFO 24-02-22 06:53:11.0081 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:11.0086 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.605113 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:11.0090 UTC hyperparameters_optimizer.cc:582] [503/1100] Score: -0.605113 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:11.0098 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:11.0098 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:11.0102 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:11.0155 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152329 train-accuracy:0.612469 valid-loss:1.140254 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:11.1069 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638401\n",
      "[INFO 24-02-22 06:53:11.1069 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:11.1071 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:11.1071 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.638401 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:11.1075 UTC hyperparameters_optimizer.cc:582] [504/1100] Score: -0.638401 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:11.1077 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:11.1078 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:11.1080 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:11.1809 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.164841 train-accuracy:0.612469 valid-loss:1.137970 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:11.2341 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663456\n",
      "[INFO 24-02-22 06:53:11.2349 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:11.2361 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.663456 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:11.2366 UTC hyperparameters_optimizer.cc:582] [505/1100] Score: -0.663456 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:11.2380 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:11.2380 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:11.2385 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:11.2540 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662825\n",
      "[INFO 24-02-22 06:53:11.2540 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:53:11.2544 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.662825 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:11.2558 UTC hyperparameters_optimizer.cc:582] [506/1100] Score: -0.662825 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:11.2564 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:11.2565 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:11.2571 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:11.2676 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.071359 train-accuracy:0.803178 valid-loss:1.068892 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:11.2858 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.206022 train-accuracy:0.612469 valid-loss:1.183318 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:11.6904 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.579477\n",
      "[INFO 24-02-22 06:53:11.6904 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:53:11.6907 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.579477 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:11.6911 UTC hyperparameters_optimizer.cc:582] [507/1100] Score: -0.579477 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:11.6929 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:11.6931 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:11.6933 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:11.6969 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243493 train-accuracy:0.612469 valid-loss:1.206354 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:11.8059 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623886\n",
      "[INFO 24-02-22 06:53:11.8065 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:53:11.8068 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.623886 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:11.8077 UTC hyperparameters_optimizer.cc:582] [508/1100] Score: -0.623886 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:11.8089 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:11.8089 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:11.8091 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:11.8106 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286593 train-accuracy:0.612469 valid-loss:1.241458 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:12.1958 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.591658\n",
      "[INFO 24-02-22 06:53:12.1958 UTC gradient_boosted_trees.cc:271] Truncates the model to 182 tree(s) i.e. 182  iteration(s).\n",
      "[INFO 24-02-22 06:53:12.1959 UTC gradient_boosted_trees.cc:334] Final model num-trees:182 valid-loss:0.591658 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:12.1969 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:12.1969 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:12.1971 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:12.1987 UTC hyperparameters_optimizer.cc:582] [509/1100] Score: -0.591658 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:12.2586 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229005 train-accuracy:0.612469 valid-loss:1.198759 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:12.3558 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650253\n",
      "[INFO 24-02-22 06:53:12.3558 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:53:12.3568 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.650253 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:12.3579 UTC hyperparameters_optimizer.cc:582] [510/1100] Score: -0.650253 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:12.3611 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:12.3611 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:12.3616 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:12.3645 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.067354 train-accuracy:0.830073 valid-loss:1.071984 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:12.4307 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669607\n",
      "[INFO 24-02-22 06:53:12.4307 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:12.4310 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.669607 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:12.4317 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:12.4317 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:12.4319 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:12.4356 UTC hyperparameters_optimizer.cc:582] [511/1100] Score: -0.669607 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:12.4493 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.170374 train-accuracy:0.612469 valid-loss:1.135822 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:12.4540 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672941\n",
      "[INFO 24-02-22 06:53:12.4540 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:12.4543 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:12.4543 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.672941 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:12.4551 UTC hyperparameters_optimizer.cc:582] [512/1100] Score: -0.672941 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:12.4552 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:12.4556 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:12.4574 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:12.4654 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.203485 train-accuracy:0.612469 valid-loss:1.164574 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:12.7133 UTC gradient_boosted_trees.cc:1638] \tnum-trees:29 train-loss:0.490743 train-accuracy:0.911980 valid-loss:0.599386 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:12.9162 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639627\n",
      "[INFO 24-02-22 06:53:12.9162 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:53:12.9166 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.639627 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:12.9170 UTC hyperparameters_optimizer.cc:582] [513/1100] Score: -0.639627 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:12.9177 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:12.9177 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:12.9179 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:12.9686 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.080776 train-accuracy:0.828851 valid-loss:1.037194 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:13.0110 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.73009\n",
      "[INFO 24-02-22 06:53:13.0111 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:13.0114 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:13.0114 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.730090 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:13.0119 UTC hyperparameters_optimizer.cc:582] [514/1100] Score: -0.73009 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:13.0132 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:13.0132 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:13.0135 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:13.0161 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.202678 train-accuracy:0.612469 valid-loss:1.160290 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:13.0568 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629708\n",
      "[INFO 24-02-22 06:53:13.0568 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:53:13.0574 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.629708 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:13.0587 UTC hyperparameters_optimizer.cc:582] [515/1100] Score: -0.629708 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:13.0601 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:13.0601 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:13.0603 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:13.0656 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.082929 train-accuracy:0.827628 valid-loss:1.048440 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:13.1506 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624099\n",
      "[INFO 24-02-22 06:53:13.1508 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:53:13.1511 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.624099 valid-accuracy:0.876712\n",
      "[INFO[INFO 24-02-22 06:53:13.1549 UTC hyperparameters_optimizer.cc:582] [516/1100] Score: -0.624099 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      " 24-02-22 06:53:13.1552 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:13.1552 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:13.1557 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:13.1763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191377 train-accuracy:0.790954 valid-loss:1.138260 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:13.3046 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.547283\n",
      "[INFO 24-02-22 06:53:13.3047 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 06:53:13.3048 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.547283 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:13.3055 UTC hyperparameters_optimizer.cc:582] [517/1100] Score: -0.547283 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:13.3068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:13.3070 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:13.3074 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:13.3864 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.589741\n",
      "[INFO 24-02-22 06:53:13.3864 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:53:13.3865 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.589741 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:13.3870 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:13.3870 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:13.3872 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:13.3896 UTC hyperparameters_optimizer.cc:582] [518/1100] Score: -0.589741 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:13.3943 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277394 train-accuracy:0.612469 valid-loss:1.245127 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:13.4146 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.215660 train-accuracy:0.612469 valid-loss:1.188738 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:13.5455 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643197\n",
      "[INFO 24-02-22 06:53:13.5455 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:13.5459 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.643197 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:13.5462 UTC hyperparameters_optimizer.cc:582] [519/1100] Score: -0.643197 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:13.5473 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:13.5475 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:13.5479 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:13.5547 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.150474 train-accuracy:0.803178 valid-loss:1.078046 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:13.9464 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625585\n",
      "[INFO 24-02-22 06:53:13.9464 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:53:13.9468 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.625585 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:13.9471 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641545\n",
      "[INFO 24-02-22 06:53:13.9471 UTC gradient_boosted_trees.cc:271] Truncates the model to 243 tree(s) i.e. 243  iteration(s).\n",
      "[INFO 24-02-22 06:53:13.9472 UTC gradient_boosted_trees.cc:334] Final model num-trees:243 valid-loss:0.641545 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:13.9488 UTC hyperparameters_optimizer.cc:582] [520/1100] Score: -0.625585 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:13.9491 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:13.9492 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:13.9493 UTC hyperparameters_optimizer.cc:582] [521/1100] Score: -0.641545 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:13.9493 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:13.9518 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:13.9518 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:13.9520 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:13.9554 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.139555 train-accuracy:0.815403 valid-loss:1.109279 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:14.0122 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640699\n",
      "[INFO 24-02-22 06:53:14.0148 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:53:14.0149 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.640699 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:14.0156 UTC hyperparameters_optimizer.cc:582] [522/1100] Score: -0.640699 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:14.0161 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:14.0161 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:14.0163 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:14.0188 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279656 train-accuracy:0.612469 valid-loss:1.242623 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:14.0310 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.547948\n",
      "[INFO 24-02-22 06:53:14.0311 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:14.0315 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.547948 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:14.0320 UTC hyperparameters_optimizer.cc:582] [523/1100] Score: -0.547948 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:14.0324 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:14.0324 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:14.0326 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:14.0683 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313149 train-accuracy:0.612469 valid-loss:1.273494 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:14.1012 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.961734 train-accuracy:0.932763 valid-loss:1.009163 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:14.1191 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615724\n",
      "[INFO 24-02-22 06:53:14.1191 UTC gradient_boosted_trees.cc:271] Truncates the model to 163 tree(s) i.e. 163  iteration(s).\n",
      "[INFO 24-02-22 06:53:14.1193 UTC gradient_boosted_trees.cc:334] Final model num-trees:163 valid-loss:0.615724 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:14.1218 UTC hyperparameters_optimizer.cc:582] [524/1100] Score: -0.615724 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:14.1253 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:14.1253 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:14.1255 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:14.1428 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153850 train-accuracy:0.795844 valid-loss:1.112406 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:14.1640 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624178\n",
      "[INFO 24-02-22 06:53:14.1641 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:53:14.1644 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.624178 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:14.1664 UTC hyperparameters_optimizer.cc:582] [525/1100] Score: -0.624178 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:14.1672 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:14.1672 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:14.1674 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:14.2011 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310324 train-accuracy:0.612469 valid-loss:1.272876 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:14.2249 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.727425\n",
      "[INFO 24-02-22 06:53:14.2249 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:14.2251 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.727425 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:14.2254 UTC hyperparameters_optimizer.cc:582] [526/1100] Score: -0.727425 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:14.2260 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:14.2260 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:14.2262 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:14.2315 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187421 train-accuracy:0.777506 valid-loss:1.128765 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:14.6056 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656405\n",
      "[INFO 24-02-22 06:53:14.6056 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:53:14.6057 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.656405 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:14.6064 UTC hyperparameters_optimizer.cc:582] [527/1100] Score: -0.656405 / -0.484448 HParams: [fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 06:53:14.6066 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:14.6067 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:14.6082 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:14.6288 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.183483 train-accuracy:0.612469 valid-loss:1.146918 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:14.7728 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603579\n",
      "[INFO 24-02-22 06:53:14.7728 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:53:14.7731 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.603579 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:14.7733 UTC hyperparameters_optimizer.cc:582] [528/1100] Score: -0.603579 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:14.7738 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:14.7738 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:14.7740 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:14.8103 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.143057 train-accuracy:0.806846 valid-loss:1.097540 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:14.8242 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658692\n",
      "[INFO 24-02-22 06:53:14.8242 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:14.8247 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.658692 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:14.8262 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:14.8262 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:14.8264 UTC hyperparameters_optimizer.cc:582] [529/1100] Score: -0.658692 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:14.8274 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:14.8746 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312033 train-accuracy:0.612469 valid-loss:1.272265 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:15.1721 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663261\n",
      "[INFO 24-02-22 06:53:15.1721 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:53:15.1730 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.663261 valid-accuracy:0.863014\n",
      "[[INFO 24-02-22 06:53:15.1760 UTC hyperparameters_optimizer.cc:582] [530/1100] Score: -0.663261 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 06:53:15.1778 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:15.1778 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:15.1799 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:15.1822 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237417 train-accuracy:0.612469 valid-loss:1.197545 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:15.4113 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.551459\n",
      "[INFO 24-02-22 06:53:15.4113 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:53:15.4114 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.551459 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:15.4127 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:15.4128 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:15.4132 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:15.4141 UTC hyperparameters_optimizer.cc:582] [531/1100] Score: -0.551459 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:15.4161 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280163 train-accuracy:0.612469 valid-loss:1.237358 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:15.5286 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.596463\n",
      "[INFO 24-02-22 06:53:15.5286 UTC gradient_boosted_trees.cc:271] Truncates the model to 133 tree(s) i.e. 133  iteration(s).\n",
      "[INFO 24-02-22 06:53:15.5288 UTC gradient_boosted_trees.cc:334] Final model num-trees:133 valid-loss:0.596463 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:15.5299 UTC hyperparameters_optimizer.cc:582] [532/1100] Score: -0.596463 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:15.5314 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:15.5315 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:15.5316 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:15.5517 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.113792 train-accuracy:0.823961 valid-loss:1.105670 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:15.6400 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650258\n",
      "[INFO 24-02-22 06:53:15.6402 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:53:15.6405 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.650258 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:15.6409 UTC hyperparameters_optimizer.cc:582] [533/1100] Score: -0.650258 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:15.6450 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:15.6451 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:15.6453 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:15.6713 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644689\n",
      "[INFO 24-02-22 06:53:15.6714 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:53:15.6717 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.644689 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:15.6735 UTC hyperparameters_optimizer.cc:582] [534/1100] Score: -0.644689 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:15.6746 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:15.6746 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:15.6754 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:15.6777 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314591 train-accuracy:0.612469 valid-loss:1.273859 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:15.7100 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313788 train-accuracy:0.612469 valid-loss:1.271733 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:15.7779 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643836\n",
      "[INFO 24-02-22 06:53:15.7779 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 06:53:15.7781 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.643836 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:15.7793 UTC hyperparameters_optimizer.cc:582] [535/1100] Score: -0.643836 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:15.7800 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:15.7801 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:15.7813 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:15.7850 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092534 train-accuracy:0.805623 valid-loss:1.057414 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:15.9168 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.563896\n",
      "[INFO 24-02-22 06:53:15.9168 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:53:15.9169 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.563896 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:15.9172 UTC hyperparameters_optimizer.cc:582] [536/1100] Score: -0.563896 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:15.9176 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:15.9176 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:15.9178 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:15.9194 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.202801 train-accuracy:0.612469 valid-loss:1.165010 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:16.0233 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631821\n",
      "[INFO 24-02-22 06:53:16.0234 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:53:16.0235 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.631821 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:16.0238 UTC hyperparameters_optimizer.cc:582] [537/1100] Score: -0.631821 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:16.0246 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.0247 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.0250 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.0383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635631\n",
      "[INFO 24-02-22 06:53:16.0383 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:53:16.0388 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.635631 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:16.0392 UTC hyperparameters_optimizer.cc:582] [538/1100] Score: -0.635631 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:16.0397 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.0397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.0400 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.0467 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060965 train-accuracy:0.842298 valid-loss:1.020506 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:16.0962 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314580 train-accuracy:0.612469 valid-loss:1.273613 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:16.3427 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661081\n",
      "[INFO 24-02-22 06:53:16.3427 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:16.3430 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:16.3430 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.661081 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:16.3433 UTC hyperparameters_optimizer.cc:582] [539/1100] Score: -0.661081 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:16.3457 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.3462 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.3464 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.3479 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.546416\n",
      "[INFO 24-02-22 06:53:16.3480 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:53:16.3485 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.546416 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:16.3514 UTC hyperparameters_optimizer.cc:582] [540/1100] Score: -0.546416 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:16.3534 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.3535 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.3540 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.3597 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244239 train-accuracy:0.612469 valid-loss:1.199355 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:16.3769 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.612443\n",
      "[INFO 24-02-22 06:53:16.3769 UTC gradient_boosted_trees.cc:271] Truncates the model to 245 tree(s) i.e. 245  iteration(s).\n",
      "[INFO 24-02-22 06:53:16.3770 UTC gradient_boosted_trees.cc:334] Final model num-trees:245 valid-loss:0.612443 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:16.3789 UTC hyperparameters_optimizer.cc:582] [541/1100] Score: -0.612443 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:16.3795 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.3796 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.3828 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.4002 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.272166 train-accuracy:0.612469 valid-loss:1.240193 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:16.4082 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219218 train-accuracy:0.612469 valid-loss:1.207020 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:16.4372 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661479\n",
      "[INFO 24-02-22 06:53:16.4373 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:16.4378 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.661479 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:16.4381 UTC hyperparameters_optimizer.cc:582] [542/1100] Score: -0.661479 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:16.4388 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.4388 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.4391 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.4490 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.115169 train-accuracy:0.803178 valid-loss:1.067206 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:16.7779 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67975\n",
      "[INFO 24-02-22 06:53:16.7779 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:53:16.7781 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.679750 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:16.7783 UTC hyperparameters_optimizer.cc:582] [543/1100] Score: -0.67975 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:16.7793 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.7793 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.7795 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.8324 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281039 train-accuracy:0.612469 valid-loss:1.245549 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:16.8937 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633696\n",
      "[INFO 24-02-22 06:53:16.8937 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:16.8940 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.633696 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:16.8944 UTC hyperparameters_optimizer.cc:582] [544/1100] Score: -0.633696 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:16.8952 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.8952 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.8954 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.9019 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146931 train-accuracy:0.777506 valid-loss:1.120975 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:53:16.9792 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650205\n",
      "[INFO 24-02-22 06:53:16.9792 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:53:16.9798 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.650205 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:16.9863 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:16.9863 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:16.9865 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:16.9887 UTC hyperparameters_optimizer.cc:582] [545/1100] Score: -0.650205 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:17.0159 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.053667 train-accuracy:0.845966 valid-loss:1.049974 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:17.2812 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627399\n",
      "[INFO 24-02-22 06:53:17.2849 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:53:17.2857 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.627399 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:17.2860 UTC hyperparameters_optimizer.cc:582] [546/1100] Score: -0.627399 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:17.2876 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:17.2877 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:17.2880 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:17.3447 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.038494 train-accuracy:0.819071 valid-loss:1.019704 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:17.4354 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66631\n",
      "[INFO 24-02-22 06:53:17.4355 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 06:53:17.4358 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.666310 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:17.4381 UTC hyperparameters_optimizer.cc:582] [547/1100] Score: -0.66631 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:17.4428 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:17.4438 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:17.4440 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:17.4462 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.193567 train-accuracy:0.612469 valid-loss:1.174462 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:17.5534 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635165\n",
      "[INFO 24-02-22 06:53:17.5534 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 06:53:17.5535 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.635165 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:17.5543 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:17.5543 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:17.5545 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:17.5557 UTC hyperparameters_optimizer.cc:582] [548/1100] Score: -0.635165 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:17.5796 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67135\n",
      "[INFO 24-02-22 06:53:17.5796 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:53:17.5797 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.671350 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:17.5804 UTC hyperparameters_optimizer.cc:582] [549/1100] Score: -0.67135 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:17.5814 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.068538 train-accuracy:0.816626 valid-loss:1.061964 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:17.5817 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:17.5817 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:17.5819 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:17.5883 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239568 train-accuracy:0.612469 valid-loss:1.195804 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:17.6986 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.613555\n",
      "[INFO 24-02-22 06:53:17.6987 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:53:17.6989 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.613555 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:17.6998 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:17.6999 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:17.7001 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[[INFO 24-02-22 06:53:17.7012 UTC hyperparameters_optimizer.cc:582] [550/1100] Score: -0.613555 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "INFO 24-02-22 06:53:17.7017 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290990 train-accuracy:0.612469 valid-loss:1.248762 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:17.7282 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655105\n",
      "[INFO 24-02-22 06:53:17.7284 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:53:17.7288 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.655105 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:17.7304 UTC hyperparameters_optimizer.cc:582] [551/1100] Score: -0.655105 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:17.7343 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:17.7349 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:17.7351 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:17.7461 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284420 train-accuracy:0.612469 valid-loss:1.243969 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:17.9834 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658331\n",
      "[INFO 24-02-22 06:53:17.9834 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:17.9836 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.658331 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:17.9841 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:17.9841 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:17.9843 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:17.9853 UTC hyperparameters_optimizer.cc:582] [552/1100] Score: -0.658331 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:18.0467 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.212916 train-accuracy:0.612469 valid-loss:1.177480 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:18.0530 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634724\n",
      "[INFO 24-02-22 06:53:18.0530 UTC gradient_boosted_trees.cc:271] Truncates the model to 167 tree(s) i.e. 167  iteration(s).\n",
      "[INFO 24-02-22 06:53:18.0530 UTC gradient_boosted_trees.cc:334] Final model num-trees:167 valid-loss:0.634724 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:18.0534 UTC hyperparameters_optimizer.cc:582] [553/1100] Score: -0.634724 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:18.0538 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.0538 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.0543 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:18.1070 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.145249 train-accuracy:0.742054 valid-loss:1.088221 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:18.1965 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617883\n",
      "[INFO 24-02-22 06:53:18.1970 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:53:18.1972 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.617883 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:18.1978 UTC hyperparameters_optimizer.cc:582] [554/1100] Score: -0.617883 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:18.1983 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.1983 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.1988 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:18.2056 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130138 train-accuracy:0.772616 valid-loss:1.109762 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:53:18.4784 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703046\n",
      "[INFO 24-02-22 06:53:18.4784 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:53:18.4787 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.703046 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:18.4795 UTC hyperparameters_optimizer.cc:582] [555/1100] Score: -0.703046 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:18.4815 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.4816 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.4818 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:18.4929 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634766\n",
      "[INFO 24-02-22 06:53:18.4930 UTC gradient_boosted_trees.cc:271] Truncates the model to 130 tree(s) i.e. 130  iteration(s).\n",
      "[INFO 24-02-22 06:53:18.4933 UTC gradient_boosted_trees.cc:334] Final model num-trees:130 valid-loss:0.634766 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:18.4936 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588103\n",
      "[INFO 24-02-22 06:53:18.4936 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:53:18.4938 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.588103 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:18.4941 UTC hyperparameters_optimizer.cc:582] [556/1100] Score: -0.588103 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:18.4948 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.4948 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.4950 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:18.4951 UTC hyperparameters_optimizer.cc:582] [557/1100] Score: -0.634766 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:18.4997 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.4999 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.5003 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:18.5135 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.078322 train-accuracy:0.821516 valid-loss:1.039457 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:18.5195 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.136112 train-accuracy:0.612469 valid-loss:1.149606 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:18.5333 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207687 train-accuracy:0.612469 valid-loss:1.188305 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:18.5724 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.612952\n",
      "[INFO 24-02-22 06:53:18.5725 UTC gradient_boosted_trees.cc:271] Truncates the model to 81 tree(s) i.e. 81  iteration(s).\n",
      "[INFO 24-02-22 06:53:18.5742 UTC gradient_boosted_trees.cc:334] Final model num-trees:81 valid-loss:0.612952 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:18.5750 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.5751 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.5753 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:18.5773 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284372 train-accuracy:0.612469 valid-loss:1.244436 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:18.5785 UTC hyperparameters_optimizer.cc:582] [558/1100] Score: -0.612952 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:18.9334 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695149\n",
      "[INFO 24-02-22 06:53:18.9334 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:18.9337 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:18.9337 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.695149 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:18.9339 UTC hyperparameters_optimizer.cc:582] [559/1100] Score: -0.695149 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:18.9354 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.9354 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.9365 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:18.9649 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.602696\n",
      "[INFO 24-02-22 06:53:18.9649 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:53:18.9651 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.602696 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:18.9672 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209265 train-accuracy:0.612469 valid-loss:1.161516 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:18.9681 UTC hyperparameters_optimizer.cc:582] [560/1100] Score: -0.602696 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:18.9685 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.9685 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.9687 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:18.9798 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315535 train-accuracy:0.612469 valid-loss:1.274424 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:18.9933 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665872\n",
      "[INFO 24-02-22 06:53:18.9933 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:18.9935 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:18.9935 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.665872 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:18.9938 UTC hyperparameters_optimizer.cc:582] [561/1100] Score: -0.665872 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:18.9942 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.9943 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:18.9946 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-22 06:53:18.9970 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640793\n",
      "[INFO 24-02-22 06:53:18.9970 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      " 24-02-22 06:53:18.9969 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188796 train-accuracy:0.612469 valid-loss:1.140941 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:18.9975 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.640793 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:18.9995 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:18.9996 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:19.0000 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:19.0020 UTC hyperparameters_optimizer.cc:582] [562/1100] Score: -0.640793 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:19.0030 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188300 train-accuracy:0.724939 valid-loss:1.143645 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:53:19.1531 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639922\n",
      "[INFO 24-02-22 06:53:19.1531 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:53:19.1534 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.639922 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:19.1537 UTC hyperparameters_optimizer.cc:582] [563/1100] Score: -0.639922 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:19.1568 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:19.1573 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:19.1575 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:19.1739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.267437 train-accuracy:0.612469 valid-loss:1.239855 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:19.4086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623847\n",
      "[INFO 24-02-22 06:53:19.4086 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:53:19.4087 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.623847 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:19.4090 UTC hyperparameters_optimizer.cc:582] [564/1100] Score: -0.623847 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:19.4097 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:19.4098 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:19.4101 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:19.4132 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312589 train-accuracy:0.612469 valid-loss:1.272800 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:19.9098 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649907\n",
      "[INFO 24-02-22 06:53:19.9098 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 06:53:19.9101 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.649907 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:19.9135 UTC hyperparameters_optimizer.cc:582] [565/1100] Score: -0.649907 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:19.9210 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:19.9211 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:19.9214 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:19.9412 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.994557 train-accuracy:0.892421 valid-loss:1.047471 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:20.1511 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690968\n",
      "[INFO 24-02-22 06:53:20.1511 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.1517 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.690968 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:20.1542 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.1542 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.1544 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.1587 UTC hyperparameters_optimizer.cc:582] [566/1100] Score: -0.690968 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:20.1650 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.078442 train-accuracy:0.839853 valid-loss:1.064203 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:20.2202 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662439\n",
      "[INFO 24-02-22 06:53:20.2202 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.2206 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.662439 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:20.2211 UTC hyperparameters_optimizer.cc:582] [567/1100] Score: -0.662439 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:20.2227 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.2228 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.2231 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.2936 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.272938 train-accuracy:0.612469 valid-loss:1.238901 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:20.4213 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642792\n",
      "[INFO 24-02-22 06:53:20.4214 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.4216 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.642792 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:20.4218 UTC hyperparameters_optimizer.cc:582] [568/1100] Score: -0.642792 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:20.4222 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.4222 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.4224 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.4407 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312349 train-accuracy:0.612469 valid-loss:1.272286 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:20.5043 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643138\n",
      "[INFO 24-02-22 06:53:20.5043 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:20.5049 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:20.5049 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.643138 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:20.5054 UTC hyperparameters_optimizer.cc:582] [569/1100] Score: -0.643138 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:20.5067 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.5068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.5070 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.5141 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66127\n",
      "[INFO 24-02-22 06:53:20.5142 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.5154 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.661270 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:20.5170 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219809 train-accuracy:0.612469 valid-loss:1.193801 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:20.5176 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.5176 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.5179 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.5187 UTC hyperparameters_optimizer.cc:582] [570/1100] Score: -0.66127 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:20.5269 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.265184 train-accuracy:0.612469 valid-loss:1.233531 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:20.5388 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662366\n",
      "[INFO 24-02-22 06:53:20.5389 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.5403 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634094\n",
      "[INFO 24-02-22 06:53:20.5404 UTC gradient_boosted_trees.cc:271] Truncates the model to 145 tree(s) i.e. 145  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.5407 UTC gradient_boosted_trees.cc:334] Final model num-trees:145 valid-loss:0.634094 valid-accuracy:0.863014\n",
      "[WARNING 24-02-22 06:53:20.5408 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:20.5408 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.662366 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:20.5420 UTC hyperparameters_optimizer.cc:582] [571/1100] Score: -0.662366 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:20.5438 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.5438 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.5440 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.5440 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.5441 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.5442 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.5460 UTC hyperparameters_optimizer.cc:582] [572/1100] Score: -0.634094 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:20.5540 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155679 train-accuracy:0.777506 valid-loss:1.093022 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:20.5904 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102282 train-accuracy:0.822738 valid-loss:1.049750 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:20.7242 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.607645\n",
      "[INFO 24-02-22 06:53:20.7243 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.7246 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.607645 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:20.7258 UTC hyperparameters_optimizer.cc:582] [573/1100] Score: -0.607645 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:20.7261 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.7261 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.7265 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.7820 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.175161 train-accuracy:0.612469 valid-loss:1.135623 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:20.8273 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.620179\n",
      "[INFO 24-02-22 06:53:20.8273 UTC gradient_boosted_trees.cc:271] Truncates the model to 270 tree(s) i.e. 270  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.8274 UTC gradient_boosted_trees.cc:334] Final model num-trees:270 valid-loss:0.620179 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:20.8324 UTC hyperparameters_optimizer.cc:582] [574/1100] Score: -0.620179 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:20.8327 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.8327 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.8329 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:20.8803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228788 train-accuracy:0.612469 valid-loss:1.204277 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:20.9439 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66884\n",
      "[INFO 24-02-22 06:53:20.9439 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:20.9451 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.668840 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:20.9521 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:20.9521 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:20.9522 UTC hyperparameters_optimizer.cc:582] [575/1100] Score: -0.66884 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:20.9581 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:21.0413 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.131793 train-accuracy:0.776284 valid-loss:1.084646 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:21.0844 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65622\n",
      "[INFO 24-02-22 06:53:21.0845 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:21.0851 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.656220 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:21.0892 UTC hyperparameters_optimizer.cc:582] [576/1100] Score: -0.65622 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:21.0914 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:21.0915 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:21.0917 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:21.1434 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130500 train-accuracy:0.793399 valid-loss:1.089239 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:21.1583 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664522\n",
      "[INFO 24-02-22 06:53:21.1583 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:53:21.1620 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.664522 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:21.1678 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:21.1679 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:21.1681 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:21.1682 UTC hyperparameters_optimizer.cc:582] [577/1100] Score: -0.664522 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:21.1763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246390 train-accuracy:0.612469 valid-loss:1.200929 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:21.2382 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.589856\n",
      "[INFO 24-02-22 06:53:21.2382 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:53:21.2384 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.589856 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:21.2395 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:21.2396 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:21.2399 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:21.2420 UTC hyperparameters_optimizer.cc:582] [578/1100] Score: -0.589856 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:21.2918 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103203 train-accuracy:0.812958 valid-loss:1.084161 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:21.4436 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593831\n",
      "[INFO 24-02-22 06:53:21.4436 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:53:21.4436 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.593831 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:21.4439 UTC hyperparameters_optimizer.cc:582] [579/1100] Score: -0.593831 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:21.4443 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:21.4443 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:21.4446 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:21.5086 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277113 train-accuracy:0.612469 valid-loss:1.241307 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:21.7747 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.616387\n",
      "[INFO 24-02-22 06:53:21.7748 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 06:53:21.7752 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.616387 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:21.7761 UTC hyperparameters_optimizer.cc:582] [580/1100] Score: -0.616387 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:21.7783 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:21.7784 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:21.7787 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:21.7947 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.983841 train-accuracy:0.872861 valid-loss:0.964399 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:22.0103 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.611109\n",
      "[INFO 24-02-22 06:53:22.0103 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:53:22.0104 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.611109 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:22.0107 UTC hyperparameters_optimizer.cc:582] [581/1100] Score: -0.611109 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:22.0113 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:22.0113 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:22.0115 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:22.0346 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230139 train-accuracy:0.612469 valid-loss:1.205162 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:22.2547 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63642\n",
      "[INFO 24-02-22 06:53:22.2548 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:22.2552 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.636420 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 06:53:22.2565 UTC hyperparameters_optimizer.cc:582] [582/1100] Score: -0.63642 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 06:53:22.2572 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:22.2572 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:22.2575 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:22.2614 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.179656 train-accuracy:0.612469 valid-loss:1.149048 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:22.2892 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.579875\n",
      "[INFO 24-02-22 06:53:22.2893 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:22.2901 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.579875 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:22.2913 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:22.2913 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:22.2915 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:22.2928 UTC hyperparameters_optimizer.cc:582] [583/1100] Score: -0.579875 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:22.3026 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081195 train-accuracy:0.823961 valid-loss:1.058912 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:22.6032 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.565065\n",
      "[INFO 24-02-22 06:53:22.6032 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:53:22.6035 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.565065 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:22.6048 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:22.6049 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:22.6051 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:22.6087 UTC hyperparameters_optimizer.cc:582] [584/1100] Score: -0.565065 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:22.6158 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196072 train-accuracy:0.612469 valid-loss:1.159079 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:22.7377 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.570157\n",
      "[INFO 24-02-22 06:53:22.7377 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:53:22.7383 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.570157 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:22.7388 UTC hyperparameters_optimizer.cc:582] [585/1100] Score: -0.570157 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:22.7401 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:22.7402 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:22.7406 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:22.7739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240341 train-accuracy:0.612469 valid-loss:1.194999 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:23.2359 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.628178\n",
      "[INFO 24-02-22 06:53:23.2359 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.2361 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.628178 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:23.2365 UTC hyperparameters_optimizer.cc:582] [586/1100] Score: -0.628178 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:23.2375 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.2376 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.2380 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.2450 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223328 train-accuracy:0.612469 valid-loss:1.162889 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:23.2564 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653854\n",
      "[INFO 24-02-22 06:53:23.2565 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.2568 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.653854 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:23.2582 UTC hyperparameters_optimizer.cc:582] [587/1100] Score: -0.653854 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:23.2591 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.2591 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.2605 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.2624 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.202665 train-accuracy:0.784841 valid-loss:1.143970 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:23.4199 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.595105\n",
      "[INFO 24-02-22 06:53:23.4199 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.4201 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.595105 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:23.4205 UTC hyperparameters_optimizer.cc:582] [588/1100] Score: -0.595105 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:23.4213 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.4213 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.4216 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.4285 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146655 train-accuracy:0.755501 valid-loss:1.106700 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:53:23.4559 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627781\n",
      "[INFO 24-02-22 06:53:23.4559 UTC gradient_boosted_trees.cc:271] Truncates the model to 85 tree(s) i.e. 85  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.4561 UTC gradient_boosted_trees.cc:334] Final model num-trees:85 valid-loss:0.627781 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:23.4571 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.4571 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.4573 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.4620 UTC hyperparameters_optimizer.cc:582] [589/1100] Score: -0.627781 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:23.4646 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081953 train-accuracy:0.815403 valid-loss:1.036550 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:23.5798 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588892\n",
      "[INFO 24-02-22 06:53:23.5798 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.5799 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.588892 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:23.5802 UTC hyperparameters_optimizer.cc:582] [590/1100] Score: -0.588892 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:23.5807 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.5807 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.5826 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.5891 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176739 train-accuracy:0.612469 valid-loss:1.169391 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:23.7082 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664239\n",
      "[INFO 24-02-22 06:53:23.7082 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.7086 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.664239 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:23.7104 UTC hyperparameters_optimizer.cc:582] [591/1100] Score: -0.664239 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:23.7125 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.7127 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.7130 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.7361 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.069355 train-accuracy:0.836186 valid-loss:1.019444 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:23.7766 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6754\n",
      "[INFO 24-02-22 06:53:23.7767 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.7768 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.675400 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:23.7773 UTC hyperparameters_optimizer.cc:582] [592/1100] Score: -0.6754 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:23.7794 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.7795 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.7797 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.7873 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282202 train-accuracy:0.612469 valid-loss:1.242898 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:23.8074 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.628187\n",
      "[INFO 24-02-22 06:53:23.8074 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.8076 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.628187 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:23.8078 UTC hyperparameters_optimizer.cc:582] [593/1100] Score: -0.628187 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:23.8081 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.8081 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.8084 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.8147 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079851 train-accuracy:0.830073 valid-loss:1.035604 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:23.8225 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634435\n",
      "[INFO 24-02-22 06:53:23.8227 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:53:23.8227 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.634435 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:23.8229 UTC hyperparameters_optimizer.cc:582] [594/1100] Score: -0.634435 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:23.8233 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:23.8233 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:23.8235 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:23.8473 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281108 train-accuracy:0.612469 valid-loss:1.245270 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.0386 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691012\n",
      "[INFO 24-02-22 06:53:24.0386 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.0423 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.691012 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:24.0431 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.0431 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.0433 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.0436 UTC hyperparameters_optimizer.cc:582] [595/1100] Score: -0.691012 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:24.0528 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184032 train-accuracy:0.612469 valid-loss:1.140461 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.1054 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650358\n",
      "[INFO 24-02-22 06:53:24.1055 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.1056 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.650358 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:24.1061 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.1061 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.1064 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.1066 UTC hyperparameters_optimizer.cc:582] [596/1100] Score: -0.650358 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:24.1089 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.693503\n",
      "[INFO 24-02-22 06:53:24.1089 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.1093 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.693503 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:24.1100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.1100 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.1102 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.1122 UTC hyperparameters_optimizer.cc:582] [597/1100] Score: -0.693503 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:24.1146 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277270 train-accuracy:0.612469 valid-loss:1.236132 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.1348 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290253 train-accuracy:0.612469 valid-loss:1.247102 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.2179 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657524\n",
      "[INFO 24-02-22 06:53:24.2180 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.2181 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.657524 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:24.2185 UTC hyperparameters_optimizer.cc:582] [598/1100] Score: -0.657524 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:24.2193 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.2193 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.2195 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.2336 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.179519 train-accuracy:0.612469 valid-loss:1.154750 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.4255 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.602075\n",
      "[INFO 24-02-22 06:53:24.4255 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.4256 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.602075 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:24.4259 UTC hyperparameters_optimizer.cc:582] [599/1100] Score: -0.602075 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:24.4266 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.4266 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.4269 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.4488 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229593 train-accuracy:0.612469 valid-loss:1.201352 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.4954 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.551543\n",
      "[INFO 24-02-22 06:53:24.4954 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.4956 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.551543 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:24.4959 UTC hyperparameters_optimizer.cc:582] [600/1100] Score: -0.551543 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:24.4979 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.4980 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.4984 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.5245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657561\n",
      "[INFO 24-02-22 06:53:24.5247 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.5252 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.657561 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:24.5257 UTC hyperparameters_optimizer.cc:582] [601/1100] Score: -0.657561 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:24.5263 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.5263 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.5265 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.5336 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.026468 train-accuracy:0.841076 valid-loss:1.010924 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:24.5374 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314628 train-accuracy:0.612469 valid-loss:1.274074 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.6658 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671777\n",
      "[INFO 24-02-22 06:53:24.6658 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.6660 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.671777 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:24.6662 UTC hyperparameters_optimizer.cc:582] [602/1100] Score: -0.671777 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:24.6666 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.6666 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.6668 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.6828 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245544 train-accuracy:0.612469 valid-loss:1.203396 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.8793 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668702\n",
      "[INFO 24-02-22 06:53:24.8793 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.8801 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.668702 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:24.8808 UTC hyperparameters_optimizer.cc:582] [603/1100] Score: -0.668702 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:24.8827 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.8828 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.8832 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.9008 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316647 train-accuracy:0.612469 valid-loss:1.276266 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:24.9057 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647332\n",
      "[INFO 24-02-22 06:53:24.9058 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 06:53:24.9060 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.647332 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:24.9074 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:24.9074 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:24.9076 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:24.9154 UTC hyperparameters_optimizer.cc:582] [604/1100] Score: -0.647332 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:24.9172 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.166549 train-accuracy:0.717604 valid-loss:1.113723 valid-accuracy:0.726027\n",
      "[INFO 24-02-22 06:53:25.1148 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659361\n",
      "[INFO 24-02-22 06:53:25.1149 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.1152 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.659361 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:25.1158 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.1158 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.1160 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.1220 UTC hyperparameters_optimizer.cc:582] [605/1100] Score: -0.659361 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:25.1272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.037451 train-accuracy:0.837408 valid-loss:1.025445 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:25.3025 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.585768\n",
      "[INFO 24-02-22 06:53:25.3025 UTC gradient_boosted_trees.cc:271] Truncates the model to 164 tree(s) i.e. 164  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.3027 UTC gradient_boosted_trees.cc:334] Final model num-trees:164 valid-loss:0.585768 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:25.3039 UTC hyperparameters_optimizer.cc:582] [606/1100] Score: -0.585768 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:25.3045 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.3045 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.3058 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.3079 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162135 train-accuracy:0.784841 valid-loss:1.132935 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:25.3111 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.69857\n",
      "[INFO 24-02-22 06:53:25.3111 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.3112 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.698570 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:25.3114 UTC hyperparameters_optimizer.cc:582] [607/1100] Score: -0.69857 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:25.3118 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.3118 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.3120 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.3396 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316441 train-accuracy:0.612469 valid-loss:1.273323 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:25.3479 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636737\n",
      "[INFO 24-02-22 06:53:25.3479 UTC gradient_boosted_trees.cc:271] Truncates the model to 88 tree(s) i.e. 88  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.3479 UTC gradient_boosted_trees.cc:334] Final model num-trees:88 valid-loss:0.636737 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:25.3481 UTC hyperparameters_optimizer.cc:582] [608/1100] Score: -0.636737 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:25.3484 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.3484 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.3486 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.3722 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.126869 train-accuracy:0.792176 valid-loss:1.079423 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:25.5303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662741\n",
      "[INFO 24-02-22 06:53:25.5303 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.5308 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.662741 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:25.5313 UTC hyperparameters_optimizer.cc:582] [609/1100] Score: -0.662741 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:25.5319 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.5319 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.5324 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.6113 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668881\n",
      "[INFO 24-02-22 06:53:25.6113 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:25.6116 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:25.6116 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.668881 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:25.6123 UTC hyperparameters_optimizer.cc:582] [610/1100] Score: -0.668881 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:25.6128 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.6128 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.6130 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.6149 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282907 train-accuracy:0.612469 valid-loss:1.236747 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:25.6309 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.203254 train-accuracy:0.612469 valid-loss:1.193391 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:25.6895 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.589455\n",
      "[INFO 24-02-22 06:53:25.6895 UTC gradient_boosted_trees.cc:271] Truncates the model to 56 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.6899 UTC gradient_boosted_trees.cc:334] Final model num-trees:56 valid-loss:0.589455 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:25.6905 UTC hyperparameters_optimizer.cc:582] [611/1100] Score: -0.589455 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:25.6925 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.6927 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.6929 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.6942 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647472\n",
      "[INFO 24-02-22 06:53:25.6942 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.6943 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.647472 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:25.6945 UTC hyperparameters_optimizer.cc:582] [612/1100] Score: -0.647472 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:25.6949 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.6949 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.6952 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.6967 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.126839 train-accuracy:0.779951 valid-loss:1.127905 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:25.6978 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314499 train-accuracy:0.612469 valid-loss:1.273262 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:25.8702 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635053\n",
      "[INFO 24-02-22 06:53:25.8702 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.8705 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.635053 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:25.8732 UTC hyperparameters_optimizer.cc:582] [613/1100] Score: -0.635053 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:25.8752 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.8755 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.8760 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.8853 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151706 train-accuracy:0.768949 valid-loss:1.106876 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:25.9570 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688051\n",
      "[INFO 24-02-22 06:53:25.9570 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.9573 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.688051 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:25.9579 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.559779\n",
      "[INFO 24-02-22 06:53:25.9580 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:25.9580 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.9580 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.9582 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.9585 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.559779 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:25.9588 UTC hyperparameters_optimizer.cc:582] [614/1100] Score: -0.688051 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:25.9593 UTC hyperparameters_optimizer.cc:582] [615/1100] Score: -0.559779 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:25.9600 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:25.9600 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:25.9602 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:25.9616 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196108 train-accuracy:0.612469 valid-loss:1.156107 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:25.9661 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284938 train-accuracy:0.612469 valid-loss:1.243102 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:26.0066 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651994\n",
      "[INFO 24-02-22 06:53:26.0066 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.0068 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.651994 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:26.0073 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.0073 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.0076 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.0088 UTC hyperparameters_optimizer.cc:582] [616/1100] Score: -0.651994 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:26.0110 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146670 train-accuracy:0.739609 valid-loss:1.120054 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:26.0195 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636622\n",
      "[INFO 24-02-22 06:53:26.0195 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.0196 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.636622 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:26.0199 UTC hyperparameters_optimizer.cc:582] [617/1100] Score: -0.636622 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:26.0205 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.0206 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.0210 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.0279 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.035851 train-accuracy:0.826406 valid-loss:1.027117 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:26.0794 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.576061\n",
      "[INFO 24-02-22 06:53:26.0795 UTC gradient_boosted_trees.cc:271] Truncates the model to 169 tree(s) i.e. 169  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.0800 UTC gradient_boosted_trees.cc:334] Final model num-trees:169 valid-loss:0.576061 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:26.0816 UTC hyperparameters_optimizer.cc:582] [618/1100] Score: -0.576061 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.0842 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.0843 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.0845 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.1113 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248214 train-accuracy:0.612469 valid-loss:1.194917 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:26.1843 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.618477\n",
      "[INFO 24-02-22 06:53:26.1844 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.1845 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.618477 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:26.1852 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.1852 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.1857 UTC hyperparameters_optimizer.cc:582] [619/1100] Score: -0.618477 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:26.1927 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.2175 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.111163 train-accuracy:0.800734 valid-loss:1.074718 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:26.2226 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609881\n",
      "[INFO 24-02-22 06:53:26.2226 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.2229 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.609881 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:26.2237 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.2237 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.2239 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.2254 UTC hyperparameters_optimizer.cc:582] [620/1100] Score: -0.609881 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.2266 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232382 train-accuracy:0.612469 valid-loss:1.191057 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:26.2317 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.589388\n",
      "[INFO 24-02-22 06:53:26.2317 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.2331 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.589388 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:26.2339 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.2339 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.2342 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.2353 UTC hyperparameters_optimizer.cc:582] [621/1100] Score: -0.589388 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.2428 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.123675 train-accuracy:0.612469 valid-loss:1.133846 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:26.2518 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691002\n",
      "[INFO 24-02-22 06:53:26.2518 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.2521 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.691002 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:26.2525 UTC hyperparameters_optimizer.cc:582] [622/1100] Score: -0.691002 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.2535 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.2535 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.2538 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.2984 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.074384 train-accuracy:0.888753 valid-loss:1.096908 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:26.3343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62728\n",
      "[INFO 24-02-22 06:53:26.3343 UTC gradient_boosted_trees.cc:271] Truncates the model to 202 tree(s) i.e. 202  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.3346 UTC gradient_boosted_trees.cc:334] Final model num-trees:202 valid-loss:0.627280 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:26.3368 UTC hyperparameters_optimizer.cc:582] [623/1100] Score: -0.62728 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:26.3372 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.3372 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.3375 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.3901 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.590418\n",
      "[INFO 24-02-22 06:53:26.3901 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.3902 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.590418 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:26.3908 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.3908 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.3910 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.3954 UTC hyperparameters_optimizer.cc:582] [624/1100] Score: -0.590418 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:26.4040 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310887 train-accuracy:0.612469 valid-loss:1.271822 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:26.4240 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.075801 train-accuracy:0.806846 valid-loss:1.027527 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:26.4254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.607595\n",
      "[INFO 24-02-22 06:53:26.4254 UTC gradient_boosted_trees.cc:271] Truncates the model to 258 tree(s) i.e. 258  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.4256 UTC gradient_boosted_trees.cc:334] Final model num-trees:258 valid-loss:0.607595 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:26.4276 UTC hyperparameters_optimizer.cc:582] [625/1100] Score: -0.607595 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.4283 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.4283 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.4301 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.4315 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290576 train-accuracy:0.612469 valid-loss:1.248120 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:26.4824 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639876\n",
      "[INFO 24-02-22 06:53:26.4825 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.4827 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.639876 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:26.4835 UTC hyperparameters_optimizer.cc:582] [626/1100] Score: -0.639876 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.4844 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.4845 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.4848 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.4995 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224222 train-accuracy:0.612469 valid-loss:1.189967 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:26.5753 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.58699\n",
      "[INFO 24-02-22 06:53:26.5753 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.5756 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.586990 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:26.5767 UTC hyperparameters_optimizer.cc:582] [627/1100] Score: -0.58699 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.5769 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.724531\n",
      "[INFO 24-02-22 06:53:26.5769 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.5774 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.5775 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.5780 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.724531 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:26.5785 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.5790 UTC hyperparameters_optimizer.cc:582] [628/1100] Score: -0.724531 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.5839 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.5839 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.5840 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.052919 train-accuracy:0.833741 valid-loss:1.020078 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:26.5843 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.6176 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.113501 train-accuracy:0.768949 valid-loss:1.120430 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:26.6368 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668436\n",
      "[INFO 24-02-22 06:53:26.6368 UTC gradient_boosted_trees.cc:271] Truncates the model to 132 tree(s) i.e. 132  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.6369 UTC gradient_boosted_trees.cc:334] Final model num-trees:132 valid-loss:0.668436 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:26.6378 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.6378 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.6381 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.6420 UTC hyperparameters_optimizer.cc:582] [629/1100] Score: -0.668436 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.6563 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103706 train-accuracy:0.805623 valid-loss:1.078985 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:26.7203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669067\n",
      "[INFO 24-02-22 06:53:26.7203 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:26.7206 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:26.7206 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.669067 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:26.7210 UTC hyperparameters_optimizer.cc:582] [630/1100] Score: -0.669067 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:26.7217 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.7217 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.7221 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.7303 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180271 train-accuracy:0.612469 valid-loss:1.145772 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:26.9705 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664653\n",
      "[INFO 24-02-22 06:53:26.9706 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:26.9709 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.664653 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:26.9713 UTC hyperparameters_optimizer.cc:582] [631/1100] Score: -0.664653 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:26.9725 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:26.9727 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:26.9730 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:26.9915 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226532 train-accuracy:0.612469 valid-loss:1.189507 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:27.1549 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660747\n",
      "[INFO 24-02-22 06:53:27.1549 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 06:53:27.1552 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.660747 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:27.1563 UTC hyperparameters_optimizer.cc:582] [632/1100] Score: -0.660747 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:27.1579 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:27.1580 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:27.1583 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:27.2272 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650722\n",
      "[INFO 24-02-22 06:53:27.2272 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:27.2274 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.650722 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:27.2281 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:27.2281 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-22 06:53:27.2284 UTC hyperparameters_optimizer.cc:582] [633/1100] Score: -0.650722 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 06:53:27.2287 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:27.2465 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313265 train-accuracy:0.612469 valid-loss:1.274179 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:27.2584 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304689 train-accuracy:0.612469 valid-loss:1.270894 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:27.2952 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.568745\n",
      "[INFO 24-02-22 06:53:27.2952 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:53:27.2977 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.568745 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:27.2988 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:27.2988 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:27.2991 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:27.3059 UTC hyperparameters_optimizer.cc:582] [634/1100] Score: -0.568745 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:27.3515 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.303600 train-accuracy:0.612469 valid-loss:1.271924 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:27.5405 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62543\n",
      "[INFO 24-02-22 06:53:27.5405 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:53:27.5406 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.625430 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:27.5409 UTC hyperparameters_optimizer.cc:582] [635/1100] Score: -0.62543 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:27.5413 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:27.5413 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:27.5416 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:27.5465 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.091333 train-accuracy:0.803178 valid-loss:1.034227 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:27.7391 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.583309\n",
      "[INFO 24-02-22 06:53:27.7391 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:53:27.7392 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.583309 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:27.7395 UTC hyperparameters_optimizer.cc:582] [636/1100] Score: -0.583309 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:27.7399 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:27.7399 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:27.7403 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:27.7429 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177710 train-accuracy:0.612469 valid-loss:1.135958 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:27.7910 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.598491 train-accuracy:0.893643 valid-loss:0.632700 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:27.7911 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:53:27.7911 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.630449 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:27.7917 UTC hyperparameters_optimizer.cc:582] [637/1100] Score: -0.630449 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:27.7930 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:27.7930 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:27.7933 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:27.8340 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158737 train-accuracy:0.790954 valid-loss:1.099535 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:27.8861 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614498\n",
      "[INFO 24-02-22 06:53:27.8861 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:53:27.8866 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.614498 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:27.8872 UTC hyperparameters_optimizer.cc:582] [638/1100] Score: -0.614498 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:27.8892 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:27.8894 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:27.8896 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:27.8946 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090895 train-accuracy:0.805623 valid-loss:1.038304 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:27.9610 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623497\n",
      "[INFO 24-02-22 06:53:27.9610 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:53:27.9611 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.623497 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:53:27.9616 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:27.9617 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:27.9619 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:27.9657 UTC hyperparameters_optimizer.cc:582] [639/1100] Score: -0.623497 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:27.9758 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.267437 train-accuracy:0.612469 valid-loss:1.239855 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:28.0984 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625106\n",
      "[INFO 24-02-22 06:53:28.0984 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:53:28.0988 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.625106 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:28.0992 UTC hyperparameters_optimizer.cc:582] [640/1100] Score: -0.625106 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:28.1002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:28.1002 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:28.1004 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:28.1162 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656461\n",
      "[INFO 24-02-22 06:53:28.1201 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:28.1213 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.656461 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:28.1215 UTC hyperparameters_optimizer.cc:582] [641/1100] Score: -0.656461 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:28.1219 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:28.1219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:28.1221 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:28.1240 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.559341\n",
      "[INFO 24-02-22 06:53:28.1240 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 06:53:28.1240 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187006 train-accuracy:0.612469 valid-loss:1.153871 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:28.1241 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.559341 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:28.1245 UTC hyperparameters_optimizer.cc:582] [642/1100] Score: -0.559341 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:28.1254 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:28.1254 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:28.1257 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:28.1471 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313147 train-accuracy:0.612469 valid-loss:1.273616 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:28.1484 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.010983 train-accuracy:0.877751 valid-loss:1.015190 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:28.2744 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655659\n",
      "[INFO 24-02-22 06:53:28.2745 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:28.2751 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.655659 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:28.2763 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:28.2764 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:28.2766 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:28.2780 UTC hyperparameters_optimizer.cc:582] [643/1100] Score: -0.655659 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:28.2844 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658285\n",
      "[INFO 24-02-22 06:53:28.2871 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:53:28.2873 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.658285 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:28.2878 UTC hyperparameters_optimizer.cc:582] [644/1100] Score: -0.658285 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:28.2905 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:28.2908 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:28.2910 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:28.2931 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.203971 train-accuracy:0.612469 valid-loss:1.160216 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:28.3599 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277983 train-accuracy:0.612469 valid-loss:1.240052 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:28.6886 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.55368\n",
      "[INFO 24-02-22 06:53:28.6893 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 06:53:28.6894 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.553680 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:28.6902 UTC hyperparameters_optimizer.cc:582] [645/1100] Score: -0.55368 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:28.6933 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:28.6946 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:28.6949 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:28.7449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231888 train-accuracy:0.612469 valid-loss:1.189850 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:28.7572 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680024\n",
      "[INFO 24-02-22 06:53:28.7573 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:28.7575 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.680024 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:28.7640 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-22 06:53:28.7640 UTC gradient_boosted_trees.cc:1218]  24-02-22 06:53:28.7640 UTC hyperparameters_optimizer.cc:582] [646/1100] Score: -0.680024 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:28.7645 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:28.7680 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196108 train-accuracy:0.612469 valid-loss:1.156107 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:29.0763 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690968\n",
      "[INFO 24-02-22 06:53:29.0763 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:53:29.0769 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.690968 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:29.0798 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:29.0798 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:29.0801 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:29.0823 UTC hyperparameters_optimizer.cc:582] [647/1100] Score: -0.690968 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:29.0888 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094285 train-accuracy:0.801956 valid-loss:1.073015 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:29.0978 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609881\n",
      "[INFO 24-02-22 06:53:29.0996 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:53:29.0998 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.609881 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:29.1004 UTC hyperparameters_optimizer.cc:582] [648/1100] Score: -0.609881 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:29.1009 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:29.1009 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:29.1014 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:29.1285 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.166269 train-accuracy:0.612469 valid-loss:1.127990 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:29.3272 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.731155\n",
      "[INFO 24-02-22 06:53:29.3272 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:29.3275 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:29.3276 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.731155 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:29.3278 UTC hyperparameters_optimizer.cc:582] [649/1100] Score: -0.731155 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:29.3285 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:29.3285 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:29.3289 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:29.3930 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191622 train-accuracy:0.612469 valid-loss:1.148208 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:29.5113 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601053\n",
      "[INFO 24-02-22 06:53:29.5113 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:53:29.5115 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.601053 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:29.5122 UTC hyperparameters_optimizer.cc:582] [650/1100] Score: -0.601053 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:29.5128 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:29.5128 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:29.5131 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:29.5256 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153699 train-accuracy:0.776284 valid-loss:1.113206 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:30.5099 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631164\n",
      "[INFO 24-02-22 06:53:30.5099 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:53:30.5102 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.631164 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:30.5106 UTC hyperparameters_optimizer.cc:582] [651/1100] Score: -0.631164 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:30.5119 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:30.5119 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:30.5124 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:30.5199 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286328 train-accuracy:0.612469 valid-loss:1.246452 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:30.5636 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609421\n",
      "[INFO 24-02-22 06:53:30.5636 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:53:30.5638 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.609421 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:30.5641 UTC hyperparameters_optimizer.cc:582] [652/1100] Score: -0.609421 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:30.5661 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:30.5662 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:30.5664 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:30.6301 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219564 train-accuracy:0.612469 valid-loss:1.187873 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:30.6448 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.581865\n",
      "[INFO 24-02-22 06:53:30.6449 UTC gradient_boosted_trees.cc:271] Truncates the model to 140 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 24-02-22 06:53:30.6451 UTC gradient_boosted_trees.cc:334] Final model num-trees:140 valid-loss:0.581865 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:30.6459 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:30.6460 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:30.6462 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:30.6487 UTC hyperparameters_optimizer.cc:582] [653/1100] Score: -0.581865 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:30.6539 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632934\n",
      "[INFO 24-02-22 06:53:30.6539 UTC gradient_boosted_trees.cc:271] Truncates the model to 160 tree(s) i.e. 160  iteration(s).\n",
      "[INFO 24-02-22 06:53:30.6543 UTC gradient_boosted_trees.cc:334] Final model num-trees:160 valid-loss:0.632934 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:30.6559 UTC hyperparameters_optimizer.cc:582] [654/1100] Score: -0.632934 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:30.6574 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:30.6575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:30.6578 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:30.6632 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311677 train-accuracy:0.612469 valid-loss:1.272124 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:30.6636 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296420 train-accuracy:0.612469 valid-loss:1.253488 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:30.7527 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.570676\n",
      "[INFO 24-02-22 06:53:30.7527 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:53:30.7528 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.570676 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:30.7534 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:30.7534 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:30.7536 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:30.7554 UTC hyperparameters_optimizer.cc:582] [655/1100] Score: -0.570676 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:30.7730 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292450 train-accuracy:0.612469 valid-loss:1.243842 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:30.9165 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639253\n",
      "[INFO 24-02-22 06:53:30.9165 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:53:30.9171 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.639253 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:30.9176 UTC hyperparameters_optimizer.cc:582] [656/1100] Score: -0.639253 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:30.9194 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:30.9195 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:30.9199 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:30.9225 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079090 train-accuracy:0.816626 valid-loss:1.050784 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:30.9713 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629674\n",
      "[INFO 24-02-22 06:53:30.9714 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      "[INFO 24-02-22 06:53:30.9719 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.629674 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:30.9757 UTC hyperparameters_optimizer.cc:582] [657/1100] Score: -0.629674 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:30.9809 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:30.9809 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:30.9812 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:30.9865 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142705 train-accuracy:0.751834 valid-loss:1.100336 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:53:31.0619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684463\n",
      "[INFO 24-02-22 06:53:31.0621 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:31.0625 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:31.0627 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.684463 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:31.0634 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.0634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.0636 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.0653 UTC hyperparameters_optimizer.cc:582] [658/1100] Score: -0.684463 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:31.1211 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654251\n",
      "[INFO 24-02-22 06:53:31.1212 UTC gradient_boosted_trees.cc:271] Truncates the model to 140 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 24-02-22 06:53:31.1221 UTC gradient_boosted_trees.cc:334] Final model num-trees:140 valid-loss:0.654251 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:31.1248 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.1249 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.1250 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.1254 UTC hyperparameters_optimizer.cc:582] [659/1100] Score: -0.654251 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:31.1377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102548 train-accuracy:0.806846 valid-loss:1.055521 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:31.1792 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623714\n",
      "[INFO 24-02-22 06:53:31.1792 UTC gradient_boosted_trees.cc:271] Truncates the model to 217 tree(s) i.e. 217  iteration(s).\n",
      "[INFO 24-02-22 06:53:31.1794 UTC gradient_boosted_trees.cc:334] Final model num-trees:217 valid-loss:0.623714 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:31.1811 UTC hyperparameters_optimizer.cc:582] [660/1100] Score: -0.623714 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:31.1831 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.1831 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.1833 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.1890 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085736 train-accuracy:0.849633 valid-loss:1.047194 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:31.2109 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.994495 train-accuracy:0.859413 valid-loss:0.996094 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:31.4119 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637217\n",
      "[INFO 24-02-22 06:53:31.4119 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:31.4121 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.637217 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:31.4138 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.4138 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.4138 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651592\n",
      "[INFO 24-02-22 06:53:31.4139 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:53:31.4140 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.4140 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.651592 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:31.4145 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.4145 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.4147 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.4153 UTC hyperparameters_optimizer.cc:582] [661/1100] Score: -0.637217 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:31.4155 UTC hyperparameters_optimizer.cc:582] [662/1100] Score: -0.651592 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:31.4214 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155159 train-accuracy:0.782396 valid-loss:1.120861 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:53:31.4502 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.269173 train-accuracy:0.612469 valid-loss:1.241396 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:31.5728 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648162\n",
      "[INFO 24-02-22 06:53:31.5729 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:53:31.5732 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.648162 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:31.5735 UTC hyperparameters_optimizer.cc:582] [663/1100] Score: -0.648162 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:31.5759 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.5759 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.5761 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.5859 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.113810 train-accuracy:0.809291 valid-loss:1.102804 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:31.7118 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630623\n",
      "[INFO 24-02-22 06:53:31.7118 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:53:31.7119 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.630623 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:31.7129 UTC hyperparameters_optimizer.cc:582] [664/1100] Score: -0.630623 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:31.7147 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.7147 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.7150 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.7178 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.199653 train-accuracy:0.612469 valid-loss:1.167670 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:31.7664 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641919\n",
      "[INFO 24-02-22 06:53:31.7664 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:31.7665 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.641919 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:31.7670 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.7671 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.7672 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.7688 UTC hyperparameters_optimizer.cc:582] [665/1100] Score: -0.641919 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:31.7717 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.204120 train-accuracy:0.612469 valid-loss:1.167148 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:31.8824 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625713\n",
      "[INFO 24-02-22 06:53:31.8852 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:53:31.8854 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.625713 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:31.8860 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:31.8861 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:31.8863 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:31.8873 UTC hyperparameters_optimizer.cc:582] [666/1100] Score: -0.625713 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:31.9101 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228521 train-accuracy:0.612469 valid-loss:1.194709 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:32.0788 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62433\n",
      "[INFO 24-02-22 06:53:32.0788 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:53:32.0789 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.624330 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:32.0791 UTC hyperparameters_optimizer.cc:582] [667/1100] Score: -0.62433 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:32.0797 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:32.0798 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:32.0799 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:32.0827 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.129695 train-accuracy:0.777506 valid-loss:1.124718 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:32.1821 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66507\n",
      "[INFO 24-02-22 06:53:32.1821 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:53:32.1824 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.665070 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:32.1828 UTC hyperparameters_optimizer.cc:582] [668/1100] Score: -0.66507 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:32.1838 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:32.1838 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:32.1841 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:32.1877 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675074\n",
      "[INFO 24-02-22 06:53:32.1878 UTC gradient_boosted_trees.cc:271] Truncates the model to 210 tree(s) i.e. 210  iteration(s).\n",
      "[INFO 24-02-22 06:53:32.1878 UTC gradient_boosted_trees.cc:334] Final model num-trees:210 valid-loss:0.675074 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:32.1883 UTC hyperparameters_optimizer.cc:582] [669/1100] Score: -0.675074 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:32.1895 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:32.1895 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:32.1897 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:32.1902 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132530 train-accuracy:0.797066 valid-loss:1.104536 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:32.2200 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645853\n",
      "[INFO 24-02-22 06:53:32.2200 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:53:32.2204 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.645853 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:32.2213 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:32.2214 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:32.2215 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:32.2220 UTC hyperparameters_optimizer.cc:582] [670/1100] Score: -0.645853 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:32.2305 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.093613 train-accuracy:0.801956 valid-loss:1.068293 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:32.2365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242560 train-accuracy:0.612469 valid-loss:1.205713 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:32.6467 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623746\n",
      "[INFO 24-02-22 06:53:32.6494 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:32.6501 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.623746 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:32.6504 UTC hyperparameters_optimizer.cc:582] [671/1100] Score: -0.623746 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:32.6509 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:32.6510 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:32.6512 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:32.6963 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.035805 train-accuracy:0.860636 valid-loss:1.063734 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:32.9159 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606261\n",
      "[INFO 24-02-22 06:53:32.9159 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:53:32.9162 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.606261 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:32.9168 UTC hyperparameters_optimizer.cc:582] [672/1100] Score: -0.606261 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:32.9177 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:32.9178 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:32.9180 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:32.9657 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615179\n",
      "[INFO 24-02-22 06:53:32.9658 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:53:32.9658 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.615179 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:32.9662 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:32.9662 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:32.9664 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:32.9687 UTC hyperparameters_optimizer.cc:582] [673/1100] Score: -0.615179 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:32.9828 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.074048 train-accuracy:0.826406 valid-loss:1.038353 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:32.9964 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.053003 train-accuracy:0.836186 valid-loss:1.072484 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:33.4245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605468\n",
      "[INFO 24-02-22 06:53:33.4245 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:53:33.4247 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.605468 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:33.4251 UTC hyperparameters_optimizer.cc:582] [674/1100] Score: -0.605468 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:33.4259 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:33.4262 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:33.4267 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:33.4277 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162135 train-accuracy:0.784841 valid-loss:1.132935 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:33.4922 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666531\n",
      "[INFO 24-02-22 06:53:33.4922 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:53:33.4922 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.666531 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:33.4925 UTC hyperparameters_optimizer.cc:582] [675/1100] Score: -0.666531 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:33.4928 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:33.4929 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:33.4934 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:33.5528 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314916 train-accuracy:0.612469 valid-loss:1.274435 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:33.7319 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63895\n",
      "[INFO 24-02-22 06:53:33.7320 UTC gradient_boosted_trees.cc:271] Truncates the model to 160 tree(s) i.e. 160  iteration(s).\n",
      "[INFO 24-02-22 06:53:33.7323 UTC gradient_boosted_trees.cc:334] Final model num-trees:160 valid-loss:0.638950 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:33.7342 UTC hyperparameters_optimizer.cc:582] [676/1100] Score: -0.63895 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:33.7350 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:33.7350 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:33.7374 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:33.7424 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316519 train-accuracy:0.612469 valid-loss:1.274703 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:33.9224 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65512\n",
      "[INFO 24-02-22 06:53:33.9224 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:53:33.9227 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.655120 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:33.9229 UTC hyperparameters_optimizer.cc:582] [677/1100] Score: -0.65512 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:33.9236 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:33.9236 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:33.9239 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:33.9306 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277593 train-accuracy:0.612469 valid-loss:1.239730 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:34.0196 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647038\n",
      "[INFO 24-02-22 06:53:34.0196 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.0198 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.647038 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:34.0201 UTC hyperparameters_optimizer.cc:582] [678/1100] Score: -0.647038 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:34.0207 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.0207 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.0211 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.0883 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223508 train-accuracy:0.612469 valid-loss:1.190535 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:34.1626 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650948\n",
      "[INFO 24-02-22 06:53:34.1632 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.1634 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.650948 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:34.1638 UTC hyperparameters_optimizer.cc:582] [679/1100] Score: -0.650948 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:34.1649 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.1649 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.1652 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.1776 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.997668 train-accuracy:0.858191 valid-loss:1.008580 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:34.3855 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648889\n",
      "[INFO 24-02-22 06:53:34.3856 UTC gradient_boosted_trees.cc:271] Truncates the model to 175 tree(s) i.e. 175  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.3856 UTC gradient_boosted_trees.cc:334] Final model num-trees:175 valid-loss:0.648889 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:34.3859 UTC hyperparameters_optimizer.cc:582] [680/1100] Score: -0.648889 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:34.3862 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.3862 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.3865 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.4236 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.60759\n",
      "[INFO 24-02-22 06:53:34.4236 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.4241 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.607590 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:34.4246 UTC hyperparameters_optimizer.cc:582] [681/1100] Score: -0.60759 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:34.4260 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.4260 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.4263 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.4271 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.133567 train-accuracy:0.784841 valid-loss:1.096539 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:34.4580 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230722 train-accuracy:0.612469 valid-loss:1.199649 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:34.5055 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.587246\n",
      "[INFO 24-02-22 06:53:34.5055 UTC gradient_boosted_trees.cc:271] Truncates the model to 81 tree(s) i.e. 81  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.5056 UTC gradient_boosted_trees.cc:334] Final model num-trees:81 valid-loss:0.587246 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:34.5057 UTC hyperparameters_optimizer.cc:582] [682/1100] Score: -0.587246 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:34.5063 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.5064 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.5066 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.5123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.113037 train-accuracy:0.798289 valid-loss:1.062654 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:34.7324 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.587565\n",
      "[INFO 24-02-22 06:53:34.7324 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.7328 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.587565 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:34.7333 UTC hyperparameters_optimizer.cc:582] [683/1100] Score: -0.587565 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:34.7350 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.7352 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.7358 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.7425 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314693 train-accuracy:0.612469 valid-loss:1.275653 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:34.8332 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.581697\n",
      "[INFO 24-02-22 06:53:34.8332 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.8335 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.581697 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:34.8346 UTC hyperparameters_optimizer.cc:582] [684/1100] Score: -0.581697 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:34.8362 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.8362 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.8364 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.8811 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663598\n",
      "[INFO 24-02-22 06:53:34.8811 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.8818 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.663598 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:34.8873 UTC hyperparameters_optimizer.cc:582] [685/1100] Score: -0.663598 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:34.8895 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.8895 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.8910 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.8950 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.075703 train-accuracy:0.837408 valid-loss:1.051812 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:34.8968 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315462 train-accuracy:0.612469 valid-loss:1.273813 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:34.9731 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.592926\n",
      "[INFO 24-02-22 06:53:34.9756 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:53:34.9758 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.592926 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:34.9760 UTC hyperparameters_optimizer.cc:582] [686/1100] Score: -0.592926 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:34.9765 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:34.9765 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:34.9768 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:34.9855 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112110 train-accuracy:0.781174 valid-loss:1.090371 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:35.2389 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.600592\n",
      "[INFO 24-02-22 06:53:35.2390 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:35.2397 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:35.2397 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.600592 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:35.2401 UTC hyperparameters_optimizer.cc:582] [687/1100] Score: -0.600592 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:35.2414 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:35.2415 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:35.2419 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:35.2641 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.251857 train-accuracy:0.612469 valid-loss:1.196193 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:35.3188 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.460411 train-accuracy:0.936430 valid-loss:0.622551 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:35.3188 UTC gradient_boosted_trees.cc:271] Truncates the model to 297 tree(s) i.e. 297  iteration(s).\n",
      "[INFO 24-02-22 06:53:35.3188 UTC gradient_boosted_trees.cc:334] Final model num-trees:297 valid-loss:0.622084 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:35.3205 UTC hyperparameters_optimizer.cc:582] [688/1100] Score: -0.622084 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:35.3224 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:35.3224 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:35.3231 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:35.3330 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279298 train-accuracy:0.612469 valid-loss:1.245202 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:35.4991 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.484448\n",
      "[INFO 24-02-22 06:53:35.4991 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:53:35.4993 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.484448 valid-accuracy:0.904110\n",
      "[[INFO 24-02-22 06:53:35.5010 UTC hyperparameters_optimizer.cc:582] [689/1100] Score: -0.484448 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:53:35.5013 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:35.5014 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:35.5017 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:35.5207 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.129378 train-accuracy:0.794621 valid-loss:1.096994 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:35.7888 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650069\n",
      "[INFO 24-02-22 06:53:35.7888 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 06:53:35.7891 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.650069 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:35.7902 UTC hyperparameters_optimizer.cc:582] [690/1100] Score: -0.650069 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:35.7930 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:35.7930 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:35.7933 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:35.7962 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233331 train-accuracy:0.612469 valid-loss:1.190995 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:36.0580 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.628294\n",
      "[INFO 24-02-22 06:53:36.0580 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.0582 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.628294 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:36.0590 UTC hyperparameters_optimizer.cc:582] [691/1100] Score: -0.628294 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:36.0596 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.0596 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.0600 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.0642 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313667 train-accuracy:0.612469 valid-loss:1.272007 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:36.0655 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.586584\n",
      "[INFO 24-02-22 06:53:36.0655 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.0658 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.586584 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:36.0667 UTC hyperparameters_optimizer.cc:582] [692/1100] Score: -0.586584 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:36.0683 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.0683 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.0686 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.0861 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063475 train-accuracy:0.809291 valid-loss:1.047459 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:36.3666 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635929\n",
      "[INFO 24-02-22 06:53:36.3666 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.3667 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.635929 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:36.3671 UTC hyperparameters_optimizer.cc:582] [693/1100] Score: -0.635929 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:36.3677 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.3677 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.3680 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.4330 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281608 train-accuracy:0.612469 valid-loss:1.245347 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:36.4605 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.604459\n",
      "[INFO 24-02-22 06:53:36.4605 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.4611 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.604459 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:36.4628 UTC hyperparameters_optimizer.cc:582] [694/1100] Score: -0.604459 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:36.4658 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.4658 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.4662 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.4916 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177571 train-accuracy:0.612469 valid-loss:1.157053 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:36.5813 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639342\n",
      "[INFO 24-02-22 06:53:36.5813 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.5816 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.639342 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:36.5860 UTC hyperparameters_optimizer.cc:582] [695/1100] Score: -0.639342 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:36.5897 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.5898 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.5900 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.6027 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162201 train-accuracy:0.612469 valid-loss:1.146697 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:36.6159 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.754995\n",
      "[INFO 24-02-22 06:53:36.6159 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.6178 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.754995 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:36.6184 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648496\n",
      "[INFO 24-02-22 06:53:36.6185 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.6195 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.648496 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:36.6232 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.6232 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.6235 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.6236 UTC hyperparameters_optimizer.cc:582] [696/1100] Score: -0.648496 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:36.6287 UTC hyperparameters_optimizer.cc:582] [697/1100] Score: -0.754995 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:36.6315 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285187 train-accuracy:0.612469 valid-loss:1.249642 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:36.6496 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.6496 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.6498 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.6940 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.194038 train-accuracy:0.612469 valid-loss:1.147727 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:36.7557 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603171\n",
      "[INFO 24-02-22 06:53:36.7558 UTC gradient_boosted_trees.cc:271] Truncates the model to 152 tree(s) i.e. 152  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.7560 UTC gradient_boosted_trees.cc:334] Final model num-trees:152 valid-loss:0.603171 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:36.7572 UTC hyperparameters_optimizer.cc:582] [698/1100] Score: -0.603171 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:36.7609 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.7610 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.7612 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.8116 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132506 train-accuracy:0.817848 valid-loss:1.101844 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:36.8185 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687956\n",
      "[INFO 24-02-22 06:53:36.8185 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.8190 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.687956 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:36.8194 UTC hyperparameters_optimizer.cc:582] [699/1100] Score: -0.687956 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:36.8216 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.8216 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.8218 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.8418 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224512 train-accuracy:0.612469 valid-loss:1.192618 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:36.9896 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.464414 train-accuracy:0.920538 valid-loss:0.620277 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:36.9896 UTC gradient_boosted_trees.cc:271] Truncates the model to 286 tree(s) i.e. 286  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.9897 UTC gradient_boosted_trees.cc:334] Final model num-trees:286 valid-loss:0.619008 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:36.9911 UTC hyperparameters_optimizer.cc:582] [700/1100] Score: -0.619008 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:36.9914 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.9914 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.9922 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.550717 train-accuracy:0.909535 valid-loss:0.639221 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:36.9922 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:53:36.9922 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.638575 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:36.9926 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.9927 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:36.9927 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:36.9928 UTC hyperparameters_optimizer.cc:582] [701/1100] Score: -0.638575 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:36.9929 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:36.9962 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.049649 train-accuracy:0.814181 valid-loss:1.020077 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:37.0016 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313007 train-accuracy:0.612469 valid-loss:1.272076 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:37.0768 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654559\n",
      "[INFO 24-02-22 06:53:37.0768 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:53:37.0770 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.654559 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:37.0772 UTC hyperparameters_optimizer.cc:582] [702/1100] Score: -0.654559 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:37.0777 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:37.0778 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:37.0780 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:37.0843 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.318979 train-accuracy:0.612469 valid-loss:1.275888 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:37.1091 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.771647\n",
      "[INFO 24-02-22 06:53:37.1091 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:37.1093 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.771647 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:37.1096 UTC hyperparameters_optimizer.cc:582] [703/1100] Score: -0.771647 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:37.1101 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:37.1101 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:37.1119 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:37.1280 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155148 train-accuracy:0.721271 valid-loss:1.126625 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:37.4688 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615858\n",
      "[INFO 24-02-22 06:53:37.4688 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:37.4689 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.615858 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 06:53:37.4696 UTC hyperparameters_optimizer.cc:582] [704/1100] Score: -0.615858 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 06:53:37.4700 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:37.4700 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:37.4705 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:37.4728 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112022 train-accuracy:0.781174 valid-loss:1.108304 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:37.5685 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651664\n",
      "[INFO 24-02-22 06:53:37.5686 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:37.5688 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:37.5688 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.651664 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:37.5695 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:37.5696 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:37.5698 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:37.5720 UTC hyperparameters_optimizer.cc:582] [705/1100] Score: -0.651664 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:37.5735 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.099332 train-accuracy:0.794621 valid-loss:1.095712 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:37.7108 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652192\n",
      "[INFO 24-02-22 06:53:37.7109 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:53:37.7111 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.652192 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:37.7114 UTC hyperparameters_optimizer.cc:582] [706/1100] Score: -0.652192 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:37.7134 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:37.7134 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:37.7136 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:37.7632 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315024 train-accuracy:0.612469 valid-loss:1.274848 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:37.8419 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.519662\n",
      "[INFO 24-02-22 06:53:37.8420 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:53:37.8421 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.519662 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:53:37.8427 UTC hyperparameters_optimizer.cc:582] [707/1100] Score: -0.519662 / [INFO 24-02-22 06:53:37.8429 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:37.8429 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:37.8431 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "-0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:37.8532 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.033787 train-accuracy:0.876528 valid-loss:1.069629 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:38.2124 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609388\n",
      "[INFO 24-02-22 06:53:38.2125 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:38.2127 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.609388 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:38.2138 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:38.2138 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:38.2141 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:38.2174 UTC hyperparameters_optimizer.cc:582] [708/1100] Score: -0.609388 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:38.2240 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085217 train-accuracy:0.814181 valid-loss:1.075628 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:38.3127 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633525\n",
      "[INFO 24-02-22 06:53:38.3127 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:53:38.3137 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.633525 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:38.3143 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:38.3143 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:38.3145 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:38.3153 UTC hyperparameters_optimizer.cc:582] [709/1100] Score: -0.633525 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:38.3292 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209847 train-accuracy:0.612469 valid-loss:1.175046 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:38.4111 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.793429\n",
      "[INFO 24-02-22 06:53:38.4111 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:38.4125 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:38.4126 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.793429 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:38.4134 UTC hyperparameters_optimizer.cc:582] [710/1100] Score: -0.793429 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:38.4160 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:38.4160 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:38.4163 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:38.4234 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.575933\n",
      "[INFO 24-02-22 06:53:38.4235 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:53:38.4237 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.575933 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:38.4246 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:38.4246 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:38.4247 UTC hyperparameters_optimizer.cc:582] [711/1100] Score: -0.575933 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:38.4320 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:38.4349 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.145935 train-accuracy:0.765281 valid-loss:1.108231 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:38.4392 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221794 train-accuracy:0.612469 valid-loss:1.196795 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:38.6529 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.729906\n",
      "[INFO 24-02-22 06:53:38.6530 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:38.6532 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:38.6532 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.729906 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:38.6540 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:38.6540 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:38.6542 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:38.6553 UTC hyperparameters_optimizer.cc:582] [712/1100] Score: -0.729906 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:38.6600 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293597 train-accuracy:0.612469 valid-loss:1.246907 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:38.7127 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653208\n",
      "[INFO 24-02-22 06:53:38.7127 UTC gradient_boosted_trees.cc:271] Truncates the model to 162 tree(s) i.e. 162  iteration(s).\n",
      "[INFO 24-02-22 06:53:38.7130 UTC gradient_boosted_trees.cc:334] Final model num-trees:162 valid-loss:0.653208 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:38.7144 UTC hyperparameters_optimizer.cc:582] [713/1100] Score: -0.653208 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:38.7182 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:38.7184 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:38.7190 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:38.7259 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646601\n",
      "[INFO 24-02-22 06:53:38.7259 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:38.7261 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.646601 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:38.7267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:38.7267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:38.7269 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:38.7287 UTC hyperparameters_optimizer.cc:582] [714/1100] Score: -0.646601 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:38.7292 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316371 train-accuracy:0.612469 valid-loss:1.274907 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:38.7587 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651407\n",
      "[INFO 24-02-22 06:53:38.7609 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:53:38.7612 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.651407 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:38.7616 UTC hyperparameters_optimizer.cc:582] [715/1100] Score: -0.651407 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:38.7623 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:38.7623 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:38.7628 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:38.7741 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295176 train-accuracy:0.612469 valid-loss:1.249367 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:38.8394 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.140515 train-accuracy:0.742054 valid-loss:1.121688 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:39.0522 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624585\n",
      "[INFO 24-02-22 06:53:39.0525 UTC gradient_boosted_trees.cc:271] Truncates the model to 174 tree(s) i.e. 174  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.0528 UTC gradient_boosted_trees.cc:334] Final model num-trees:174 valid-loss:0.624585 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:39.0533 UTC hyperparameters_optimizer.cc:582] [716/1100] Score: -0.624585 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:39.0539 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.0541 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.0544 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.1366 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.080256 train-accuracy:0.806846 valid-loss:1.048666 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:39.1635 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660907\n",
      "[INFO 24-02-22 06:53:39.1635 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.1640 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.660907 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:39.1650 UTC hyperparameters_optimizer.cc:582] [717/1100] Score: -0.660907 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:39.1658 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.1658 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.1665 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.1735 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.095518 train-accuracy:0.828851 valid-loss:1.051927 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:39.2343 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.694994 train-accuracy:0.856968 valid-loss:0.682201 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:39.2343 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.2343 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.682098 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:39.2347 UTC hyperparameters_optimizer.cc:582] [718/1100] Score: -0.682098 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:39.2356 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.2357 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.2359 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.2491 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158960 train-accuracy:0.777506 valid-loss:1.086527 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:39.2660 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646656\n",
      "[INFO 24-02-22 06:53:39.2660 UTC gradient_boosted_trees.cc:271] Truncates the model to 197 tree(s) i.e. 197  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.2665 UTC gradient_boosted_trees.cc:334] Final model num-trees:197 valid-loss:0.646656 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:39.2695 UTC hyperparameters_optimizer.cc:582] [719/1100] Score: -0.646656 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:39.2770 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.2770 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.2772 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.2851 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.037454 train-accuracy:0.850856 valid-loss:1.017845 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:39.4242 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642331\n",
      "[INFO 24-02-22 06:53:39.4243 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.4246 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.642331 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:39.4265 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.4266 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.4268 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.4329 UTC hyperparameters_optimizer.cc:582] [720/1100] Score: -0.642331 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:39.4338 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.994195 train-accuracy:0.872861 valid-loss:0.984391 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:39.5365 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619145\n",
      "[INFO 24-02-22 06:53:39.5365 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.5368 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.619145 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:39.5374 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.5374 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.5376 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.5392 UTC hyperparameters_optimizer.cc:582] [721/1100] Score: -0.619145 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:39.5446 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.254899 train-accuracy:0.612469 valid-loss:1.200738 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:39.6054 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606001\n",
      "[INFO 24-02-22 06:53:39.6055 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.6061 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.606001 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:39.6066 UTC hyperparameters_optimizer.cc:582] [722/1100] Score: -0.606001 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:39.6101 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.6106 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.6109 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.6563 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690626\n",
      "[INFO 24-02-22 06:53:39.6563 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.6566 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.690626 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:39.6568 UTC hyperparameters_optimizer.cc:582] [723/1100] Score: -0.690626 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:39.6573 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.6573 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.6575 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.6628 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.098063 train-accuracy:0.820293 valid-loss:1.039031 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:39.6817 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094653 train-accuracy:0.792176 valid-loss:1.080388 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:39.8629 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625828\n",
      "[INFO 24-02-22 06:53:39.8629 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.8630 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.625828 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:39.8631 UTC hyperparameters_optimizer.cc:582] [724/1100] Score: -0.625828 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:39.8635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.8635 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.8637 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.8947 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.154414 train-accuracy:0.735941 valid-loss:1.108693 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:39.9001 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605913\n",
      "[INFO 24-02-22 06:53:39.9001 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.9004 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.605913 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:39.9008 UTC hyperparameters_optimizer.cc:582] [725/1100] Score: -0.605913 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:39.9014 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.9014 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.9018 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.9040 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621973\n",
      "[INFO 24-02-22 06:53:39.9040 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.9042 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.621973 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:39.9045 UTC hyperparameters_optimizer.cc:582] [726/1100] Score: -0.621973 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:39.9047 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.9047 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.9050 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.9052 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.613162\n",
      "[INFO 24-02-22 06:53:39.9052 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:53:39.9052 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.613162 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:39.9056 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:39.9056 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:39.9058 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:39.9086 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.042430 train-accuracy:0.841076 valid-loss:1.033871 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:39.9089 UTC hyperparameters_optimizer.cc:582] [727/1100] Score: -0.613162 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:39.9100 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.170045 train-accuracy:0.738386 valid-loss:1.127859 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:53:39.9510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314789 train-accuracy:0.612469 valid-loss:1.272296 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:40.0211 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.563055\n",
      "[INFO 24-02-22 06:53:40.0211 UTC gradient_boosted_trees.cc:271] Truncates the model to 96 tree(s) i.e. 96  iteration(s).\n",
      "[INFO 24-02-22 06:53:40.0212 UTC gradient_boosted_trees.cc:334] Final model num-trees:96 valid-loss:0.563055 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:40.0215 UTC hyperparameters_optimizer.cc:582] [728/1100] Score: -0.563055 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:40.0219 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:40.0219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:40.0223 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:40.0245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64303\n",
      "[INFO 24-02-22 06:53:40.0245 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:40.0247 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:40.0247 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.643030 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:40.0252 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:40.0252 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:40.0253 UTC hyperparameters_optimizer.cc:582] [729/1100] Score: -0.64303 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:40.0257 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:40.0281 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196667 train-accuracy:0.612469 valid-loss:1.156902 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:40.0932 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.047226 train-accuracy:0.847188 valid-loss:0.998447 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:40.3099 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.507723\n",
      "[INFO 24-02-22 06:53:40.3099 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:53:40.3102 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.507723 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:40.3108 UTC hyperparameters_optimizer.cc:582] [730/1100] Score: -0.507723 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:40.3126 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:40.3126 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:40.3136 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:40.3721 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.976846 train-accuracy:0.878973 valid-loss:1.024438 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:40.5539 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659862\n",
      "[INFO 24-02-22 06:53:40.5539 UTC gradient_boosted_trees.cc:271] Truncates the model to 197 tree(s) i.e. 197  iteration(s).\n",
      "[INFO 24-02-22 06:53:40.5540 UTC gradient_boosted_trees.cc:334] Final model num-trees:197 valid-loss:0.659862 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:40.5542 UTC hyperparameters_optimizer.cc:582] [731/1100] Score: -0.659862 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:40.5553 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:40.5553 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:40.5558 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:40.5583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.100664 train-accuracy:0.805623 valid-loss:1.036320 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:40.5739 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63759\n",
      "[INFO 24-02-22 06:53:40.5739 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:53:40.5740 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.637590 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:40.5742 UTC hyperparameters_optimizer.cc:582] [732/1100] Score: -0.63759 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:40.5745 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:40.5745 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:40.5749 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:40.5936 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.127229 train-accuracy:0.789731 valid-loss:1.088366 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:40.7658 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.608549\n",
      "[INFO 24-02-22 06:53:40.7658 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:53:40.7660 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.608549 valid-accuracy:0.904110\n",
      "[[INFO 24-02-22 06:53:40.7670 UTC hyperparameters_optimizer.cc:582] [733/1100] Score: -0.608549 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "INFO 24-02-22 06:53:40.7675 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:40.7675 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:40.7680 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:40.7755 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314882 train-accuracy:0.612469 valid-loss:1.273821 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:41.1601 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.568189 train-accuracy:0.902200 valid-loss:0.662081 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:41.1602 UTC gradient_boosted_trees.cc:271] Truncates the model to 281 tree(s) i.e. 281  iteration(s).\n",
      "[INFO 24-02-22 06:53:41.1602 UTC gradient_boosted_trees.cc:334] Final model num-trees:281 valid-loss:0.661164 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:41.1610 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:41.1610 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-22 06:53:41.1614 UTC hyperparameters_optimizer.cc:582] [734/1100] Score: INFO 24-02-22 06:53:41.1614 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "-0.661164 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:41.1727 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.168255 train-accuracy:0.612469 valid-loss:1.135866 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:41.3580 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627252\n",
      "[INFO 24-02-22 06:53:41.3580 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:53:41.3582 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.627252 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:41.3586 UTC hyperparameters_optimizer.cc:582] [735/1100] Score: -0.627252 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:41.3589 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:41.3589 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:41.3591 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:41.4321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219270 train-accuracy:0.612469 valid-loss:1.200473 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:41.6441 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660427\n",
      "[INFO 24-02-22 06:53:41.6441 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:53:41.6447 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.660427 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:41.6452 UTC hyperparameters_optimizer.cc:582] [736/1100] Score: -0.660427 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:41.6465 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:41.6465 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:41.6469 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:41.6506 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292695 train-accuracy:0.612469 valid-loss:1.247424 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:41.9182 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.583782 train-accuracy:0.891198 valid-loss:0.644029 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:41.9182 UTC gradient_boosted_trees.cc:271] Truncates the model to 293 tree(s) i.e. 293  iteration(s).\n",
      "[INFO 24-02-22 06:53:41.9182 UTC gradient_boosted_trees.cc:334] Final model num-trees:293 valid-loss:0.641974 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:41.9189 UTC hyperparameters_optimizer.cc:582] [737/1100] Score: -0.641974 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:41.9205 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:41.9205 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:41.9214 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.0256 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.574737\n",
      "[INFO 24-02-22 06:53:42.0257 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.0257 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.574737 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:42.0259 UTC hyperparameters_optimizer.cc:582] [738/1100] Score: -0.574737 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:42.0264 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.0264 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.0266 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.0270 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.970372 train-accuracy:0.872861 valid-loss:0.976041 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:42.0308 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285813 train-accuracy:0.612469 valid-loss:1.244738 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:42.4012 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63079\n",
      "[INFO 24-02-22 06:53:42.4012 UTC gradient_boosted_trees.cc:271] Truncates the model to 175 tree(s) i.e. 175  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.4013 UTC gradient_boosted_trees.cc:334] Final model num-trees:175 valid-loss:0.630790 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:42.4017 UTC hyperparameters_optimizer.cc:582] [739/1100] Score: -0.63079 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:42.4027 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.4030 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.4033 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.4698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.149263 train-accuracy:0.784841 valid-loss:1.116701 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:42.6058 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634525\n",
      "[INFO 24-02-22 06:53:42.6058 UTC gradient_boosted_trees.cc:271] Truncates the model to 222 tree(s) i.e. 222  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.6060 UTC gradient_boosted_trees.cc:334] Final model num-trees:222 valid-loss:0.634525 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:42.6077 UTC hyperparameters_optimizer.cc:582] [740/1100] Score: -0.634525 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:42.6115 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.6118 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.6129 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.6172 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.126426 train-accuracy:0.772616 valid-loss:1.115609 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:53:42.6880 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663994\n",
      "[INFO 24-02-22 06:53:42.6881 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.6920 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.663994 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:42.6936 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.6936 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.6938 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.6954 UTC hyperparameters_optimizer.cc:582] [741/1100] Score: -0.663994 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:42.7009 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.560613\n",
      "[INFO 24-02-22 06:53:42.7011 UTC gradient_boosted_trees.cc:271] Truncates the model to 175 tree(s) i.e. 175  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.7014 UTC gradient_boosted_trees.cc:334] Final model num-trees:175 valid-loss:0.560613 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:42.7039 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.7039 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.7041 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.7048 UTC hyperparameters_optimizer.cc:582] [742/1100] Score: -0.560613 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:42.7086 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225888 train-accuracy:0.612469 valid-loss:1.193261 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:42.7136 UTC gradient_boosted_trees.cc:1638] \tnum-trees:39 train-loss:0.137564 train-accuracy:0.979218 valid-loss:0.809889 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:42.7246 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157107 train-accuracy:0.720049 valid-loss:1.100047 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:53:42.7771 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.607983\n",
      "[INFO 24-02-22 06:53:42.7772 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.7772 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.607983 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:42.7774 UTC hyperparameters_optimizer.cc:582] [743/1100] Score: -0.607983 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:42.7778 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.7778 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.7780 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.8252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282300 train-accuracy:0.612469 valid-loss:1.241346 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:42.9333 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655537\n",
      "[INFO 24-02-22 06:53:42.9333 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.9337 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.655537 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:42.9350 UTC hyperparameters_optimizer.cc:582] [744/1100] Score: -0.655537 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:42.9368 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.9369 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.9371 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.9435 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.147348 train-accuracy:0.781174 valid-loss:1.117670 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:42.9779 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641305\n",
      "[INFO 24-02-22 06:53:42.9780 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.9785 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.641305 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:42.9793 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.9793 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.9795 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.9829 UTC hyperparameters_optimizer.cc:582] [745/1100] Score: -0.641305 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:42.9934 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634285\n",
      "[INFO 24-02-22 06:53:42.9935 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:53:42.9940 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.634285 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:42.9967 UTC hyperparameters_optimizer.cc:582] [746/1100] Score: -0.634285 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:42.9973 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:42.9973 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:42.9981 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:42.9994 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.211971 train-accuracy:0.612469 valid-loss:1.173057 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:43.0066 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314337 train-accuracy:0.612469 valid-loss:1.273757 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:43.0960 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609876\n",
      "[INFO 24-02-22 06:53:43.0960 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:43.0962 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.609876 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:43.0968 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:43.0969 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:43.0971 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:43.0987 UTC hyperparameters_optimizer.cc:582] [747/1100] Score: -0.609876 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:43.1110 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.163775 train-accuracy:0.757946 valid-loss:1.131190 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:43.1926 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.57833\n",
      "[INFO 24-02-22 06:53:43.1927 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 06:53:43.1927 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.578330 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:43.1936 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:43.1936 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:43.1938 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:43.1954 UTC hyperparameters_optimizer.cc:582] [748/1100] Score: -0.57833 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:43.2331 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.044076 train-accuracy:0.853301 valid-loss:1.077743 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:43.2837 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634077\n",
      "[INFO 24-02-22 06:53:43.2838 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:43.2855 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.634077 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:43.2859 UTC hyperparameters_optimizer.cc:582] [749/1100] Score: -0.634077 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:43.2885 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:43.2885 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:43.2891 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:43.2916 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313346 train-accuracy:0.612469 valid-loss:1.271491 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:43.4348 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.564254\n",
      "[INFO 24-02-22 06:53:43.4365 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:43.4368 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.564254 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:43.4371 UTC hyperparameters_optimizer.cc:582] [750/1100] Score: -0.564254 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:43.4375 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:43.4375 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:43.4378 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:43.4425 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.117439 train-accuracy:0.784841 valid-loss:1.086285 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:43.4531 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617401\n",
      "[INFO 24-02-22 06:53:43.4532 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:53:43.4534 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.617401 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:43.4537 UTC hyperparameters_optimizer.cc:582] [751/1100] Score: -0.617401 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:43.4544 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:43.4546 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:43.4551 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:43.4892 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.048815 train-accuracy:0.850856 valid-loss:1.067179 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:43.6125 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622671\n",
      "[INFO 24-02-22 06:53:43.6125 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:53:43.6127 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.622671 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:43.6130 UTC hyperparameters_optimizer.cc:582] [752/1100] Score: -0.622671 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:43.6134 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:43.6134 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:43.6136 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:43.6222 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.129262 train-accuracy:0.786064 valid-loss:1.115284 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:53:43.8143 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642788\n",
      "[INFO 24-02-22 06:53:43.8143 UTC gradient_boosted_trees.cc:271] Truncates the model to 161 tree(s) i.e. 161  iteration(s).\n",
      "[INFO 24-02-22 06:53:43.8146 UTC gradient_boosted_trees.cc:334] Final model num-trees:161 valid-loss:0.642788 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:43.8162 UTC hyperparameters_optimizer.cc:582] [753/1100] Score: -0.642788 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:43.8187 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:43.8190 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:43.8205 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:43.8347 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188583 train-accuracy:0.612469 valid-loss:1.196417 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:43.9952 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680656\n",
      "[INFO 24-02-22 06:53:43.9952 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:53:43.9956 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.680656 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:43.9976 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:43.9977 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:43.9979 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:43.9987 UTC hyperparameters_optimizer.cc:582] [754/1100] Score: -0.680656 / -0.484448 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:44.0152 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.065573 train-accuracy:0.811736 valid-loss:1.048512 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:44.0368 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.481402\n",
      "[INFO 24-02-22 06:53:44.0368 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 06:53:44.0369 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.481402 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:44.0378 UTC hyperparameters_optimizer.cc:582] [755/1100] Score: -0.481402 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:44.0381 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:44.0382 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:44.0384 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:44.0579 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.049399 train-accuracy:0.837408 valid-loss:1.060129 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:44.0833 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.604728\n",
      "[INFO 24-02-22 06:53:44.0840 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:53:44.0841 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.604728 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:44.0844 UTC hyperparameters_optimizer.cc:582] [756/1100] Score: -0.604728 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:44.0849 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:44.0849 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:44.0852 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:44.0935 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112256 train-accuracy:0.820293 valid-loss:1.055453 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:44.3437 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621926\n",
      "[INFO 24-02-22 06:53:44.3439 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:44.3441 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.621926 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:44.3445 UTC hyperparameters_optimizer.cc:582] [757/1100] Score: -0.621926 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:44.3449 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:44.3449 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:44.3451 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:44.4842 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.046537 train-accuracy:0.927873 valid-loss:1.127152 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:44.6812 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.737159\n",
      "[INFO 24-02-22 06:53:44.6812 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:53:44.6830 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.737159 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:44.6843 UTC hyperparameters_optimizer.cc:582] [758/1100] Score: -0.737159 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:44.6904 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:44.6904 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:44.6907 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:44.7035 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.161512 train-accuracy:0.748166 valid-loss:1.128068 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:53:44.7763 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.713302\n",
      "[INFO 24-02-22 06:53:44.7763 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:44.7765 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:44.7765 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.713302 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:44.7766 UTC hyperparameters_optimizer.cc:582] [759/1100] Score: -0.713302 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:44.7770 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:44.7770 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:44.7772 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:44.8049 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.105788 train-accuracy:0.815403 valid-loss:1.091226 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:44.8425 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.707871\n",
      "[INFO 24-02-22 06:53:44.8425 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:44.8429 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.707871 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:44.8441 UTC hyperparameters_optimizer.cc:582] [760/1100] Score: -0.707871 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:44.8443 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:44.8443 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:44.8448 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:44.8468 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188064 train-accuracy:0.612469 valid-loss:1.135420 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:44.8798 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.600541\n",
      "[INFO 24-02-22 06:53:44.8798 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:53:44.8854 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.600541 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:44.8860 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:44.8860 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:44.8862 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:44.8876 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.709763\n",
      "[INFO 24-02-22 06:53:44.8876 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:44.8880 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:44.8880 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.709763 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:44.8887 UTC hyperparameters_optimizer.cc:582] [761/1100] Score: -0.600541 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:44.8889 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:44.8889 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:44.8891 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:44.8920 UTC hyperparameters_optimizer.cc:582] [762/1100] Score: -0.709763 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:44.8986 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283646 train-accuracy:0.612469 valid-loss:1.245136 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:45.0114 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.116212 train-accuracy:0.808068 valid-loss:1.095286 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:45.0221 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718559\n",
      "[INFO 24-02-22 06:53:45.0232 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:45.0236 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:45.0237 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.718559 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:45.0240 UTC hyperparameters_optimizer.cc:582] [763/1100] Score: -0.718559 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:45.0250 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:45.0253 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:45.0276 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:45.0634 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142326 train-accuracy:0.612469 valid-loss:1.157488 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:45.1621 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.556556\n",
      "[INFO 24-02-22 06:53:45.1621 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:53:45.1623 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.556556 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:53:45.1629 UTC hyperparameters_optimizer.cc:582] [764/1100] Score: -0.556556 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:45.1634 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:45.1634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:45.1640 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:45.1877 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122066 train-accuracy:0.830073 valid-loss:1.082343 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:45.3810 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621274\n",
      "[INFO 24-02-22 06:53:45.3810 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 06:53:45.3813 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.621274 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:45.3822 UTC hyperparameters_optimizer.cc:582] [765/1100] Score: -0.621274 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:45.3841 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:45.3841 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:45.3843 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:45.3866 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.193585 train-accuracy:0.612469 valid-loss:1.158811 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:45.4410 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.59347\n",
      "[INFO 24-02-22 06:53:45.4411 UTC gradient_boosted_trees.cc:271] Truncates the model to 79 tree(s) i.e. 79  iteration(s).\n",
      "[INFO 24-02-22 06:53:45.4412 UTC gradient_boosted_trees.cc:334] Final model num-trees:79 valid-loss:0.593470 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:45.4416 UTC hyperparameters_optimizer.cc:582] [766/1100] Score: -0.59347 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:45.4424 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:45.4424 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:45.4426 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:45.4680 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316308 train-accuracy:0.612469 valid-loss:1.273666 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:45.7297 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644082\n",
      "[INFO 24-02-22 06:53:45.7298 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:53:45.7301 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.644082 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:45.7310 UTC hyperparameters_optimizer.cc:582] [767/1100] Score: -0.644082 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:45.7318 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:45.7318 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:45.7326 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:45.7350 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313155 train-accuracy:0.612469 valid-loss:1.273212 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:45.9401 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629357\n",
      "[INFO 24-02-22 06:53:45.9401 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:45.9405 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.629357 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:45.9410 UTC hyperparameters_optimizer.cc:582] [768/1100] Score: -0.629357 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:45.9419 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:45.9419 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:45.9421 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:45.9583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.253022 train-accuracy:0.612469 valid-loss:1.198023 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:46.2722 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660196\n",
      "[INFO 24-02-22 06:53:46.2723 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:46.2728 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:46.2728 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.660196 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:46.2732 UTC hyperparameters_optimizer.cc:582] [769/1100] Score: -0.660196 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:46.2746 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.2746 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.2749 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.2757 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223733 train-accuracy:0.612469 valid-loss:1.181954 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:46.3366 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675322\n",
      "[INFO 24-02-22 06:53:46.3366 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:53:46.3367 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.675322 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:46.3371 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.3371 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.3373 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.3387 UTC hyperparameters_optimizer.cc:582] [770/1100] Score: -0.675322 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:46.3459 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286793 train-accuracy:0.612469 valid-loss:1.245025 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:46.4011 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636812\n",
      "[INFO 24-02-22 06:53:46.4017 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:53:46.4019 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.636812 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:46.4021 UTC hyperparameters_optimizer.cc:582] [771/1100] Score: -0.636812 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:46.4058 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63367\n",
      "[INFO 24-02-22 06:53:46.4058 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:53:46.4065 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.633670 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:46.4072 UTC hyperparameters_optimizer.cc:582] [772/1100] Score: -0.63367 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:46.4080 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.4080 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.4082 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.4092 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.4092 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.4094 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.4169 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191116 train-accuracy:0.612469 valid-loss:1.170397 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:46.4210 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239453 train-accuracy:0.612469 valid-loss:1.197951 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:46.5295 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.414130 train-accuracy:0.931540 valid-loss:0.628455 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:46.5296 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:53:46.5296 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.628455 valid-accuracy:0.876712\n",
      "[INFO[INFO 24-02-22 06:53:46.5322 UTC hyperparameters_optimizer.cc:582] [773/1100] Score: -0.628455 / -0.481402 HParams:  24-02-22 06:53:46.5323 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.5324 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.5328 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.5349 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.126985 train-accuracy:0.777506 valid-loss:1.090583 valid-accuracy:0.780822\n",
      "fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:46.7171 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593571\n",
      "[INFO 24-02-22 06:53:46.7171 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:46.7173 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.593571 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:46.7177 UTC hyperparameters_optimizer.cc:582] [774/1100] Score: -0.593571 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:46.7220 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.7249 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.7252 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.7426 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.611397\n",
      "[INFO 24-02-22 06:53:46.7427 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:53:46.7428 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.611397 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:46.7432 UTC hyperparameters_optimizer.cc:582] [775/1100] Score: -0.611397 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:46.7440 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.7443 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.7445 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.7458 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209343 train-accuracy:0.612469 valid-loss:1.165134 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:46.8301 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66533\n",
      "[INFO 24-02-22 06:53:46.8302 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:53:46.8303 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.665330 valid-accuracy:0.849315\n",
      "[[INFO 24-02-22 06:53:46.8320 UTC hyperparameters_optimizer.cc:582] [776/1100] Score: -0.66533 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:53:46.8325 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.8326 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.8332 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.8355 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287274 train-accuracy:0.612469 valid-loss:1.244507 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:46.9017 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639266\n",
      "[INFO 24-02-22 06:53:46.9022 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:53:46.9023 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.639266 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:46.9029 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:46.9029 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:46.9031 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:46.9057 UTC hyperparameters_optimizer.cc:582] [777/1100] Score: -0.639266 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:46.9141 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.973034 train-accuracy:0.929095 valid-loss:1.054566 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:46.9611 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.110726 train-accuracy:0.777506 valid-loss:1.082093 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:47.1756 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66237\n",
      "[INFO 24-02-22 06:53:47.1756 UTC gradient_boosted_trees.cc:271] Truncates the model to 102 tree(s) i.e. 102  iteration(s).\n",
      "[INFO 24-02-22 06:53:47.1757 UTC gradient_boosted_trees.cc:334] Final model num-trees:102 valid-loss:0.662370 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:47.1767 UTC hyperparameters_optimizer.cc:582] [778/1100] Score: -0.66237 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:47.1782 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:47.1782 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:47.1784 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:47.1848 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.193629 train-accuracy:0.612469 valid-loss:1.164094 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:47.1994 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648728\n",
      "[INFO 24-02-22 06:53:47.1994 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:53:47.1997 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.648728 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:47.2004 UTC hyperparameters_optimizer.cc:582] [779/1100] Score: -0.648728 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:47.2009 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:47.2009 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:47.2016 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:47.2270 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.074274 train-accuracy:0.827628 valid-loss:1.075119 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:47.2310 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599979\n",
      "[INFO 24-02-22 06:53:47.2310 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:53:47.2312 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.599979 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:47.2319 UTC hyperparameters_optimizer.cc:582] [780/1100] Score: -0.599979 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:47.2327 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:47.2328 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:47.2332 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:47.2843 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230716 train-accuracy:0.612469 valid-loss:1.185492 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:47.5348 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.578492\n",
      "[INFO 24-02-22 06:53:47.5349 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:47.5352 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.578492 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:53:47.5355 UTC hyperparameters_optimizer.cc:582] [781/1100] Score: -0.578492 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:47.5365 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:47.5367 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:47.5370 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:47.5431 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.044466 train-accuracy:0.856968 valid-loss:1.006910 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:47.6768 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.696114\n",
      "[INFO 24-02-22 06:53:47.6769 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:53:47.6769 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.696114 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:47.6771 UTC hyperparameters_optimizer.cc:582] [782/1100] Score: -0.696114 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:47.6773 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:47.6774 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:47.6776 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:47.7151 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142326 train-accuracy:0.612469 valid-loss:1.157488 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:47.7960 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630018\n",
      "[INFO 24-02-22 06:53:47.7960 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:47.7962 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:47.7962 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.630018 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:47.7969 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:47.7969 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:47.7971 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:47.7987 UTC hyperparameters_optimizer.cc:582] [783/1100] Score: -0.630018 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:47.7996 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.199500 train-accuracy:0.612469 valid-loss:1.167000 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:48.0184 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65184\n",
      "[INFO 24-02-22 06:53:48.0187 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 06:53:48.0189 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.651840 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:48.0194 UTC hyperparameters_optimizer.cc:582] [784/1100] Score: -0.65184 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:48.0226 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:48.0236 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:48.0240 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:48.0521 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281222 train-accuracy:0.612469 valid-loss:1.244165 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:48.2384 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.561321\n",
      "[INFO 24-02-22 06:53:48.2385 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:53:48.2385 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.561321 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:48.2390 UTC hyperparameters_optimizer.cc:582] [785/1100] Score: -0.561321 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:48.2398 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:48.2398 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:48.2400 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:48.2711 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122066 train-accuracy:0.830073 valid-loss:1.082343 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:48.2948 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624857\n",
      "[INFO 24-02-22 06:53:48.2948 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:48.2951 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:48.2951 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.624857 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:48.2955 UTC hyperparameters_optimizer.cc:582] [786/1100] Score: -0.624857 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:48.2960 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:48.2960 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:48.2962 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:48.2999 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.628146\n",
      "[INFO 24-02-22 06:53:48.3001 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:48.3004 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.628146 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:48.3009 UTC hyperparameters_optimizer.cc:582] [787/1100] Score: -0.628146 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:48.3015 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:48.3015 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:48.3020 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:48.3043 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155086 train-accuracy:0.784841 valid-loss:1.099971 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:48.3423 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159026 train-accuracy:0.803178 valid-loss:1.098197 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:48.4984 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617147\n",
      "[INFO 24-02-22 06:53:48.4998 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:53:48.4999 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.617147 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:48.5000 UTC hyperparameters_optimizer.cc:582] [788/1100] Score: -0.617147 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:48.5002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:48.5002 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:48.5005 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:48.5053 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.161500 train-accuracy:0.784841 valid-loss:1.111905 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:48.6072 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.71716\n",
      "[INFO 24-02-22 06:53:48.6072 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:53:48.6087 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.717160 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:48.6174 UTC hyperparameters_optimizer.cc:582] [789/1100] Score: -0.71716 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:48.6256 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:48.6260 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:48.6266 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:48.6539 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201481 train-accuracy:0.612469 valid-loss:1.143493 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:48.8404 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61797\n",
      "[INFO 24-02-22 06:53:48.8404 UTC gradient_boosted_trees.cc:271] Truncates the model to 78 tree(s) i.e. 78  iteration(s).\n",
      "[INFO 24-02-22 06:53:48.8405 UTC gradient_boosted_trees.cc:334] Final model num-trees:78 valid-loss:0.617970 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:48.8406 UTC hyperparameters_optimizer.cc:582] [790/1100] Score: -0.61797 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:48.8412 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:48.8412 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:48.8415 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:48.8681 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63367\n",
      "[INFO 24-02-22 06:53:48.8682 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:53:48.8690 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.633670 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:48.8696 UTC hyperparameters_optimizer.cc:582] [791/1100] Score: -0.63367 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:48.8710 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:48.8710 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:48.8712 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:48.9491 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207449 train-accuracy:0.612469 valid-loss:1.176663 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:49.0111 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081228 train-accuracy:0.801956 valid-loss:1.057752 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:49.3292 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.618998\n",
      "[INFO 24-02-22 06:53:49.3293 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:53:49.3293 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.618998 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:49.3299 UTC hyperparameters_optimizer.cc:582] [792/1100] Score: -0.618998 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:49.3303 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:49.3303 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:49.3309 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:49.3933 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278389 train-accuracy:0.612469 valid-loss:1.236287 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:49.7619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636812\n",
      "[INFO 24-02-22 06:53:49.7620 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:53:49.7620 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.636812 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:49.7622 UTC hyperparameters_optimizer.cc:582] [793/1100] Score: -0.636812 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:49.7625 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:49.7626 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:49.7629 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:49.7917 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096192 train-accuracy:0.783619 valid-loss:1.058059 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:49.8673 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650378\n",
      "[INFO 24-02-22 06:53:49.8674 UTC gradient_boosted_trees.cc:271] Truncates the model to 242 tree(s) i.e. 242  iteration(s).\n",
      "[INFO 24-02-22 06:53:49.8675 UTC gradient_boosted_trees.cc:334] Final model num-trees:242 valid-loss:0.650378 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:49.8701 UTC hyperparameters_optimizer.cc:582] [794/1100] Score: -0.650378 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:49.8706 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:49.8707 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:49.8717 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:49.8908 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.220295 train-accuracy:0.612469 valid-loss:1.173790 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:49.9324 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640209\n",
      "[INFO 24-02-22 06:53:49.9324 UTC gradient_boosted_trees.cc:271] Truncates the model to 195 tree(s) i.e. 195  iteration(s).\n",
      "[INFO 24-02-22 06:53:49.9327 UTC gradient_boosted_trees.cc:334] Final model num-trees:195 valid-loss:0.640209 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:49.9350 UTC hyperparameters_optimizer.cc:582] [795/1100] Score: -0.640209 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:49.9357 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:49.9357 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:49.9376 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:49.9632 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231953 train-accuracy:0.612469 valid-loss:1.190616 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:50.0961 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63498\n",
      "[INFO 24-02-22 06:53:50.0965 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:53:50.0965 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.634980 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:50.0967 UTC hyperparameters_optimizer.cc:582] [796/1100] Score: -0.63498 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:50.0970 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:50.0970 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:50.0973 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:50.1177 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.105533 train-accuracy:0.831296 valid-loss:1.073685 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:50.1521 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634641\n",
      "[INFO 24-02-22 06:53:50.1538 UTC gradient_boosted_trees.cc:271] Truncates the model to 221 tree(s) i.e. 221  iteration(s).\n",
      "[INFO 24-02-22 06:53:50.1539 UTC gradient_boosted_trees.cc:334] Final model num-trees:221 valid-loss:0.634641 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:50.1547 UTC hyperparameters_optimizer.cc:582] [797/1100] Score: -0.634641 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:50.1552 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:50.1552 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:50.1593 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:50.1659 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092682 train-accuracy:0.805623 valid-loss:1.079956 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:53:50.3070 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647896\n",
      "[INFO 24-02-22 06:53:50.3071 UTC gradient_boosted_trees.cc:271] Truncates the model to 180 tree(s) i.e. 180  iteration(s).\n",
      "[INFO 24-02-22 06:53:50.3072 UTC gradient_boosted_trees.cc:334] Final model num-trees:180 valid-loss:0.647896 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:50.3084 UTC hyperparameters_optimizer.cc:582] [798/1100] Score: -0.647896 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:50.3110 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:50.3113 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:50.3118 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:50.3300 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079674 train-accuracy:0.819071 valid-loss:1.037961 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:50.4157 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.752259\n",
      "[INFO 24-02-22 06:53:50.4158 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:50.4169 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.752259 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:50.4203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651699\n",
      "[INFO 24-02-22 06:53:50.4203 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:53:50.4204 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:50.4204 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:50.4205 UTC hyperparameters_optimizer.cc:582] [799/1100] Score: [INFO 24-02-22 06:53:50.4205 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.651699 valid-accuracy:0.835616\n",
      "-0.752259 / -0.481402 HParams: [INFO 24-02-22 06:53:50.4210 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[[INFO 24-02-22 06:53:50.4231 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:50.4231 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:50.4233 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "INFO 24-02-22 06:53:50.4281 UTC hyperparameters_optimizer.cc:582] [800/1100] Score: -0.651699 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:50.4373 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314343 train-accuracy:0.612469 valid-loss:1.273113 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:50.4390 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153955 train-accuracy:0.788509 valid-loss:1.114175 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:50.5055 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6311\n",
      "[INFO 24-02-22 06:53:50.5055 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:53:50.5057 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.631100 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:50.5063 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:50.5063 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:50.5066 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:50.5087 UTC hyperparameters_optimizer.cc:582] [801/1100] Score: -0.6311 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:50.5452 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231719 train-accuracy:0.612469 valid-loss:1.201101 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:50.6640 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603324\n",
      "[INFO 24-02-22 06:53:50.6640 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:53:50.6641 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.603324 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:50.6644 UTC hyperparameters_optimizer.cc:582] [802/1100] Score: -0.603324 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:50.6659 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:50.6659 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:50.6661 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:50.6707 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317094 train-accuracy:0.612469 valid-loss:1.275107 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:50.8403 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643403\n",
      "[INFO 24-02-22 06:53:50.8404 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:53:50.8407 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.643403 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:50.8416 UTC hyperparameters_optimizer.cc:582] [803/1100] Score: -0.643403 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:50.8435 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:50.8435 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:50.8438 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:50.8943 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311294 train-accuracy:0.612469 valid-loss:1.271434 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:51.2110 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646431\n",
      "[INFO 24-02-22 06:53:51.2110 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.2113 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.646431 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:51.2118 UTC hyperparameters_optimizer.cc:582] [804/1100] Score: -0.646431 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:51.2130 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.2130 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.2134 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.2171 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.137229 train-accuracy:0.797066 valid-loss:1.096128 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:51.3010 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650588\n",
      "[INFO 24-02-22 06:53:51.3010 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.3012 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.650588 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:51.3016 UTC hyperparameters_optimizer.cc:582] [805/1100] Score: -0.650588 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:51.3023 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.3023 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.3026 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.3066 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317832 train-accuracy:0.612469 valid-loss:1.274955 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:51.3475 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.542954\n",
      "[INFO 24-02-22 06:53:51.3475 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.3476 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.542954 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:51.3481 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.3481 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.3483 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.3487 UTC hyperparameters_optimizer.cc:582] [806/1100] Score: -0.542954 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:51.3649 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648895\n",
      "[INFO 24-02-22 06:53:51.3649 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:51.3652 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:51.3652 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.648895 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:51.3657 UTC hyperparameters_optimizer.cc:582] [807/1100] Score: -0.648895 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:51.3661 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.3661 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.3663 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.3687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.143377 train-accuracy:0.799511 valid-loss:1.102658 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:51.3704 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114146 train-accuracy:0.812958 valid-loss:1.126336 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:51.5895 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.715122\n",
      "[INFO 24-02-22 06:53:51.5896 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:51.5901 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:51.5901 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.715122 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:51.5916 UTC hyperparameters_optimizer.cc:582] [808/1100] Score: -0.715122 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:51.5941 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.5941 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.5944 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.6166 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158351 train-accuracy:0.612469 valid-loss:1.151329 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:51.6732 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627934\n",
      "[INFO 24-02-22 06:53:51.6732 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.6733 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.627934 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:51.6738 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.6738 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.6740 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.6749 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.127794 train-accuracy:0.800734 valid-loss:1.089447 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:51.6753 UTC hyperparameters_optimizer.cc:582] [809/1100] Score: -0.627934 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:51.7616 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.543437\n",
      "[INFO 24-02-22 06:53:51.7620 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.7621 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.543437 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:51.7624 UTC hyperparameters_optimizer.cc:582] [810/1100] Score: -0.543437 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:51.7629 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.7629 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.7632 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.7923 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64926\n",
      "[INFO 24-02-22 06:53:51.7923 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.7926 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.649260 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:51.7932 UTC hyperparameters_optimizer.cc:582] [811/1100] Score: -0.64926 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:51.7980 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.7980 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.7983 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.8009 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229226 train-accuracy:0.612469 valid-loss:1.194590 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:51.8036 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622366\n",
      "[INFO 24-02-22 06:53:51.8037 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.8037 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.622366 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:51.8040 UTC hyperparameters_optimizer.cc:582] [812/1100] Score: -0.622366 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:51.8044 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.8044 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.8047 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.8108 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.091379 train-accuracy:0.817848 valid-loss:1.104392 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:51.8137 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288805 train-accuracy:0.612469 valid-loss:1.245840 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:51.8755 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.618929 train-accuracy:0.882641 valid-loss:0.614873 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:51.8755 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.8755 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.614506 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:51.8764 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.8764 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.8767 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.8787 UTC hyperparameters_optimizer.cc:582] [813/1100] Score: -0.614506 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:51.9043 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.051249 train-accuracy:0.830073 valid-loss:1.038299 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:51.9645 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.564959\n",
      "[INFO 24-02-22 06:53:51.9645 UTC gradient_boosted_trees.cc:271] Truncates the model to 56 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 24-02-22 06:53:51.9647 UTC gradient_boosted_trees.cc:334] Final model num-trees:56 valid-loss:0.564959 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:51.9652 UTC hyperparameters_optimizer.cc:582] [814/1100] Score: -0.564959 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:51.9673 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:51.9674 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:51.9676 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:51.9984 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222511 train-accuracy:0.612469 valid-loss:1.201512 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:52.0956 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632556\n",
      "[INFO 24-02-22 06:53:52.0956 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:53:52.0958 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.632556 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:52.0964 UTC hyperparameters_optimizer.cc:582] [815/1100] Score: -0.632556 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:52.0975 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:52.0975 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:52.0977 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:52.1086 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.271187 train-accuracy:0.612469 valid-loss:1.244514 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:52.2201 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675593\n",
      "[INFO 24-02-22 06:53:52.2202 UTC gradient_boosted_trees.cc:271] Truncates the model to 206 tree(s) i.e. 206  iteration(s).\n",
      "[INFO 24-02-22 06:53:52.2203 UTC gradient_boosted_trees.cc:334] Final model num-trees:206 valid-loss:0.675593 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:52.2209 UTC hyperparameters_optimizer.cc:582] [816/1100] Score: -0.675593 / -0.481402 HParams: [INFO 24-02-22 06:53:52.2210 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:52.2210 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:52.2221 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:52.2323 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311682 train-accuracy:0.612469 valid-loss:1.271323 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:52.5076 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.615041 train-accuracy:0.881418 valid-loss:0.646863 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:52.5077 UTC gradient_boosted_trees.cc:271] Truncates the model to 291 tree(s) i.e. 291  iteration(s).\n",
      "[INFO 24-02-22 06:53:52.5077 UTC gradient_boosted_trees.cc:334] Final model num-trees:291 valid-loss:0.646431 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:52.5085 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:52.5085 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:52.5087 UTC hyperparameters_optimizer.cc:582] [817/1100] Score: -0.646431 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:52.5102 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:52.5219 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221492 train-accuracy:0.612469 valid-loss:1.181412 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:52.6377 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658887\n",
      "[INFO 24-02-22 06:53:52.6381 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:52.6384 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.658887 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:52.6391 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:52.6391 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:52.6393 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:52.6426 UTC hyperparameters_optimizer.cc:582] [818/1100] Score: -0.658887 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:52.6983 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182410 train-accuracy:0.612469 valid-loss:1.140549 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:52.9488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646917\n",
      "[INFO 24-02-22 06:53:52.9488 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:53:52.9490 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.646917 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:52.9492 UTC hyperparameters_optimizer.cc:582] [819/1100] Score: -0.646917 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:52.9498 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:52.9498 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:52.9500 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:52.9536 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.049816 train-accuracy:0.838631 valid-loss:1.022028 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:53.0413 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6508\n",
      "[INFO 24-02-22 06:53:53.0413 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:53:53.0420 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.650800 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:53.0441 UTC hyperparameters_optimizer.cc:582] [820/1100] Score: -0.6508 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:53.0480 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.0482 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.0485 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.0647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.318866 train-accuracy:0.612469 valid-loss:1.276824 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:53.1601 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.554313\n",
      "[INFO 24-02-22 06:53:53.1602 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:53:53.1608 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.554313 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:53.1615 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.1615 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.1617 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.1653 UTC hyperparameters_optimizer.cc:582] [821/1100] Score: -0.554313 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:53.1717 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182265 train-accuracy:0.612469 valid-loss:1.149626 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:53.2556 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624079\n",
      "[INFO 24-02-22 06:53:53.2557 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:53.2562 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.624079 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:53.2579 UTC hyperparameters_optimizer.cc:582] [822/1100] Score: -0.624079 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:53.2606 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.2621 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.2628 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.2640 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.779099\n",
      "[INFO 24-02-22 06:53:53.2640 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:53.2656 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:53.2656 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.779099 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:53.2664 UTC hyperparameters_optimizer.cc:582] [823/1100] Score: -0.779099 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:53.2711 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.2712 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.2714 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.2865 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314013 train-accuracy:0.612469 valid-loss:1.273375 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:53.3769 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.106395 train-accuracy:0.779951 valid-loss:1.118670 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:53.4334 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683377\n",
      "[INFO 24-02-22 06:53:53.4334 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:53:53.4337 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.683377 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:53.4346 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.4347 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.4349 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.4354 UTC hyperparameters_optimizer.cc:582] [824/1100] Score: -0.683377 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:53.5064 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.57618\n",
      "[INFO 24-02-22 06:53:53.5064 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:53:53.5067 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.576180 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:53.5079 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.5079 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.5082 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.5121 UTC hyperparameters_optimizer.cc:582] [825/1100] Score: -0.57618 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:53.5213 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.169262 train-accuracy:0.789731 valid-loss:1.122037 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:53.5248 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280433 train-accuracy:0.612469 valid-loss:1.238499 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:53.8772 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.585286\n",
      "[INFO 24-02-22 06:53:53.8772 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:53:53.8775 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.585286 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:53:53.8780 UTC hyperparameters_optimizer.cc:582] [826/1100] Score: -0.585286 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:53.8786 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.8786 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.8788 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.8900 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153735 train-accuracy:0.781174 valid-loss:1.114274 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:53:53.9128 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665495\n",
      "[INFO 24-02-22 06:53:53.9128 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:53:53.9130 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.665495 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:53.9138 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.9138 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.9140 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.9153 UTC hyperparameters_optimizer.cc:582] [827/1100] Score: -0.665495 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:53.9364 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.70689\n",
      "[INFO 24-02-22 06:53:53.9364 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:53.9372 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:53.9373 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.706890 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:53.9383 UTC hyperparameters_optimizer.cc:582] [828/1100] Score: -0.70689 / -0.481402 HParams: [INFOfields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } } 24-02-22 06:53:53.9384 UTC \n",
      "gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.031773 train-accuracy:0.854523 valid-loss:1.007415 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:53.9401 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:53.9404 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:53.9409 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:53.9998 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.105793 train-accuracy:0.612469 valid-loss:1.156945 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:54.0545 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.589427\n",
      "[INFO 24-02-22 06:53:54.0545 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:53:54.0546 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.589427 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:54.0551 UTC hyperparameters_optimizer.cc:582] [829/1100] Score: -0.589427 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:54.0562 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:54.0562 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:54.0564 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:54.1191 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155923 train-accuracy:0.612469 valid-loss:1.150203 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:54.1980 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67414\n",
      "[INFO 24-02-22 06:53:54.1980 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:53:54.1985 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.674140 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:54.1992 UTC hyperparameters_optimizer.cc:582] [830/1100] Score: -0.67414 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:54.2009 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:54.2010 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:54.2014 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:54.2573 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.594471\n",
      "[INFO 24-02-22 06:53:54.2573 UTC gradient_boosted_trees.cc:271] Truncates the model to 204 tree(s) i.e. 204  iteration(s).\n",
      "[INFO 24-02-22 06:53:54.2574 UTC gradient_boosted_trees.cc:334] Final model num-trees:204 valid-loss:0.594471 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:54.2581 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:54.2581 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:54.2583 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:54.2586 UTC hyperparameters_optimizer.cc:582] [831/1100] Score: -0.594471 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:54.2753 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.014038 train-accuracy:0.849633 valid-loss:0.994050 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:54.2774 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313265 train-accuracy:0.612469 valid-loss:1.274179 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:54.4527 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644627\n",
      "[INFO 24-02-22 06:53:54.4528 UTC gradient_boosted_trees.cc:271] Truncates the model to 222 tree(s) i.e. 222  iteration(s).\n",
      "[INFO 24-02-22 06:53:54.4530 UTC gradient_boosted_trees.cc:334] Final model num-trees:222 valid-loss:0.644627 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:54.4547 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:54.4547 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:54.4550 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:54.4587 UTC hyperparameters_optimizer.cc:582] [832/1100] Score: -0.644627 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:54.4746 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102782 train-accuracy:0.814181 valid-loss:1.066541 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:54.6821 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654425\n",
      "[INFO 24-02-22 06:53:54.6821 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:53:54.6826 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.654425 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:54.6887 UTC hyperparameters_optimizer.cc:582] [833/1100] Score: -0.654425 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:54.6897 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:54.6898 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:54.6928 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:54.7203 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226329 train-accuracy:0.612469 valid-loss:1.181645 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:55.0095 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624516\n",
      "[INFO 24-02-22 06:53:55.0095 UTC gradient_boosted_trees.cc:271] Truncates the model to 105 tree(s) i.e. 105  iteration(s).\n",
      "[INFO 24-02-22 06:53:55.0096 UTC gradient_boosted_trees.cc:334] Final model num-trees:105 valid-loss:0.624516 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:55.0099 UTC hyperparameters_optimizer.cc:582] [834/1100] Score: -0.624516 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:55.0108 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:55.0108 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:55.0111 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:55.0209 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315424 train-accuracy:0.612469 valid-loss:1.274049 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:55.0585 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699899\n",
      "[INFO 24-02-22 06:53:55.0585 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:53:55.0637 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.699899 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:55.0643 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:55.0643 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:55.0645 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:55.0693 UTC hyperparameters_optimizer.cc:582] [835/1100] Score: -0.699899 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:55.1261 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.301953 train-accuracy:0.612469 valid-loss:1.267751 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:55.2815 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.597897\n",
      "[INFO 24-02-22 06:53:55.2815 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:53:55.2817 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.597897 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:55.2821 UTC hyperparameters_optimizer.cc:582] [836/1100] Score: -0.597897 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:55.2830 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:55.2830 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:55.2852 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:55.4053 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.269657 train-accuracy:0.612469 valid-loss:1.233374 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:55.5645 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657811\n",
      "[INFO 24-02-22 06:53:55.5645 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:55.5646 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.657811 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:55.5648 UTC hyperparameters_optimizer.cc:582] [837/1100] Score: -0.657811 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:55.5654 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:55.5654 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:55.5656 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:55.6094 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315935 train-accuracy:0.612469 valid-loss:1.275468 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:55.6418 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633303\n",
      "[INFO 24-02-22 06:53:55.6419 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:53:55.6420 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.633303 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:55.6424 UTC hyperparameters_optimizer.cc:582] [838/1100] Score: -0.633303 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:55.6430 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:55.6431 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:55.6433 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:55.6460 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.194662 train-accuracy:0.612469 valid-loss:1.146602 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:55.9000 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621417\n",
      "[INFO 24-02-22 06:53:55.9001 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:53:55.9002 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.621417 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:55.9007 UTC hyperparameters_optimizer.cc:582] [839/1100] Score: -0.621417 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:55.9013 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:55.9014 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:55.9020 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:55.9143 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310881 train-accuracy:0.612469 valid-loss:1.272570 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:56.2421 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630343\n",
      "[INFO 24-02-22 06:53:56.2422 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:56.2425 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.630343 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:56.2432 UTC hyperparameters_optimizer.cc:582] [840/1100] Score: -0.630343 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:56.2440 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:56.2440 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:56.2444 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:56.2478 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.185286 train-accuracy:0.612469 valid-loss:1.177896 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:56.4635 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.60488\n",
      "[INFO 24-02-22 06:53:56.4635 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:53:56.4637 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.604880 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:56.4645 UTC hyperparameters_optimizer.cc:582] [841/1100] Score: -0.60488 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:56.4647 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:56.4647 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:56.4652 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:56.4670 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315624 train-accuracy:0.612469 valid-loss:1.272565 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:56.9837 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.733535\n",
      "[INFO 24-02-22 06:53:56.9837 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:53:56.9855 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.733535 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:56.9903 UTC hyperparameters_optimizer.cc:582] [842/1100] Score: -0.733535 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:56.9969 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:56.9982 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:56.9985 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.0366 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114696 train-accuracy:0.801956 valid-loss:1.063470 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:53:57.0973 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.543610 train-accuracy:0.905868 valid-loss:0.612045 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:57.0973 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:53:57.0973 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.612045 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:57.0986 UTC hyperparameters_optimizer.cc:582] [843/1100] Score: -0.612045 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:57.0988 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.0989 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.1001 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.1206 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.204276 train-accuracy:0.612469 valid-loss:1.158637 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:57.5472 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.349954 train-accuracy:0.947433 valid-loss:0.566937 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:57.5472 UTC gradient_boosted_trees.cc:271] Truncates the model to 288 tree(s) i.e. 288  iteration(s).\n",
      "[INFO 24-02-22 06:53:57.5474 UTC gradient_boosted_trees.cc:334] Final model num-trees:288 valid-loss:0.565572 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:57.5492 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599615\n",
      "[INFO 24-02-22 06:53:57.5492 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:53:57.5496 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:53:57.5496 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.599615 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:57.5499 UTC hyperparameters_optimizer.cc:582] [844/1100] Score: -0.599615 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:57.5502 UTC hyperparameters_optimizer.cc:582] [845/1100] Score: -0.565572 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:57.5507 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.5508 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.5539 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.5539 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.5541 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-22 06:53:57.5567 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151425 train-accuracy:0.732274 valid-loss:1.126261 valid-accuracy:0.726027\n",
      " 24-02-22 06:53:57.5566 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.5607 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315144 train-accuracy:0.612469 valid-loss:1.275124 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:57.7613 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632934\n",
      "[INFO 24-02-22 06:53:57.7619 UTC gradient_boosted_trees.cc:271] Truncates the model to 160 tree(s) i.e. 160  iteration(s).\n",
      "[INFO 24-02-22 06:53:57.7621 UTC gradient_boosted_trees.cc:334] Final model num-trees:160 valid-loss:0.632934 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:57.7638 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.7638 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.7640 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.7653 UTC hyperparameters_optimizer.cc:582] [846/1100] Score: -0.632934 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:57.7738 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070071 train-accuracy:0.827628 valid-loss:1.041498 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:57.8025 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.577642\n",
      "[INFO 24-02-22 06:53:57.8026 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:53:57.8029 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.577642 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:57.8034 UTC hyperparameters_optimizer.cc:582] [847/1100] Score: -0.577642 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:57.8049 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.8049 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.8051 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.8079 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.038611 train-accuracy:0.838631 valid-loss:0.985855 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:57.8440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.603841\n",
      "[INFO 24-02-22 06:53:57.8460 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:53:57.8463 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.603841 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:57.8472 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.8472 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.8474 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.8487 UTC hyperparameters_optimizer.cc:582] [848/1100] Score: -0.603841 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:57.8529 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643047\n",
      "[INFO 24-02-22 06:53:57.8531 UTC gradient_boosted_trees.cc:271] Truncates the model to 192 tree(s) i.e. 192  iteration(s).\n",
      "[INFO 24-02-22 06:53:57.8534 UTC gradient_boosted_trees.cc:334] Final model num-trees:192 valid-loss:0.643047 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:57.8545 UTC hyperparameters_optimizer.cc:582] [849/1100] Score: -0.643047 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:53:57.8571 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.8572 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.8575 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.8592 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284849 train-accuracy:0.612469 valid-loss:1.245986 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:57.8853 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280671 train-accuracy:0.612469 valid-loss:1.241413 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:57.9570 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617235\n",
      "[INFO 24-02-22 06:53:57.9571 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:53:57.9574 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.617235 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:53:57.9577 UTC hyperparameters_optimizer.cc:582] [850/1100] Score: -0.617235 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:57.9582 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.9582 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.9584 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.9594 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672246\n",
      "[INFO 24-02-22 06:53:57.9594 UTC gradient_boosted_trees.cc:271] Truncates the model to 129 tree(s) i.e. 129  iteration(s).\n",
      "[INFO 24-02-22 06:53:57.9601 UTC gradient_boosted_trees.cc:334] Final model num-trees:129 valid-loss:0.672246 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:57.9642 UTC hyperparameters_optimizer.cc:582] [851/1100] Score: -0.672246 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:57.9654 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:57.9654 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:57.9683 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:57.9767 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.258592 train-accuracy:0.612469 valid-loss:1.204390 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:57.9876 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274925 train-accuracy:0.612469 valid-loss:1.240368 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:58.0276 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621085\n",
      "[INFO 24-02-22 06:53:58.0276 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:58.0279 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.621085 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:58.0288 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:58.0288 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:58.0290 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:58.0304 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244207 train-accuracy:0.612469 valid-loss:1.206943 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:58.0308 UTC hyperparameters_optimizer.cc:582] [852/1100] Score: -0.621085 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:58.0755 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626741\n",
      "[INFO 24-02-22 06:53:58.0756 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:53:58.0758 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.626741 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:58.0763 UTC hyperparameters_optimizer.cc:582] [853/1100] Score: -0.626741 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:58.0768 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:58.0768 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:58.0770 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:58.0844 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313251 train-accuracy:0.612469 valid-loss:1.275865 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:58.2987 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609986\n",
      "[INFO 24-02-22 06:53:58.2987 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:53:58.2988 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.609986 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:58.2992 UTC hyperparameters_optimizer.cc:582] [854/1100] Score: -0.609986 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:58.2996 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:58.2996 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:58.3001 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:58.3060 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283686 train-accuracy:0.612469 valid-loss:1.244512 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:58.5018 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651549\n",
      "[INFO 24-02-22 06:53:58.5018 UTC gradient_boosted_trees.cc:271] Truncates the model to 196 tree(s) i.e. 196  iteration(s).\n",
      "[INFO 24-02-22 06:53:58.5020 UTC gradient_boosted_trees.cc:334] Final model num-trees:196 valid-loss:0.651549 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:58.5036 UTC hyperparameters_optimizer.cc:582] [855/1100] Score: -0.651549 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:58.5041 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:58.5041 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:58.5054 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:58.5097 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314024 train-accuracy:0.612469 valid-loss:1.273414 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:58.7179 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.505413 train-accuracy:0.908313 valid-loss:0.612604 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:58.7179 UTC gradient_boosted_trees.cc:271] Truncates the model to 287 tree(s) i.e. 287  iteration(s).\n",
      "[INFO 24-02-22 06:53:58.7180 UTC gradient_boosted_trees.cc:334] Final model num-trees:287 valid-loss:0.612569 valid-accuracy:0.904110\n",
      "[[INFO 24-02-22 06:53:58.7207 UTC hyperparameters_optimizer.cc:582] [856/1100] Score: -0.612569 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "INFO 24-02-22 06:53:58.7213 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:58.7213 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:58.7220 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:58.7269 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.212315 train-accuracy:0.612469 valid-loss:1.165014 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:58.7561 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615793\n",
      "[INFO 24-02-22 06:53:58.7561 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:53:58.7563 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.615793 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:58.7572 UTC hyperparameters_optimizer.cc:582] [857/1100] Score: -0.615793 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:58.7588 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:58.7588 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:58.7591 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:58.8049 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626154\n",
      "[INFO 24-02-22 06:53:58.8049 UTC gradient_boosted_trees.cc:271] Truncates the model to 92 tree(s) i.e. 92  iteration(s).\n",
      "[INFO 24-02-22 06:53:58.8051 UTC gradient_boosted_trees.cc:334] Final model num-trees:92 valid-loss:0.626154 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:58.8062 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:58.8062 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:58.8064 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:58.8072 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319109 train-accuracy:0.612469 valid-loss:1.277920 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:58.8078 UTC hyperparameters_optimizer.cc:582] [858/1100] Score: -0.626154 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:58.8240 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221417 train-accuracy:0.612469 valid-loss:1.188091 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:58.9594 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646433\n",
      "[INFO 24-02-22 06:53:58.9595 UTC gradient_boosted_trees.cc:271] Truncates the model to 108 tree(s) i.e. 108  iteration(s).\n",
      "[INFO 24-02-22 06:53:58.9596 UTC gradient_boosted_trees.cc:334] Final model num-trees:108 valid-loss:0.646433 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:58.9601 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:58.9601 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:58.9604 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:58.9605 UTC hyperparameters_optimizer.cc:582] [859/1100] Score: -0.646433 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:58.9675 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277591 train-accuracy:0.612469 valid-loss:1.242456 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.0719 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.723152 train-accuracy:0.848411 valid-loss:0.683751 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:59.0719 UTC gradient_boosted_trees.cc:271] Truncates the model to 274 tree(s) i.e. 274  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.0720 UTC gradient_boosted_trees.cc:334] Final model num-trees:274 valid-loss:0.682565 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:59.0723 UTC hyperparameters_optimizer.cc:582] [860/1100] Score: -0.682565 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:59.0750 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.0759 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.0762 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.0968 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278479 train-accuracy:0.612469 valid-loss:1.238091 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.1086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.612897\n",
      "[INFO 24-02-22 06:53:59.1087 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.1090 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.612897 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:59.1112 UTC hyperparameters_optimizer.cc:582] [861/1100] Score: -0.612897 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:53:59.1120 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.1120 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.1123 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.1213 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314500 train-accuracy:0.612469 valid-loss:1.274076 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.1390 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645648\n",
      "[INFO 24-02-22 06:53:59.1392 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.1395 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.645648 valid-accuracy:0.863014\n",
      "[[INFO 24-02-22 06:53:59.1406 UTC hyperparameters_optimizer.cc:582] [862/1100] Score: -0.645648 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:53:59.1420 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.1421 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.1423 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.1535 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625026\n",
      "[INFO 24-02-22 06:53:59.1535 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.1537 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.625026 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:59.1544 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.1544 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.1547 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.1555 UTC hyperparameters_optimizer.cc:582] [863/1100] Score: -0.625026 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:59.1657 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.181811 train-accuracy:0.612469 valid-loss:1.149759 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.2357 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311190 train-accuracy:0.612469 valid-loss:1.273907 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.4793 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660381\n",
      "[INFO 24-02-22 06:53:59.4794 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.4796 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.660381 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:53:59.4805 UTC hyperparameters_optimizer.cc:582] [864/1100] Score: -0.660381 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:59.4811 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.4812 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.4822 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.4823 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.558592\n",
      "[INFO 24-02-22 06:53:59.4823 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.4824 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.558592 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:59.4829 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.4829 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.4831 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.4846 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112580 train-accuracy:0.808068 valid-loss:1.062395 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:59.4853 UTC hyperparameters_optimizer.cc:582] [865/1100] Score: -0.558592 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:59.4860 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182901 train-accuracy:0.612469 valid-loss:1.157123 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.4921 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61604\n",
      "[INFO 24-02-22 06:53:59.4922 UTC gradient_boosted_trees.cc:271] Truncates the model to 108 tree(s) i.e. 108  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.4925 UTC gradient_boosted_trees.cc:334] Final model num-trees:108 valid-loss:0.616040 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:59.4945 UTC hyperparameters_optimizer.cc:582] [866/1100] Score: -0.61604 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:59.4964 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.4964 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.4966 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.5890 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094218 train-accuracy:0.845966 valid-loss:1.091158 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:59.6205 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668718\n",
      "[INFO 24-02-22 06:53:59.6206 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.6208 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.668718 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:59.6211 UTC hyperparameters_optimizer.cc:582] [867/1100] Score: -0.668718 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:59.6218 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.6218 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.6221 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.6248 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.080564 train-accuracy:0.804401 valid-loss:1.040871 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:59.7021 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633792\n",
      "[INFO 24-02-22 06:53:59.7021 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.7023 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.633792 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:59.7029 UTC hyperparameters_optimizer.cc:582] [868/1100] Score: -0.633792 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:59.7037 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.7037 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.7039 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.7205 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285941 train-accuracy:0.612469 valid-loss:1.247520 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.7773 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.693115 train-accuracy:0.872861 valid-loss:0.670867 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:59.7773 UTC gradient_boosted_trees.cc:271] Truncates the model to 292 tree(s) i.e. 292  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.7773 UTC gradient_boosted_trees.cc:334] Final model num-trees:292 valid-loss:0.670276 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:53:59.7778 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.7779 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.7780 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.542653\n",
      "[INFO 24-02-22 06:53:59.7780 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.7781 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.7782 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.542653 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:53:59.7788 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.7788 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.7790 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.7801 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177580 train-accuracy:0.709046 valid-loss:1.137410 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:53:59.7820 UTC hyperparameters_optimizer.cc:582] [869/1100] Score: -0.670276 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:53:59.7825 UTC hyperparameters_optimizer.cc:582] [870/1100] Score: -0.542653 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:59.7991 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637074\n",
      "[INFO 24-02-22 06:53:59.7991 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.7994 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.637074 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:59.8040 UTC early_stopping.cc[INFO 24-02-22 06:53:59.8040 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.8041 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      ":53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648425\n",
      "[INFO 24-02-22 06:53:59.8041 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.8043 UTC hyperparameters_optimizer.cc:582] [871/1100] Score: -0.637074 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:59.8044 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.648425 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:53:59.8051 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.8051 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.8053 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.8063 UTC hyperparameters_optimizer.cc:582] [872/1100] Score: -0.648425 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:53:59.8118 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.8129 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313983 train-accuracy:0.612469 valid-loss:1.272459 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.8166 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209694 train-accuracy:0.612469 valid-loss:1.177561 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:53:59.8977 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.109022 train-accuracy:0.786064 valid-loss:1.086316 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:53:59.9579 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.560651\n",
      "[INFO 24-02-22 06:53:59.9579 UTC gradient_boosted_trees.cc:271] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "[INFO 24-02-22 06:53:59.9580 UTC gradient_boosted_trees.cc:334] Final model num-trees:116 valid-loss:0.560651 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:53:59.9586 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:53:59.9586 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:53:59.9589 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:53:59.9590 UTC hyperparameters_optimizer.cc:582] [873/1100] Score: -0.560651 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:53:59.9673 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312972 train-accuracy:0.612469 valid-loss:1.271631 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:00.1409 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.604277\n",
      "[INFO 24-02-22 06:54:00.1410 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:54:00.1416 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.604277 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:00.1432 UTC hyperparameters_optimizer.cc:582] [874/1100] Score: -0.604277 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:00.1467 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:00.1468 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:00.1470 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:00.1506 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.119408 train-accuracy:0.768949 valid-loss:1.087972 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:54:00.2925 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619332\n",
      "[INFO 24-02-22 06:54:00.2926 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:54:00.2930 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.619332 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:00.2954 UTC hyperparameters_optimizer.cc:582] [875/1100] Score: -0.619332 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:54:00.2976 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:00.2976 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:00.2979 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:00.3067 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.197101 train-accuracy:0.612469 valid-loss:1.164170 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:00.4709 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624744\n",
      "[INFO 24-02-22 06:54:00.4709 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:54:00.4711 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.624744 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:00.4720 UTC hyperparameters_optimizer.cc:582] [876/1100] Score: -0.624744 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:00.4732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:00.4743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:00.4745 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:00.4820 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146692 train-accuracy:0.793399 valid-loss:1.112227 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:54:00.5842 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650509\n",
      "[INFO 24-02-22 06:54:00.5842 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:54:00.5844 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.650509 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:00.5856 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:00.5857 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:00.5859 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:00.5889 UTC hyperparameters_optimizer.cc:582] [877/1100] Score: -0.650509 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:00.6103 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.165766 train-accuracy:0.612469 valid-loss:1.128296 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:00.9054 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.582781\n",
      "[INFO 24-02-22 06:54:00.9054 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:54:00.9056 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.582781 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:00.9059 UTC hyperparameters_optimizer.cc:582] [878/1100] Score: -0.582781 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:00.9065 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:00.9065 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:00.9069 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:00.9301 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294898 train-accuracy:0.612469 valid-loss:1.251710 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:01.0807 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62058\n",
      "[INFO 24-02-22 06:54:01.0807 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 06:54:01.0808 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.620580 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:01.0812 UTC hyperparameters_optimizer.cc:582] [879/1100] Score: -0.62058 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:01.0822 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:01.0822 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:01.0824 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:01.1067 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284144 train-accuracy:0.612469 valid-loss:1.249597 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:01.1329 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646437\n",
      "[INFO 24-02-22 06:54:01.1330 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:54:01.1334 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.646437 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:01.1368 UTC hyperparameters_optimizer.cc:582] [880/1100] Score: -0.646437 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:01.1407 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:01.1407 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:01.1411 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:01.1504 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.075178 train-accuracy:0.801956 valid-loss:1.057344 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:01.1574 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633112\n",
      "[INFO 24-02-22 06:54:01.1577 UTC gradient_boosted_trees.cc:271] Truncates the model to 206 tree(s) i.e. 206  iteration(s).\n",
      "[INFO 24-02-22 06:54:01.1588 UTC gradient_boosted_trees.cc:334] Final model num-trees:206 valid-loss:0.633112 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:01.1618 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:01.1639 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:01.1642 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:01.1687 UTC hyperparameters_optimizer.cc:582] [881/1100] Score: -0.633112 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:01.1907 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315430 train-accuracy:0.612469 valid-loss:1.275338 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:01.4825 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632272\n",
      "[INFO 24-02-22 06:54:01.4826 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 06:54:01.4829 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.632272 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:01.4858 UTC hyperparameters_optimizer.cc:582] [882/1100] Score: -0.632272 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:01.4867 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:01.4867 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:01.4890 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:01.5017 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.194591 train-accuracy:0.612469 valid-loss:1.146269 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:01.5272 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.589102\n",
      "[INFO 24-02-22 06:54:01.5273 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:54:01.5274 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.589102 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:01.5277 UTC hyperparameters_optimizer.cc:582] [883/1100] Score: -0.589102 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:01.5282 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:01.5282 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:01.5285 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:01.5537 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176215 train-accuracy:0.612469 valid-loss:1.130062 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:01.6590 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64143\n",
      "[INFO 24-02-22 06:54:01.6591 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:54:01.6595 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.641430 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:01.6599 UTC hyperparameters_optimizer.cc:582] [884/1100] Score: -0.64143 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:01.6605 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:01.6605 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:01.6608 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:01.6706 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225614 train-accuracy:0.612469 valid-loss:1.183831 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:01.8597 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659935\n",
      "[INFO 24-02-22 06:54:01.8597 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:54:01.8601 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.659935 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:01.8606 UTC hyperparameters_optimizer.cc:582] [885/1100] Score: -0.659935 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:01.8612 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:01.8612 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:01.8617 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:01.9677 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.131030 train-accuracy:0.612469 valid-loss:1.118920 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:02.1263 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624847\n",
      "[INFO 24-02-22 06:54:02.1263 UTC gradient_boosted_trees.cc:271] Truncates the model to 90 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 24-02-22 06:54:02.1266 UTC gradient_boosted_trees.cc:334] Final model num-trees:90 valid-loss:0.624847 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:02.1282 UTC hyperparameters_optimizer.cc:582] [886/1100] Score: -0.624847 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:02.1289 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:02.1289 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:02.1301 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:02.1321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186688 train-accuracy:0.724939 valid-loss:1.137191 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:54:02.2575 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674441\n",
      "[INFO 24-02-22 06:54:02.2575 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:54:02.2579 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.674441 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:02.2585 UTC hyperparameters_optimizer.cc:582] [887/1100] Score: -0.674441 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:02.2600 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:02.2601 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:02.2604 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:02.2782 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243197 train-accuracy:0.612469 valid-loss:1.204666 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:02.3075 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6488\n",
      "[INFO 24-02-22 06:54:02.3075 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:54:02.3076 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.648800 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:02.3079 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:02.3079 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:02.3081 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:02.3087 UTC hyperparameters_optimizer.cc:582] [888/1100] Score: -0.6488 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:02.3263 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227467 train-accuracy:0.612469 valid-loss:1.194061 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:02.4716 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650588\n",
      "[INFO 24-02-22 06:54:02.4716 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:54:02.4721 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.650588 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:02.4733 UTC hyperparameters_optimizer.cc:582] [889/1100] Score: -0.650588 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:02.4741 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:02.4741 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:02.4751 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:02.4782 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285431 train-accuracy:0.612469 valid-loss:1.248660 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:02.4858 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.608344\n",
      "[INFO 24-02-22 06:54:02.4858 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:54:02.4860 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.608344 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:02.4875 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:02.4876 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:02.4878 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:02.4887 UTC hyperparameters_optimizer.cc:582] [890/1100] Score: -0.608344 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:02.5069 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225882 train-accuracy:0.612469 valid-loss:1.183170 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:02.5208 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65158\n",
      "[INFO 24-02-22 06:54:02.5208 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:54:02.5210 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.651580 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:02.5217 UTC hyperparameters_optimizer.cc:582] [891/1100] Score: -0.65158 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:02.5230 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:02.5232 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:02.5235 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:02.5944 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224886 train-accuracy:0.612469 valid-loss:1.182613 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:02.8620 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633549\n",
      "[INFO 24-02-22 06:54:02.8622 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:54:02.8623 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.633549 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:02.8634 UTC hyperparameters_optimizer.cc:582] [892/1100] Score: -0.633549 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:02.8640 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:02.8640 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:02.8647 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:02.9013 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279555 train-accuracy:0.612469 valid-loss:1.239399 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:03.1637 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666309\n",
      "[INFO 24-02-22 06:54:03.1638 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.1641 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.666309 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:03.1644 UTC hyperparameters_optimizer.cc:582] [893/1100] Score: -0.666309 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:03.1649 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.1651 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:03.1654 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.1686 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092251 train-accuracy:0.812958 valid-loss:1.062496 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:03.2801 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.569784\n",
      "[INFO 24-02-22 06:54:03.2802 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.2804 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.569784 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:03.2808 UTC hyperparameters_optimizer.cc:582] [894/1100] Score: -0.569784 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:03.2814 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.2814 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:03.2819 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.2830 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130741 train-accuracy:0.784841 valid-loss:1.073300 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:03.3244 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632866\n",
      "[INFO 24-02-22 06:54:03.3244 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.3252 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.632866 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:03.3264 UTC hyperparameters_optimizer.cc:582] [895/1100] Score: -0.632866 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:03.3294 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.3303 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:03.3306 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.3638 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286037 train-accuracy:0.612469 valid-loss:1.242518 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:03.3869 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654252\n",
      "[INFO 24-02-22 06:54:03.3870 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.3870 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.654252 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:03.3872 UTC hyperparameters_optimizer.cc:582] [896/1100] Score: -0.654252 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:03.3876 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.3876 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:03.3878 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.3906 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092913 train-accuracy:0.822738 valid-loss:1.066403 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:54:03.4294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633345\n",
      "[INFO 24-02-22 06:54:03.4294 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.4296 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.633345 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:03.4303 UTC hyperparameters_optimizer.cc:582] [897/1100] Score: -0.633345 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:03.4307 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.4307 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:03.4309 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.4540 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.569665\n",
      "[INFO 24-02-22 06:54:03.4540 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.4541 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.569665 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:03.4547 UTC hyperparameters_optimizer.cc:582] [898/1100] Score: -0.569665 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:03.4552 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.4552 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:03.4557 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.4631 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279417 train-accuracy:0.612469 valid-loss:1.245193 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:03.4802 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.089751 train-accuracy:0.820293 valid-loss:1.066620 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:54:03.5719 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695451\n",
      "[INFO 24-02-22 06:54:03.5719 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.5722 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.695451 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:03.5729 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.5732 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:03.5735 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.5750 UTC hyperparameters_optimizer.cc:582] [899/1100] Score: -0.695451 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:03.6050 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.120458 train-accuracy:0.776284 valid-loss:1.112597 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:54:03.6138 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638143\n",
      "[INFO 24-02-22 06:54:03.6138 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.6140 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.638143 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:03.6148 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.6149 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9[ feature(s).INFO\n",
      "[ 24-02-22 06:54:03.6151 UTC hyperparameters_optimizer.cc:582] [900/1100] Score: -0.638143 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 06:54:03.6159 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.6424 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.105504 train-accuracy:0.786064 valid-loss:1.082446 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:03.9044 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.620617\n",
      "[INFO 24-02-22 06:54:03.9044 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:54:03.9049 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.620617 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:03.9060 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:03.9060 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:03.9063 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:03.9083 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102110 train-accuracy:0.817848 valid-loss:1.060704 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:03.9087 UTC hyperparameters_optimizer.cc:582] [901/1100] Score: -0.620617 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:04.0781 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65924\n",
      "[INFO 24-02-22 06:54:04.0781 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:54:04.0784 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.659240 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:04.0792 UTC hyperparameters_optimizer.cc:582] [902/1100] Score: -0.65924 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:04.0798 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.0798 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.0802 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.0840 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.252015 train-accuracy:0.612469 valid-loss:1.203256 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:04.0957 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615278\n",
      "[INFO 24-02-22 06:54:04.0957 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:54:04.0959 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.615278 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:04.0974 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.0974 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.0976 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.0988 UTC hyperparameters_optimizer.cc:582] [903/1100] Score: -0.615278 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:04.1066 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184587 train-accuracy:0.612469 valid-loss:1.152206 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:04.1961 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627705\n",
      "[INFO 24-02-22 06:54:04.1991 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:54:04.1994 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.627705 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:04.2005 UTC hyperparameters_optimizer.cc:582] [904/1100] Score: -0.627705 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:04.2028 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.2028 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.2030 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.2220 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.111711 train-accuracy:0.761614 valid-loss:1.083523 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:54:04.3860 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671806\n",
      "[INFO 24-02-22 06:54:04.3860 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:54:04.3860 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.671806 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:04.3865 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.3865 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.3867 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.3888 UTC hyperparameters_optimizer.cc:582] [905/1100] Score: -0.671806 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:04.3935 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236005 train-accuracy:0.612469 valid-loss:1.200544 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:04.4833 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639346\n",
      "[INFO 24-02-22 06:54:04.4833 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:54:04.4837 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.639346 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:04.4840 UTC hyperparameters_optimizer.cc:582] [906/1100] Score: -0.639346 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:04.4845 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.4845 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.4848 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.4966 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311499 train-accuracy:0.612469 valid-loss:1.270391 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:04.5921 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.598363\n",
      "[INFO 24-02-22 06:54:04.5922 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:54:04.5927 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.598363 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:04.5929 UTC hyperparameters_optimizer.cc:582] [907/1100] Score: -0.598363 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:04.5935 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.5935 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.5937 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.5962 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226044 train-accuracy:0.612469 valid-loss:1.195147 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:04.6494 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686776\n",
      "[INFO 24-02-22 06:54:04.6515 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:04.6518 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:04.6518 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.686776 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:04.6521 UTC hyperparameters_optimizer.cc:582] [908/1100] Score: -0.686776 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:04.6527 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.6527 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.6529 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.6626 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191687 train-accuracy:0.612469 valid-loss:1.151170 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:04.8752 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.628075\n",
      "[INFO 24-02-22 06:54:04.8752 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-22 06:54:04.8756 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.628075 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:04.8764 UTC hyperparameters_optimizer.cc:582] [909/1100] Score: -0.628075 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:04.8780 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.8782 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.8785 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.9035 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.160930 train-accuracy:0.770171 valid-loss:1.098380 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:54:04.9566 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622671\n",
      "[INFO 24-02-22 06:54:04.9566 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:54:04.9567 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.622671 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:04.9575 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:04.9575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:04.9578 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:04.9587 UTC hyperparameters_optimizer.cc:582] [910/1100] Score: -0.622671 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:04.9608 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314151 train-accuracy:0.612469 valid-loss:1.273378 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:05.0228 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.724639\n",
      "[INFO 24-02-22 06:54:05.0228 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.0278 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.724639 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:05.0385 UTC hyperparameters_optimizer.cc:582] [911/1100] Score: -0.724639 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:05.0665 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.0665 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.0668 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.0726 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228911 train-accuracy:0.612469 valid-loss:1.190148 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:05.0918 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650286\n",
      "[INFO 24-02-22 06:54:05.0918 UTC gradient_boosted_trees.cc:271] Truncates the model to 169 tree(s) i.e. 169  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.0919 UTC gradient_boosted_trees.cc:334] Final model num-trees:169 valid-loss:0.650286 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:05.0977 UTC hyperparameters_optimizer.cc:582] [912/1100] Score: -0.650286 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:05.1020 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.1021 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.1032 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.1176 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.586661\n",
      "[INFO 24-02-22 06:54:05.1177 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.1179 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.586661 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:05.1182 UTC hyperparameters_optimizer.cc:582] [913/1100] Score: -0.586661 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:05.1189 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.1189 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.1192 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.1241 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186390 train-accuracy:0.777506 valid-loss:1.138180 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:05.1252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132530 train-accuracy:0.797066 valid-loss:1.104536 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:05.1306 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605011\n",
      "[INFO 24-02-22 06:54:05.1307 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.1309 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.605011 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:05.1315 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.1315 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.1317 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.1349 UTC hyperparameters_optimizer.cc:582] [914/1100] Score: -0.605011 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:05.1393 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275466 train-accuracy:0.612469 valid-loss:1.241002 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:05.2609 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.59587\n",
      "[INFO 24-02-22 06:54:05.2645 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.2647 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.595870 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:05.2652 UTC hyperparameters_optimizer.cc:582] [915/1100] Score: -0.59587 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:05.2658 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.2658 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.2663 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.2690 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196318 train-accuracy:0.612469 valid-loss:1.171285 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:05.3912 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638601\n",
      "[INFO 24-02-22 06:54:05.3913 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.3915 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.638601 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:05.3920 UTC hyperparameters_optimizer.cc:582] [916/1100] Score: -0.638601 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:05.3924 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.3925 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.3929 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.4450 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.600711\n",
      "[INFO 24-02-22 06:54:05.4453 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.4461 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.600711 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:05.4467 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.4467 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.4469 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.4479 UTC hyperparameters_optimizer.cc:582] [917/1100] Score: -0.600711 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:05.4519 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.259946 train-accuracy:0.612469 valid-loss:1.223200 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:05.4535 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313900 train-accuracy:0.612469 valid-loss:1.269627 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:05.5013 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655788\n",
      "[INFO 24-02-22 06:54:05.5017 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.5028 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.655788 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:05.5035 UTC hyperparameters_optimizer.cc:582] [918/1100] Score: -0.655788 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:05.5047 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.5047 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.5049 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.5250 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184307 train-accuracy:0.612469 valid-loss:1.147548 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:05.5337 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.639139 train-accuracy:0.877751 valid-loss:0.613025 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:05.5337 UTC gradient_boosted_trees.cc:271] Truncates the model to 292 tree(s) i.e. 292  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.5338 UTC gradient_boosted_trees.cc:334] Final model num-trees:292 valid-loss:0.609618 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:05.5346 UTC hyperparameters_optimizer.cc:582] [919/1100] Score: -0.609618 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:54:05.5357 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.5357 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.5363 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.5392 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315540 train-accuracy:0.612469 valid-loss:1.273900 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:05.6174 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638916\n",
      "[INFO 24-02-22 06:54:05.6174 UTC gradient_boosted_trees.cc:271] Truncates the model to 85 tree(s) i.e. 85  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.6184 UTC gradient_boosted_trees.cc:334] Final model num-trees:85 valid-loss:0.638916 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:05.6248 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.6248 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.6250 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.6266 UTC hyperparameters_optimizer.cc:582] [920/1100] Score: -0.638916 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:05.6724 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.042338 train-accuracy:0.836186 valid-loss:0.995025 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:05.7240 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.435259 train-accuracy:0.927873 valid-loss:0.604237 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:05.7240 UTC gradient_boosted_trees.cc:271] Truncates the model to 293 tree(s) i.e. 293  iteration(s).\n",
      "[INFO 24-02-22 06:54:05.7240 UTC gradient_boosted_trees.cc:334] Final model num-trees:293 valid-loss:0.602409 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:05.7279 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:05.7279 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:05.7282 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:05.7336 UTC hyperparameters_optimizer.cc:582] [921/1100] Score: -0.602409 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:05.7352 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157044 train-accuracy:0.756724 valid-loss:1.120204 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:54:06.0810 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.709057\n",
      "[INFO 24-02-22 06:54:06.0810 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:54:06.0814 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.709057 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:06.0834 UTC hyperparameters_optimizer.cc:582] [922/1100] Score: -0.709057 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:06.0860 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:06.0876 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:06.0878 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:06.1023 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634318\n",
      "[INFO 24-02-22 06:54:06.1023 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:54:06.1027 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.634318 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:06.1036 UTC hyperparameters_optimizer.cc:582] [923/1100] Score: -0.634318 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:06.1044 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:06.1044 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:06.1053 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:06.1117 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316350 train-accuracy:0.612469 valid-loss:1.276657 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:06.1258 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153404 train-accuracy:0.612469 valid-loss:1.155728 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:06.2282 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634986\n",
      "[INFO 24-02-22 06:54:06.2283 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:54:06.2284 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.634986 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:06.2290 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:06.2291 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:06.2293 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:06.2320 UTC hyperparameters_optimizer.cc:582] [924/1100] Score: -0.634986 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:06.2523 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.173274 train-accuracy:0.612469 valid-loss:1.132459 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:06.2807 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639155\n",
      "[INFO 24-02-22 06:54:06.2807 UTC gradient_boosted_trees.cc:271] Truncates the model to 253 tree(s) i.e. 253  iteration(s).\n",
      "[INFO 24-02-22 06:54:06.2809 UTC gradient_boosted_trees.cc:334] Final model num-trees:253 valid-loss:0.639155 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:06.2829 UTC hyperparameters_optimizer.cc:582] [925/1100] Score: -0.639155 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:06.2855 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:06.2855 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:06.2857 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:06.2920 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282733 train-accuracy:0.612469 valid-loss:1.241213 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:06.4645 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.620669\n",
      "[INFO 24-02-22 06:54:06.4646 UTC gradient_boosted_trees.cc:271] Truncates the model to 133 tree(s) i.e. 133  iteration(s).\n",
      "[INFO 24-02-22 06:54:06.4651 UTC gradient_boosted_trees.cc:334] Final model num-trees:133 valid-loss:0.620669 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:06.4699 UTC hyperparameters_optimizer.cc:582] [926/1100] Score: -0.620669 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:06.4775 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:06.4775 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:06.4777 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:06.4802 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.105252 train-accuracy:0.805623 valid-loss:1.068848 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:06.5989 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646207\n",
      "[INFO 24-02-22 06:54:06.5989 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:54:06.5991 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.646207 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:06.5998 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:06.5998 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:06.6000 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:06.6020 UTC hyperparameters_optimizer.cc:582] [927/1100] Score: -0.646207 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:06.6558 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278033 train-accuracy:0.612469 valid-loss:1.235127 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:06.7959 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688085\n",
      "[INFO 24-02-22 06:54:06.7959 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:06.7968 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.688085 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:06.7974 UTC hyperparameters_optimizer.cc:582] [928/1100] Score: -0.688085 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:06.8066 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:06.8067 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:06.8069 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:06.8348 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285396 train-accuracy:0.612469 valid-loss:1.246639 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:07.0470 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665951\n",
      "[INFO 24-02-22 06:54:07.0470 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.0472 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.665951 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:07.0478 UTC hyperparameters_optimizer.cc:582] [929/1100] Score: -0.665951 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:07.0495 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.0498 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.0504 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.0535 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313679 train-accuracy:0.612469 valid-loss:1.273042 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:07.1331 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622182\n",
      "[INFO 24-02-22 06:54:07.1331 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.1331 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.622182 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:07.1337 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.1337 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.1339 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.1387 UTC hyperparameters_optimizer.cc:582] [930/1100] Score: -0.622182 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:07.1676 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083038 train-accuracy:0.825183 valid-loss:1.019060 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:07.2626 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661942\n",
      "[INFO 24-02-22 06:54:07.2626 UTC gradient_boosted_trees.cc:271] Truncates the model to 189 tree(s) i.e. 189  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.2628 UTC gradient_boosted_trees.cc:334] Final model num-trees:189 valid-loss:0.661942 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:07.2641 UTC hyperparameters_optimizer.cc:582] [931/1100] Score: -0.661942 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:07.2669 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.2671 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.2677 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.2774 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314500 train-accuracy:0.612469 valid-loss:1.275937 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:07.3344 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632795\n",
      "[INFO 24-02-22 06:54:07.3345 UTC gradient_boosted_trees.cc:271] Truncates the model to 257 tree(s) i.e. 257  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.3345 UTC gradient_boosted_trees.cc:334] Final model num-trees:257 valid-loss:0.632795 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:07.3349 UTC hyperparameters_optimizer.cc:582] [932/1100] Score: -0.632795 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:07.3356 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.3356 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.3359 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.3420 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142129 train-accuracy:0.815403 valid-loss:1.102484 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:07.3420 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.538434\n",
      "[INFO 24-02-22 06:54:07.3420 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.3424 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.538434 valid-accuracy:0.931507\n",
      "[INFO 24-02-22 06:54:07.3430 UTC hyperparameters_optimizer.cc:582] [933/1100] Score: -0.538434 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:07.3431 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624919\n",
      "[INFO 24-02-22 06:54:07.3432 UTC gradient_boosted_trees.cc:271] Truncates the model to 246 tree(s) i.e. 246  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.3433 UTC gradient_boosted_trees.cc:334] Final model num-trees:246 valid-loss:0.624919 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:07.3441 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.3442 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.3444 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.3456 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.3459 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.3461 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.3487 UTC hyperparameters_optimizer.cc:582] [934/1100] Score: -0.624919 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:54:07.4022 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.272464 train-accuracy:0.612469 valid-loss:1.234010 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:07.4357 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.170509 train-accuracy:0.612469 valid-loss:1.147805 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:07.4463 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.565415\n",
      "[INFO 24-02-22 06:54:07.4464 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.4465 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.565415 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:07.4467 UTC hyperparameters_optimizer.cc:582] [935/1100] Score: -0.565415 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:07.4471 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.4471 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.4473 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.4518 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090999 train-accuracy:0.808068 valid-loss:1.056373 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:54:07.6195 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668482\n",
      "[INFO 24-02-22 06:54:07.6195 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.6198 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.668482 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:07.6201 UTC hyperparameters_optimizer.cc:582] [936/1100] Score: -0.668482 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:07.6208 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.6208 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.6210 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.7018 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.574429\n",
      "[INFO 24-02-22 06:54:07.7018 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.7021 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.574429 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:07.7025 UTC hyperparameters_optimizer.cc:582] [937/1100] Score: -0.574429 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:07.7031 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.7031 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.7036 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.7098 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315423 train-accuracy:0.612469 valid-loss:1.275385 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:07.7112 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625739\n",
      "[INFO 24-02-22 06:54:07.7113 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.7119 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.625739 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:07.7125 UTC hyperparameters_optimizer.cc:582] [938/1100] Score: -0.625739 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:07.7138 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.7138 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.7143 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.7150 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.088284 train-accuracy:0.831296 valid-loss:1.094587 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:07.7210 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314312 train-accuracy:0.612469 valid-loss:1.273884 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:07.7411 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643582\n",
      "[INFO 24-02-22 06:54:07.7411 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.7416 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.643582 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:07.7426 UTC hyperparameters_optimizer.cc:582] [939/1100] Score: -0.643582 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:07.7430 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.7430 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.7435 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.7544 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.052851 train-accuracy:0.838631 valid-loss:1.011171 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:07.8351 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.578004\n",
      "[INFO 24-02-22 06:54:07.8351 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:54:07.8355 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.578004 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:07.8363 UTC hyperparameters_optimizer.cc:582] [940/1100] Score: -0.578004 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:07.8369 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:07.8369 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:07.8372 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:07.8513 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288484 train-accuracy:0.612469 valid-loss:1.246624 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:08.3086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.592761\n",
      "[INFO 24-02-22 06:54:08.3087 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:54:08.3097 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.592761 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:54:08.3102 UTC hyperparameters_optimizer.cc:582] [941/1100] Score: -0.592761 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:08.3113 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:08.3113 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:08.3115 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:08.3283 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.183509 train-accuracy:0.612469 valid-loss:1.160402 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:08.3673 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662782\n",
      "[INFO 24-02-22 06:54:08.3673 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:54:08.3674 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.662782 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:08.3677 UTC hyperparameters_optimizer.cc:582] [942/1100] Score: -0.662782 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:08.3683 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:08.3683 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:08.3688 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:08.3762 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084570 train-accuracy:0.801956 valid-loss:1.061578 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:54:08.3855 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651768\n",
      "[INFO 24-02-22 06:54:08.3855 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:54:08.3858 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.651768 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:08.3861 UTC hyperparameters_optimizer.cc:582] [943/1100] Score: -0.651768 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:08.3877 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:08.3877 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:08.3879 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:08.3931 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184350 train-accuracy:0.612469 valid-loss:1.137358 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:08.6050 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631825\n",
      "[INFO 24-02-22 06:54:08.6051 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:54:08.6054 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.631825 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:08.6058 UTC hyperparameters_optimizer.cc:582] [944/1100] Score: -0.631825 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:08.6066 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:08.6067 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:08.6070 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:08.6682 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177892 train-accuracy:0.612469 valid-loss:1.164734 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:08.6963 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671325\n",
      "[INFO 24-02-22 06:54:08.6964 UTC gradient_boosted_trees.cc:271] Truncates the model to 173 tree(s) i.e. 173  iteration(s).\n",
      "[INFO 24-02-22 06:54:08.6966 UTC gradient_boosted_trees.cc:334] Final model num-trees:173 valid-loss:0.671325 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:08.6982 UTC hyperparameters_optimizer.cc:582] [945/1100] Score: -0.671325 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:08.7025 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:08.7026 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:08.7029 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:08.7108 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310982 train-accuracy:0.612469 valid-loss:1.272680 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:08.8962 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675709\n",
      "[INFO 24-02-22 06:54:08.8962 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:54:08.8964 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.675709 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:08.8970 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:08.8970 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:08.8973 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:08.9020 UTC hyperparameters_optimizer.cc:582] [946/1100] Score: -0.675709 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:08.9028 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244758 train-accuracy:0.612469 valid-loss:1.212655 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:09.2831 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639241\n",
      "[INFO 24-02-22 06:54:09.2831 UTC gradient_boosted_trees.cc:271] Truncates the model to 223 tree(s) i.e. 223  iteration(s).\n",
      "[INFO 24-02-22 06:54:09.2832 UTC gradient_boosted_trees.cc:334] Final model num-trees:223 valid-loss:0.639241 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:09.2852 UTC hyperparameters_optimizer.cc:582] [947/1100] Score: -0.639241 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:09.2877 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:09.2877 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:09.2880 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:09.3022 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.128247 train-accuracy:0.832518 valid-loss:1.118817 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:54:09.3264 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655652\n",
      "[INFO 24-02-22 06:54:09.3264 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:54:09.3265 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.655652 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:09.3268 UTC hyperparameters_optimizer.cc:582] [948/1100] Score: -0.655652 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:09.3273 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:09.3273 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:09.3276 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:09.4520 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.199778 train-accuracy:0.612469 valid-loss:1.176648 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:09.6498 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.479020 train-accuracy:0.911980 valid-loss:0.583222 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:54:09.6498 UTC gradient_boosted_trees.cc:271] Truncates the model to 274 tree(s) i.e. 274  iteration(s).\n",
      "[INFO 24-02-22 06:54:09.6500 UTC gradient_boosted_trees.cc:334] Final model num-trees:274 valid-loss:0.581735 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 06:54:09.6521 UTC hyperparameters_optimizer.cc:582] [949/1100] Score: -0.581735 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:09.6528 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:09.6528 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:09.6541 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:09.6793 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121013 train-accuracy:0.798289 valid-loss:1.122116 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:09.8116 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615674\n",
      "[INFO 24-02-22 06:54:09.8117 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:54:09.8118 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.615674 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:09.8122 UTC hyperparameters_optimizer.cc:582] [950/1100] Score: -0.615674 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:09.8134 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:09.8134 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:09.8137 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:09.8221 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313109 train-accuracy:0.612469 valid-loss:1.273274 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:09.9396 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673735\n",
      "[INFO 24-02-22 06:54:09.9397 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:54:09.9399 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.673735 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:09.9403 UTC hyperparameters_optimizer.cc:582] [951/1100] Score: -0.673735 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:09.9427 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:09.9437 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:09.9441 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:09.9457 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096344 train-accuracy:0.804401 valid-loss:1.048784 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:09.9835 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632698\n",
      "[INFO 24-02-22 06:54:09.9835 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 06:54:09.9838 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.632698 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:09.9847 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:09.9847 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:09.9849 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:09.9859 UTC hyperparameters_optimizer.cc:582] [952/1100] Score: -0.632698 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:10.0073 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599325\n",
      "[INFO 24-02-22 06:54:10.0074 UTC gradient_boosted_trees.cc:271] Truncates the model to 81 tree(s) i.e. 81  iteration(s).\n",
      "[INFO 24-02-22 06:54:10.0075 UTC gradient_boosted_trees.cc:334] Final model num-trees:81 valid-loss:0.599325 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:10.0078 UTC hyperparameters_optimizer.cc:582] [953/1100] Score: -0.599325 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:54:10.0085 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:10.0087 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:10.0089 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:10.0210 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.140578 train-accuracy:0.612469 valid-loss:1.132094 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:10.0782 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277266 train-accuracy:0.612469 valid-loss:1.240246 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:10.1671 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674776\n",
      "[INFO 24-02-22 06:54:10.1671 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:54:10.1678 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.674776 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:10.1694 UTC hyperparameters_optimizer.cc:582] [954/1100] Score: -0.674776 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:10.1730 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:10.1730 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:10.1732 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:10.1808 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229889 train-accuracy:0.612469 valid-loss:1.198410 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:10.3027 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629865\n",
      "[INFO 24-02-22 06:54:10.3027 UTC gradient_boosted_trees.cc:271] Truncates the model to 234 tree(s) i.e. 234  iteration(s).\n",
      "[INFO 24-02-22 06:54:10.3029 UTC gradient_boosted_trees.cc:334] Final model num-trees:234 valid-loss:0.629865 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:10.3045 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:10.3046 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:10.3048 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[[INFO 24-02-22 06:54:10.3064 UTC hyperparameters_optimizer.cc:582] [955/1100] Score: -0.629865 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 06:54:10.3075 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315736 train-accuracy:0.612469 valid-loss:1.272418 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:10.4324 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633365\n",
      "[INFO 24-02-22 06:54:10.4325 UTC gradient_boosted_trees.cc:271] Truncates the model to 181 tree(s) i.e. 181  iteration(s).\n",
      "[INFO 24-02-22 06:54:10.4326 UTC gradient_boosted_trees.cc:334] Final model num-trees:181 valid-loss:0.633365 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:10.4343 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:10.4344 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:10.4346 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:10.4354 UTC hyperparameters_optimizer.cc:582] [956/1100] Score: -0.633365 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:10.4930 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313633 train-accuracy:0.612469 valid-loss:1.272635 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:10.6987 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678636\n",
      "[INFO 24-02-22 06:54:10.6987 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:10.6991 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.678636 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:10.6999 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-22 06:54:10.6999 UTC hyperparameters_optimizer.cc:582] [957/1100] Score:  24-02-22 06:54:10.6999 UTC gradient_boosted_trees.cc:1218] -0.678636 / -0.481402 HParams: Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:10.7004 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:10.7387 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.163324 train-accuracy:0.800734 valid-loss:1.114985 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:10.9057 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645969\n",
      "[INFO 24-02-22 06:54:10.9058 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:54:10.9061 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.645969 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:10.9065 UTC hyperparameters_optimizer.cc:582] [958/1100] Score: -0.645969 / -0.481402 HParams: [INFO 24-02-22 06:54:10.9070 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:10.9070 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:10.9072 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:10.9086 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083240 train-accuracy:0.806846 valid-loss:1.015231 valid-accuracy:0.821918\n",
      "fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:10.9187 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.572089 train-accuracy:0.891198 valid-loss:0.624226 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:10.9188 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 06:54:10.9188 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.622473 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:10.9198 UTC hyperparameters_optimizer.cc:582] [959/1100] Score: -0.622473 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:10.9200 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:10.9201 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:10.9209 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:10.9596 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.032689 train-accuracy:0.926650 valid-loss:1.064278 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:11.0400 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.515327\n",
      "[INFO 24-02-22 06:54:11.0400 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:54:11.0402 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.515327 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:11.0407 UTC hyperparameters_optimizer.cc:582] [960/1100] Score: -0.515327 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:11.0424 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:11.0425 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:11.0428 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:11.0590 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319141 train-accuracy:0.612469 valid-loss:1.276218 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:11.2379 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656845\n",
      "[INFO 24-02-22 06:54:11.2379 UTC gradient_boosted_trees.cc:271] Truncates the model to 152 tree(s) i.e. 152  iteration(s).\n",
      "[INFO 24-02-22 06:54:11.2381 UTC gradient_boosted_trees.cc:334] Final model num-trees:152 valid-loss:0.656845 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:11.2397 UTC hyperparameters_optimizer.cc:582] [961/1100] Score: -0.656845 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:11.2403 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:11.2404 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:11.2423 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:11.2632 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61106\n",
      "[INFO 24-02-22 06:54:11.2632 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:54:11.2635 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.611060 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:11.2644 UTC hyperparameters_optimizer.cc:582] [962/1100] Score: -0.61106 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:11.2651 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:11.2652 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:11.2672 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:11.2787 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316232 train-accuracy:0.612469 valid-loss:1.274864 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:11.2904 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.5924\n",
      "[INFO 24-02-22 06:54:11.2905 UTC gradient_boosted_trees.cc:271] Truncates the model to 184 tree(s) i.e. 184  iteration(s).\n",
      "[INFO 24-02-22 06:54:11.2906 UTC gradient_boosted_trees.cc:334] Final model num-trees:184 valid-loss:0.592400 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:11.2928 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:11.2928 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:11.2930 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:11.2953 UTC hyperparameters_optimizer.cc:582] [963/1100] Score: -0.5924 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:11.3324 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290102 train-accuracy:0.612469 valid-loss:1.246715 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:11.3409 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.072478 train-accuracy:0.834963 valid-loss:1.052914 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:11.4886 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625523\n",
      "[INFO 24-02-22 06:54:11.4892 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:54:11.4897 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.625523 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:11.4900 UTC hyperparameters_optimizer.cc:582] [964/1100] Score: -0.625523 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:11.4909 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:11.4909 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:11.4912 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:11.4968 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.143632 train-accuracy:0.783619 valid-loss:1.115904 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:54:11.6888 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667361\n",
      "[INFO 24-02-22 06:54:11.6888 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:54:11.6891 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.667361 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:11.6895 UTC hyperparameters_optimizer.cc:582] [965/1100] Score: -0.667361 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:11.6902 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:11.6903 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:11.6906 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:11.7531 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.041977 train-accuracy:0.833741 valid-loss:1.037489 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:11.7714 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647782\n",
      "[INFO 24-02-22 06:54:11.7714 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:11.7716 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.647782 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:11.7718 UTC hyperparameters_optimizer.cc:582] [966/1100] Score: -0.647782 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:11.7723 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:11.7723 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:11.7725 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:11.7946 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.057835 train-accuracy:0.841076 valid-loss:1.110262 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:12.0811 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632376\n",
      "[INFO 24-02-22 06:54:12.0816 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:54:12.0819 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.632376 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:12.0825 UTC hyperparameters_optimizer.cc:582] [967/1100] Score: -0.632376 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:12.0832 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:12.0832 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:12.0839 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:12.0879 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233396 train-accuracy:0.612469 valid-loss:1.195484 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:12.2113 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601005\n",
      "[INFO 24-02-22 06:54:12.2125 UTC gradient_boosted_trees.cc:271] Truncates the model to 85 tree(s) i.e. 85  iteration(s).\n",
      "[INFO 24-02-22 06:54:12.2127 UTC gradient_boosted_trees.cc:334] Final model num-trees:85 valid-loss:0.601005 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:12.2133 UTC hyperparameters_optimizer.cc:582] [968/1100] Score: -0.601005 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:54:12.2157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:12.2157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:12.2159 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:12.2181 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315485 train-accuracy:0.612469 valid-loss:1.274016 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:12.3392 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649887\n",
      "[INFO 24-02-22 06:54:12.3392 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:54:12.3397 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.649887 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:12.3405 UTC hyperparameters_optimizer.cc:582] [969/1100] Score: -0.649887 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:12.3412 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:12.3412 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:12.3414 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:12.3610 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.189240 train-accuracy:0.612469 valid-loss:1.138911 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:12.4617 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64819\n",
      "[INFO 24-02-22 06:54:12.4617 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:54:12.4619 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.648190 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:12.4665 UTC hyperparameters_optimizer.cc:582] [970/1100] Score: -0.64819 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:12.4668 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:12.4668 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:12.4711 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:12.4793 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290287 train-accuracy:0.612469 valid-loss:1.249979 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:12.5999 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665807\n",
      "[INFO 24-02-22 06:54:12.6000 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:54:12.6000 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.665807 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:12.6004 UTC hyperparameters_optimizer.cc:582] [971/1100] Score: -0.665807 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:54:12.6013 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:12.6014 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:12.6017 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:12.6039 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.200649 train-accuracy:0.612469 valid-loss:1.163030 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:12.7140 UTC gradient_boosted_trees.cc:1638] \tnum-trees:36 train-loss:0.506387 train-accuracy:0.925428 valid-loss:0.676068 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:12.8373 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609553\n",
      "[INFO 24-02-22 06:54:12.8373 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:54:12.8376 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.609553 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:12.8381 UTC hyperparameters_optimizer.cc:582] [972/1100] Score: -0.609553 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:12.8388 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:12.8388 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:12.8391 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:12.8521 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.486881 train-accuracy:0.914425 valid-loss:0.647843 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:12.8521 UTC gradient_boosted_trees.cc:271] Truncates the model to 284 tree(s) i.e. 284  iteration(s).\n",
      "[INFO 24-02-22 06:54:12.8522 UTC gradient_boosted_trees.cc:334] Final model num-trees:284 valid-loss:0.642933 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:12.8543 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:12.8543 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:12.8546 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:12.8553 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177301 train-accuracy:0.612469 valid-loss:1.154252 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:12.8587 UTC hyperparameters_optimizer.cc:582] [973/1100] Score: -0.642933 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:12.9059 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090131 train-accuracy:0.812958 valid-loss:1.036691 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:13.1079 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630544\n",
      "[INFO 24-02-22 06:54:13.1079 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:54:13.1082 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.630544 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:13.1086 UTC hyperparameters_optimizer.cc:582] [974/1100] Score: -0.630544 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:13.1088 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.1088 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.1091 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.1336 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684891\n",
      "[INFO 24-02-22 06:54:13.1337 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:54:13.1340 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.684891 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 06:54:13.1350 UTC hyperparameters_optimizer.cc:582] [975/1100] Score: -0.684891 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 06:54:13.1353 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.1354 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.1358 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.1469 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263067 train-accuracy:0.612469 valid-loss:1.241937 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:13.1872 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226598 train-accuracy:0.612469 valid-loss:1.197129 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:13.5021 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.581592\n",
      "[INFO 24-02-22 06:54:13.5021 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:54:13.5022 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.581592 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:13.5024 UTC hyperparameters_optimizer.cc:582] [976/1100] Score: -0.581592 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:13.5030 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.5030 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.5033 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.5061 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.173925 train-accuracy:0.612469 valid-loss:1.139824 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:13.5287 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.733343\n",
      "[INFO 24-02-22 06:54:13.5287 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:13.5305 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:13.5305 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.733343 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:13.5320 UTC hyperparameters_optimizer.cc:582] [977/1100] Score: -0.733343 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:13.5364 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.5365 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.5367 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.5385 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.123756 train-accuracy:0.784841 valid-loss:1.085482 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:13.6360 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601035\n",
      "[INFO 24-02-22 06:54:13.6372 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:54:13.6374 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.601035 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:13.6381 UTC hyperparameters_optimizer.cc:582] [978/1100] Score: -0.601035 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:13.6388 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.6388 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.6390 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.6412 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090171 train-accuracy:0.847188 valid-loss:1.036789 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:13.6516 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680696\n",
      "[INFO 24-02-22 06:54:13.6516 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:54:13.6621 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.680696 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:13.6629 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.6629 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.6631 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.6648 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240755 train-accuracy:0.612469 valid-loss:1.202444 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:13.6688 UTC hyperparameters_optimizer.cc:582] [979/1100] Score: -0.680696 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:13.7526 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.707047\n",
      "[INFO 24-02-22 06:54:13.7528 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:54:13.7536 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.707047 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:13.7539 UTC hyperparameters_optimizer.cc:582] [980/1100] Score: -0.707047 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:13.7577 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.7577 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.7579 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.7820 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.071359 train-accuracy:0.803178 valid-loss:1.068892 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:13.8099 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635759\n",
      "[INFO 24-02-22 06:54:13.8099 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:54:13.8100 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.635759 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:13.8103 UTC hyperparameters_optimizer.cc:582] [981/1100] Score: -0.635759 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:13.8108 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.8108 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.8126 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.8177 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317658 train-accuracy:0.612469 valid-loss:1.276104 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:13.9283 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.601542\n",
      "[INFO 24-02-22 06:54:13.9283 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:54:13.9286 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.601542 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:13.9428 UTC hyperparameters_optimizer.cc:582] [982/1100] Score: -0.601542 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:13.9435 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:13.9435 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:13.9441 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:13.9612 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.135046 train-accuracy:0.799511 valid-loss:1.086486 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:14.2212 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690722\n",
      "[INFO 24-02-22 06:54:14.2212 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.2214 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.690722 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:14.2216 UTC hyperparameters_optimizer.cc:582] [983/1100] Score: -0.690722 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:14.2229 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.2229 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.2232 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.2260 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315701 train-accuracy:0.612469 valid-loss:1.275265 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:14.5455 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671112\n",
      "[INFO 24-02-22 06:54:14.5455 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.5457 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.671112 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:14.5466 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.5466 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.5468 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.5470 UTC hyperparameters_optimizer.cc:582] [984/1100] Score: -0.671112 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:14.5725 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.027043 train-accuracy:0.864303 valid-loss:1.034509 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:14.6645 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690196\n",
      "[INFO 24-02-22 06:54:14.6646 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.6660 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.690196 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:14.6697 UTC hyperparameters_optimizer.cc:582] [985/1100] Score: -0.690196 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:14.6782 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.6783 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.6785 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.6787 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615573\n",
      "[INFO 24-02-22 06:54:14.6788 UTC gradient_boosted_trees.cc:271] Truncates the model to 229 tree(s) i.e. 229  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.6789 UTC gradient_boosted_trees.cc:334] Final model num-trees:229 valid-loss:0.615573 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:14.6796 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319558 train-accuracy:0.612469 valid-loss:1.278456 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:14.6821 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.6822 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.6823 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.6847 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.148455 train-accuracy:0.734719 valid-loss:1.128905 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:54:14.6854 UTC hyperparameters_optimizer.cc:582] [986/1100] Score: -0.615573 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:54:14.7413 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.714483\n",
      "[INFO 24-02-22 06:54:14.7415 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.7419 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.714483 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:14.7426 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.7426 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.7429 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.7453 UTC hyperparameters_optimizer.cc:582] [987/1100] Score: -0.714483 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:14.7455 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284177 train-accuracy:0.612469 valid-loss:1.249931 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:14.8129 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.556892\n",
      "[INFO 24-02-22 06:54:14.8129 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.8132 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.556892 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:14.8135 UTC hyperparameters_optimizer.cc:582] [988/1100] Score: -0.556892 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:14.8142 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.8142 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.8146 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.8439 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.045678 train-accuracy:0.832518 valid-loss:1.047249 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:14.8520 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639476\n",
      "[INFO 24-02-22 06:54:14.8521 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.8524 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.639476 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:14.8533 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.8533 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.8535 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.8551 UTC hyperparameters_optimizer.cc:582] [989/1100] Score: -0.639476 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:14.8792 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313396 train-accuracy:0.612469 valid-loss:1.273092 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:14.9687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.603410 train-accuracy:0.883863 valid-loss:0.653436 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:14.9687 UTC gradient_boosted_trees.cc:271] Truncates the model to 272 tree(s) i.e. 272  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.9688 UTC gradient_boosted_trees.cc:334] Final model num-trees:272 valid-loss:0.650073 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:14.9696 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.9696 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.9698 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.9743 UTC hyperparameters_optimizer.cc:582] [990/1100] Score: -0.650073 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:14.9782 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.733417 train-accuracy:0.847188 valid-loss:0.682239 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:14.9782 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 06:54:14.9782 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.681858 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:14.9786 UTC hyperparameters_optimizer.cc:582] [991/1100] Score: -0.681858 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:14.9790 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:14.9790 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:14.9796 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:14.9803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278974 train-accuracy:0.612469 valid-loss:1.241363 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:14.9927 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156574 train-accuracy:0.743276 valid-loss:1.104702 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:54:15.0859 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.610086\n",
      "[INFO 24-02-22 06:54:15.0912 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:54:15.0913 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.610086 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:15.0916 UTC hyperparameters_optimizer.cc:582] [992/1100] Score: -0.610086 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:15.0929 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:15.0929 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:15.0932 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.1005 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294047 train-accuracy:0.612469 valid-loss:1.248952 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:15.2280 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621417\n",
      "[INFO 24-02-22 06:54:15.2280 UTC gradient_boosted_trees.cc:271] Truncates the model to 140 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 24-02-22 06:54:15.2282 UTC gradient_boosted_trees.cc:334] Final model num-trees:140 valid-loss:0.621417 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:15.2316 UTC hyperparameters_optimizer.cc:582] [993/1100] Score: -0.621417 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:15.2351 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:15.2351 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:15.2353 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.2884 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266350 train-accuracy:0.612469 valid-loss:1.229941 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:15.4491 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636313\n",
      "[INFO 24-02-22 06:54:15.4491 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:15.4497 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.636313 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:15.4501 UTC hyperparameters_optimizer.cc:582] [994/1100] Score: -0.636313 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:15.4510 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:15.4511 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:15.4513 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.4539 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286360 train-accuracy:0.612469 valid-loss:1.247134 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:15.5870 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675323\n",
      "[INFO 24-02-22 06:54:15.5871 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:15.5874 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:15.5874 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.675323 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:15.5881 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[[INFOINFO 24-02-22 06:54:15.5883 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[ 24-02-22 06:54:15.5883 UTC hyperparameters_optimizer.cc:582] [995/1100] Score: -0.675323 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 06:54:15.5891 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.5934 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.068450 train-accuracy:0.836186 valid-loss:1.087997 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:54:15.7593 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684289\n",
      "[INFO 24-02-22 06:54:15.7593 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:54:15.7620 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.684289 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:15.7625 UTC hyperparameters_optimizer.cc:582] [996/1100] Score: -0.684289 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:15.7627 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:15.7627 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:15.7633 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.7764 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635281\n",
      "[INFO 24-02-22 06:54:15.7765 UTC gradient_boosted_trees.cc:271] Truncates the model to 93 tree(s) i.e. 93  iteration(s).\n",
      "[INFO 24-02-22 06:54:15.7767 UTC gradient_boosted_trees.cc:334] Final model num-trees:93 valid-loss:0.635281 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:15.7775 UTC hyperparameters_optimizer.cc:582] [997/1100] Score: -0.635281 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:15.7784 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:15.7785 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:15.7788 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.7808 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669302\n",
      "[INFO 24-02-22 06:54:15.7808 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:15.7818 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:15.7818 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.669302 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:15.7844 UTC hyperparameters_optimizer.cc:582] [998/1100] Score: -0.669302 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:15.7903 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313011 train-accuracy:0.612469 valid-loss:1.271220 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:15.7920 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:15.7920 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:15.7923 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.8215 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.216907 train-accuracy:0.612469 valid-loss:1.196765 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:15.8418 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637258\n",
      "[INFO 24-02-22 06:54:15.8419 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:54:15.8425 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.637258 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:15.8434 UTC hyperparameters_optimizer.cc:582] [999/1100] Score: -0.637258 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:15.8441 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:15.8441 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:15.8450 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.8533 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277394 train-accuracy:0.612469 valid-loss:1.245127 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:15.8553 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649522\n",
      "[INFO 24-02-22 06:54:15.8553 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:54:15.8573 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.649522 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:15.8576 UTC hyperparameters_optimizer.cc:582] [1000/1100] Score: -0.649522 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:15.8589 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:15.8589 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:15.8592 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:15.8602 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.082855 train-accuracy:0.827628 valid-loss:1.041407 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:15.8733 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114873 train-accuracy:0.784841 valid-loss:1.074716 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:16.2760 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617197\n",
      "[INFO 24-02-22 06:54:16.2760 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:54:16.2763 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.617197 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:16.2766 UTC hyperparameters_optimizer.cc:582] [1001/1100] Score: -0.617197 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:16.2772 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:16.2772 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:16.2774 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:16.3745 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311249 train-accuracy:0.612469 valid-loss:1.270333 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:16.6001 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.709948 train-accuracy:0.852078 valid-loss:0.659043 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:16.6002 UTC gradient_boosted_trees.cc:271] Truncates the model to 297 tree(s) i.e. 297  iteration(s).\n",
      "[INFO 24-02-22 06:54:16.6002 UTC gradient_boosted_trees.cc:334] Final model num-trees:297 valid-loss:0.658049 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:16.6006 UTC hyperparameters_optimizer.cc:582] [1002/1100] Score: -0.658049 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:16.6015 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:16.6015 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:16.6017 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:16.6095 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664568\n",
      "[INFO 24-02-22 06:54:16.6096 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:54:16.6099 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.664568 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:16.6110 UTC hyperparameters_optimizer.cc:582] [1003/1100] Score: -0.664568 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:16.6118 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.118992 train-accuracy:0.788509 valid-loss:1.095532 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:16.6133 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:16.6135 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:16.6140 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:16.6259 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243228 train-accuracy:0.612469 valid-loss:1.201037 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:16.6365 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.522856\n",
      "[INFO 24-02-22 06:54:16.6366 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 06:54:16.6368 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.522856 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:16.6374 UTC hyperparameters_optimizer.cc:582] [1004/1100] Score: -0.522856 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:16.6385 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:16.6385 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:16.6388 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:16.6420 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081088 train-accuracy:0.828851 valid-loss:1.052346 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:16.8656 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679006\n",
      "[INFO 24-02-22 06:54:16.8656 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:16.8661 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.679006 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:16.8667 UTC hyperparameters_optimizer.cc:582] [1005/1100] Score: -0.679006 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:16.8672 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:16.8672 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:16.8674 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:16.8747 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.037552 train-accuracy:0.854523 valid-loss:1.017783 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:17.0233 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648079\n",
      "[INFO 24-02-22 06:54:17.0234 UTC gradient_boosted_trees.cc:271] Truncates the model to 247 tree(s) i.e. 247  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.0235 UTC gradient_boosted_trees.cc:334] Final model num-trees:247 valid-loss:0.648079 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:17.0239 UTC hyperparameters_optimizer.cc:582] [1006/1100] Score: -0.648079 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:17.0250 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.0250 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.0253 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.0472 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.117680 train-accuracy:0.795844 valid-loss:1.137560 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 06:54:17.0990 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631424\n",
      "[INFO 24-02-22 06:54:17.0990 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.0995 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.631424 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:17.0998 UTC hyperparameters_optimizer.cc:582] [1007/1100] Score: -0.631424 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:17.1010 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.1010 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.1012 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.1096 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.035918 train-accuracy:0.847188 valid-loss:1.027447 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:17.2032 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691297\n",
      "[INFO 24-02-22 06:54:17.2033 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:17.2036 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:17.2036 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.691297 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:17.2043 UTC hyperparameters_optimizer.cc:582] [1008/1100] Score: -0.691297 / -0.481402 HParams: [INFO 24-02-22 06:54:17.2043 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.2044 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:17.2048 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.2181 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.002003 train-accuracy:0.855746 valid-loss:1.023652 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:17.2346 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635562\n",
      "[INFO 24-02-22 06:54:17.2346 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.2356 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.635562 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:17.2365 UTC hyperparameters_optimizer.cc:582] [1009/1100] Score: -0.635562 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:17.2396 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.2397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.2400 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.2427 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.139137 train-accuracy:0.784841 valid-loss:1.095168 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 06:54:17.2548 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663696\n",
      "[INFO 24-02-22 06:54:17.2549 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.2555 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.663696 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:17.2563 UTC hyperparameters_optimizer.cc:582] [1010/1100] Score: -0.663696 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:17.2596 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.2597 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.2598 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.2620 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083001 train-accuracy:0.815403 valid-loss:1.040922 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:17.3573 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679546\n",
      "[INFO 24-02-22 06:54:17.3573 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.3582 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.679546 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:17.3588 UTC hyperparameters_optimizer.cc:582] [1011/1100] Score: -0.679546 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:17.3598 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.3600 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.3603 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.3612 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257794 train-accuracy:0.612469 valid-loss:1.217043 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:17.3747 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619382\n",
      "[INFO 24-02-22 06:54:17.3748 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.3751 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.619382 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:17.3758 UTC hyperparameters_optimizer.cc:582] [1012/1100] Score: -0.619382 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:17.3768 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.3769 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.3773 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.4687 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660165\n",
      "[INFO 24-02-22 06:54:17.4687 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.4688 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.660165 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:17.4691 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.4692 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.4693 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.4710 UTC hyperparameters_optimizer.cc:582] [1013/1100] Score: -0.660165 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:17.4846 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261416 train-accuracy:0.612469 valid-loss:1.227801 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:17.4869 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.068620 train-accuracy:0.844743 valid-loss:1.092628 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:17.8237 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694163\n",
      "[INFO 24-02-22 06:54:17.8237 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.8244 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.694163 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:17.8250 UTC hyperparameters_optimizer.cc:582] [1014/1100] Score: -0.694163 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:17.8272 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.8274 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.8276 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.8337 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.197538 train-accuracy:0.612469 valid-loss:1.157022 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:17.8481 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.732395\n",
      "[INFO 24-02-22 06:54:17.8481 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:17.8495 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.732395 valid-accuracy:0.835616\n",
      "[[INFO 24-02-22 06:54:17.8509 UTC hyperparameters_optimizer.cc:582] [1015/1100] Score: -0.732395 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 06:54:17.8512 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:17.8514 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:17.8520 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:17.8587 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.318506 train-accuracy:0.612469 valid-loss:1.274627 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:18.2078 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651572\n",
      "[INFO 24-02-22 06:54:18.2078 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.2082 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.651572 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:18.2088 UTC hyperparameters_optimizer.cc:582] [1016/1100] Score: -0.651572 / -0.481402 HParams: [fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 06:54:18.2093 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.2093 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.2097 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.2106 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319109 train-accuracy:0.612469 valid-loss:1.277920 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:18.2486 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640926\n",
      "[INFO 24-02-22 06:54:18.2495 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.2504 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.640926 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:18.2512 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.2512 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.2514 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.2542 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.049482 train-accuracy:0.841076 valid-loss:1.028042 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:18.2557 UTC hyperparameters_optimizer.cc:582] [1017/1100] Score: -0.640926 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:18.2767 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655405\n",
      "[INFO 24-02-22 06:54:18.2767 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.2769 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.655405 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:18.2775 UTC hyperparameters_optimizer.cc:582] [1018/1100] Score: -0.655405 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:18.2780 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.2780 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.2787 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.2810 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.154493 train-accuracy:0.784841 valid-loss:1.101644 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:18.3177 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656602\n",
      "[INFO 24-02-22 06:54:18.3177 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.3178 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.656602 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:18.3182 UTC hyperparameters_optimizer.cc:582] [1019/1100] Score: -0.656602 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:18.3188 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.3188 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.3192 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.3241 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.169949 train-accuracy:0.767726 valid-loss:1.123228 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 06:54:18.4370 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.608399\n",
      "[INFO 24-02-22 06:54:18.4371 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.4373 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.608399 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:18.4378 UTC hyperparameters_optimizer.cc:582] [1020/1100] Score: -0.608399 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:18.4395 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.4396 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.4398 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.4495 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.725359 train-accuracy:0.847188 valid-loss:0.680279 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:18.4503 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.4503 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.680279 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:18.4510 UTC hyperparameters_optimizer.cc:582] [1021/1100] Score: -0.680279 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:18.4521 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.4521 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.4524 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.4590 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.106217 train-accuracy:0.821516 valid-loss:1.075645 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:18.4625 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62921\n",
      "[INFO 24-02-22 06:54:18.4625 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.4625 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.629210 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:18.4627 UTC hyperparameters_optimizer.cc:582] [1022/1100] Score: -0.62921 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:18.4631 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.4631 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.4634 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.4657 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132805 train-accuracy:0.784841 valid-loss:1.081558 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:18.4766 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631446\n",
      "[INFO 24-02-22 06:54:18.4767 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.4770 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.631446 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:18.4777 UTC hyperparameters_optimizer.cc:582] [1023/1100] Score: -0.631446 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:18.4781 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.4781 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.4785 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.4943 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240020 train-accuracy:0.612469 valid-loss:1.197260 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:18.5070 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.015034 train-accuracy:0.867971 valid-loss:0.990674 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:18.5452 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629275\n",
      "[INFO 24-02-22 06:54:18.5452 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.5470 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.629275 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:18.5477 UTC hyperparameters_optimizer.cc:582] [1024/1100] Score: -0.629275 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:18.5491 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.5491 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.5493 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.5612 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280926 train-accuracy:0.612469 valid-loss:1.250701 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:18.7856 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.574241\n",
      "[INFO 24-02-22 06:54:18.7857 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.7857 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.574241 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:18.7861 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.7861 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.7864 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.7865 UTC hyperparameters_optimizer.cc:582] [1025/1100] Score: -0.574241 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:18.7897 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177595 train-accuracy:0.612469 valid-loss:1.159770 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:18.8323 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688345\n",
      "[INFO 24-02-22 06:54:18.8324 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.8341 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.688345 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:18.8372 UTC hyperparameters_optimizer.cc:582] [1026/1100] Score: -0.688345 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:18.8458 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.8460 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.8466 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.8586 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311988 train-accuracy:0.612469 valid-loss:1.272786 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:18.9204 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.596278\n",
      "[INFO 24-02-22 06:54:18.9205 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:54:18.9206 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.596278 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:18.9212 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:18.9212 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:18.9214 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:18.9221 UTC hyperparameters_optimizer.cc:582] [1027/1100] Score: -0.596278 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:18.9511 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.217806 train-accuracy:0.612469 valid-loss:1.192019 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:19.1024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61785\n",
      "[INFO 24-02-22 06:54:19.1025 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 06:54:19.1029 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.617850 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:19.1043 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:19.1043 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:19.1044 UTC hyperparameters_optimizer.cc:582] [1028/1100] Score: -0.61785 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:19.1048 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:19.1152 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63465\n",
      "[INFO 24-02-22 06:54:19.1152 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:54:19.1255 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.634650 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:19.1258 UTC hyperparameters_optimizer.cc:582] [1029/1100] Score: -0.63465 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:19.1263 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:19.1263 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:19.1267 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:19.1428 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.183311 train-accuracy:0.629584 valid-loss:1.126953 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:19.1879 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.150824 train-accuracy:0.612469 valid-loss:1.131388 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:19.6196 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646249\n",
      "[INFO 24-02-22 06:54:19.6197 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:54:19.6198 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.646249 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:19.6201 UTC hyperparameters_optimizer.cc:582] [1030/1100] Score: -0.646249 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:19.6205 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:19.6205 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:19.6208 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:19.6693 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224977 train-accuracy:0.612469 valid-loss:1.177606 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:19.6931 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648426\n",
      "[INFO 24-02-22 06:54:19.6932 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:54:19.6935 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.648426 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:19.6946 UTC hyperparameters_optimizer.cc:582] [1031/1100] Score: -0.648426 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:19.6989 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:19.6989 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:19.7017 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:19.7045 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063691 train-accuracy:0.811736 valid-loss:1.058209 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:19.8548 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605278\n",
      "[INFO 24-02-22 06:54:19.8549 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 06:54:19.8550 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.605278 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:19.8552 UTC hyperparameters_optimizer.cc:582] [1032/1100] Score: -0.605278 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:19.8558 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:19.8559 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:19.8560 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:19.8579 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162135 train-accuracy:0.784841 valid-loss:1.127103 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:19.8667 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.69671\n",
      "[INFO 24-02-22 06:54:19.8668 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:19.8670 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:19.8670 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.696710 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:19.8672 UTC hyperparameters_optimizer.cc:582] [1033/1100] Score: -0.69671 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:19.8681 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:19.8682 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:19.8686 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:19.8743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221248 train-accuracy:0.612469 valid-loss:1.166735 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:20.0961 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651958\n",
      "[INFO 24-02-22 06:54:20.0961 UTC gradient_boosted_trees.cc:271] Truncates the model to 195 tree(s) i.e. 195  iteration(s).\n",
      "[INFO 24-02-22 06:54:20.0963 UTC gradient_boosted_trees.cc:334] Final model num-trees:195 valid-loss:0.651958 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:20.0984 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:20.0984 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:20.0987 UTC hyperparameters_optimizer.cc:582] [1034/1100] Score: -0.651958 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:20.1013 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:20.1676 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.053974 train-accuracy:0.847188 valid-loss:1.067740 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:20.2869 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.60375\n",
      "[INFO 24-02-22 06:54:20.2870 UTC gradient_boosted_trees.cc:271] Truncates the model to 153 tree(s) i.e. 153  iteration(s).\n",
      "[INFO 24-02-22 06:54:20.2870 UTC gradient_boosted_trees.cc:334] Final model num-trees:153 valid-loss:0.603750 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:20.2874 UTC hyperparameters_optimizer.cc:582] [1035/1100] Score: -0.60375 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:20.2879 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:20.2879 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:20.2881 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:20.3499 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281393 train-accuracy:0.612469 valid-loss:1.243031 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:20.4800 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.693205 train-accuracy:0.853301 valid-loss:0.660203 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:20.4800 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:54:20.4800 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.660203 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:20.4803 UTC hyperparameters_optimizer.cc:582] [1036/1100] Score: -0.660203 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:20.4806 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:20.4806 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:20.4810 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:20.5069 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060407 train-accuracy:0.845966 valid-loss:1.036236 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:20.8031 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63121\n",
      "[INFO 24-02-22 06:54:20.8032 UTC gradient_boosted_trees.cc:271] Truncates the model to 93 tree(s) i.e. 93  iteration(s).\n",
      "[INFO 24-02-22 06:54:20.8032 UTC gradient_boosted_trees.cc:334] Final model num-trees:93 valid-loss:0.631210 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:20.8034 UTC hyperparameters_optimizer.cc:582] [1037/1100] Score: -0.63121 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:20.8038 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:20.8038 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:20.8040 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:20.8209 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.179439 train-accuracy:0.612469 valid-loss:1.134966 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:21.2443 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.400453 train-accuracy:0.938875 valid-loss:0.585908 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:21.2443 UTC gradient_boosted_trees.cc:271] Truncates the model to 275 tree(s) i.e. 275  iteration(s).\n",
      "[INFO 24-02-22 06:54:21.2444 UTC gradient_boosted_trees.cc:334] Final model num-trees:275 valid-loss:0.579912 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:21.2450 UTC hyperparameters_optimizer.cc:582] [1038/1100] Score: -0.579912 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:21.2481 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:21.2484 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:21.2506 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:21.2629 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156101 train-accuracy:0.765281 valid-loss:1.125540 valid-accuracy:0.726027\n",
      "[INFO 24-02-22 06:54:21.3198 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655094\n",
      "[INFO 24-02-22 06:54:21.3199 UTC gradient_boosted_trees.cc:271] Truncates the model to 162 tree(s) i.e. 162  iteration(s).\n",
      "[INFO 24-02-22 06:54:21.3200 UTC gradient_boosted_trees.cc:334] Final model num-trees:162 valid-loss:0.655094 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:21.3210 UTC hyperparameters_optimizer.cc:582] [1039/1100] Score: -0.655094 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:21.3214 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:21.3214 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:21.3216 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:21.3324 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.086712 train-accuracy:0.823961 valid-loss:1.083404 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 06:54:21.4627 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.599897\n",
      "[INFO 24-02-22 06:54:21.4627 UTC gradient_boosted_trees.cc:271] Truncates the model to 212 tree(s) i.e. 212  iteration(s).\n",
      "[INFO 24-02-22 06:54:21.4630 UTC gradient_boosted_trees.cc:334] Final model num-trees:212 valid-loss:0.599897 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:21.4691 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:21.4691 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-22 06:54:21.4694 UTC hyperparameters_optimizer.cc:582] [1040/1100] Score: -0.599897 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }INFO 24-02-22 06:54:21.4696 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "\n",
      "[INFO 24-02-22 06:54:21.4953 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.566341\n",
      "[INFO 24-02-22 06:54:21.4955 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:54:21.4958 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.566341 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:21.4969 UTC hyperparameters_optimizer.cc:582] [1041/1100] Score: -0.566341 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:21.4974 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:21.4974 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:21.4983 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:21.5054 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.273872 train-accuracy:0.612469 valid-loss:1.243293 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:21.5532 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191816 train-accuracy:0.612469 valid-loss:1.148917 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:21.7037 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609728\n",
      "[INFO 24-02-22 06:54:21.7037 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:21.7041 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.609728 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:21.7049 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:21.7049 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:21.7051 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:21.7087 UTC hyperparameters_optimizer.cc:582] [1042/1100] Score: -0.609728 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:21.7294 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311348 train-accuracy:0.612469 valid-loss:1.272928 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:21.7471 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671655\n",
      "[INFO 24-02-22 06:54:21.7472 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:54:21.7475 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.671655 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:21.7479 UTC hyperparameters_optimizer.cc:582] [1043/1100] Score: -0.671655 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:21.7489 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:21.7489 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:21.7494 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:21.7714 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282949 train-accuracy:0.612469 valid-loss:1.243268 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:21.8212 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68351\n",
      "[INFO 24-02-22 06:54:21.8213 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:21.8215 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.683510 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:21.8217 UTC hyperparameters_optimizer.cc:582] [1044/1100] Score: -0.68351 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:21.8226 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:21.8231 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:21.8237 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:21.8602 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112600 train-accuracy:0.788509 valid-loss:1.099957 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:21.8648 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.559248\n",
      "[INFO 24-02-22 06:54:21.8649 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:54:21.8652 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.559248 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:21.8657 UTC hyperparameters_optimizer.cc:582] [1045/1100] Score: -0.559248 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:21.8663 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:21.8663 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:21.8682 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:21.8993 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.169723 train-accuracy:0.612469 valid-loss:1.125963 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:22.3146 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651177\n",
      "[INFO 24-02-22 06:54:22.3147 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:22.3149 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:22.3149 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.651177 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:22.3151 UTC hyperparameters_optimizer.cc:582] [1046/1100] Score: -0.651177 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:22.3158 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:22.3158 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:22.3161 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:22.3192 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248605 train-accuracy:0.612469 valid-loss:1.205651 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:22.6001 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.611864\n",
      "[INFO 24-02-22 06:54:22.6002 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 06:54:22.6005 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.611864 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:22.6012 UTC hyperparameters_optimizer.cc:582] [1047/1100] Score: -0.611864 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:22.6029 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:22.6031 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:22.6034 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:22.6097 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230749 train-accuracy:0.612469 valid-loss:1.190341 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:22.6794 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.595714\n",
      "[INFO 24-02-22 06:54:22.6795 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:54:22.6797 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.595714 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:22.6802 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:22.6802 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:22.6804 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:22.6821 UTC hyperparameters_optimizer.cc:582] [1048/1100] Score: -0.595714 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:22.6863 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.147500 train-accuracy:0.784841 valid-loss:1.107030 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:22.7016 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.308004 train-accuracy:0.959658 valid-loss:0.601009 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:22.7016 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 06:54:22.7016 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.600869 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:22.7061 UTC hyperparameters_optimizer.cc:582] [1049/1100] Score: -0.600869 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:22.7080 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:22.7080 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:22.7111 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:22.7114 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647179\n",
      "[INFO 24-02-22 06:54:22.7115 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:22.7118 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.647179 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:22.7125 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:22.7125 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:22.7127 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:22.7154 UTC hyperparameters_optimizer.cc:582] [1050/1100] Score: -0.647179 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:22.7227 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.106625 train-accuracy:0.784841 valid-loss:1.066596 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:22.7351 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070862 train-accuracy:0.867971 valid-loss:1.018423 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:23.0331 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635304\n",
      "[INFO 24-02-22 06:54:23.0354 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:54:23.0356 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.635304 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:23.0360 UTC hyperparameters_optimizer.cc:582] [1051/1100] Score: -0.635304 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:23.0380 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:23.0381 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:23.0383 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:23.0410 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638244\n",
      "[INFO 24-02-22 06:54:23.0410 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:54:23.0411 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.638244 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:23.0414 UTC hyperparameters_optimizer.cc:582] [1052/1100] Score: -0.638244 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:23.0420 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:23.0421 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:23.0422 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:23.0485 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.053643 train-accuracy:0.834963 valid-loss:1.046706 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:23.0610 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278698 train-accuracy:0.612469 valid-loss:1.248153 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:23.3181 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659034\n",
      "[INFO 24-02-22 06:54:23.3181 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:54:23.3184 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.659034 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:23.3186 UTC hyperparameters_optimizer.cc:582] [1053/1100] Score: -0.659034 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:23.3194 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:23.3194 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:23.3196 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:23.3274 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666694\n",
      "[INFO 24-02-22 06:54:23.3292 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:54:23.3295 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.666694 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:23.3297 UTC hyperparameters_optimizer.cc:582] [1054/1100] Score: -0.666694 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:23.3302 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:23.3303 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:23.3306 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:23.3510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.216044 train-accuracy:0.612469 valid-loss:1.192423 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:23.4058 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312247 train-accuracy:0.612469 valid-loss:1.272012 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:23.4533 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652707\n",
      "[INFO 24-02-22 06:54:23.4533 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:54:23.4536 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.652707 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:23.4545 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:23.4545 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:23.4547 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:23.4587 UTC hyperparameters_optimizer.cc:582] [1055/1100] Score: -0.652707 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:23.5092 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280571 train-accuracy:0.612469 valid-loss:1.245611 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:23.6105 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649608\n",
      "[INFO 24-02-22 06:54:23.6105 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:23.6108 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:23.6108 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.649608 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:23.6111 UTC hyperparameters_optimizer.cc:582] [1056/1100] Score: -0.649608 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:23.6117 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:23.6117 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:23.6120 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:23.6387 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180787 train-accuracy:0.612469 valid-loss:1.161048 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:23.9106 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.534674\n",
      "[INFO 24-02-22 06:54:23.9107 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:54:23.9110 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.534674 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:23.9117 UTC hyperparameters_optimizer.cc:582] [1057/1100] Score: -0.534674 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:23.9130 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:23.9130 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:23.9134 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:23.9218 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588889\n",
      "[INFO 24-02-22 06:54:23.9219 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:54:23.9221 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.588889 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:23.9224 UTC hyperparameters_optimizer.cc:582] [1058/1100] Score: -0.588889 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:23.9236 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:23.9237 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:23.9238 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:23.9283 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.167735 train-accuracy:0.750611 valid-loss:1.124655 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:54:23.9413 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230139 train-accuracy:0.612469 valid-loss:1.205618 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:24.1494 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665817\n",
      "[INFO 24-02-22 06:54:24.1495 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:54:24.1496 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.665817 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:24.1502 UTC hyperparameters_optimizer.cc:582] [1059/1100] Score: -0.665817 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:24.1519 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:24.1519 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:24.1521 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:24.1591 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278974 train-accuracy:0.612469 valid-loss:1.241363 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:24.2048 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681593\n",
      "[INFO 24-02-22 06:54:24.2049 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 06:54:24.2087 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.681593 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:24.2101 UTC hyperparameters_optimizer.cc:582] [1060/1100] Score: -0.681593 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:24.2107 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:24.2107 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:24.2117 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:24.2166 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190927 train-accuracy:0.612469 valid-loss:1.150892 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:24.2533 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.611919\n",
      "[INFO 24-02-22 06:54:24.2543 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:54:24.2544 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.611919 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:24.2547 UTC hyperparameters_optimizer.cc:582] [1061/1100] Score: -0.611919 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:24.2557 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:24.2557 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:24.2559 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:24.2809 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226079 train-accuracy:0.612469 valid-loss:1.181416 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:24.4524 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614729\n",
      "[INFO 24-02-22 06:54:24.4524 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:54:24.4526 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.614729 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:24.4532 UTC hyperparameters_optimizer.cc:582] [1062/1100] Score: -0.614729 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:24.4539 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:24.4539 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:24.4541 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:24.4757 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225554 train-accuracy:0.612469 valid-loss:1.186913 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:24.5905 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.700034\n",
      "[INFO 24-02-22 06:54:24.5906 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:54:24.5912 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.700034 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:24.5916 UTC hyperparameters_optimizer.cc:582] [1063/1100] Score: -0.700034 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:24.5923 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:24.5923 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:24.5929 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:24.6111 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221185 train-accuracy:0.612469 valid-loss:1.197297 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:24.9297 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641797\n",
      "[INFO 24-02-22 06:54:24.9297 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:54:24.9299 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.641797 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:24.9310 UTC hyperparameters_optimizer.cc:582] [1064/1100] Score: -0.641797 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:24.9316 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:24.9316 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:24.9331 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:24.9337 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635315\n",
      "[INFO 24-02-22 06:54:24.9337 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:54:24.9340 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.635315 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:24.9350 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:24.9350 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:24.9352 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:24.9353 UTC hyperparameters_optimizer.cc:582] [1065/1100] Score: -0.635315 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:24.9390 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155679 train-accuracy:0.777506 valid-loss:1.093022 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:24.9411 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.129831 train-accuracy:0.777506 valid-loss:1.051644 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 06:54:25.2237 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646568\n",
      "[INFO 24-02-22 06:54:25.2237 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:54:25.2240 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.646568 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:25.2247 UTC hyperparameters_optimizer.cc:582] [1066/1100] Score: -0.646568 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:25.2265 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:25.2265 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:25.2269 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:25.2349 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146727 train-accuracy:0.784841 valid-loss:1.113953 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:25.4954 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.620043\n",
      "[INFO 24-02-22 06:54:25.4954 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:54:25.4955 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.620043 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:25.4958 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:25.4958 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:25.4960 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:25.4987 UTC hyperparameters_optimizer.cc:582] [1067/1100] Score: -0.620043 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:25.5136 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224089 train-accuracy:0.612469 valid-loss:1.197309 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:25.5231 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636212\n",
      "[INFO 24-02-22 06:54:25.5247 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 06:54:25.5249 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.636212 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:25.5251 UTC hyperparameters_optimizer.cc:582] [1068/1100] Score: -0.636212 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:25.5256 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:25.5257 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:25.5259 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:25.5943 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277402 train-accuracy:0.612469 valid-loss:1.237396 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:25.6397 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.610658\n",
      "[INFO 24-02-22 06:54:25.6397 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:54:25.6398 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.610658 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 06:54:25.6401 UTC hyperparameters_optimizer.cc:582] [1069/1100] Score: -0.610658 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:25.6405 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:25.6405 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:25.6408 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:25.6538 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.596326\n",
      "[INFO 24-02-22 06:54:25.6540 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:54:25.6544 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.596326 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:25.6549 UTC hyperparameters_optimizer.cc:582] [1070/1100] Score: -0.596326 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:25.6630 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[[INFO 24-02-22 06:54:25.6641 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66679\n",
      "[INFO 24-02-22 06:54:25.6642 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "INFO 24-02-22 06:54:25.6642 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:25.6651 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:25.6691 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.666790 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:25.6712 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:25.6712 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:25.6714 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:25.6733 UTC hyperparameters_optimizer.cc:582] [1071/1100] Score: -0.66679 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:25.6836 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085460 train-accuracy:0.816626 valid-loss:1.061979 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 06:54:25.6874 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229626 train-accuracy:0.612469 valid-loss:1.192820 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:25.7082 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092667 train-accuracy:0.794621 valid-loss:1.059779 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:25.8124 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657965\n",
      "[INFO 24-02-22 06:54:25.8124 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:54:25.8127 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.657965 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:25.8136 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:25.8137 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:25.8139 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:25.8156 UTC hyperparameters_optimizer.cc:582] [1072/1100] Score: -0.657965 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:25.8699 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656367\n",
      "[INFO 24-02-22 06:54:25.8699 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:54:25.8701 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.656367 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:25.8709 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:25.8709 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:25.8711 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:25.8740 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235569 train-accuracy:0.612469 valid-loss:1.190927 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:25.8757 UTC hyperparameters_optimizer.cc:582] [1073/1100] Score: -0.656367 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:25.8773 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188153 train-accuracy:0.612469 valid-loss:1.161301 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:26.1440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624528\n",
      "[INFO 24-02-22 06:54:26.1440 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:54:26.1443 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.624528 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:26.1446 UTC hyperparameters_optimizer.cc:582] [1074/1100] Score: -0.624528 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:26.1456 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.1456 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.1460 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.1647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.026623 train-accuracy:0.863081 valid-loss:1.017969 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:26.2525 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631913\n",
      "[INFO 24-02-22 06:54:26.2525 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:54:26.2530 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.631913 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:26.2536 UTC hyperparameters_optimizer.cc:582] [1075/1100] Score: -0.631913 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:26.2542 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.2542 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.2544 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.2633 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234239 train-accuracy:0.612469 valid-loss:1.206396 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:26.3762 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656996\n",
      "[INFO 24-02-22 06:54:26.3775 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:54:26.3777 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.656996 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:26.3781 UTC hyperparameters_optimizer.cc:582] [1076/1100] Score: -0.656996 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:26.3790 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.3790 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.3792 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.3852 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.052914 train-accuracy:0.837408 valid-loss:1.015152 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:26.4271 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640239\n",
      "[INFO 24-02-22 06:54:26.4271 UTC gradient_boosted_trees.cc:271] Truncates the model to 56 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 24-02-22 06:54:26.4274 UTC gradient_boosted_trees.cc:334] Final model num-trees:56 valid-loss:0.640239 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:26.4282 UTC hyperparameters_optimizer.cc:582] [1077/1100] Score: -0.640239 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:26.4295 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.4297 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.4301 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.4477 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292450 train-accuracy:0.612469 valid-loss:1.243842 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:26.5422 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.616124\n",
      "[INFO 24-02-22 06:54:26.5475 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:54:26.5479 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.616124 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:26.5487 UTC hyperparameters_optimizer.cc:582] [1078/1100] Score: -0.616124 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:54:26.5527 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.5530 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.5532 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.5817 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274529 train-accuracy:0.612469 valid-loss:1.243185 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:26.5883 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.608347\n",
      "[INFO 24-02-22 06:54:26.5883 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 06:54:26.5886 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.608347 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:26.5889 UTC hyperparameters_optimizer.cc:582] [1079/1100] Score: -0.608347 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:26.5898 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.5898 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.5901 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.6551 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648678\n",
      "[INFO 24-02-22 06:54:26.6552 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:54:26.6554 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.648678 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:26.6564 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.6564 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.6566 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.6587 UTC hyperparameters_optimizer.cc:582] [1080/1100] Score: -0.648678 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:26.6838 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.007225 train-accuracy:0.866748 valid-loss:0.986224 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:26.6909 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311287 train-accuracy:0.612469 valid-loss:1.273373 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:26.7102 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641283\n",
      "[INFO 24-02-22 06:54:26.7102 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:26.7105 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:26.7105 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.641283 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:26.7109 UTC hyperparameters_optimizer.cc:582] [1081/1100] Score: -0.641283 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:26.7114 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.7115 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.7118 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.7171 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157599 train-accuracy:0.748166 valid-loss:1.124264 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 06:54:26.8441 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621317\n",
      "[INFO 24-02-22 06:54:26.8442 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:54:26.8444 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.621317 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:26.8451 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:26.8451 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:26.8462 UTC hyperparameters_optimizer.cc:582] [1082/1100] Score: -0.621317 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 06:54:26.8492 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:26.9088 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.050988 train-accuracy:0.822738 valid-loss:1.012384 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:27.1511 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617094\n",
      "[INFO 24-02-22 06:54:27.1511 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 06:54:27.1514 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.617094 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:27.1516 UTC hyperparameters_optimizer.cc:582] [1083/1100] Score: -0.617094 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:27.1523 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:27.1525 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:27.1528 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:27.1569 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245695 train-accuracy:0.612469 valid-loss:1.211308 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 06:54:27.2819 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.579914\n",
      "[INFO 24-02-22 06:54:27.2820 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:54:27.2822 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.579914 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:27.2838 UTC hyperparameters_optimizer.cc:582] [1084/1100] Score: -0.579914 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:27.2855 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:54:27.2855 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:54:27.2859 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 06:54:27.2941 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.116117 train-accuracy:0.803178 valid-loss:1.072469 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:27.4623 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633088\n",
      "[INFO 24-02-22 06:54:27.4624 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 06:54:27.4627 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.633088 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:27.4636 UTC hyperparameters_optimizer.cc:582] [1085/1100] Score: -0.633088 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:27.6440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.609867\n",
      "[INFO 24-02-22 06:54:27.6440 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:54:27.6441 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.609867 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:27.6446 UTC hyperparameters_optimizer.cc:582] [1086/1100] Score: -0.609867 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:27.7086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657624\n",
      "[INFO 24-02-22 06:54:27.7101 UTC gradient_boosted_trees.cc:271] Truncates the model to 155 tree(s) i.e. 155  iteration(s).\n",
      "[INFO 24-02-22 06:54:27.7105 UTC gradient_boosted_trees.cc:334] Final model num-trees:155 valid-loss:0.657624 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:27.7159 UTC hyperparameters_optimizer.cc:582] [1087/1100] Score: -0.657624 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:27.8819 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605766\n",
      "[INFO 24-02-22 06:54:27.8820 UTC gradient_boosted_trees.cc:271] Truncates the model to 158 tree(s) i.e. 158  iteration(s).\n",
      "[INFO 24-02-22 06:54:27.8821 UTC gradient_boosted_trees.cc:334] Final model num-trees:158 valid-loss:0.605766 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:27.8829 UTC hyperparameters_optimizer.cc:582] [1088/1100] Score: -0.605766 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 06:54:27.9001 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.598086\n",
      "[INFO 24-02-22 06:54:27.9001 UTC gradient_boosted_trees.cc:271] Truncates the model to 244 tree(s) i.e. 244  iteration(s).\n",
      "[INFO 24-02-22 06:54:27.9003 UTC gradient_boosted_trees.cc:334] Final model num-trees:244 valid-loss:0.598086 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:27.9046 UTC hyperparameters_optimizer.cc:582] [1089/1100] Score: -0.598086 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:28.0086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637899\n",
      "[INFO 24-02-22 06:54:28.0086 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:54:28.0094 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.637899 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:28.0106 UTC hyperparameters_optimizer.cc:582] [1090/1100] Score: -0.637899 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:28.0584 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.574272\n",
      "[INFO 24-02-22 06:54:28.0584 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:54:28.0586 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.574272 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:28.0591 UTC hyperparameters_optimizer.cc:582] [1091/1100] Score: -0.574272 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:28.1733 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676926\n",
      "[INFO 24-02-22 06:54:28.1733 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:54:28.1736 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.676926 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:28.1744 UTC hyperparameters_optimizer.cc:582] [1092/1100] Score: -0.676926 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:28.7754 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.723972\n",
      "[INFO 24-02-22 06:54:28.7754 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 06:54:28.7756 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 06:54:28.7756 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.723972 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 06:54:28.7758 UTC hyperparameters_optimizer.cc:582] [1093/1100] Score: -0.723972 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:29.0675 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665822\n",
      "[INFO 24-02-22 06:54:29.0675 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:54:29.0676 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.665822 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 06:54:29.0678 UTC hyperparameters_optimizer.cc:582] [1094/1100] Score: -0.665822 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:29.7841 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.558984\n",
      "[INFO 24-02-22 06:54:29.7841 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:54:29.7842 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.558984 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:29.7846 UTC hyperparameters_optimizer.cc:582] [1095/1100] Score: -0.558984 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:29.8087 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629045\n",
      "[INFO 24-02-22 06:54:29.8088 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:54:29.8088 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.629045 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:29.8093 UTC hyperparameters_optimizer.cc:582] [1096/1100] Score: -0.629045 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:30.0449 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669062\n",
      "[INFO 24-02-22 06:54:30.0449 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 06:54:30.0451 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.669062 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 06:54:30.0460 UTC hyperparameters_optimizer.cc:582] [1097/1100] Score: -0.669062 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 06:54:30.1259 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639493\n",
      "[INFO 24-02-22 06:54:30.1259 UTC gradient_boosted_trees.cc:271] Truncates the model to 206 tree(s) i.e. 206  iteration(s).\n",
      "[INFO 24-02-22 06:54:30.1260 UTC gradient_boosted_trees.cc:334] Final model num-trees:206 valid-loss:0.639493 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 06:54:30.1262 UTC hyperparameters_optimizer.cc:582] [1098/1100] Score: -0.639493 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:30.6245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623052\n",
      "[INFO 24-02-22 06:54:30.6245 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 06:54:30.6248 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.623052 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:30.6254 UTC hyperparameters_optimizer.cc:582] [1099/1100] Score: -0.623052 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:34.7411 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632966\n",
      "[INFO 24-02-22 06:54:34.7411 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:54:34.7413 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.632966 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 06:54:34.7428 UTC hyperparameters_optimizer.cc:582] [1100/1100] Score: -0.632966 / -0.481402 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 06:54:34.7520 UTC hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 7\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  value {\n",
      "    categorical: \"RANDOM\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  value {\n",
      "    categorical: \"BEST_FIRST_GLOBAL\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_num_nodes\"\n",
      "  value {\n",
      "    integer: 16\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  value {\n",
      "    categorical: \"true\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  value {\n",
      "    real: 0.2\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  value {\n",
      "    real: 0.2\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  value {\n",
      "    categorical: \"SPARSE_OBLIQUE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_normalization\"\n",
      "  value {\n",
      "    categorical: \"NONE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_weights\"\n",
      "  value {\n",
      "    categorical: \"BINARY\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_num_projections_exponent\"\n",
      "  value {\n",
      "    real: 1.5\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:54:34.7563 UTC kernel.cc:919] Export model in log directory: /tmp/tmp67f8kk_x with prefix 58371fdca305417c\n",
      "[INFO 24-02-22 06:54:34.7610 UTC kernel.cc:937] Save model in resources\n",
      "[INFO 24-02-22 06:54:34.7629 UTC abstract_model.cc:881] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 0.481402\n",
      "\n",
      "Accuracy: 0.90411  CI95[W][0 1]\n",
      "ErrorRate: : 0.0958904\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42   6\n",
      "2   1  24\n",
      "Total: 73\n",
      "\n",
      "\n",
      "[INFO 24-02-22 06:54:34.7751 UTC kernel.cc:1233] Loading model from path /tmp/tmp67f8kk_x/model/ with prefix 58371fdca305417c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:02:22.088756\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-22 06:54:34.7843 UTC decision_forest.cc:660] Model loaded with 82 root(s), 2330 node(s), and 9 input feature(s).\n",
      "[INFO 24-02-22 06:54:34.7843 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-02-22 06:54:34.7844 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x704bc469da50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "tuned_model.fit(train_ds, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x704bcc693560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x704bcc693560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the TF-DF hyper-parameter tuner: 0.8258\n"
     ]
    }
   ],
   "source": [
    "tuned_model.compile([\"accuracy\"])\n",
    "tuned_test_accuracy = tuned_model.evaluate(test_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy with the TF-DF hyper-parameter tuner: {tuned_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpf8og66t6 as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-02-22 06:45:44.0102 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:45:44.0102 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:45:44.0102 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tensor examples:\n",
      "Features: {'Pclass': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'Age': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'Fare': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'People': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'Sex_female': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'Sex_male': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'Embarked_C': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>, 'Embarked_Q': <tf.Tensor 'data_7:0' shape=(None,) dtype=int64>, 'Embarked_S': <tf.Tensor 'data_8:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_9:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'Pclass': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Age': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Fare': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'People': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Sex_female': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'Sex_male': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'Embarked_C': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'Embarked_Q': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'Embarked_S': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>)}\n",
      "Training dataset read in 0:00:01.714312. Found 713 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-22 06:45:45.7465 UTC kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-02-22 06:45:45.7465 UTC kernel.cc:772] Collect training examples\n",
      "[INFO 24-02-22 06:45:45.7465 UTC kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7467 UTC kernel.cc:391] Number of batches: 1\n",
      "[INFO 24-02-22 06:45:45.7467 UTC kernel.cc:392] Number of examples: 713\n",
      "[INFO 24-02-22 06:45:45.7468 UTC kernel.cc:792] Training dataset:\n",
      "Number of records: 713\n",
      "Number of columns: 10\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 9 (90%)\n",
      "\tCATEGORICAL: 1 (10%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 9 (90%)\n",
      "\t0: \"Age\" NUMERICAL mean:28.8925 min:0.42 max:80 sd:13.0626\n",
      "\t1: \"Embarked_C\" NUMERICAL mean:0.187938 min:0 max:1 sd:0.390663\n",
      "\t2: \"Embarked_Q\" NUMERICAL mean:0.0869565 min:0 max:1 sd:0.281771\n",
      "\t3: \"Embarked_S\" NUMERICAL mean:0.725105 min:0 max:1 sd:0.446461\n",
      "\t4: \"Fare\" NUMERICAL mean:33.3333 min:0 max:512.329 sd:52.2398\n",
      "\t5: \"Pclass\" NUMERICAL mean:2.2777 min:1 max:3 sd:0.841604\n",
      "\t6: \"People\" NUMERICAL mean:1.85694 min:1 max:11 sd:1.56818\n",
      "\t7: \"Sex_female\" NUMERICAL mean:0.353436 min:0 max:1 sd:0.478037\n",
      "\t8: \"Sex_male\" NUMERICAL mean:0.646564 min:0 max:1 sd:0.478037\n",
      "\n",
      "CATEGORICAL: 1 (10%)\n",
      "\t9: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7469 UTC kernel.cc:808] Configure learner\n",
      "[WARNING 24-02-22 06:45:45.7471 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:45:45.7471 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:45:45.7471 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-22 06:45:45.7471 UTC kernel.cc:822] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Embarked_C$\"\n",
      "features: \"^Embarked_Q$\"\n",
      "features: \"^Embarked_S$\"\n",
      "features: \"^Fare$\"\n",
      "features: \"^Pclass$\"\n",
      "features: \"^People$\"\n",
      "features: \"^Sex_female$\"\n",
      "features: \"^Sex_male$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "    features: \"^Age$\"\n",
      "    features: \"^Embarked_C$\"\n",
      "    features: \"^Embarked_Q$\"\n",
      "    features: \"^Embarked_S$\"\n",
      "    features: \"^Fare$\"\n",
      "    features: \"^Pclass$\"\n",
      "    features: \"^People$\"\n",
      "    features: \"^Sex_female$\"\n",
      "    features: \"^Sex_male$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: CLASSIFICATION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 6\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: -1\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      shrinkage: 0.1\n",
      "      loss: DEFAULT\n",
      "      validation_set_ratio: 0.1\n",
      "      validation_interval_in_trees: 1\n",
      "      early_stopping: VALIDATION_LOSS_INCREASE\n",
      "      early_stopping_num_trees_look_ahead: 30\n",
      "      l2_regularization: 0\n",
      "      lambda_loss: 1\n",
      "      mart {\n",
      "      }\n",
      "      adapt_subsample_for_maximum_training_duration: false\n",
      "      l1_regularization: 0\n",
      "      use_hessian_gain: false\n",
      "      l2_regularization_categorical: 1\n",
      "      stochastic_gradient_boosting {\n",
      "        ratio: 1\n",
      "      }\n",
      "      apply_link_function: true\n",
      "      compute_permutation_variable_importance: false\n",
      "      binary_focal_loss_options {\n",
      "        misprediction_exponent: 2\n",
      "        positive_sample_coefficient: 0.5\n",
      "      }\n",
      "      early_stopping_initial_iteration: 10\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 500\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "  predefined_search_space {\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7474 UTC kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmpf8og66t6/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7475 UTC kernel.cc:887] Train model\n",
      "[INFO 24-02-22 06:45:45.7476 UTC hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_projection_density_factor\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"LOCAL\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"BEST_FIRST_GLOBAL\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_num_nodes\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 16\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 32\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 64\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 128\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 256\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 512\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"BEST_FIRST_GLOBAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_depth\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 6\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 8\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"LOCAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sampling_method\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"subsample\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 0.6\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 0.8\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 0.9\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"RANDOM\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.02\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.05\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 7\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 20\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"false\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.5\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.9\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7479 UTC hyperparameters_optimizer.cc:500] Start local tuner with 16 thread(s)\n",
      "[INFO[INFO[INFO[INFO 24-02-22 06:45:45.7500 UTC gradient_boosted_trees.cc: 24-02-22 06:45:45.7500 UTC  24-02-22 06:45:45.7500 UTC gradient_boosted_trees.cc: 24-02-22 06:45:45.7500 UTC [591[INFOINFO] gradient_boosted_trees.cc591gradient_boosted_trees.cc] Default loss set to :BINOMIAL_LOG_LIKELIHOOD591\n",
      "] :Default loss set to  24-02-22 06:45:45.7501 UTC [INFOBINOMIAL_LOG_LIKELIHOOD 24-02-22 06:45:45.7501 UTC Default loss set to  24-02-22 06:45:45.7501 UTC gradient_boosted_trees.cc:\n",
      "[gradient_boosted_trees.cc:591] BINOMIAL_LOG_LIKELIHOOD\n",
      "591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "INFO[INFO 24-02-22 06:45:45.7501 UTC gradient_boosted_trees.cc:1218Default loss set to [ 24-02-22 06:45:45.7501 UTC gradient_boosted_trees.cc[INFO591INFO:591BINOMIAL_LOG_LIKELIHOOD] gradient_boosted_trees.ccDefault loss set to  24-02-22 06:45:45.7501 UTC :BINOMIAL_LOG_LIKELIHOOD1218\n",
      "] gradient_boosted_trees.cc:1218[] Training gradient boosted tree on INFO[]  24-02-22 06:45:45.7501 UTC Training gradient boosted tree on \n",
      "713] INFODefault loss set to 713 24-02-22 06:45:45.7501 UTC  24-02-22 06:45:45.7502 UTC  example(s) and 9gradient_boosted_trees.ccBINOMIAL_LOG_LIKELIHOOD:\n",
      " example(s) and 9 feature(s).gradient_boosted_trees.cc[\n",
      "1218INFO] [gradient_boosted_trees.cc feature(s).INFOTraining gradient boosted tree on 713 example(s) and Training gradient boosted tree on \n",
      " 24-02-22 06:45:45.7502 UTC  24-02-22 06:45:45.7502 UTC gradient_boosted_trees.ccgradient_boosted_trees.cc:7131218:1218:] 591]  example(s) and 9 feature(s).\n",
      "Default loss set to BINOMIAL_LOG_LIKELIHOODTraining gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      ":1218\n",
      "] Training gradient boosted tree on 713] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      " example(s) and 9 feature(s).\n",
      "[INFO[INFO 24-02-22 06:45:45.7502 UTC [INFO[INFO 24-02-22 06:45:45.7502 UTC gradient_boosted_trees.cc: 24-02-22 06:45:45.7502 UTC 591gradient_boosted_trees.ccgradient_boosted_trees.cc:1218]  24-02-22 06:45:45.7502 UTC gradient_boosted_trees.cc:] 591Default loss set to :591[Training gradient boosted tree on 713INFOBINOMIAL_LOG_LIKELIHOOD\n",
      "]  example(s) and 9 feature(s). 24-02-22 06:45:45.7503 UTC gradient_boosted_trees.cc:591] Default loss set to \n",
      "Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[BINOMIAL_LOG_LIKELIHOOD\n",
      "INFO[ 24-02-22 06:45:45.7503 UTC gradient_boosted_trees.cc:[[INFOINFO591]  24-02-22 06:45:45.7503 UTC 9 feature(s).\n",
      "gradient_boosted_trees.ccINFODefault loss set to : 24-02-22 06:45:45.7503 UTC BINOMIAL_LOG_LIKELIHOOD 24-02-22 06:45:45.7503 UTC gradient_boosted_trees.cc:1218] 1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "gradient_boosted_trees.ccTraining gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      ":1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:45.7503 UTC gradient_boosted_trees.cc:1261] 647[INFO[[INFO examples used for training and  24-02-22 06:45:45.7504 UTC gradient_boosted_trees.cc:\n",
      "INFO66 24-02-22 06:45:45.7504 UTC  24-02-22 06:45:45.7504 UTC gradient_boosted_trees.cc:591] Default loss set to [INFO1261] 647gradient_boosted_trees.ccBINOMIAL_LOG_LIKELIHOOD\n",
      ":1261 examples used for training and ] [[66 24-02-22 06:45:45.7504 UTC INFOINFO 24-02-22 06:45:45.7504 UTC Default loss set to  examples used for validationBINOMIAL_LOG_LIKELIHOOD examples used for validation\n",
      "\n",
      " 24-02-22 06:45:45.7504 UTC gradient_boosted_trees.cc] :1218] Training gradient boosted tree on gradient_boosted_trees.ccgradient_boosted_trees.cc:1218] 647[713[INFO examples used for training and 66 examples used for validation\n",
      "Training gradient boosted tree on 713: example(s) and 1261[ example(s) and ] INFO9\n",
      " feature(s).[647 examples used for training and 66 examples used for validation 24-02-22 06:45:45.7504 UTC \n",
      "gradient_boosted_trees.cc 24-02-22 06:45:45.7504 UTC gradient_boosted_trees.cc:\n",
      ":INFO12611261[] INFO]  24-02-22 06:45:45.7505 UTC 647 examples used for training and  24-02-22 06:45:45.7504 UTC 64766[ examples used for validation[INFOINFO examples used for training and  24-02-22 06:45:45.7505 UTC 66gradient_boosted_trees.cc examples used for validation:1261\n",
      " 24-02-22 06:45:45.7505 UTC gradient_boosted_trees.cc:\n",
      "591] [INFOgradient_boosted_trees.cc[INFODefault loss set to  24-02-22 06:45:45.7505 UTC ] gradient_boosted_trees.cc 24-02-22 06:45:45.7505 UTC :BINOMIAL_LOG_LIKELIHOOD\n",
      "1218[INFO]  24-02-22 06:45:45.7505 UTC 9gradient_boosted_trees.cc feature(s).\n",
      ":647gradient_boosted_trees.cc:591Training gradient boosted tree on 1261713]  example(s) and 647 examples used for training and gradient_boosted_trees.cc66::12611218] 9Training gradient boosted tree on 713] ] 647Default loss set to  examples used for training and BINOMIAL_LOG_LIKELIHOOD66\n",
      " examples used for validation examples used for training and  feature(s). example(s) and \n",
      "966 feature(s). examples used for validation\n",
      "\n",
      "\n",
      " examples used for validationINFO[[INFO\n",
      " 24-02-22 06:45:45.7505 UTC  24-02-22 06:45:45.7505 UTC gradient_boosted_trees.cc:gradient_boosted_trees.cc1261] 647 examples used for training and 66INFO examples used for validation\n",
      ": 24-02-22 06:45:45.7506 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:45.7506 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:45.7506 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:45.7507 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:45.7507 UTC gradient_boosted_trees.cc[INFO:1261]  24-02-22 06:45:45.7507 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 64766 examples used for validation\n",
      " examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:45.7566 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299102 train-accuracy:0.599691 valid-loss:1.281556 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7581 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.327167 train-accuracy:0.599691 valid-loss:1.303853 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7595 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248973 train-accuracy:0.599691 valid-loss:1.242635 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7598 UTC gradient_boosted_trees.cc:1638] \tnum-trees:2 train-loss:1.258656 train-accuracy:0.599691 valid-loss:1.252313 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7610 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246921 train-accuracy:0.599691 valid-loss:1.244506 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7636 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242535 train-accuracy:0.599691 valid-loss:1.239770 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7640 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238261 train-accuracy:0.599691 valid-loss:1.242172 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323255 train-accuracy:0.599691 valid-loss:1.301899 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7668 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284455 train-accuracy:0.599691 valid-loss:1.272638 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7696 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240513 train-accuracy:0.599691 valid-loss:1.236605 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325033 train-accuracy:0.599691 valid-loss:1.301812 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7723 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289820 train-accuracy:0.599691 valid-loss:1.273541 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286567 train-accuracy:0.599691 valid-loss:1.272373 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323071 train-accuracy:0.599691 valid-loss:1.301134 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7744 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295236 train-accuracy:0.599691 valid-loss:1.279608 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7767 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231723 train-accuracy:0.599691 valid-loss:1.247217 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7881 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219171 train-accuracy:0.599691 valid-loss:1.232235 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.0446 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.879663\n",
      "[INFO 24-02-22 06:45:46.0457 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.0458 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.879663 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:46.0461 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.0461 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.0462 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.0469 UTC hyperparameters_optimizer.cc:582] [1/500] Score: -0.879663 / -0.879663 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:46.0572 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326041 train-accuracy:0.599691 valid-loss:1.301055 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.1083 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.810702\n",
      "[INFO 24-02-22 06:45:46.1084 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.1085 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.810702 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:46.1089 UTC hyperparameters_optimizer.cc:582] [2/500] Score: -0.810702 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:46.1093 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.1093 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.1095 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.1189 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286585 train-accuracy:0.599691 valid-loss:1.271529 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.4318 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.813087\n",
      "[INFO 24-02-22 06:45:46.4319 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.4319 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.813087 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:46.4321 UTC hyperparameters_optimizer.cc:582] [3/500] Score: -0.813087 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.4325 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.4325 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.4326 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.4429 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320005 train-accuracy:0.599691 valid-loss:1.297612 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.6083 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846985\n",
      "[INFO 24-02-22 06:45:46.6085 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.6089 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.846985 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:46.6093 UTC hyperparameters_optimizer.cc:582] [4/500] Score: -0.846985 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:46.6100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.6102 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.6106 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.6287 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326903 train-accuracy:0.599691 valid-loss:1.302218 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.7098 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.821244\n",
      "[INFO 24-02-22 06:45:46.7098 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.7099 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.821244 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:46.7102 UTC hyperparameters_optimizer.cc:582] [5/500] Score: -0.821244 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.7107 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.7107 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.7109 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.7139 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.898714\n",
      "[INFO 24-02-22 06:45:46.7139 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.7142 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.898714 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:46.7150 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.7150 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.7152 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.7154 UTC hyperparameters_optimizer.cc:582] [6/500] Score: -0.898714 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.7168 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329044 train-accuracy:0.599691 valid-loss:1.304259 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.7244 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323562 train-accuracy:0.599691 valid-loss:1.300765 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.8103 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.787401\n",
      "[INFO 24-02-22 06:45:46.8104 UTC gradient_boosted_trees.cc:271] Truncates the model to 183 tree(s) i.e. 183  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.8104 UTC gradient_boosted_trees.cc:334] Final model num-trees:183 valid-loss:0.787401 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:46.8110 UTC hyperparameters_optimizer.cc:582] [7/500] Score: -0.787401 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:46.8114 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.8114 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.8118 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.8193 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.877771\n",
      "[INFO 24-02-22 06:45:46.8193 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.8195 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.877771 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:46.8199 UTC hyperparameters_optimizer.cc:582] [8/500] Score: -0.877771 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.8208 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.8208 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.8210 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.8268 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232001 train-accuracy:0.599691 valid-loss:1.246278 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.8386 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223497 train-accuracy:0.599691 valid-loss:1.224562 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.8763 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851705\n",
      "[INFO 24-02-22 06:45:46.8763 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.8765 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.851705 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:46.8771 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.8771 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.8773 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.8820 UTC hyperparameters_optimizer.cc:582] [9/500] Score: -0.851705 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:46.8957 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282480 train-accuracy:0.599691 valid-loss:1.277844 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.9701 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.856374\n",
      "[INFO 24-02-22 06:45:46.9702 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.9704 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.856374 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:46.9710 UTC hyperparameters_optimizer.cc:582] [10/500] Score: -0.856374 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.9732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.9734 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.9736 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.9884 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321756 train-accuracy:0.599691 valid-loss:1.299039 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.0134 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862188\n",
      "[INFO 24-02-22 06:45:47.0134 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.0137 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.862188 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:47.0143 UTC hyperparameters_optimizer.cc:582] [11/500] Score: -0.862188 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:47.0158 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.0158 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.0160 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.0199 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846504\n",
      "[INFO 24-02-22 06:45:47.0201 UTC gradient_boosted_trees.cc:271] Truncates the model to 210 tree(s) i.e. 210  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.0202 UTC gradient_boosted_trees.cc:334] Final model num-trees:210 valid-loss:0.846504 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.0214 UTC hyperparameters_optimizer.cc:582] [12/500] Score: -0.846504 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:47.0234 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.0236 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.0239 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.0315 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322018 train-accuracy:0.599691 valid-loss:1.302492 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.0441 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319056 train-accuracy:0.599691 valid-loss:1.302298 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.0878 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876741\n",
      "[INFO 24-02-22 06:45:47.0879 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.0880 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.876741 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.0884 UTC hyperparameters_optimizer.cc:582] [13/500] Score: -0.876741 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:47.0896 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.0896 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.0897 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.0941 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266406 train-accuracy:0.599691 valid-loss:1.252495 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.5185 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89407\n",
      "[INFO 24-02-22 06:45:47.5186 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.5187 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.894070 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.5192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.5192 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.5194 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.5221 UTC hyperparameters_optimizer.cc:582] [14/500] Score: -0.89407 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:47.5321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225584 train-accuracy:0.599691 valid-loss:1.246779 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.5820 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875676\n",
      "[INFO 24-02-22 06:45:47.5820 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.5822 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.875676 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.5833 UTC hyperparameters_optimizer.cc:582] [15/500] Score: -0.875676 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:47.5855 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.5855 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.5857 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.6009 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285744 train-accuracy:0.599691 valid-loss:1.269879 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.6549 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86677\n",
      "[INFO 24-02-22 06:45:47.6549 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.6551 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.866770 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:47.6554 UTC hyperparameters_optimizer.cc:582] [16/500] Score: -0.86677 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:47.6561 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.6561 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.6563 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.6658 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297947 train-accuracy:0.599691 valid-loss:1.276181 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.7337 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.822231\n",
      "[INFO 24-02-22 06:45:47.7337 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.7338 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.822231 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:47.7340 UTC hyperparameters_optimizer.cc:582] [17/500] Score: -0.822231 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:47.7344 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.7344 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.7346 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.7480 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323394 train-accuracy:0.599691 valid-loss:1.300948 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.8691 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823503\n",
      "[INFO 24-02-22 06:45:47.8691 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.8693 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.823503 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.8698 UTC hyperparameters_optimizer.cc:582] [18/500] Score: -0.823503 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:47.8707 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.8708 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.8709 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.8878 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294626 train-accuracy:0.599691 valid-loss:1.274379 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.9052 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.833291\n",
      "[INFO 24-02-22 06:45:47.9053 UTC gradient_boosted_trees.cc:271] Truncates the model to 188 tree(s) i.e. 188  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.9055 UTC gradient_boosted_trees.cc:334] Final model num-trees:188 valid-loss:0.833291 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:47.9065 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.9066 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.9067 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.9087 UTC hyperparameters_optimizer.cc:582] [19/500] Score: -0.833291 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:47.9215 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322378 train-accuracy:0.599691 valid-loss:1.299599 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.9568 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872595\n",
      "[INFO 24-02-22 06:45:47.9568 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.9571 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.872595 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.9585 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.9585 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.9587 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.9587 UTC hyperparameters_optimizer.cc:582] [20/500] Score: -0.872595 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:47.9739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227822 train-accuracy:0.599691 valid-loss:1.254822 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.1502 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858256\n",
      "[INFO 24-02-22 06:45:48.1502 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.1504 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.858256 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.1514 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.1514 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.1515 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.1521 UTC hyperparameters_optimizer.cc:582] [21/500] Score: -0.858256 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:48.1685 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238191 train-accuracy:0.599691 valid-loss:1.246720 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.1981 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.895892\n",
      "[INFO 24-02-22 06:45:48.1982 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.1984 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.895892 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:48.1992 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.1992 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.1994 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.2014 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324782 train-accuracy:0.599691 valid-loss:1.302546 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.2015 UTC hyperparameters_optimizer.cc:582] [22/500] Score: -0.895892 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:48.2182 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902587\n",
      "[INFO 24-02-22 06:45:48.2182 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.2185 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.902587 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:48.2188 UTC hyperparameters_optimizer.cc:582] [23/500] Score: -0.902587 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:48.2207 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.2209 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.2214 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.2283 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262533 train-accuracy:0.599691 valid-loss:1.263113 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.3251 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.898929\n",
      "[INFO 24-02-22 06:45:48.3252 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.3254 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.898929 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:48.3263 UTC hyperparameters_optimizer.cc:582] [24/500] Score: -0.898929 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:48.3273 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.3274 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.3277 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.3405 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324916 train-accuracy:0.599691 valid-loss:1.304121 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.3508 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81927\n",
      "[INFO 24-02-22 06:45:48.3510 UTC gradient_boosted_trees.cc:271] Truncates the model to 239 tree(s) i.e. 239  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.3511 UTC gradient_boosted_trees.cc:334] Final model num-trees:239 valid-loss:0.819270 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.3516 UTC hyperparameters_optimizer.cc:582] [25/500] Score: -0.81927 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:48.3519 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.3519 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.3521 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.3573 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263809 train-accuracy:0.599691 valid-loss:1.259300 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.6712 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838898\n",
      "[INFO 24-02-22 06:45:48.6712 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.6717 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.838898 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:48.6718 UTC hyperparameters_optimizer.cc:582] [26/500] Score: -0.838898 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:48.6722 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.6722 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.6724 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.6853 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294104 train-accuracy:0.599691 valid-loss:1.281722 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.7048 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834405\n",
      "[INFO 24-02-22 06:45:48.7048 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.7049 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.834405 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:48.7052 UTC hyperparameters_optimizer.cc:582] [27/500] Score: -0.834405 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:48.7056 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.7057 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.7060 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.7189 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880495\n",
      "[INFO 24-02-22 06:45:48.7190 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.7193 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.880495 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.7197 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238102 train-accuracy:0.599691 valid-loss:1.239705 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.7218 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.7219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.7221 UTC hyperparameters_optimizer.cc:582] [28/500] Score: -0.880495 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:48.7233 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.7380 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226669 train-accuracy:0.599691 valid-loss:1.233602 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.7445 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.612892 train-accuracy:0.893354 valid-loss:0.827650 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.7446 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.7447 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.827600 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.7453 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.7453 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.7455 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.7487 UTC hyperparameters_optimizer.cc:582] [29/500] Score: -0.8276 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:48.7647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285128 train-accuracy:0.599691 valid-loss:1.280545 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.8688 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89547\n",
      "[INFO 24-02-22 06:45:48.8688 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.8691 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.895470 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:48.8697 UTC hyperparameters_optimizer.cc:582] [30/500] Score: -0.89547 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:48.8702 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.8702 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.8707 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.8772 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261617 train-accuracy:0.599691 valid-loss:1.258390 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.0243 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860766\n",
      "[INFO 24-02-22 06:45:49.0243 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.0245 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.860766 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:49.0252 UTC hyperparameters_optimizer.cc:582] [31/500] Score: -0.860766 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.0266 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.0266 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.0268 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.0332 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328892 train-accuracy:0.599691 valid-loss:1.305558 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.1086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.803955\n",
      "[INFO 24-02-22 06:45:49.1086 UTC gradient_boosted_trees.cc:271] Truncates the model to 196 tree(s) i.e. 196  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.1087 UTC gradient_boosted_trees.cc:334] Final model num-trees:196 valid-loss:0.803955 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:49.1100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.1100 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.1102 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.1122 UTC hyperparameters_optimizer.cc:582] [32/500] Score: -0.803955 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.1248 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322124 train-accuracy:0.599691 valid-loss:1.296306 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.2516 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.816475\n",
      "[INFO 24-02-22 06:45:49.2517 UTC gradient_boosted_trees.cc:271] Truncates the model to 133 tree(s) i.e. 133  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.2517 UTC gradient_boosted_trees.cc:334] Final model num-trees:133 valid-loss:0.816475 valid-accuracy:0.818182\n",
      "[[INFO 24-02-22 06:45:49.2523 UTC hyperparameters_optimizer.cc:582] [33/500] Score: -0.816475 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "INFO 24-02-22 06:45:49.2527 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.2527 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.2533 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.2695 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292946 train-accuracy:0.599691 valid-loss:1.274051 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.3222 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.841766\n",
      "[INFO 24-02-22 06:45:49.3223 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.3224 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.841766 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:49.3229 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.3229 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.3229 UTC hyperparameters_optimizer.cc:582] [34/500] Score: -0.841766 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.3254 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.3477 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297498 train-accuracy:0.599691 valid-loss:1.282897 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.4206 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.841924\n",
      "[INFO 24-02-22 06:45:49.4207 UTC gradient_boosted_trees.cc:271] Truncates the model to 56 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.4209 UTC gradient_boosted_trees.cc:334] Final model num-trees:56 valid-loss:0.841924 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:49.4213 UTC hyperparameters_optimizer.cc:582] [35/500] Score: -0.841924 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.4230 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.4230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.4232 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.4344 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.861837\n",
      "[INFO 24-02-22 06:45:49.4345 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.4347 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.861837 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:49.4351 UTC hyperparameters_optimizer.cc:582] [36/500] Score: -0.861837 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:49.4367 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.4371 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.4384 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.4429 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239855 train-accuracy:0.599691 valid-loss:1.255424 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.4569 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239919 train-accuracy:0.599691 valid-loss:1.240268 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.5893 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867645\n",
      "[INFO 24-02-22 06:45:49.5894 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.5896 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.867645 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:49.5907 UTC hyperparameters_optimizer.cc:582] [37/500] Score: -0.867645 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:49.5928 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.5928 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.5929 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.5969 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.300715 train-accuracy:0.599691 valid-loss:1.283338 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.6343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.816823\n",
      "[INFO 24-02-22 06:45:49.6343 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.6344 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.816823 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:49.6346 UTC hyperparameters_optimizer.cc:582] [38/500] Score: -0.816823 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:49.6351 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.6351 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.6354 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.6423 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328624 train-accuracy:0.599691 valid-loss:1.304430 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.8027 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85208\n",
      "[INFO 24-02-22 06:45:49.8027 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.8029 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.852080 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:49.8045 UTC hyperparameters_optimizer.cc:582] [39/500] Score: -0.85208 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.8059 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.8059 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.8069 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.8078 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261860 train-accuracy:0.599691 valid-loss:1.261429 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.8407 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845917\n",
      "[INFO 24-02-22 06:45:49.8408 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.8408 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.845917 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:49.8412 UTC hyperparameters_optimizer.cc:582] [40/500] Score: -0.845917 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:49.8417 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.8417 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.8420 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.8483 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326488 train-accuracy:0.599691 valid-loss:1.301378 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.8574 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866422\n",
      "[INFO 24-02-22 06:45:49.8574 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.8577 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.866422 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:49.8583 UTC hyperparameters_optimizer.cc:582] [41/500] Score: -0.866422 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:49.8592 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.8593 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.8599 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.8647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326360 train-accuracy:0.599691 valid-loss:1.302910 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.9391 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.853363\n",
      "[INFO 24-02-22 06:45:49.9391 UTC gradient_boosted_trees.cc:271] Truncates the model to 79 tree(s) i.e. 79  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.9392 UTC gradient_boosted_trees.cc:334] Final model num-trees:79 valid-loss:0.853363 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:49.9396 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.9396 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-22 06:45:49.9398 UTC hyperparameters_optimizer.cc:582] [42/500] Score: -0.853363 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "INFO 24-02-22 06:45:49.9401 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.9438 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263660 train-accuracy:0.599691 valid-loss:1.256220 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.9974 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.909584\n",
      "[INFO 24-02-22 06:45:49.9975 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.9977 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.909584 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:49.9985 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.9985 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.9986 UTC hyperparameters_optimizer.cc:582] [43/500] Score: -0.909584 / -0.787401 HParams: [INFO 24-02-22 06:45:49.9987 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      " examples used for validation\n",
      "[INFO 24-02-22 06:45:50.0113 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293281 train-accuracy:0.599691 valid-loss:1.277729 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.1343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836923\n",
      "[INFO 24-02-22 06:45:50.1347 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.1348 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.836923 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:50.1355 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.1356 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.1357 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.1381 UTC hyperparameters_optimizer.cc:582] [44/500] Score: -0.836923 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:50.1524 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286836 train-accuracy:0.599691 valid-loss:1.277966 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.1733 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848447\n",
      "[INFO 24-02-22 06:45:50.1734 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.1735 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.848447 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:50.1739 UTC hyperparameters_optimizer.cc:582] [45/500] Score: -0.848447 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:50.1743 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.1743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.1746 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.1868 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872035\n",
      "[INFO 24-02-22 06:45:50.1870 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.1873 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.872035 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.1890 UTC hyperparameters_optimizer.cc:582] [46/500] Score: -0.872035 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:50.1909 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.1910 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.1911 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.1949 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281181 train-accuracy:0.599691 valid-loss:1.280599 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.1992 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323041 train-accuracy:0.599691 valid-loss:1.298193 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.2724 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.853001\n",
      "[INFO 24-02-22 06:45:50.2724 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.2726 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.853001 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.2732 UTC hyperparameters_optimizer.cc:582] [47/500] Score: -0.853001 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:50.2744 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.2745 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.2748 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.2866 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235518 train-accuracy:0.599691 valid-loss:1.241700 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.3189 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851016\n",
      "[INFO 24-02-22 06:45:50.3190 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.3191 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.851016 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.3193 UTC hyperparameters_optimizer.cc:582] [48/500] Score: -0.851016 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:50.3196 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.3196 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.3198 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.3353 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321901 train-accuracy:0.599691 valid-loss:1.298070 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.4037 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.80436\n",
      "[INFO 24-02-22 06:45:50.4037 UTC gradient_boosted_trees.cc:271] Truncates the model to 93 tree(s) i.e. 93  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.4038 UTC gradient_boosted_trees.cc:334] Final model num-trees:93 valid-loss:0.804360 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.4040 UTC hyperparameters_optimizer.cc:582] [49/500] Score: -0.80436 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:50.4046 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.4046 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.4049 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.4081 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.818985\n",
      "[INFO 24-02-22 06:45:50.4081 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.4082 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.818985 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:50.4085 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304026 train-accuracy:0.599691 valid-loss:1.289701 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.4092 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.4092 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.4093 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.4120 UTC hyperparameters_optimizer.cc:582] [50/500] Score: -0.818985 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:50.4148 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326409 train-accuracy:0.599691 valid-loss:1.300988 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.4685 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824662\n",
      "[INFO 24-02-22 06:45:50.4685 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.4687 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.824662 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.4692 UTC hyperparameters_optimizer.cc:582] [51/500] Score: -0.824662 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:50.4699 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.4701 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.4705 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.4883 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236742 train-accuracy:0.599691 valid-loss:1.242617 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.6818 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86202\n",
      "[INFO 24-02-22 06:45:50.6818 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.6821 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.862020 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:50.6840 UTC hyperparameters_optimizer.cc:582] [52/500] Score: -0.86202 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:50.6847 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.6847 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.6864 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.6903 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.255817 train-accuracy:0.599691 valid-loss:1.241683 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.7593 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827896\n",
      "[INFO 24-02-22 06:45:50.7593 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.7595 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.827896 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:50.7599 UTC hyperparameters_optimizer.cc:582] [53/500] Score: -0.827896 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:50.7607 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.7607 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.7610 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.7697 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325228 train-accuracy:0.599691 valid-loss:1.302135 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.7828 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.895343\n",
      "[INFO 24-02-22 06:45:50.7861 UTC gradient_boosted_trees.cc:271] Truncates the model to 79 tree(s) i.e. 79  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.7862 UTC gradient_boosted_trees.cc:334] Final model num-trees:79 valid-loss:0.895343 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:50.7866 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.7867 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.7868 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.7921 UTC hyperparameters_optimizer.cc:582] [54/500] Score: -0.895343 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:50.8047 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292122 train-accuracy:0.599691 valid-loss:1.279078 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.8333 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.649951 train-accuracy:0.873261 valid-loss:0.862889 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:50.8333 UTC gradient_boosted_trees.cc:271] Truncates the model to 295 tree(s) i.e. 295  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.8333 UTC gradient_boosted_trees.cc:334] Final model num-trees:295 valid-loss:0.861282 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:50.8336 UTC hyperparameters_optimizer.cc:582] [55/500] Score: -0.861282 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:50.8343 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.8343 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.8345 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.8529 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323356 train-accuracy:0.599691 valid-loss:1.300296 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.9153 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.877363\n",
      "[INFO 24-02-22 06:45:50.9153 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.9155 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.877363 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:50.9158 UTC hyperparameters_optimizer.cc:582] [56/500] Score: -0.877363 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:50.9171 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.9171 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.9173 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.9322 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292667 train-accuracy:0.599691 valid-loss:1.277179 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.9755 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.847727\n",
      "[INFO 24-02-22 06:45:50.9755 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.9757 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.847727 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.9762 UTC hyperparameters_optimizer.cc:582] [57/500] Score: -0.847727 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:50.9769 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.9770 UTC gradient_boosted_trees.cc[INFO 24-02-22 06:45:50.9770 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842974\n",
      "[INFO 24-02-22 06:45:50.9770 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.9771 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.842974 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:50.9772 UTC hyperparameters_optimizer.cc:582] [58/500] Score: -0.842974 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      ":1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.9775 UTC gradient_boosted_trees.cc:1261] [INFO 24-02-22 06:45:50.9775 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.9777 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.9778 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.9863 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290440 train-accuracy:0.599691 valid-loss:1.280076 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.9926 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229263 train-accuracy:0.599691 valid-loss:1.215434 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.0850 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867761\n",
      "[INFO 24-02-22 06:45:51.0851 UTC gradient_boosted_trees.cc:271] Truncates the model to 105 tree(s) i.e. 105  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.0853 UTC gradient_boosted_trees.cc:334] Final model num-trees:105 valid-loss:0.867761 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:51.0866 UTC hyperparameters_optimizer.cc:582] [59/500] Score: -0.867761 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:51.0871 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.0871 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.0873 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.0987 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326501 train-accuracy:0.599691 valid-loss:1.301450 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.2619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843369\n",
      "[INFO 24-02-22 06:45:51.2619 UTC gradient_boosted_trees.cc:271] Truncates the model to 177 tree(s) i.e. 177  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.2627 UTC gradient_boosted_trees.cc:334] Final model num-trees:177 valid-loss:0.843369 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:51.2634 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.2634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.2636 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.2655 UTC hyperparameters_optimizer.cc:582] [60/500] Score: -0.843369 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:51.2701 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235285 train-accuracy:0.599691 valid-loss:1.228840 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.3009 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848051\n",
      "[INFO 24-02-22 06:45:51.3010 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.3012 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.848051 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:51.3016 UTC hyperparameters_optimizer.cc:582] [61/500] Score: -0.848051 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:51.3027 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.3028 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.3031 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.3126 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840029\n",
      "[INFO 24-02-22 06:45:51.3126 UTC gradient_boosted_trees.cc:271] Truncates the model to 261 tree(s) i.e. 261  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.3127 UTC gradient_boosted_trees.cc:334] Final model num-trees:261 valid-loss:0.840029 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:51.3133 UTC hyperparameters_optimizer.cc:582] [62/500] Score: -0.840029 / -0.787401 HParams: [INFO 24-02-22 06:45:51.3135 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.3135 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:51.3142 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.3206 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229674 train-accuracy:0.599691 valid-loss:1.231917 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.3271 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850837\n",
      "[INFO 24-02-22 06:45:51.3272 UTC gradient_boosted_trees.cc:271] Truncates the model to 164 tree(s) i.e. 164  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.3273 UTC gradient_boosted_trees.cc:334] Final model num-trees:164 valid-loss:0.850837 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:51.3277 UTC hyperparameters_optimizer.cc:582] [63/500] Score: -0.850837 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:51.3285 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.3286 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.3288 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.3312 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286460 train-accuracy:0.599691 valid-loss:1.271635 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.3380 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299536 train-accuracy:0.599691 valid-loss:1.282935 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.4937 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.758798\n",
      "[INFO 24-02-22 06:45:51.4937 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.4939 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.758798 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:51.4944 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.4945 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.4945 UTC hyperparameters_optimizer.cc:582] [64/500] Score: -0.758798 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:51.4948 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.4953 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.909965\n",
      "[INFO 24-02-22 06:45:51.4953 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.4958 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.909965 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:51.4965 UTC hyperparameters_optimizer.cc:582] [65/500] Score: -0.909965 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:51.4979 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.4981 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.4983 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.4994 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328051 train-accuracy:0.599691 valid-loss:1.303930 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.5110 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321813 train-accuracy:0.599691 valid-loss:1.300878 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.5846 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.619778 train-accuracy:0.884080 valid-loss:0.850183 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:51.5847 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.5847 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.849889 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:51.5853 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.5853 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.5855 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.5887 UTC hyperparameters_optimizer.cc:582] [66/500] Score: -0.849889 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:51.6016 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842691\n",
      "[INFO 24-02-22 06:45:51.6016 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.6017 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.842691 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:51.6020 UTC hyperparameters_optimizer.cc:582] [67/500] Score: -0.842691 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:51.6022 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.6022 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.6025 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.6039 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243126 train-accuracy:0.599691 valid-loss:1.245450 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.6189 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321678 train-accuracy:0.599691 valid-loss:1.297279 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.6650 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838923\n",
      "[INFO 24-02-22 06:45:51.6651 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.6653 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.838923 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:51.6664 UTC hyperparameters_optimizer.cc:582] [68/500] Score: -0.838923 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:51.6671 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.6672 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.6679 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.6776 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248908 train-accuracy:0.599691 valid-loss:1.246901 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.7674 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872517\n",
      "[INFO 24-02-22 06:45:51.7675 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.7676 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.872517 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:51.7680 UTC hyperparameters_optimizer.cc:582] [69/500] Score: -0.872517 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:51.7685 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.7685 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.7686 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.7797 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288404 train-accuracy:0.599691 valid-loss:1.277787 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.8430 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866987\n",
      "[INFO 24-02-22 06:45:51.8431 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.8432 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.866987 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:51.8438 UTC hyperparameters_optimizer.cc:582] [70/500] Score: -0.866987 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:51.8441 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.8441 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.8449 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.8582 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324076 train-accuracy:0.599691 valid-loss:1.303412 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.1086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876655\n",
      "[INFO 24-02-22 06:45:52.1090 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.1091 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.876655 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:52.1093 UTC hyperparameters_optimizer.cc:582] [71/500] Score: -0.876655 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:52.1103 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.1103 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.1104 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.1214 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851702\n",
      "[INFO 24-02-22 06:45:52.1214 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.1217 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.851702 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:52.1227 UTC hyperparameters_optimizer.cc:582] [72/500] Score: -0.851702 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:52.1239 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.1239 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.1240 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.1304 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236587 train-accuracy:0.599691 valid-loss:1.246619 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.1500 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321382 train-accuracy:0.599691 valid-loss:1.301534 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.1951 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834659\n",
      "[INFO 24-02-22 06:45:52.1951 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.1952 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.834659 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:52.1958 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.1958 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.1960 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.1987 UTC hyperparameters_optimizer.cc:582] [73/500] Score: -0.834659 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:52.2047 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286572 train-accuracy:0.599691 valid-loss:1.277108 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.2068 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.923587\n",
      "[INFO 24-02-22 06:45:52.2068 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.2072 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.923587 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:52.2084 UTC hyperparameters_optimizer.cc:582] [74/500] Score: -0.923587 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:52.2104 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.2106 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.2110 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.2241 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325547 train-accuracy:0.599691 valid-loss:1.302126 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.2644 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851685\n",
      "[INFO 24-02-22 06:45:52.2644 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.2645 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.851685 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:52.2650 UTC hyperparameters_optimizer.cc:582] [75/500] Score: -0.851685 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:52.2655 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.2655 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.2658 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.2688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326290 train-accuracy:0.599691 valid-loss:1.303772 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.4845 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851117\n",
      "[INFO 24-02-22 06:45:52.4845 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.4847 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.851117 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:52.4852 UTC hyperparameters_optimizer.cc:582] [76/500] Score: -0.851117 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:52.4860 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.4860 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.4862 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.5004 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322180 train-accuracy:0.599691 valid-loss:1.298601 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.5132 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.906451\n",
      "[INFO 24-02-22 06:45:52.5133 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.5135 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.906451 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:52.5140 UTC hyperparameters_optimizer.cc:582] [77/500] Score: -0.906451 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:52.5142 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.5142 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.5210 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.5453 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321438 train-accuracy:0.599691 valid-loss:1.301863 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.7504 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.583254 train-accuracy:0.891808 valid-loss:0.852778 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:52.7504 UTC gradient_boosted_trees.cc:271] Truncates the model to 277 tree(s) i.e. 277  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.7504 UTC gradient_boosted_trees.cc:334] Final model num-trees:277 valid-loss:0.850376 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:52.7509 UTC hyperparameters_optimizer.cc:582] [78/500] Score: -0.850376 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:52.7513 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.7513 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.7518 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.7617 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321874 train-accuracy:0.599691 valid-loss:1.305339 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.8101 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832839\n",
      "[INFO 24-02-22 06:45:52.8101 UTC gradient_boosted_trees.cc:271] Truncates the model to 90 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.8102 UTC gradient_boosted_trees.cc:334] Final model num-trees:90 valid-loss:0.832839 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:52.8107 UTC hyperparameters_optimizer.cc:582] [79/500] Score: -0.832839 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:52.8112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.8112 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.8116 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.8233 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322529 train-accuracy:0.599691 valid-loss:1.302170 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.8268 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89632\n",
      "[INFO 24-02-22 06:45:52.8269 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.8272 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.896320 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:52.8277 UTC hyperparameters_optimizer.cc:582] [80/500] Score: -0.89632 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:52.8291 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.8291 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.8293 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.8396 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323234 train-accuracy:0.599691 valid-loss:1.297781 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.8659 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850266\n",
      "[INFO 24-02-22 06:45:52.8660 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.8662 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.850266 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:52.8668 UTC hyperparameters_optimizer.cc:582] [81/500] Score: -0.850266 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:52.8673 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.8674 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.8680 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.8826 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227562 train-accuracy:0.599691 valid-loss:1.229230 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.9265 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827327\n",
      "[INFO 24-02-22 06:45:52.9266 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.9267 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.827327 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:52.9271 UTC hyperparameters_optimizer.cc:582] [82/500] Score: -0.827327 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:52.9278 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.9279 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.9280 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.9425 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222877 train-accuracy:0.599691 valid-loss:1.224680 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.0650 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876295\n",
      "[INFO 24-02-22 06:45:53.0653 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.0656 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.876295 valid-accuracy:0.818182\n",
      "[[INFO 24-02-22 06:45:53.0664 UTC hyperparameters_optimizer.cc:582] [83/500] Score: -0.876295 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "INFO 24-02-22 06:45:53.0668 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.0669 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.0671 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.0796 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286184 train-accuracy:0.599691 valid-loss:1.275303 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.0892 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842445\n",
      "[INFO 24-02-22 06:45:53.0892 UTC gradient_boosted_trees.cc:271] Truncates the model to 203 tree(s) i.e. 203  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.0893 UTC gradient_boosted_trees.cc:334] Final model num-trees:203 valid-loss:0.842445 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:53.0899 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.0899 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.0900 UTC hyperparameters_optimizer.cc:582] [84/500] Score: -0.842445 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:53.0902 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.0949 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329622 train-accuracy:0.599691 valid-loss:1.303086 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.1827 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839654\n",
      "[INFO 24-02-22 06:45:53.1827 UTC gradient_boosted_trees.cc:271] Truncates the model to 225 tree(s) i.e. 225  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.1828 UTC gradient_boosted_trees.cc:334] Final model num-trees:225 valid-loss:0.839654 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:53.1832 UTC hyperparameters_optimizer.cc:582] [85/500] Score: -0.839654 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:53.1842 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.1842 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.1844 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.2070 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225415 train-accuracy:0.599691 valid-loss:1.238964 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.2616 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.900662\n",
      "[INFO 24-02-22 06:45:53.2616 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.2618 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.900662 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:53.2639 UTC hyperparameters_optimizer.cc:582] [86/500] Score: -0.900662 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:53.2647 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.2647 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.2649 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.2753 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326253 train-accuracy:0.599691 valid-loss:1.299680 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.6476 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.937712\n",
      "[INFO 24-02-22 06:45:53.6476 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.6479 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.937712 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:53.6484 UTC hyperparameters_optimizer.cc:582] [87/500] Score: -0.937712 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:53.6493 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.6493 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.6497 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.6604 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321537 train-accuracy:0.599691 valid-loss:1.299628 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.8431 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848033\n",
      "[INFO 24-02-22 06:45:53.8431 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.8433 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.848033 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:53.8437 UTC hyperparameters_optimizer.cc:582] [88/500] Score: -0.848033 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:53.8446 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.8446 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.8448 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.8584 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229778 train-accuracy:0.599691 valid-loss:1.261166 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.0087 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881817\n",
      "[INFO 24-02-22 06:45:54.0087 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.0089 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.881817 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.0092 UTC hyperparameters_optimizer.cc:582] [89/500] Score: -0.881817 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.0097 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.0097 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.0100 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.0235 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290843 train-accuracy:0.599691 valid-loss:1.274431 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.3646 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842427\n",
      "[INFO 24-02-22 06:45:54.3647 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.3649 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.842427 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.3655 UTC hyperparameters_optimizer.cc:582] [90/500] Score: -0.842427 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:54.3663 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.3666 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.3670 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.3731 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.882998\n",
      "[INFO 24-02-22 06:45:54.3733 UTC gradient_boosted_trees.cc:271] Truncates the model to 131 tree(s) i.e. 131  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.3738 UTC gradient_boosted_trees.cc:334] Final model num-trees:131 valid-loss:0.882998 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:54.3756 UTC hyperparameters_optimizer.cc:582] [91/500] Score: -0.882998 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:54.3796 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.3797 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.3798 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246865 train-accuracy:0.599691 valid-loss:1.240165 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.3801 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4015 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287206 train-accuracy:0.599691 valid-loss:1.282408 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.4048 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.884995\n",
      "[INFO 24-02-22 06:45:54.4049 UTC gradient_boosted_trees.cc:271] Truncates the model to 97 tree(s) i.e. 97  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.4052 UTC gradient_boosted_trees.cc:334] Final model num-trees:97 valid-loss:0.884995 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.4053 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875413\n",
      "[INFO 24-02-22 06:45:54.4053 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.4056 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.875413 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.4065 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.4066 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.4068 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4075 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.4075 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.4077 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4087 UTC hyperparameters_optimizer.cc:582] [92/500] Score: -0.884995 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.4093 UTC hyperparameters_optimizer.cc:582] [93/500] Score: -0.875413 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:54.4226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284457 train-accuracy:0.599691 valid-loss:1.274963 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.4252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321726 train-accuracy:0.599691 valid-loss:1.300783 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.4539 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873489\n",
      "[INFO 24-02-22 06:45:54.4539 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.4543 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.873489 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.4553 UTC hyperparameters_optimizer.cc:582] [94/500] Score: -0.873489 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.4557 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873904\n",
      "[INFO 24-02-22 06:45:54.4558 UTC gradient_boosted_trees.cc:271] Truncates the model to 113 tree(s) i.e. 113  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.4560 UTC gradient_boosted_trees.cc:334] Final model num-trees:113 valid-loss:0.873904 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.4560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.4560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.4568 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4573 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.4573 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.4575 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4587 UTC hyperparameters_optimizer.cc:582] [95/500] Score: -0.873904 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:54.4765 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321857 train-accuracy:0.599691 valid-loss:1.299707 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.4768 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293400 train-accuracy:0.599691 valid-loss:1.278410 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.5096 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883627\n",
      "[INFO 24-02-22 06:45:54.5096 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.5098 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.883627 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.5103 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.5103 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.5105 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.5121 UTC hyperparameters_optimizer.cc:582] [96/500] Score: -0.883627 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.5286 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320953 train-accuracy:0.599691 valid-loss:1.300458 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.6652 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.818453\n",
      "[INFO 24-02-22 06:45:54.6653 UTC gradient_boosted_trees.cc:271] Truncates the model to 192 tree(s) i.e. 192  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.6653 UTC gradient_boosted_trees.cc:334] Final model num-trees:192 valid-loss:0.818453 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.6668 UTC hyperparameters_optimizer.cc:582] [97/500] Score: -0.818453 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:54.6678 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.6678 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.6680 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.6696 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.301557 train-accuracy:0.599691 valid-loss:1.290466 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.6942 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851904\n",
      "[INFO 24-02-22 06:45:54.6943 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.6946 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.851904 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:54.6959 UTC hyperparameters_optimizer.cc:582] [98/500] Score: -0.851904 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:54.6972 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.6972 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.6974 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.7104 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236315 train-accuracy:0.599691 valid-loss:1.244088 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.7184 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883665\n",
      "[INFO 24-02-22 06:45:54.7184 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.7185 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.883665 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.7190 UTC hyperparameters_optimizer.cc:582] [99/500] Score: -0.883665 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.7196 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.7197 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.7198 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.7365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321471 train-accuracy:0.599691 valid-loss:1.295724 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.7714 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858828\n",
      "[INFO 24-02-22 06:45:54.7715 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.7717 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.858828 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.7727 UTC hyperparameters_optimizer.cc:582] [100/500] Score: -0.858828 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:54.7734 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.7735 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.7743 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.7836 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.630140 train-accuracy:0.877898 valid-loss:0.835657 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:54.7836 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.7837 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.834202 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.7841 UTC hyperparameters_optimizer.cc:582] [101/500] Score: -0.834202 / -0.758798 HParams: [INFOfields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      " 24-02-22 06:45:54.7841 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.7841 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.7844 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.7906 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284991 train-accuracy:0.599691 valid-loss:1.283349 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.8013 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224230 train-accuracy:0.599691 valid-loss:1.230998 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.8587 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848704\n",
      "[INFO 24-02-22 06:45:54.8588 UTC gradient_boosted_trees.cc:271] Truncates the model to 168 tree(s) i.e. 168  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.8590 UTC gradient_boosted_trees.cc:334] Final model num-trees:168 valid-loss:0.848704 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.8606 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.8606 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.8608 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.8624 UTC hyperparameters_optimizer.cc:582] [102/500] Score: -0.848704 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:54.8776 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240591 train-accuracy:0.599691 valid-loss:1.250737 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.1457 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823628\n",
      "[INFO 24-02-22 06:45:55.1458 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.1459 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.823628 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:55.1466 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.1466 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.1466 UTC hyperparameters_optimizer.cc:582] [103/500] Score: -0.823628 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:55.1470 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.1606 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241544 train-accuracy:0.599691 valid-loss:1.246401 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.3254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849427\n",
      "[INFO 24-02-22 06:45:55.3254 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.3256 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.849427 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.3262 UTC hyperparameters_optimizer.cc:582] [104/500] Score: -0.849427 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:55.3266 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.3267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.3272 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.3326 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326646 train-accuracy:0.599691 valid-loss:1.301765 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.3468 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.888552\n",
      "[INFO 24-02-22 06:45:55.3472 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.3478 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.888552 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:55.3493 UTC hyperparameters_optimizer.cc:582] [105/500] Score: -0.888552 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:55.3498 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.3499 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.3508 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.3599 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266087 train-accuracy:0.599691 valid-loss:1.262687 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.6215 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.894546\n",
      "[INFO 24-02-22 06:45:55.6215 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.6218 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.894546 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:55.6280 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.88059\n",
      "[INFO 24-02-22 06:45:55.6280 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.6296 UTC hyperparameters_optimizer.cc:582] [106/500] Score: -0.894546 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:55.6299 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.880590 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.6303 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.6303 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.6307 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.6307 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.6308 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.6309 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.6357 UTC hyperparameters_optimizer.cc:582] [107/500] Score: -0.88059 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:55.6381 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.256282 train-accuracy:0.599691 valid-loss:1.249756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.6450 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.327334 train-accuracy:0.599691 valid-loss:1.303216 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.7141 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855232\n",
      "[INFO 24-02-22 06:45:55.7141 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.7143 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.855232 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:55.7150 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.7150 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.7151 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.7187 UTC hyperparameters_optimizer.cc:582] [108/500] Score: -0.855232 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:55.7255 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324626 train-accuracy:0.599691 valid-loss:1.303213 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.7460 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.811014\n",
      "[INFO 24-02-22 06:45:55.7460 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.7462 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.811014 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.7465 UTC hyperparameters_optimizer.cc:582] [109/500] Score: -0.811014 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:55.7469 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.7469 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.7471 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.7648 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284398 train-accuracy:0.599691 valid-loss:1.286776 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.7717 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.476921 train-accuracy:0.924266 valid-loss:0.825049 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:55.7717 UTC gradient_boosted_trees.cc:271] Truncates the model to 281 tree(s) i.e. 281  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.7717 UTC gradient_boosted_trees.cc:334] Final model num-trees:281 valid-loss:0.824350 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.7725 UTC hyperparameters_optimizer.cc:582] [110/500] Score: -0.82435 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:55.7738 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.7738 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.7741 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.7874 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284343 train-accuracy:0.599691 valid-loss:1.271003 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.8541 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.90319\n",
      "[INFO 24-02-22 06:45:55.8541 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.8544 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.903190 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:55.8551 UTC hyperparameters_optimizer.cc:582] [111/500] Score: -0.90319 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:55.8556 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.8556 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.8559 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.8656 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323505 train-accuracy:0.599691 valid-loss:1.299270 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.8843 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.890846\n",
      "[INFO 24-02-22 06:45:55.8843 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.8855 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.890846 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.8887 UTC hyperparameters_optimizer.cc:582] [112/500] Score: -0.890846 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:55.8899 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.8899 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.8901 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.8991 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294888 train-accuracy:0.599691 valid-loss:1.280547 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.9444 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842825\n",
      "[INFO 24-02-22 06:45:55.9444 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.9446 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.842825 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.9449 UTC hyperparameters_optimizer.cc:582] [113/500] Score: -0.842825 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:55.9452 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.9453 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.9459 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.9740 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225948 train-accuracy:0.599691 valid-loss:1.241712 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.0807 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806746\n",
      "[INFO 24-02-22 06:45:56.0808 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.0809 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.806746 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:56.0811 UTC hyperparameters_optimizer.cc:582] [114/500] Score: -0.806746 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:56.0814 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.0814 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.0816 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.0993 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238274 train-accuracy:0.599691 valid-loss:1.234636 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.1823 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845586\n",
      "[INFO 24-02-22 06:45:56.1824 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.1826 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.845586 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:56.1833 UTC hyperparameters_optimizer.cc:582] [115/500] Score: -0.845586 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:56.1840 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.1840 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.1842 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.1942 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292518 train-accuracy:0.599691 valid-loss:1.276618 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.3668 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.894137\n",
      "[INFO 24-02-22 06:45:56.3669 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.3672 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.894137 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:56.3689 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.3690 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.3692 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.3694 UTC hyperparameters_optimizer.cc:582] [116/500] Score: -0.894137 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:56.3882 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324088 train-accuracy:0.599691 valid-loss:1.303607 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.3943 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836579\n",
      "[INFO 24-02-22 06:45:56.3943 UTC gradient_boosted_trees.cc:271] Truncates the model to 78 tree(s) i.e. 78  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.3943 UTC gradient_boosted_trees.cc:334] Final model num-trees:78 valid-loss:0.836579 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:56.3947 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.3947 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.3953 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.3987 UTC hyperparameters_optimizer.cc:582] [117/500] Score: -0.836579 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:56.4045 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247594 train-accuracy:0.599691 valid-loss:1.248466 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.4996 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849021\n",
      "[INFO 24-02-22 06:45:56.4996 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.4999 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.849021 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:56.5008 UTC hyperparameters_optimizer.cc:582] [118/500] Score: -0.849021 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:56.5030 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.5030 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.5032 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.5187 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234196 train-accuracy:0.599691 valid-loss:1.232174 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.7319 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880967\n",
      "[INFO 24-02-22 06:45:56.7319 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.7323 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.880967 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:56.7327 UTC hyperparameters_optimizer.cc:582] [119/500] Score: -0.880967 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:56.7337 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.7337 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.7340 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.7535 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282339 train-accuracy:0.599691 valid-loss:1.276376 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.8866 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839515\n",
      "[INFO 24-02-22 06:45:56.8866 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.8868 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.839515 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:56.8876 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.8876 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.8877 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.8893 UTC hyperparameters_optimizer.cc:582] [120/500] Score: -0.839515 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:56.8930 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246510 train-accuracy:0.599691 valid-loss:1.249096 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.9001 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871688\n",
      "[INFO 24-02-22 06:45:56.9001 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.9004 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.871688 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:56.9016 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.9017 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.9019 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.9054 UTC hyperparameters_optimizer.cc:582] [121/500] Score: -0.871688 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:56.9105 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236788 train-accuracy:0.599691 valid-loss:1.237309 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.9914 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852859\n",
      "[INFO 24-02-22 06:45:56.9914 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.9916 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.852859 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:56.9919 UTC hyperparameters_optimizer.cc:582] [122/500] Score: -0.852859 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:56.9924 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.9924 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.9927 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.0185 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226874 train-accuracy:0.599691 valid-loss:1.245509 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.0648 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.828724\n",
      "[INFO 24-02-22 06:45:57.0649 UTC gradient_boosted_trees.cc:271] Truncates the model to 250 tree(s) i.e. 250  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.0649 UTC gradient_boosted_trees.cc:334] Final model num-trees:250 valid-loss:0.828724 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:57.0654 UTC hyperparameters_optimizer.cc:582] [123/500] Score: -0.828724 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:57.0657 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.0657 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.0661 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.0761 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840335\n",
      "[INFO 24-02-22 06:45:57.0761 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.0762 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.840335 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.0768 UTC hyperparameters_optimizer.cc:582] [124/500] Score: -0.840335 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:57.0805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.0805 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.0807 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.0824 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288320 train-accuracy:0.599691 valid-loss:1.277649 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1084 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287834 train-accuracy:0.599691 valid-loss:1.277494 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1300 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.870566\n",
      "[INFO 24-02-22 06:45:57.1300 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.1303 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.870566 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:57.1308 UTC hyperparameters_optimizer.cc:582] [125/500] Score: -0.870566 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:57.1312 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.1312 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.1317 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.1489 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324613 train-accuracy:0.599691 valid-loss:1.299334 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1671 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.837656\n",
      "[INFO 24-02-22 06:45:57.1672 UTC gradient_boosted_trees.cc:271] Truncates the model to 258 tree(s) i.e. 258  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.1672 UTC gradient_boosted_trees.cc:334] Final model num-trees:258 valid-loss:0.837656 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.1678 UTC hyperparameters_optimizer.cc:582] [126/500] Score: -0.837656 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:57.1692 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.1693 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.1698 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.1849 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866406\n",
      "[INFO 24-02-22 06:45:57.1849 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.1850 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.866406 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.1855 UTC hyperparameters_optimizer.cc:582] [127/500] Score: -0.866406 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:57.1865 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.1865 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.1867 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.1877 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243688 train-accuracy:0.599691 valid-loss:1.255966 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1967 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322819 train-accuracy:0.599691 valid-loss:1.298133 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1972 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881582\n",
      "[INFO 24-02-22 06:45:57.1972 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.1975 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.881582 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:57.1978 UTC hyperparameters_optimizer.cc:582] [128/500] Score: -0.881582 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:57.1983 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.1983 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.1987 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.2127 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325571 train-accuracy:0.599691 valid-loss:1.304232 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.3259 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858251\n",
      "[INFO 24-02-22 06:45:57.3259 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.3261 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.858251 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:57.3269 UTC hyperparameters_optimizer.cc:582] [129/500] Score: -0.858251 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:57.3276 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.3276 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.3278 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.3377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322770 train-accuracy:0.599691 valid-loss:1.298749 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.5135 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86566\n",
      "[INFO 24-02-22 06:45:57.5137 UTC gradient_boosted_trees.cc:271] Truncates the model to 131 tree(s) i.e. 131  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.5140 UTC gradient_boosted_trees.cc:334] Final model num-trees:131 valid-loss:0.865660 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:57.5147 UTC hyperparameters_optimizer.cc:582] [130/500] Score: -0.86566 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:57.5165 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.5165 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.5168 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.5252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298239 train-accuracy:0.599691 valid-loss:1.279649 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.5350 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844609\n",
      "[INFO 24-02-22 06:45:57.5351 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.5353 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.844609 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.5360 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.5361 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.5364 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.5387 UTC hyperparameters_optimizer.cc:582] [131/500] Score: -0.844609 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:57.5457 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232166 train-accuracy:0.599691 valid-loss:1.245184 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.5472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868087\n",
      "[INFO 24-02-22 06:45:57.5473 UTC gradient_boosted_trees.cc:271] Truncates the model to 151 tree(s) i.e. 151  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.5475 UTC gradient_boosted_trees.cc:334] Final model num-trees:151 valid-loss:0.868087 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.5489 UTC hyperparameters_optimizer.cc:582] [132/500] Score: -0.868087 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:57.5503 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.5505 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.5509 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.5646 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232204 train-accuracy:0.599691 valid-loss:1.237812 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.6116 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.821189\n",
      "[INFO 24-02-22 06:45:57.6116 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.6120 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.821189 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:57.6126 UTC hyperparameters_optimizer.cc:582] [133/500] Score: -0.821189 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:57.6128 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.6128 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.6130 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.6226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323450 train-accuracy:0.599691 valid-loss:1.297224 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.7260 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842676\n",
      "[INFO 24-02-22 06:45:57.7260 UTC gradient_boosted_trees.cc:271] Truncates the model to 151 tree(s) i.e. 151  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.7261 UTC gradient_boosted_trees.cc:334] Final model num-trees:151 valid-loss:0.842676 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:57.7271 UTC hyperparameters_optimizer.cc:582] [134/500] Score: -0.842676 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:57.7277 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.7277 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.7286 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.7433 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324091 train-accuracy:0.599691 valid-loss:1.296394 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.7812 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845881\n",
      "[INFO 24-02-22 06:45:57.7812 UTC gradient_boosted_trees.cc:271] Truncates the model to 140 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.7815 UTC gradient_boosted_trees.cc:334] Final model num-trees:140 valid-loss:0.845881 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:57.7828 UTC hyperparameters_optimizer.cc:582] [135/500] Score: -0.845881 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:57.7842 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.7842 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.7844 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.7958 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324051 train-accuracy:0.599691 valid-loss:1.302081 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.9601 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.899409\n",
      "[INFO 24-02-22 06:45:57.9601 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.9604 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.899409 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:57.9609 UTC hyperparameters_optimizer.cc:582] [136/500] Score: -0.899409 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:57.9614 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.9614 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.9616 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.9712 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323619 train-accuracy:0.599691 valid-loss:1.302112 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.0054 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891364\n",
      "[INFO 24-02-22 06:45:58.0054 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.0056 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.891364 valid-accuracy:0.772727\n",
      "[[INFO 24-02-22 06:45:58.0061 UTC hyperparameters_optimizer.cc:582] [137/500] Score: -0.891364 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "INFO 24-02-22 06:45:58.0062 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.0062 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.0067 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.0192 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229498 train-accuracy:0.599691 valid-loss:1.245338 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.1479 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859885\n",
      "[INFO 24-02-22 06:45:58.1479 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.1481 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.859885 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.1508 UTC gradient_boosted_trees.cc:[INFO 24-02-22 06:45:58.1524 UTC hyperparameters_optimizer.cc:582] 591] Default loss set to [138/BINOMIAL_LOG_LIKELIHOOD\n",
      "500] Score: -0.859885 / -0.758798 HParams: [INFO 24-02-22 06:45:58.1525 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.1530 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.1694 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231566 train-accuracy:0.599691 valid-loss:1.242215 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.1879 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846067\n",
      "[INFO 24-02-22 06:45:58.1880 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.1882 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.846067 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:58.1891 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.1891 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.1892 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.1919 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328953 train-accuracy:0.599691 valid-loss:1.304642 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.1921 UTC hyperparameters_optimizer.cc:582] [139/500] Score: -0.846067 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.2933 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.830987\n",
      "[INFO 24-02-22 06:45:58.2934 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.2936 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.830987 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:58.2939 UTC hyperparameters_optimizer.cc:582] [140/500] Score: -0.830987 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:58.2962 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.2963 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.2965 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.3056 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290789 train-accuracy:0.599691 valid-loss:1.277578 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.4010 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834941\n",
      "[INFO 24-02-22 06:45:58.4010 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.4011 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.834941 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:58.4013 UTC hyperparameters_optimizer.cc:582] [141/500] Score: -0.834941 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.4024 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.4026 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.4029 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.4170 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321871 train-accuracy:0.599691 valid-loss:1.303112 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.5752 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845996\n",
      "[INFO 24-02-22 06:45:58.5752 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.5753 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.845996 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.5757 UTC hyperparameters_optimizer.cc:582] [142/500] Score: -0.845996 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:58.5761 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.5761 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.5765 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.5800 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.88359\n",
      "[INFO 24-02-22 06:45:58.5800 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.5803 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.883590 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.5811 UTC hyperparameters_optimizer.cc:582] [143/500] Score: -0.88359 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.5827 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.5828 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.5830 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.5845 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.249482 train-accuracy:0.599691 valid-loss:1.259961 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.6072 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222709 train-accuracy:0.599691 valid-loss:1.245217 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.7198 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867383\n",
      "[INFO 24-02-22 06:45:58.7198 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.7200 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.867383 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.7205 UTC hyperparameters_optimizer.cc:582] [144/500] Score: -0.867383 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.7211 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.7211 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.7214 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.7251 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299191 train-accuracy:0.599691 valid-loss:1.287499 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.9340 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867043\n",
      "[INFO 24-02-22 06:45:58.9341 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.9343 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.867043 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.9347 UTC hyperparameters_optimizer.cc:582] [145/500] Score: -0.867043 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:58.9356 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.9356 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.9359 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.9452 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286003 train-accuracy:0.599691 valid-loss:1.269670 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.9801 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868128\n",
      "[INFO 24-02-22 06:45:58.9802 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.9804 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.868128 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.9810 UTC hyperparameters_optimizer.cc:582] [146/500] Score: -0.868128 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.9821 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.9821 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.9824 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.0007 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292728 train-accuracy:0.599691 valid-loss:1.278734 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.1461 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.665948 train-accuracy:0.877898 valid-loss:0.862057 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.1461 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.1480 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.862057 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.1485 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.1485 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.1486 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.1524 UTC hyperparameters_optimizer.cc:582] [147/500] Score: -0.862057 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.1655 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288129 train-accuracy:0.599691 valid-loss:1.269813 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.1941 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.8915\n",
      "[INFO 24-02-22 06:45:59.1942 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.1946 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.891500 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:59.1972 UTC hyperparameters_optimizer.cc:582] [148/500] Score: -0.8915 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.2002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.2003 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.2006 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.2160 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.250557 train-accuracy:0.599691 valid-loss:1.250360 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.3566 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.841222\n",
      "[INFO 24-02-22 06:45:59.3566 UTC gradient_boosted_trees.cc:271] Truncates the model to 110 tree(s) i.e. 110  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.3569 UTC gradient_boosted_trees.cc:334] Final model num-trees:110 valid-loss:0.841222 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:59.3578 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.3578 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.3580 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.3587 UTC hyperparameters_optimizer.cc:582] [149/500] Score: -0.841222 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.3743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240513 train-accuracy:0.599691 valid-loss:1.236605 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.4124 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839641\n",
      "[INFO 24-02-22 06:45:59.4125 UTC gradient_boosted_trees.cc:271] Truncates the model to 154 tree(s) i.e. 154  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.4125 UTC gradient_boosted_trees.cc:334] Final model num-trees:154 valid-loss:0.839641 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.4129 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.4130 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.4130 UTC hyperparameters_optimizer.cc:582] [150/500] Score: -0.839641 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:59.4133 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.4359 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280830 train-accuracy:0.599691 valid-loss:1.269141 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.4762 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.828555\n",
      "[INFO 24-02-22 06:45:59.4762 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.4763 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.828555 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.4765 UTC hyperparameters_optimizer.cc:582] [151/500] Score: -0.828555 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.4769 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.4770 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.4772 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.4903 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243165 train-accuracy:0.599691 valid-loss:1.253930 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5050 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849009\n",
      "[INFO 24-02-22 06:45:59.5050 UTC gradient_boosted_trees.cc:271] Truncates the model to 158 tree(s) i.e. 158  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5051 UTC gradient_boosted_trees.cc:334] Final model num-trees:158 valid-loss:0.849009 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:59.5064 UTC hyperparameters_optimizer.cc:582] [152/500] Score: -0.849009 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:59.5069 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5070 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.5076 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.5111 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849079\n",
      "[INFO 24-02-22 06:45:59.5112 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5113 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.849079 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.5119 UTC hyperparameters_optimizer.cc:582] [153/500] Score: -0.849079 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:59.5127 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5127 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.5129 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.5159 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867116\n",
      "[INFO 24-02-22 06:45:59.5159 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5161 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.867116 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:59.5169 UTC hyperparameters_optimizer.cc:582] [154/500] Score: -0.867116 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:59.5172 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.909698\n",
      "[INFO 24-02-22 06:45:59.5172 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5174 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.909698 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.5175 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302074 train-accuracy:0.599691 valid-loss:1.284614 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5180 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5180 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.5181 UTC hyperparameters_optimizer.cc:582] [155/500] Score: -0.909698 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.5184 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5184 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.5185 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.5186 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.5251 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.303281 train-accuracy:0.599691 valid-loss:1.286197 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5299 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236326 train-accuracy:0.599691 valid-loss:1.239036 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5405 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321382 train-accuracy:0.599691 valid-loss:1.301534 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5965 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881148\n",
      "[INFO 24-02-22 06:45:59.5966 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5968 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.881148 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:59.5976 UTC hyperparameters_optimizer.cc:582] [156/500] Score: -0.881148 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.5982 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5982 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.6004 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.6205 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291178 train-accuracy:0.599691 valid-loss:1.279230 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.7239 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.886151\n",
      "[INFO 24-02-22 06:45:59.7239 UTC gradient_boosted_trees.cc:271] Truncates the model to 178 tree(s) i.e. 178  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.7241 UTC gradient_boosted_trees.cc:334] Final model num-trees:178 valid-loss:0.886151 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.7253 UTC hyperparameters_optimizer.cc:582] [157/500] Score: -0.886151 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:59.7279 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.7279 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.7288 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.7431 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324904 train-accuracy:0.599691 valid-loss:1.300962 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.8839 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866793\n",
      "[INFO 24-02-22 06:45:59.8839 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.8842 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.866793 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.8849 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.8849 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.8851 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.8879 UTC hyperparameters_optimizer.cc:582] [158/500] Score: -0.866793 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:59.8970 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323661 train-accuracy:0.599691 valid-loss:1.300292 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.1692 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846071\n",
      "[INFO 24-02-22 06:46:00.1692 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.1694 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.846071 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:00.1702 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.1702 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.1704 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.1707 UTC hyperparameters_optimizer.cc:582] [159/500] Score: -0.846071 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:00.1818 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234480 train-accuracy:0.599691 valid-loss:1.239550 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.2073 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844673\n",
      "[INFO 24-02-22 06:46:00.2073 UTC gradient_boosted_trees.cc:271] Truncates the model to 165 tree(s) i.e. 165  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.2075 UTC gradient_boosted_trees.cc:334] Final model num-trees:165 valid-loss:0.844673 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:00.2091 UTC hyperparameters_optimizer.cc:582] [160/500] Score: -0.844673 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.2106 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.2108 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.2113 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.2258 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290114 train-accuracy:0.599691 valid-loss:1.275710 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.2793 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832439\n",
      "[INFO 24-02-22 06:46:00.2793 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.2793 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.832439 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:00.2795 UTC hyperparameters_optimizer.cc:582] [161/500] Score: -0.832439 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:00.2798 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.2798 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.2800 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.2809 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.812552\n",
      "[INFO 24-02-22 06:46:00.2809 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.2810 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.812552 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:00.2813 UTC hyperparameters_optimizer.cc:582] [162/500] Score: -0.812552 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.2818 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.2820 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.2824 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.2828 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883554\n",
      "[INFO 24-02-22 06:46:00.2828 UTC gradient_boosted_trees.cc:271] Truncates the model to 129 tree(s) i.e. 129  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.2830 UTC gradient_boosted_trees.cc:334] Final model num-trees:129 valid-loss:0.883554 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:00.2845 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.2845 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.2847 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.2854 UTC hyperparameters_optimizer.cc:582] [163/500] Score: -0.883554 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.2911 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246292 train-accuracy:0.599691 valid-loss:1.253693 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.2980 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320625 train-accuracy:0.599691 valid-loss:1.301433 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.2984 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.267449 train-accuracy:0.599691 valid-loss:1.260474 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.3297 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.79449\n",
      "[INFO 24-02-22 06:46:00.3298 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.3299 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.794490 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:00.3302 UTC hyperparameters_optimizer.cc:582] [164/500] Score: -0.79449 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.3306 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.3306 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.3309 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.3363 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.250811 train-accuracy:0.599691 valid-loss:1.251427 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.3933 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836357\n",
      "[INFO 24-02-22 06:46:00.3933 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.3935 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.836357 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:00.3941 UTC hyperparameters_optimizer.cc:582] [165/500] Score: -0.836357 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.3952 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.3955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.3960 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.3990 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262917 train-accuracy:0.599691 valid-loss:1.255451 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.4302 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855804\n",
      "[INFO 24-02-22 06:46:00.4302 UTC gradient_boosted_trees.cc:271] Truncates the model to 163 tree(s) i.e. 163  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.4304 UTC gradient_boosted_trees.cc:334] Final model num-trees:163 valid-loss:0.855804 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:00.4314 UTC hyperparameters_optimizer.cc:582] [166/500] Score: -0.855804 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:00.4318 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.4318 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.4326 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.4509 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292517 train-accuracy:0.599691 valid-loss:1.282027 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.5316 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.816336\n",
      "[INFO 24-02-22 06:46:00.5316 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.5318 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.816336 valid-accuracy:0.833333\n",
      "[[INFO 24-02-22 06:46:00.5324 UTC hyperparameters_optimizer.cc:582] [167/500] Score: -0.816336 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "INFO 24-02-22 06:46:00.5327 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.5327 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.5330 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.5505 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226879 train-accuracy:0.599691 valid-loss:1.241126 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.7037 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858464\n",
      "[INFO 24-02-22 06:46:00.7038 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.7038 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.858464 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:00.7042 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.7042 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.7044 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.7054 UTC hyperparameters_optimizer.cc:582] [168/500] Score: -0.858464 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:00.7149 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235176 train-accuracy:0.599691 valid-loss:1.223951 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.7425 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850947\n",
      "[INFO 24-02-22 06:46:00.7426 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.7427 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.850947 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:00.7431 UTC hyperparameters_optimizer.cc:582] [169/500] Score: -0.850947 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:00.7434 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.7434 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.7438 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.7497 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324958 train-accuracy:0.599691 valid-loss:1.301035 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.9318 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.821383\n",
      "[INFO 24-02-22 06:46:00.9319 UTC gradient_boosted_trees.cc:271] Truncates the model to 257 tree(s) i.e. 257  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.9319 UTC gradient_boosted_trees.cc:334] Final model num-trees:257 valid-loss:0.821383 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:00.9322 UTC hyperparameters_optimizer.cc:582] [170/500] Score: -0.821383 / -0.758798 HParams: [INFO 24-02-22 06:46:00.9324 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.9324 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.9326 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:00.9435 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323168 train-accuracy:0.599691 valid-loss:1.304000 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.0035 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.915345\n",
      "[INFO 24-02-22 06:46:01.0035 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.0038 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.915345 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:01.0043 UTC hyperparameters_optimizer.cc:582] [171/500] Score: -0.915345 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:01.0049 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.0049 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.0055 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.0239 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230135 train-accuracy:0.599691 valid-loss:1.238685 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.0655 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855706\n",
      "[INFO 24-02-22 06:46:01.0656 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.0658 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.855706 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:01.0661 UTC hyperparameters_optimizer.cc:582] [172/500] Score: -0.855706 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.0669 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.0669 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.0671 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.0800 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233363 train-accuracy:0.599691 valid-loss:1.234657 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.1778 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.828484\n",
      "[INFO 24-02-22 06:46:01.1778 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.1779 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.828484 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:01.1782 UTC hyperparameters_optimizer.cc:582] [173/500] Score: -0.828484 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:01.1786 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.1786 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.1788 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.1907 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284759 train-accuracy:0.599691 valid-loss:1.269787 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.2326 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.812656\n",
      "[INFO 24-02-22 06:46:01.2326 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.2328 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.812656 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.2333 UTC hyperparameters_optimizer.cc:582] [174/500] Score: -0.812656 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:01.2337 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.2337 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.2340 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.2343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.802782\n",
      "[INFO 24-02-22 06:46:01.2343 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.2343 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.802782 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:01.2346 UTC hyperparameters_optimizer.cc:582] [175/500] Score: -0.802782 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.2350 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.2350 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.2353 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.2447 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291651 train-accuracy:0.599691 valid-loss:1.274528 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.2448 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293438 train-accuracy:0.599691 valid-loss:1.270533 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.2628 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838958\n",
      "[INFO 24-02-22 06:46:01.2634 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.2636 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.838958 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.2641 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.2641 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.2643 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.2675 UTC hyperparameters_optimizer.cc:582] [176/500] Score: -0.838958 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.2774 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325116 train-accuracy:0.599691 valid-loss:1.300908 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.3058 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.892219\n",
      "[INFO 24-02-22 06:46:01.3059 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.3061 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.892219 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.3074 UTC hyperparameters_optimizer.cc:582] [177/500] Score: -0.892219 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.3086 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.3087 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.3089 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.3176 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296573 train-accuracy:0.599691 valid-loss:1.279891 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.4113 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850301\n",
      "[INFO 24-02-22 06:46:01.4116 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.4118 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.850301 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:01.4120 UTC hyperparameters_optimizer.cc:582] [178/500] Score: -0.850301 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.4143 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.4143 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.4145 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.4298 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323628 train-accuracy:0.599691 valid-loss:1.301374 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.5122 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.87215\n",
      "[INFO 24-02-22 06:46:01.5123 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.5124 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.872150 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.5128 UTC hyperparameters_optimizer.cc:582] [179/500] Score: -0.87215 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:01.5139 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.5139 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.5141 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.5314 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224710 train-accuracy:0.599691 valid-loss:1.241904 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.5915 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86204\n",
      "[INFO 24-02-22 06:46:01.5915 UTC gradient_boosted_trees.cc:271] Truncates the model to 130 tree(s) i.e. 130  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.5917 UTC gradient_boosted_trees.cc:334] Final model num-trees:130 valid-loss:0.862040 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:01.5925 UTC hyperparameters_optimizer.cc:582] [180/500] Score: -0.86204 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:01.5944 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.5944 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.5946 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.6005 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.250313 train-accuracy:0.599691 valid-loss:1.234948 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.6836 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.87804\n",
      "[INFO 24-02-22 06:46:01.6836 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.6838 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.878040 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.6843 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.6843 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.6845 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.6846 UTC hyperparameters_optimizer.cc:582] [181/500] Score: -0.87804 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:01.6865 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297247 train-accuracy:0.599691 valid-loss:1.291178 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.7245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850297\n",
      "[INFO 24-02-22 06:46:01.7245 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.7246 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.850297 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:01.7255 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.7255 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.7257 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.7287 UTC hyperparameters_optimizer.cc:582] [182/500] Score: -0.850297 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:01.7471 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321078 train-accuracy:0.599691 valid-loss:1.300097 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.7875 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859761\n",
      "[INFO 24-02-22 06:46:01.7902 UTC gradient_boosted_trees.cc:271] Truncates the model to 102 tree(s) i.e. 102  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.7903 UTC gradient_boosted_trees.cc:334] Final model num-trees:102 valid-loss:0.859761 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:01.7908 UTC hyperparameters_optimizer.cc:582] [183/500] Score: -0.859761 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:01.7924 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.7924 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.7926 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.8035 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325976 train-accuracy:0.599691 valid-loss:1.303840 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.0154 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.84785\n",
      "[INFO 24-02-22 06:46:02.0154 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.0155 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.847850 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.0159 UTC hyperparameters_optimizer.cc:582] [184/500] Score: -0.84785 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.0165 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.0165 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.0167 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.0220 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263445 train-accuracy:0.599691 valid-loss:1.257060 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.0619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875343\n",
      "[INFO 24-02-22 06:46:02.0619 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.0625 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.875343 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.0628 UTC hyperparameters_optimizer.cc:582] [185/500] Score: -0.875343 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:02.0634 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.0634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.0635 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.0792 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322625 train-accuracy:0.599691 valid-loss:1.298635 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.1166 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.84172\n",
      "[INFO 24-02-22 06:46:02.1166 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.1168 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.841720 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.1171 UTC hyperparameters_optimizer.cc:582] [186/500] Score: -0.84172 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:02.1174 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.1174 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.1176 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.1288 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326067 train-accuracy:0.599691 valid-loss:1.300447 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.1316 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864405\n",
      "[INFO 24-02-22 06:46:02.1316 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.1318 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.864405 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:02.1326 UTC hyperparameters_optimizer.cc:582] [187/500] Score: -0.864405 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.1331 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.1332 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.1338 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.1387 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257049 train-accuracy:0.599691 valid-loss:1.251756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.2045 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838905\n",
      "[INFO 24-02-22 06:46:02.2045 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.2047 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.838905 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:02.2054 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.2054 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.2056 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.2087 UTC hyperparameters_optimizer.cc:582] [188/500] Score: -0.838905 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:02.2142 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852657\n",
      "[INFO 24-02-22 06:46:02.2142 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.2144 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.852657 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.2147 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244933 train-accuracy:0.599691 valid-loss:1.249263 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.2149 UTC hyperparameters_optimizer.cc:582] [189/500] Score: -0.852657 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.2218 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.2219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.2222 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.2355 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237601 train-accuracy:0.599691 valid-loss:1.224684 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.2439 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875839\n",
      "[INFO 24-02-22 06:46:02.2442 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.2447 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.875839 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.2452 UTC hyperparameters_optimizer.cc:582] [190/500] Score: -0.875839 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:02.2461 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.2462 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.2466 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.2583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242063 train-accuracy:0.599691 valid-loss:1.247574 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.3636 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873904\n",
      "[INFO 24-02-22 06:46:02.3636 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.3638 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.873904 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.3648 UTC hyperparameters_optimizer.cc:582] [191/500] Score: -0.873904 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.3672 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.3673 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.3676 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.3728 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326447 train-accuracy:0.599691 valid-loss:1.300664 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.4263 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859907\n",
      "[INFO 24-02-22 06:46:02.4263 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.4264 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.859907 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.4269 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.4269 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.4271 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.4276 UTC hyperparameters_optimizer.cc:582] [192/500] Score: -0.859907 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:02.4367 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238566 train-accuracy:0.599691 valid-loss:1.238345 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.5500 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.870194\n",
      "[INFO 24-02-22 06:46:02.5500 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.5503 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.870194 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.5509 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.5509 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.5511 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.5521 UTC hyperparameters_optimizer.cc:582] [193/500] Score: -0.870194 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:02.5604 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290180 train-accuracy:0.599691 valid-loss:1.273954 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.5886 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851558\n",
      "[INFO 24-02-22 06:46:02.5886 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.5886 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.851558 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.5889 UTC hyperparameters_optimizer.cc:582] [194/500] Score: -0.851558 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.5892 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.5892 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.5894 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.5984 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326388 train-accuracy:0.599691 valid-loss:1.303335 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.7303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.822583\n",
      "[INFO 24-02-22 06:46:02.7303 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.7303 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.822583 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:02.7305 UTC hyperparameters_optimizer.cc:582] [195/500] Score: -0.822583 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.7309 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.7309 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.7311 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.7484 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322536 train-accuracy:0.599691 valid-loss:1.298201 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.8320 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.853052\n",
      "[INFO 24-02-22 06:46:02.8320 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.8322 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.853052 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:02.8326 UTC hyperparameters_optimizer.cc:582] [196/500] Score: -0.853052 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.8339 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.8341 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.8343 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.8472 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325359 train-accuracy:0.599691 valid-loss:1.302685 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.9511 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.893887\n",
      "[INFO 24-02-22 06:46:02.9511 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.9513 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.893887 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:02.9517 UTC hyperparameters_optimizer.cc:582] [197/500] Score: -0.893887 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.9522 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.9523 UTC gradient_boosted_trees.cc:[INFO1218] Training gradient boosted tree on 713 example(s) and 9 feature(s). 24-02-22 06:46:02.9524 UTC \n",
      "[INFO 24-02-22 06:46:02.9528 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845838\n",
      "[INFO 24-02-22 06:46:02.9531 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.9533 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.845838 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:02.9536 UTC hyperparameters_optimizer.cc:582] [198/500] Score: -0.845838 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:02.9540 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.9541 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.9542 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.9642 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288404 train-accuracy:0.599691 valid-loss:1.274297 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.9650 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288797 train-accuracy:0.599691 valid-loss:1.279459 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.0098 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85871\n",
      "[INFO 24-02-22 06:46:03.0098 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.0102 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.858710 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:03.0116 UTC hyperparameters_optimizer.cc:582] [199/500] Score: -0.85871 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:03.0130 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.0130 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.0133 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.0252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234473 train-accuracy:0.599691 valid-loss:1.214245 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.0814 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.896019\n",
      "[INFO 24-02-22 06:46:03.0814 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.0815 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.896019 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.0818 UTC hyperparameters_optimizer.cc:582] [200/500] Score: -0.896019 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:03.0826 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.0826 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.0829 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.0955 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322473 train-accuracy:0.599691 valid-loss:1.302628 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.3211 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.885119\n",
      "[INFO 24-02-22 06:46:03.3214 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.3216 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.885119 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:03.3221 UTC hyperparameters_optimizer.cc:582] [201/500] Score: -0.885119 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:03.3232 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.3234 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.3237 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.3390 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866671\n",
      "[INFO 24-02-22 06:46:03.3391 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.3393 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.866671 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.3411 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.3412 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.3413 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.3423 UTC hyperparameters_optimizer.cc:582] [202/500] Score: -0.866671 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:03.3510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322796 train-accuracy:0.599691 valid-loss:1.300515 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.3617 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292385 train-accuracy:0.599691 valid-loss:1.278833 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.5250 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838083\n",
      "[INFO 24-02-22 06:46:03.5250 UTC gradient_boosted_trees.cc:271] Truncates the model to 196 tree(s) i.e. 196  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.5251 UTC gradient_boosted_trees.cc:334] Final model num-trees:196 valid-loss:0.838083 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:03.5254 UTC hyperparameters_optimizer.cc:582] [203/500] Score: -0.838083 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:03.5263 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.5263 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.5271 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.5312 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295128 train-accuracy:0.599691 valid-loss:1.281679 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.6199 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.829883\n",
      "[INFO 24-02-22 06:46:03.6199 UTC gradient_boosted_trees.cc:271] Truncates the model to 163 tree(s) i.e. 163  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.6201 UTC gradient_boosted_trees.cc:334] Final model num-trees:163 valid-loss:0.829883 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:03.6208 UTC hyperparameters_optimizer.cc:582] [204/500] Score: -0.829883 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:03.6211 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.6219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.6226 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.6289 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261358 train-accuracy:0.599691 valid-loss:1.251163 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.7815 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843416\n",
      "[INFO 24-02-22 06:46:03.7815 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.7817 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.843416 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.7825 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.7825 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.7827 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.7854 UTC hyperparameters_optimizer.cc:582] [205/500] Score: -0.843416 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:03.7886 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302953 train-accuracy:0.599691 valid-loss:1.288614 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.9383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845857\n",
      "[INFO 24-02-22 06:46:03.9386 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.9387 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.845857 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.9388 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865152\n",
      "[INFO 24-02-22 06:46:03.9388 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.9389 UTC hyperparameters_optimizer.cc:582] [206/500] Score: -0.845857 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:03.9390 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.865152 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.9394 UTC hyperparameters_optimizer.cc:582] [207/500] Score: -0.865152 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:03.9406 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.9406 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.9408 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.9421 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.9436 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.9438 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.9547 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246865 train-accuracy:0.599691 valid-loss:1.231841 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.9564 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247269 train-accuracy:0.599691 valid-loss:1.237954 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.0689 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843644\n",
      "[INFO 24-02-22 06:46:04.0690 UTC gradient_boosted_trees.cc:271] Truncates the model to 207 tree(s) i.e. 207  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.0691 UTC gradient_boosted_trees.cc:334] Final model num-trees:207 valid-loss:0.843644 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:04.0707 UTC hyperparameters_optimizer.cc:582] [208/500] Score: -0.843644 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:04.0732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.0732 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.0734 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.0854 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322168 train-accuracy:0.599691 valid-loss:1.301637 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.1871 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86079\n",
      "[INFO 24-02-22 06:46:04.1871 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.1872 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.860790 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:04.1874 UTC hyperparameters_optimizer.cc:582] [209/500] Score: -0.86079 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:04.1879 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.1879 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.1882 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.1908 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86558\n",
      "[INFO 24-02-22 06:46:04.1908 UTC gradient_boosted_trees.cc:271] Truncates the model to 153 tree(s) i.e. 153  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.1909 UTC gradient_boosted_trees.cc:334] Final model num-trees:153 valid-loss:0.865580 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:04.1913 UTC hyperparameters_optimizer.cc:582] [210/500] Score: -0.86558 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:04.1920 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.1921 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.1924 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.1929 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262566 train-accuracy:0.599691 valid-loss:1.251289 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.2203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839867\n",
      "[INFO 24-02-22 06:46:04.2204 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.2206 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.839867 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:04.2214 UTC hyperparameters_optimizer.cc:582] [211/500] Score: -0.839867 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:04.2239 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.2239 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.2241 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.2323 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281334 train-accuracy:0.599691 valid-loss:1.279522 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.2426 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235015 train-accuracy:0.599691 valid-loss:1.221871 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.2991 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.890413\n",
      "[INFO 24-02-22 06:46:04.2992 UTC gradient_boosted_trees.cc:271] Truncates the model to 92 tree(s) i.e. 92  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.2994 UTC gradient_boosted_trees.cc:334] Final model num-trees:92 valid-loss:0.890413 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:04.3004 UTC hyperparameters_optimizer.cc:582] [212/500] Score: -0.890413 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:04.3031 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.3031 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.3033 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.3146 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325544 train-accuracy:0.599691 valid-loss:1.300727 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.4796 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.809691\n",
      "[INFO 24-02-22 06:46:04.4796 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.4797 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.809691 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:04.4799 UTC hyperparameters_optimizer.cc:582] [213/500] Score: -0.809691 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:04.4805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.4805 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.4806 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.4874 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237323 train-accuracy:0.599691 valid-loss:1.232162 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.5692 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859307\n",
      "[INFO 24-02-22 06:46:04.5693 UTC gradient_boosted_trees.cc:271] Truncates the model to 172 tree(s) i.e. 172  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.5695 UTC gradient_boosted_trees.cc:334] Final model num-trees:172 valid-loss:0.859307 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:04.5707 UTC hyperparameters_optimizer.cc:582] [214/500] Score: -0.859307 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:04.5712 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.5712 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.5723 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.5910 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279918 train-accuracy:0.599691 valid-loss:1.273780 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.6118 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852731\n",
      "[INFO 24-02-22 06:46:04.6118 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.6120 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.852731 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:04.6125 UTC hyperparameters_optimizer.cc:582] [215/500] Score: -0.852731 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:04.6131 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.6132 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.6134 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.6270 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323972 train-accuracy:0.599691 valid-loss:1.299657 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.6432 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.818836\n",
      "[INFO 24-02-22 06:46:04.6432 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.6434 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.818836 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:04.6440 UTC hyperparameters_optimizer.cc:582] [216/500] Score: -0.818836 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:04.6457 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.6457 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.6459 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.6627 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238784 train-accuracy:0.599691 valid-loss:1.240684 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.6723 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.807477\n",
      "[INFO 24-02-22 06:46:04.6723 UTC gradient_boosted_trees.cc:271] Truncates the model to 192 tree(s) i.e. 192  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.6724 UTC gradient_boosted_trees.cc:334] Final model num-trees:192 valid-loss:0.807477 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:04.6736 UTC hyperparameters_optimizer.cc:582] [217/500] Score: -0.807477 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:04.6743 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.6744 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.6751 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.6767 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825382\n",
      "[INFO 24-02-22 06:46:04.6767 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.6768 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.825382 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:04.6773 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.6773 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.6775 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.6787 UTC hyperparameters_optimizer.cc:582] [218/500] Score: -0.825382 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:04.6838 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329031 train-accuracy:0.599691 valid-loss:1.305317 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.6910 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322495 train-accuracy:0.599691 valid-loss:1.299464 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.7063 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.856445\n",
      "[INFO 24-02-22 06:46:04.7064 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.7067 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.856445 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:04.7071 UTC hyperparameters_optimizer.cc:582] [219/500] Score: -0.856445 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:04.7078 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.7080 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.7085 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.7214 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286585 train-accuracy:0.599691 valid-loss:1.271529 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.9661 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.863366\n",
      "[INFO 24-02-22 06:46:04.9661 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.9663 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.863366 valid-accuracy:0.803030\n",
      "[[INFO 24-02-22 06:46:04.9668 UTC hyperparameters_optimizer.cc:582] [220/500] Score: -0.863366 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "INFO 24-02-22 06:46:04.9670 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.9671 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.9673 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.9759 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248951 train-accuracy:0.599691 valid-loss:1.244663 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.9955 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850757\n",
      "[INFO 24-02-22 06:46:04.9957 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.9957 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.850757 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:04.9959 UTC hyperparameters_optimizer.cc:582] [221/500] Score: -0.850757 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:04.9964 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.9964 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.9966 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.0111 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246771 train-accuracy:0.599691 valid-loss:1.245844 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.0678 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867971\n",
      "[INFO 24-02-22 06:46:05.0678 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.0681 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.867971 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:05.0692 UTC hyperparameters_optimizer.cc:582] [222/500] Score: -0.867971 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:05.0714 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.0714 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.0716 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.0847 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286886 train-accuracy:0.599691 valid-loss:1.275457 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.2246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864505\n",
      "[INFO 24-02-22 06:46:05.2246 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.2249 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.864505 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:05.2266 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.2268 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.2271 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.2274 UTC hyperparameters_optimizer.cc:582] [223/500] Score: -0.864505 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:05.2416 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322900 train-accuracy:0.599691 valid-loss:1.298998 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.3313 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.829992\n",
      "[INFO 24-02-22 06:46:05.3314 UTC gradient_boosted_trees.cc:271] Truncates the model to 158 tree(s) i.e. 158  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.3315 UTC gradient_boosted_trees.cc:334] Final model num-trees:158 valid-loss:0.829992 valid-accuracy:0.803030\n",
      "[INFO[INFO 24-02-22 06:46:05.3328 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-22 06:46:05.3328 UTC hyperparameters_optimizer.cc:[582] [224/INFO500 24-02-22 06:46:05.3329 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713] Score:  example(s) and 9 feature(s).\n",
      "-0.829992 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:05.3337 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.3437 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325154 train-accuracy:0.599691 valid-loss:1.303593 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.5202 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85535\n",
      "[INFO 24-02-22 06:46:05.5202 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.5203 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.855350 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:05.5208 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.5208 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.5210 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.5220 UTC hyperparameters_optimizer.cc:582] [225/500] Score: -0.85535 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:05.5262 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328930 train-accuracy:0.599691 valid-loss:1.305670 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.5589 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.877662\n",
      "[INFO 24-02-22 06:46:05.5589 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.5592 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.877662 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:05.5609 UTC hyperparameters_optimizer.cc:582] [226/500] Score: -0.877662 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:05.5635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.5637 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.5640 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.5722 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329552 train-accuracy:0.599691 valid-loss:1.303615 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.6370 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860485\n",
      "[INFO 24-02-22 06:46:05.6370 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.6373 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.860485 valid-accuracy:0.818182\n",
      "[[INFO 24-02-22 06:46:05.6383 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.6383 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.6385 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "INFO 24-02-22 06:46:05.6420 UTC hyperparameters_optimizer.cc:582] [227/500] Score: -0.860485 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:05.6515 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245420 train-accuracy:0.599691 valid-loss:1.247387 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.6926 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862188\n",
      "[INFO 24-02-22 06:46:05.6927 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.6929 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.862188 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:05.6936 UTC hyperparameters_optimizer.cc:582] [228/500] Score: -0.862188 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:05.6953 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.6955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.6958 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.7102 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292511 train-accuracy:0.599691 valid-loss:1.274700 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.8047 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851912\n",
      "[INFO 24-02-22 06:46:05.8047 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.8049 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.851912 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:05.8054 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.8054 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.8054 UTC hyperparameters_optimizer.cc:582] [229/500] Score: -0.851912 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:05.8058 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.8149 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296740 train-accuracy:0.599691 valid-loss:1.286736 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.9596 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838981\n",
      "[INFO 24-02-22 06:46:05.9596 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.9598 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.838981 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:05.9603 UTC hyperparameters_optimizer.cc:582] [230/500] Score: -0.838981 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:05.9611 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.9612 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.9613 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.9748 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245440 train-accuracy:0.599691 valid-loss:1.241328 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.0173 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.661777 train-accuracy:0.870170 valid-loss:0.842121 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:06.0173 UTC gradient_boosted_trees.cc:271] Truncates the model to 279 tree(s) i.e. 279  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.0174 UTC gradient_boosted_trees.cc:334] Final model num-trees:279 valid-loss:0.838642 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:06.0177 UTC hyperparameters_optimizer.cc:582] [231/500] Score: -0.838642 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:06.0179 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.0179 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.0191 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.0279 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.889677\n",
      "[INFO 24-02-22 06:46:06.0279 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.0282 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.889677 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:06.0294 UTC hyperparameters_optimizer.cc:582] [232/500] Score: -0.889677 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:06.0322 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.0322 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.0327 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.0363 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322583 train-accuracy:0.599691 valid-loss:1.297591 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.0443 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287503 train-accuracy:0.599691 valid-loss:1.279301 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.1627 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866232\n",
      "[INFO 24-02-22 06:46:06.1627 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.1630 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.866232 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:06.1645 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.1646 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.1649 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.1654 UTC hyperparameters_optimizer.cc:582] [233/500] Score: -0.866232 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:06.1716 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298153 train-accuracy:0.599691 valid-loss:1.278018 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.4805 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.854953\n",
      "[INFO 24-02-22 06:46:06.4805 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.4806 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.854953 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:06.4809 UTC hyperparameters_optimizer.cc:582] [234/500] Score: -0.854953 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:06.4812 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.4812 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.4815 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.4975 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288895 train-accuracy:0.599691 valid-loss:1.277117 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.5177 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876373\n",
      "[INFO 24-02-22 06:46:06.5177 UTC gradient_boosted_trees.cc:271] Truncates the model to 167 tree(s) i.e. 167  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.5181 UTC gradient_boosted_trees.cc:334] Final model num-trees:167 valid-loss:0.876373 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:06.5194 UTC hyperparameters_optimizer.cc:582] [235/500] Score: -0.876373 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:06.5215 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.5217 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.5220 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.5365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237479 train-accuracy:0.599691 valid-loss:1.234575 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.5830 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876528\n",
      "[INFO 24-02-22 06:46:06.5830 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.5832 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.876528 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:06.5845 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.5845 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.5847 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.5854 UTC hyperparameters_optimizer.cc:582] [236/500] Score: -0.876528 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:06.6000 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222966 train-accuracy:0.599691 valid-loss:1.246790 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.6276 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873442\n",
      "[INFO 24-02-22 06:46:06.6277 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.6279 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.873442 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:06.6294 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.6294 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.6296 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.6323 UTC hyperparameters_optimizer.cc:582] [237/500] Score: -0.873442 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:06.6456 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235615 train-accuracy:0.599691 valid-loss:1.237404 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.6570 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860329\n",
      "[INFO 24-02-22 06:46:06.6571 UTC gradient_boosted_trees.cc:271] Truncates the model to 150 tree(s) i.e. 150  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.6572 UTC gradient_boosted_trees.cc:334] Final model num-trees:150 valid-loss:0.860329 valid-accuracy:0.803030\n",
      "[INFO[INFO 24-02-22 06:46:06.6585 UTC hyperparameters_optimizer.cc:582] [238/500] Score:  24-02-22 06:46:06.6585 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "-0.860329 / -0.758798 HParams: [INFO 24-02-22 06:46:06.6586 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:06.6590 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.6811 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286899 train-accuracy:0.599691 valid-loss:1.272996 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.6949 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845889\n",
      "[INFO 24-02-22 06:46:06.6950 UTC gradient_boosted_trees.cc:271] Truncates the model to 252 tree(s) i.e. 252  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.6950 UTC gradient_boosted_trees.cc:334] Final model num-trees:252 valid-loss:0.845889 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:06.6957 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.6965 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.6971 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.6987 UTC hyperparameters_optimizer.cc:582] [239/500] Score: -0.845889 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:06.7126 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241522 train-accuracy:0.599691 valid-loss:1.258464 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.7548 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.831642\n",
      "[INFO 24-02-22 06:46:06.7548 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.7549 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.831642 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:06.7554 UTC hyperparameters_optimizer.cc:582] [240/500] Score: -0.831642 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:06.7560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.7560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.7563 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.7658 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326161 train-accuracy:0.599691 valid-loss:1.300731 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.8487 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.87982\n",
      "[INFO 24-02-22 06:46:06.8487 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.8491 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.879820 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:06.8501 UTC hyperparameters_optimizer.cc:582] [241/500] Score: -0.87982 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:06.8508 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.8508 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.8518 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.8650 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324468 train-accuracy:0.599691 valid-loss:1.301262 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.9173 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.900699\n",
      "[INFO 24-02-22 06:46:06.9173 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.9175 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.900699 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:06.9180 UTC hyperparameters_optimizer.cc:582] [242/500] Score: -0.900699 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:06.9188 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.9188 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.9192 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.9285 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292518 train-accuracy:0.599691 valid-loss:1.275395 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.0136 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832069\n",
      "[INFO 24-02-22 06:46:07.0136 UTC gradient_boosted_trees.cc:271] Truncates the model to 105 tree(s) i.e. 105  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.0137 UTC gradient_boosted_trees.cc:334] Final model num-trees:105 valid-loss:0.832069 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:07.0145 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.0145 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.0147 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.0188 UTC hyperparameters_optimizer.cc:582] [243/500] Score: -0.832069 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:07.0320 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226622 train-accuracy:0.599691 valid-loss:1.237185 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.0554 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859188\n",
      "[INFO 24-02-22 06:46:07.0554 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.0558 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.859188 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:07.0565 UTC hyperparameters_optimizer.cc:582] [244/500] Score: -0.859188 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:07.0578 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.0578 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.0580 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.0604 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.628379 train-accuracy:0.879444 valid-loss:0.831342 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:07.0605 UTC gradient_boosted_trees.cc:271] Truncates the model to 283 tree(s) i.e. 283  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.0607 UTC gradient_boosted_trees.cc:334] Final model num-trees:283 valid-loss:0.828854 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:07.0610 UTC hyperparameters_optimizer.cc:582] [245/500] Score: -0.828854 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:07.0618 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.0620 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.0622 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.0703 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325515 train-accuracy:0.599691 valid-loss:1.298934 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.0778 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228902 train-accuracy:0.599691 valid-loss:1.229746 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.1417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.826073\n",
      "[INFO 24-02-22 06:46:07.1418 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.1419 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.826073 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:07.1455 UTC hyperparameters_optimizer.cc:582] [246/500] Score: -0.826073 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:07.1460 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.1460 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.1463 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.1543 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325921 train-accuracy:0.599691 valid-loss:1.302890 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.2254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.928827\n",
      "[INFO 24-02-22 06:46:07.2254 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.2257 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.928827 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:07.2266 UTC hyperparameters_optimizer.cc:582] [247/500] Score: -0.928827 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:07.2270 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.2270 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.2274 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.2436 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321405 train-accuracy:0.599691 valid-loss:1.298983 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.3254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872076\n",
      "[INFO 24-02-22 06:46:07.3256 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.3261 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.872076 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:07.3271 UTC hyperparameters_optimizer.cc:582] [248/500] Score: -0.872076 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:07.3298 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.3299 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.3301 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.3569 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324738 train-accuracy:0.599691 valid-loss:1.301937 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.4007 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832025\n",
      "[INFO 24-02-22 06:46:07.4007 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.4009 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.832025 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:07.4017 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.4017 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.4019 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.4055 UTC hyperparameters_optimizer.cc:582] [249/500] Score: -0.832025 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:07.4133 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848385\n",
      "[INFO 24-02-22 06:46:07.4134 UTC gradient_boosted_trees.cc:271] Truncates the model to 171 tree(s) i.e. 171  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.4135 UTC gradient_boosted_trees.cc:334] Final model num-trees:171 valid-loss:0.848385 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:07.4144 UTC hyperparameters_optimizer.cc:582] [250/500] Score: -0.848385 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:07.4166 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.4167 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.4169 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.4202 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285471 train-accuracy:0.599691 valid-loss:1.269148 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.4294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876855\n",
      "[INFO 24-02-22 06:46:07.4295 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.4296 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.876855 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:07.4298 UTC hyperparameters_optimizer.cc:582] [251/500] Score: -0.876855 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:07.4302 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.4302 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.4307 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.4322 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286526 train-accuracy:0.599691 valid-loss:1.282790 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.4419 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323554 train-accuracy:0.599691 valid-loss:1.301333 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.5219 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.863857\n",
      "[INFO 24-02-22 06:46:07.5219 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.5221 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.863857 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:07.5224 UTC hyperparameters_optimizer.cc:582] [252/500] Score: -0.863857 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:07.5229 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.5230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.5234 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.5318 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248003 train-accuracy:0.599691 valid-loss:1.239043 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.9130 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.830535\n",
      "[INFO 24-02-22 06:46:07.9131 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.9133 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.830535 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:07.9137 UTC hyperparameters_optimizer.cc:582] [253/500] Score: -0.830535 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:07.9145 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.9145 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.9147 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.9229 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233637 train-accuracy:0.599691 valid-loss:1.235401 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.0282 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852118\n",
      "[INFO 24-02-22 06:46:08.0282 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.0285 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.852118 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.0291 UTC hyperparameters_optimizer.cc:582] [254/500] Score: -0.852118 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:08.0300 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.0300 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.0303 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.0418 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325674 train-accuracy:0.599691 valid-loss:1.304057 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.0693 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871876\n",
      "[INFO 24-02-22 06:46:08.0693 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.0711 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.871876 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.0735 UTC hyperparameters_optimizer.cc:582] [255/500] Score: -0.871876 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.0737 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.0737 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.0739 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.0796 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.300954 train-accuracy:0.599691 valid-loss:1.284301 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.1174 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.882252\n",
      "[INFO 24-02-22 06:46:08.1174 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.1177 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.882252 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:08.1182 UTC hyperparameters_optimizer.cc:582] [256/500] Score: -0.882252 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:08.1212 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.1212 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.1214 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.1321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326067 train-accuracy:0.599691 valid-loss:1.300447 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.1374 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867302\n",
      "[INFO 24-02-22 06:46:08.1374 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.1377 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.867302 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:08.1382 UTC hyperparameters_optimizer.cc:582] [257/500] Score: -0.867302 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:08.1393 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.1393 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.1395 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.1429 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880944\n",
      "[INFO 24-02-22 06:46:08.1430 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.1433 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.880944 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:08.1445 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.1446 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.1447 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.1453 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.251238 train-accuracy:0.599691 valid-loss:1.251439 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.1487 UTC hyperparameters_optimizer.cc:582] [258/500] Score: -0.880944 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.1569 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266269 train-accuracy:0.599691 valid-loss:1.261001 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.4817 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840626\n",
      "[INFO 24-02-22 06:46:08.4817 UTC gradient_boosted_trees.cc:271] Truncates the model to 231 tree(s) i.e. 231  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.4818 UTC gradient_boosted_trees.cc:334] Final model num-trees:231 valid-loss:0.840626 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.4824 UTC hyperparameters_optimizer.cc:582] [259/500] Score: -0.840626 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:08.4830 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.4830 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.4834 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.5028 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321840 train-accuracy:0.599691 valid-loss:1.303972 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.5297 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859662\n",
      "[INFO 24-02-22 06:46:08.5297 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.5299 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.859662 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.5302 UTC hyperparameters_optimizer.cc:582] [260/500] Score: -0.859662 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.5324 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.5327 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.5330 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.5449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234676 train-accuracy:0.599691 valid-loss:1.239601 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.5853 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845099\n",
      "[INFO 24-02-22 06:46:08.5854 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.5857 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.845099 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.5869 UTC hyperparameters_optimizer.cc:582] [261/500] Score: -0.845099 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.5892 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.5892 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.5894 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.6076 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850324\n",
      "[INFO 24-02-22 06:46:08.6077 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.6079 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.850324 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.6084 UTC hyperparameters_optimizer.cc:582] [262/500] Score: -0.850324 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:08.6090 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.6090 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.6094 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.6120 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321870 train-accuracy:0.599691 valid-loss:1.296363 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.6258 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305521 train-accuracy:0.599691 valid-loss:1.290511 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.6385 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.870874\n",
      "[INFO 24-02-22 06:46:08.6385 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.6388 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.870874 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.6397 UTC hyperparameters_optimizer.cc:582] [263/500] Score: -0.870874 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:08.6413 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.6416 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.6417 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.6583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320908 train-accuracy:0.599691 valid-loss:1.298668 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.6789 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.819528\n",
      "[INFO 24-02-22 06:46:08.6790 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.6792 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.819528 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.6798 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.6800 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.6803 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.6820 UTC hyperparameters_optimizer.cc:582] [264/500] Score: -0.819528 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.6971 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321313 train-accuracy:0.599691 valid-loss:1.301700 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.8113 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.817027\n",
      "[INFO 24-02-22 06:46:08.8113 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.8113 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.817027 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.8115 UTC hyperparameters_optimizer.cc:582] [265/500] Score: -0.817027 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:08.8119 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.8119 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.8155 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.8406 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295592 train-accuracy:0.599691 valid-loss:1.280203 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.8551 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838496\n",
      "[INFO 24-02-22 06:46:08.8551 UTC gradient_boosted_trees.cc:271] Truncates the model to 180 tree(s) i.e. 180  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.8552 UTC gradient_boosted_trees.cc:334] Final model num-trees:180 valid-loss:0.838496 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.8562 UTC hyperparameters_optimizer.cc:582] [266/500] Score: -0.838496 / -0.758798 HParams: [INFO 24-02-22 06:46:08.8564 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.8564 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.8566 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:08.8626 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.301723 train-accuracy:0.599691 valid-loss:1.284914 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.9681 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876352\n",
      "[INFO 24-02-22 06:46:08.9681 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.9683 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.876352 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.9713 UTC hyperparameters_optimizer.cc:582] [267/500] Score: -0.876352 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:08.9728 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.9729 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.9731 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.9803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305073 train-accuracy:0.599691 valid-loss:1.288816 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.0725 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.819336\n",
      "[INFO 24-02-22 06:46:09.0726 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.0727 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.819336 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:09.0731 UTC hyperparameters_optimizer.cc:582] [268/500] Score: -0.819336 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:09.0741 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.0741 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.0742 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.0839 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325710 train-accuracy:0.599691 valid-loss:1.302621 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.1358 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.909216\n",
      "[INFO 24-02-22 06:46:09.1358 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.1362 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.909216 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:09.1375 UTC hyperparameters_optimizer.cc:582] [269/500] Score: -0.909216 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:09.1396 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.1398 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.1401 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.1408 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862655\n",
      "[INFO 24-02-22 06:46:09.1409 UTC gradient_boosted_trees.cc:271] Truncates the model to 130 tree(s) i.e. 130  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.1410 UTC gradient_boosted_trees.cc:334] Final model num-trees:130 valid-loss:0.862655 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:09.1420 UTC hyperparameters_optimizer.cc:582] [270/500] Score: -0.862655 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:09.1447 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.1447 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.1449 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.1509 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324348 train-accuracy:0.599691 valid-loss:1.301131 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.1510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304974 train-accuracy:0.599691 valid-loss:1.287256 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.5470 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864952\n",
      "[INFO 24-02-22 06:46:09.5470 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.5470 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.864952 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:09.5472 UTC hyperparameters_optimizer.cc:582] [271/500] Score: -0.864952 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:09.5475 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.5476 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.5477 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.5690 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288655 train-accuracy:0.599691 valid-loss:1.273381 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.6038 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.910278\n",
      "[INFO 24-02-22 06:46:09.6038 UTC gradient_boosted_trees.cc:271] Truncates the model to 108 tree(s) i.e. 108  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.6041 UTC gradient_boosted_trees.cc:334] Final model num-trees:108 valid-loss:0.910278 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:09.6053 UTC hyperparameters_optimizer.cc:582] [272/500] Score: -0.910278 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:09.6076 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.6077 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.6080 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.6103 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855391\n",
      "[INFO 24-02-22 06:46:09.6104 UTC gradient_boosted_trees.cc:271] Truncates the model to 155 tree(s) i.e. 155  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.6114 UTC gradient_boosted_trees.cc:334] Final model num-trees:155 valid-loss:0.855391 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:09.6124 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.6125 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.6127 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.6154 UTC hyperparameters_optimizer.cc:582] [273/500] Score: -0.855391 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:09.6185 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287649 train-accuracy:0.599691 valid-loss:1.277522 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.6330 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286742 train-accuracy:0.599691 valid-loss:1.277768 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.6440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872668\n",
      "[INFO 24-02-22 06:46:09.6441 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.6441 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.872668 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:09.6444 UTC hyperparameters_optimizer.cc:582] [274/500] Score: -0.872668 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:09.6449 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.6449 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.6451 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.6507 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.300742 train-accuracy:0.599691 valid-loss:1.283290 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.0027 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864656\n",
      "[INFO 24-02-22 06:46:10.0027 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.0029 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.864656 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:10.0045 UTC hyperparameters_optimizer.cc:582] [275/500] Score: -0.864656 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.0063 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.0063 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.0066 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.0174 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242955 train-accuracy:0.599691 valid-loss:1.248737 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.3411 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823306\n",
      "[INFO 24-02-22 06:46:10.3411 UTC gradient_boosted_trees.cc:271] Truncates the model to 213 tree(s) i.e. 213  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.3411 UTC gradient_boosted_trees.cc:334] Final model num-trees:213 valid-loss:0.823306 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:10.3414 UTC hyperparameters_optimizer.cc:582] [276/500] Score: -0.823306 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:10.3421 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.3421 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.3423 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.3490 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296139 train-accuracy:0.599691 valid-loss:1.280746 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.3589 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824332\n",
      "[INFO 24-02-22 06:46:10.3589 UTC gradient_boosted_trees.cc:271] Truncates the model to 166 tree(s) i.e. 166  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.3590 UTC gradient_boosted_trees.cc:334] Final model num-trees:166 valid-loss:0.824332 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:10.3593 UTC hyperparameters_optimizer.cc:582] [277/500] Score: -0.824332 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.3597 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.3597 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.3600 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.3687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326301 train-accuracy:0.599691 valid-loss:1.301626 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.3951 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844423\n",
      "[INFO 24-02-22 06:46:10.3984 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.4001 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.844423 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:10.4004 UTC hyperparameters_optimizer.cc:582] [278/500] Score: -0.844423 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.4009 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.4009 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.4013 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.4059 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263216 train-accuracy:0.599691 valid-loss:1.259980 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.4596 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.802028\n",
      "[INFO 24-02-22 06:46:10.4597 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.4599 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.802028 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:10.4603 UTC hyperparameters_optimizer.cc:582] [279/500] Score: -0.802028 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:10.4609 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.4609 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.4613 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.4814 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226188 train-accuracy:0.599691 valid-loss:1.237855 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.6322 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881\n",
      "[INFO 24-02-22 06:46:10.6322 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.6323 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.881000 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:10.6326 UTC hyperparameters_optimizer.cc:582] [280/500] Score: -0.881 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.6332 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.6332 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.6334 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.6455 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245692 train-accuracy:0.599691 valid-loss:1.240063 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.6889 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824926\n",
      "[INFO 24-02-22 06:46:10.6889 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.6890 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.824926 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:10.6892 UTC hyperparameters_optimizer.cc:582] [281/500] Score: -0.824926 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:10.6896 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.6896 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.6903 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.6960 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305820 train-accuracy:0.599691 valid-loss:1.287657 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.8056 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.83236\n",
      "[INFO 24-02-22 06:46:10.8056 UTC gradient_boosted_trees.cc:271] Truncates the model to 193 tree(s) i.e. 193  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.8057 UTC gradient_boosted_trees.cc:334] Final model num-trees:193 valid-loss:0.832360 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:10.8067 UTC hyperparameters_optimizer.cc:582] [282/500] Score: -0.83236 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:10.8096 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.8096 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.8099 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.8197 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293968 train-accuracy:0.599691 valid-loss:1.275316 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.8693 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842824\n",
      "[INFO 24-02-22 06:46:10.8694 UTC gradient_boosted_trees.cc:271] Truncates the model to 176 tree(s) i.e. 176  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.8695 UTC gradient_boosted_trees.cc:334] Final model num-trees:176 valid-loss:0.842824 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:10.8704 UTC hyperparameters_optimizer.cc:582] [283/500] Score: -0.842824 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.8720 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.8720 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.8722 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.8803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291077 train-accuracy:0.599691 valid-loss:1.278862 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.8818 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867523\n",
      "[INFO 24-02-22 06:46:10.8818 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.8820 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.867523 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:10.8824 UTC hyperparameters_optimizer.cc:582] [284/500] Score: -0.867523 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.8833 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.8834 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.8835 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.8947 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284775 train-accuracy:0.599691 valid-loss:1.278194 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.0825 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.802925\n",
      "[INFO 24-02-22 06:46:11.0826 UTC gradient_boosted_trees.cc:271] Truncates the model to 193 tree(s) i.e. 193  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.0826 UTC gradient_boosted_trees.cc:334] Final model num-trees:193 valid-loss:0.802925 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:11.0835 UTC hyperparameters_optimizer.cc:582] [285/500] Score: -0.802925 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:11.0845 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.0846 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.0854 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.0875 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262917 train-accuracy:0.599691 valid-loss:1.255451 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.0963 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.830561\n",
      "[INFO 24-02-22 06:46:11.0964 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.0964 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.830561 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.0967 UTC hyperparameters_optimizer.cc:582] [286/500] Score: -0.830561 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.0977 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.0977 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.0979 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.1148 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246352 train-accuracy:0.599691 valid-loss:1.244529 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.2288 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.420433 train-accuracy:0.930448 valid-loss:0.801530 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.2288 UTC gradient_boosted_trees.cc:271] Truncates the model to 271 tree(s) i.e. 271  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.2291 UTC gradient_boosted_trees.cc:334] Final model num-trees:271 valid-loss:0.793794 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.2306 UTC hyperparameters_optimizer.cc:582] [287/500] Score: -0.793794 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.2310 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.2310 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.2311 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.2427 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233539 train-accuracy:0.599691 valid-loss:1.239797 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.3198 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846757\n",
      "[INFO 24-02-22 06:46:11.3198 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.3199 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.846757 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.3201 UTC hyperparameters_optimizer.cc:582] [288/500] Score: -0.846757 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.3205 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.3205 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.3207 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.3266 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296664 train-accuracy:0.599691 valid-loss:1.276545 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.4127 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.931659\n",
      "[INFO 24-02-22 06:46:11.4127 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.4129 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.931659 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.4133 UTC hyperparameters_optimizer.cc:582] [289/500] Score: -0.931659 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:11.4147 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.4148 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.4150 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.4203 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248183 train-accuracy:0.599691 valid-loss:1.249650 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.4294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855735\n",
      "[INFO 24-02-22 06:46:11.4296 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.4298 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.855735 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.4310 UTC hyperparameters_optimizer.cc:582] [290/500] Score: -0.855735 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.4321 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.4383 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.4385 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.4535 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288545 train-accuracy:0.599691 valid-loss:1.277084 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.6303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.835988\n",
      "[INFO 24-02-22 06:46:11.6303 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.6305 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.835988 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.6314 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.6315 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.6316 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.6320 UTC hyperparameters_optimizer.cc:582] [291/500] Score: -0.835988 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:11.6485 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282687 train-accuracy:0.599691 valid-loss:1.275411 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.6513 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824072\n",
      "[INFO 24-02-22 06:46:11.6513 UTC gradient_boosted_trees.cc:271] Truncates the model to 211 tree(s) i.e. 211  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.6515 UTC gradient_boosted_trees.cc:334] Final model num-trees:211 valid-loss:0.824072 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.6529 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.6530 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.6531 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.6533 UTC hyperparameters_optimizer.cc:582] [292/500] Score: -0.824072 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:11.6550 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859561\n",
      "[INFO 24-02-22 06:46:11.6550 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.6553 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.859561 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.6560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.6560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.6562 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.6590 UTC hyperparameters_optimizer.cc:582] [293/500] Score: -0.859561 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:11.6687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324331 train-accuracy:0.599691 valid-loss:1.300421 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.6718 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323661 train-accuracy:0.599691 valid-loss:1.300292 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.7024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843953\n",
      "[INFO 24-02-22 06:46:11.7024 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.7030 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.843953 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.7036 UTC hyperparameters_optimizer.cc:582] [294/500] Score: -0.843953 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.7053 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.7054 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.7056 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.7180 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234389 train-accuracy:0.599691 valid-loss:1.229050 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.8065 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865345\n",
      "[INFO 24-02-22 06:46:11.8065 UTC gradient_boosted_trees.cc:271] Truncates the model to 132 tree(s) i.e. 132  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.8067 UTC gradient_boosted_trees.cc:334] Final model num-trees:132 valid-loss:0.865345 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.8079 UTC hyperparameters_optimizer.cc:582] [295/500] Score: -0.865345 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:11.8085 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.8085 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.8096 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.8233 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324068 train-accuracy:0.599691 valid-loss:1.300491 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.8520 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855365\n",
      "[INFO 24-02-22 06:46:11.8520 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.8524 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.855365 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:11.8529 UTC hyperparameters_optimizer.cc:582] [296/500] Score: -0.855365 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:11.8536 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.8536 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.8538 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.8713 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288569 train-accuracy:0.599691 valid-loss:1.274876 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.8735 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.835406\n",
      "[INFO 24-02-22 06:46:11.8735 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.8736 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.835406 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.8740 UTC hyperparameters_optimizer.cc:582] [297/500] Score: -0.835406 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.8745 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.8745 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.8748 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.8786 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263192 train-accuracy:0.599691 valid-loss:1.259511 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.9024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.890069\n",
      "[INFO 24-02-22 06:46:11.9025 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.9028 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.890069 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:11.9036 UTC hyperparameters_optimizer.cc:582] [298/500] Score: -0.890069 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:11.9045 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.9045 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.9047 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.9135 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.253553 train-accuracy:0.599691 valid-loss:1.250270 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.0138 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862767\n",
      "[INFO 24-02-22 06:46:12.0138 UTC gradient_boosted_trees.cc:271] Truncates the model to 165 tree(s) i.e. 165  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.0140 UTC gradient_boosted_trees.cc:334] Final model num-trees:165 valid-loss:0.862767 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:12.0221 UTC hyperparameters_optimizer.cc:582] [299/500] Score: -0.862767 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:12.0259 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.0259 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.0271 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.0487 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322590 train-accuracy:0.599691 valid-loss:1.299636 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.0701 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855295\n",
      "[INFO 24-02-22 06:46:12.0701 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.0702 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.855295 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.0707 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.0707 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.0708 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.0754 UTC hyperparameters_optimizer.cc:582] [300/500] Score: -0.855295 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:12.0879 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283832 train-accuracy:0.599691 valid-loss:1.274965 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.1001 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.835615\n",
      "[INFO 24-02-22 06:46:12.1001 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.1003 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.835615 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.1007 UTC hyperparameters_optimizer.cc:582] [301/500] Score: -0.835615 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:12.1012 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.1013 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.1015 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.1132 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295079 train-accuracy:0.599691 valid-loss:1.272891 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.2854 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872935\n",
      "[INFO 24-02-22 06:46:12.2854 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.2856 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.872935 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:12.2877 UTC hyperparameters_optimizer.cc:582] [302/500] Score: -0.872935 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:12.2882 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.2883 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.2887 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.3081 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322844 train-accuracy:0.599691 valid-loss:1.298466 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.3300 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.914054\n",
      "[INFO 24-02-22 06:46:12.3300 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.3309 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.914054 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.3312 UTC hyperparameters_optimizer.cc:582] [303/500] Score: -0.914054 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:12.3320 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.3320 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.3323 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.3514 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325281 train-accuracy:0.599691 valid-loss:1.302328 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.4242 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824073\n",
      "[INFO 24-02-22 06:46:12.4242 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.4242 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.824073 valid-accuracy:0.818182\n",
      "[INFO[INFO 24-02-22 06:46:12.4246 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.4246 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      " 24-02-22 06:46:12.4246 UTC hyperparameters_optimizer.cc:582] [304/500] Score: -0.824073 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:12.4248 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.4365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323142 train-accuracy:0.599691 valid-loss:1.300930 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.4482 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.837316\n",
      "[INFO 24-02-22 06:46:12.4483 UTC gradient_boosted_trees.cc:271] Truncates the model to 193 tree(s) i.e. 193  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.4483 UTC gradient_boosted_trees.cc:334] Final model num-trees:193 valid-loss:0.837316 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.4489 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.4489 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.4490 UTC hyperparameters_optimizer.cc:582] [305/500] Score: -0.837316 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:12.4492 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.4685 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291529 train-accuracy:0.599691 valid-loss:1.273217 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.4978 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865235\n",
      "[INFO 24-02-22 06:46:12.4978 UTC gradient_boosted_trees.cc:271] Truncates the model to 161 tree(s) i.e. 161  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.4980 UTC gradient_boosted_trees.cc:334] Final model num-trees:161 valid-loss:0.865235 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.4996 UTC hyperparameters_optimizer.cc:582] [306/500] Score: -0.865235 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:12.5024 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.5024 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.5026 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.5095 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.303854 train-accuracy:0.599691 valid-loss:1.286242 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.5452 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.820399\n",
      "[INFO 24-02-22 06:46:12.5452 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.5453 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.820399 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:12.5459 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.5459 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.5461 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.5487 UTC hyperparameters_optimizer.cc:582] [307/500] Score: -0.820399 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:12.5516 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295802 train-accuracy:0.599691 valid-loss:1.281844 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.5744 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.878092\n",
      "[INFO 24-02-22 06:46:12.5744 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.5747 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.878092 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:12.5752 UTC hyperparameters_optimizer.cc:582] [308/500] Score: -0.878092 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:12.5762 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.5762 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.5765 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.5825 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285704 train-accuracy:0.599691 valid-loss:1.267563 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.9061 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.813012\n",
      "[INFO 24-02-22 06:46:12.9061 UTC gradient_boosted_trees.cc:271] Truncates the model to 245 tree(s) i.e. 245  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.9062 UTC gradient_boosted_trees.cc:334] Final model num-trees:245 valid-loss:0.813012 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:12.9066 UTC hyperparameters_optimizer.cc:582] [309/500] Score: -0.813012 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:12.9071 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.9071 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.9076 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.9226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281316 train-accuracy:0.599691 valid-loss:1.266753 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.9972 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.888231\n",
      "[INFO 24-02-22 06:46:12.9973 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.9976 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.888231 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:12.9982 UTC hyperparameters_optimizer.cc:582] [310/500] Score: -0.888231 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:12.9995 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.9998 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.0003 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.0313 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230236 train-accuracy:0.599691 valid-loss:1.233078 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.0619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871961\n",
      "[INFO 24-02-22 06:46:13.0619 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.0621 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.871961 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.0625 UTC hyperparameters_optimizer.cc:582] [311/500] Score: -0.871961 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:13.0635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.0635 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.0637 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.0671 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.327149 train-accuracy:0.599691 valid-loss:1.304756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.1252 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.870963\n",
      "[INFO 24-02-22 06:46:13.1252 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.1254 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.870963 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.1260 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.1260 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.1262 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.1263 UTC hyperparameters_optimizer.cc:582] [312/500] Score: -0.870963 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:13.1296 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329289 train-accuracy:0.599691 valid-loss:1.304668 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.3109 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.893574\n",
      "[INFO 24-02-22 06:46:13.3110 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.3112 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.893574 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:13.3115 UTC hyperparameters_optimizer.cc:582] [313/500] Score: -0.893574 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:13.3120 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.3121 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.3124 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.3302 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321295 train-accuracy:0.599691 valid-loss:1.300440 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.3946 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.811453\n",
      "[INFO 24-02-22 06:46:13.3946 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.3948 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.811453 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:13.3951 UTC hyperparameters_optimizer.cc:582] [314/500] Score: -0.811453 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:13.3960 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.3960 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.3963 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.4052 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.249042 train-accuracy:0.599691 valid-loss:1.252849 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.7578 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860244\n",
      "[INFO 24-02-22 06:46:13.7578 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.7581 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.860244 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.7599 UTC hyperparameters_optimizer.cc:582] [315/500] Score: -0.860244 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:13.7611 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85953\n",
      "[INFO 24-02-22 06:46:13.7613 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.7616 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.859530 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.7620 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.7620 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.7622 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.7626 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.7626 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.7628 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.7687 UTC hyperparameters_optimizer.cc:582] [316/500] Score: -0.85953 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:13.7707 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288577 train-accuracy:0.599691 valid-loss:1.272806 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.7763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283980 train-accuracy:0.599691 valid-loss:1.276469 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.8481 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891767\n",
      "[INFO 24-02-22 06:46:13.8481 UTC gradient_boosted_trees.cc:271] Truncates the model to 88 tree(s) i.e. 88  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.8484 UTC gradient_boosted_trees.cc:334] Final model num-trees:88 valid-loss:0.891767 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.8493 UTC hyperparameters_optimizer.cc:582] [317/500] Score: -0.891767 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:13.8506 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.8506 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.8509 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.8657 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241020 train-accuracy:0.599691 valid-loss:1.240876 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.9897 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806646\n",
      "[INFO 24-02-22 06:46:13.9900 UTC gradient_boosted_trees.cc:271] Truncates the model to 178 tree(s) i.e. 178  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.9904 UTC gradient_boosted_trees.cc:334] Final model num-trees:178 valid-loss:0.806646 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.9908 UTC hyperparameters_optimizer.cc:582] [318/500] Score: -0.806646 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:13.9915 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.9916 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.9920 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.0019 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834984\n",
      "[INFO 24-02-22 06:46:14.0019 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.0022 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.834984 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:14.0033 UTC hyperparameters_optimizer.cc:582] [319/500] Score: -0.834984 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.0049 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.0049 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.0052 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.0061 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.662497 train-accuracy:0.871716 valid-loss:0.865441 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.0061 UTC gradient_boosted_trees.cc:271] Truncates the model to 284 tree(s) i.e. 284  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.0061 UTC gradient_boosted_trees.cc:334] Final model num-trees:284 valid-loss:0.863688 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.0064 UTC hyperparameters_optimizer.cc:582] [320/500] Score: -0.863688 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:14.0068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.0068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.0071 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.0076 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844125\n",
      "[INFO 24-02-22 06:46:14.0076 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.0077 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.844125 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.0079 UTC hyperparameters_optimizer.cc:582] [321/500] Score: -0.844125 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.0083 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.0083 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.0085 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.0096 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324808 train-accuracy:0.599691 valid-loss:1.303621 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.0104 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298894 train-accuracy:0.599691 valid-loss:1.278034 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.0203 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284248 train-accuracy:0.599691 valid-loss:1.267679 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.0367 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292111 train-accuracy:0.599691 valid-loss:1.273172 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.0974 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.648473 train-accuracy:0.879444 valid-loss:0.841110 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.0974 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.0974 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.840642 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.1023 UTC hyperparameters_optimizer.cc:582] [322/500] Score: -0.840642 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:14.1041 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.1041 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.1048 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.1196 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.249250 train-accuracy:0.599691 valid-loss:1.254290 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.1374 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.908148\n",
      "[INFO 24-02-22 06:46:14.1375 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.1378 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.908148 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.1387 UTC hyperparameters_optimizer.cc:582] [323/500] Score: -0.908148 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.1400 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.1400 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.1402 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.1639 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321696 train-accuracy:0.599691 valid-loss:1.299578 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.1811 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864405\n",
      "[INFO 24-02-22 06:46:14.1811 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.1813 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.864405 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.1825 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.1826 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-22 06:46:14.1828 UTC hyperparameters_optimizer.cc:582] [324/500] Score: -0.864405 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "INFO 24-02-22 06:46:14.1837 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.1895 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302857 train-accuracy:0.599691 valid-loss:1.282740 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.3177 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849398\n",
      "[INFO 24-02-22 06:46:14.3177 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.3179 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.849398 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.3192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.3192 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.3194 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.3195 UTC hyperparameters_optimizer.cc:582] [325/500] Score: -0.849398 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:14.3223 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291512 train-accuracy:0.599691 valid-loss:1.276446 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.4102 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902137\n",
      "[INFO 24-02-22 06:46:14.4105 UTC gradient_boosted_trees.cc:271] Truncates the model to 94 tree(s) i.e. 94  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.4123 UTC gradient_boosted_trees.cc:334] Final model num-trees:94 valid-loss:0.902137 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.4136 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.4136 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.4137 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.4155 UTC hyperparameters_optimizer.cc:582] [326/500] Score: -0.902137 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:14.4257 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231591 train-accuracy:0.599691 valid-loss:1.249238 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.4305 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.835538\n",
      "[INFO 24-02-22 06:46:14.4305 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.4307 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.835538 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.4311 UTC hyperparameters_optimizer.cc:582] [327/500] Score: -0.835538 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:14.4319 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.4319 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.4321 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.4594 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322788 train-accuracy:0.599691 valid-loss:1.300967 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.6495 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874074\n",
      "[INFO 24-02-22 06:46:14.6496 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.6497 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.874074 valid-accuracy:0.803030\n",
      "[[INFO 24-02-22 06:46:14.6504 UTC hyperparameters_optimizer.cc:582] [328/500] Score: -0.874074 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "INFO 24-02-22 06:46:14.6506 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.6507 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.6510 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.6643 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322687 train-accuracy:0.599691 valid-loss:1.300945 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.6756 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839348\n",
      "[INFO 24-02-22 06:46:14.6756 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.6757 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.839348 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.6763 UTC hyperparameters_optimizer.cc:582] [329/500] Score: -0.839348 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.6774 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.6774 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.6776 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.6999 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287789 train-accuracy:0.599691 valid-loss:1.278768 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.7918 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881485\n",
      "[INFO 24-02-22 06:46:14.7919 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.7925 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.881485 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:14.7944 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.7945 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.7948 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.7954 UTC hyperparameters_optimizer.cc:582] [330/500] Score: -0.881485 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:14.7994 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297296 train-accuracy:0.599691 valid-loss:1.281059 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.8389 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.879958\n",
      "[INFO 24-02-22 06:46:14.8390 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.8392 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.879958 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:14.8397 UTC hyperparameters_optimizer.cc:582] [331/500] Score: -0.879958 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:14.8402 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.8402 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.8407 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.8510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322431 train-accuracy:0.599691 valid-loss:1.298795 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.8539 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.886162\n",
      "[INFO 24-02-22 06:46:14.8540 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.8541 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.886162 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.8547 UTC hyperparameters_optimizer.cc:582] [332/500] Score: -0.886162 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:14.8554 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.8554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.8558 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.8691 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806861\n",
      "[INFO 24-02-22 06:46:14.8691 UTC gradient_boosted_trees.cc:271] Truncates the model to 84 tree(s) i.e. 84  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.8693 UTC gradient_boosted_trees.cc:334] Final model num-trees:84 valid-loss:0.806861 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:14.8699 UTC hyperparameters_optimizer.cc:582] [333/500] Score: -0.806861 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.8708 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.8709 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.8711 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.8818 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.218532 train-accuracy:0.599691 valid-loss:1.229182 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.8925 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241439 train-accuracy:0.599691 valid-loss:1.257340 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.9606 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840271\n",
      "[INFO 24-02-22 06:46:14.9606 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.9607 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.840271 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.9611 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.9611 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.9613 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.9621 UTC hyperparameters_optimizer.cc:582] [334/500] Score: -0.840271 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.9728 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322631 train-accuracy:0.599691 valid-loss:1.299350 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.0575 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876965\n",
      "[INFO 24-02-22 06:46:15.0575 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.0577 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.876965 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:15.0577 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823232\n",
      "[INFO 24-02-22 06:46:15.0577 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.0578 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.823232 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:15.0580 UTC hyperparameters_optimizer.cc:582] [335/500] Score: -0.823232 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:15.0582 UTC hyperparameters_optimizer.cc:582] [336/[INFO 24-02-22 06:46:15.0582 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.0582 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.0584 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.0585 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.0585 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "500] Score: -0.876965 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:15.0591 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.0716 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324931 train-accuracy:0.599691 valid-loss:1.300968 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.0743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230097 train-accuracy:0.599691 valid-loss:1.233376 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.1579 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868958\n",
      "[INFO 24-02-22 06:46:15.1579 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.1582 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.868958 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:15.1589 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.1589 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.1594 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.1621 UTC hyperparameters_optimizer.cc:582] [337/500] Score: -0.868958 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:15.1784 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239919 train-accuracy:0.599691 valid-loss:1.240268 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.4469 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845635\n",
      "[INFO 24-02-22 06:46:15.4469 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.4470 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.845635 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:15.4473 UTC hyperparameters_optimizer.cc:582] [338/500] Score: -0.845635 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:15.4476 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.4477 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.4480 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.4532 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329081 train-accuracy:0.599691 valid-loss:1.304597 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.7611 UTC gradient_boosted_trees.cc:1638] \tnum-trees:69 train-loss:0.846107 train-accuracy:0.843895 valid-loss:0.943233 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:15.8052 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874903\n",
      "[INFO 24-02-22 06:46:15.8052 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.8055 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.874903 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:15.8061 UTC hyperparameters_optimizer.cc:582] [339/500] Score: -0.874903 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:15.8069 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.8070 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.8073 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.8127 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.252365 train-accuracy:0.599691 valid-loss:1.253688 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.9884 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.869719\n",
      "[INFO 24-02-22 06:46:15.9885 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.9887 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.869719 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:15.9892 UTC hyperparameters_optimizer.cc:582] [340/500] Score: -0.869719 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:15.9904 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.9906 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.9909 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.0123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279918 train-accuracy:0.599691 valid-loss:1.273780 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.0465 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862051\n",
      "[INFO 24-02-22 06:46:16.0465 UTC gradient_boosted_trees.cc:271] Truncates the model to 230 tree(s) i.e. 230  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.0467 UTC gradient_boosted_trees.cc:334] Final model num-trees:230 valid-loss:0.862051 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.0480 UTC hyperparameters_optimizer.cc:582] [341/500] Score: -0.862051 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:16.0483 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.0483 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.0485 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.0638 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290790 train-accuracy:0.599691 valid-loss:1.276983 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.0842 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851016\n",
      "[INFO 24-02-22 06:46:16.0844 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.0846 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.851016 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.0850 UTC hyperparameters_optimizer.cc:582] [342/500] Score: -0.851016 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:16.0855 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.0855 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.0857 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.1029 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323030 train-accuracy:0.599691 valid-loss:1.297347 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.1059 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824155\n",
      "[INFO 24-02-22 06:46:16.1059 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.1062 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.824155 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:16.1067 UTC hyperparameters_optimizer.cc:582] [343/500] Score: -0.824155 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:16.1073 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.1073 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.1081 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.1140 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.878121\n",
      "[INFO 24-02-22 06:46:16.1141 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.1144 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.878121 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.1147 UTC hyperparameters_optimizer.cc:582] [344/500] Score: -0.878121 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:16.1157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.1158 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.1160 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.1189 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321390 train-accuracy:0.599691 valid-loss:1.296705 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.1337 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324406 train-accuracy:0.599691 valid-loss:1.301194 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.2482 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874139\n",
      "[INFO 24-02-22 06:46:16.2482 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.2483 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.874139 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:16.2484 UTC hyperparameters_optimizer.cc:582] [345/500] Score: -0.874139 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:16.2488 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.2488 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.2489 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.2526 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298632 train-accuracy:0.599691 valid-loss:1.275730 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.3965 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871411\n",
      "[INFO 24-02-22 06:46:16.3965 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.3968 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.871411 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.3980 UTC hyperparameters_optimizer.cc:582] [346/500] Score: -0.871411 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:16.4002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.4002 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.4004 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.4099 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324156 train-accuracy:0.599691 valid-loss:1.301589 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.5706 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875705\n",
      "[INFO 24-02-22 06:46:16.5707 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.5709 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.875705 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.5720 UTC hyperparameters_optimizer.cc:582] [347/500] Score: -0.875705 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:16.5739 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.5739 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.5740 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.5843 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287035 train-accuracy:0.599691 valid-loss:1.274595 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.6693 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.811636\n",
      "[INFO 24-02-22 06:46:16.6693 UTC gradient_boosted_trees.cc:271] Truncates the model to 210 tree(s) i.e. 210  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.6695 UTC gradient_boosted_trees.cc:334] Final model num-trees:210 valid-loss:0.811636 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.6708 UTC hyperparameters_optimizer.cc:582] [348/500] Score: -0.811636 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:16.6733 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.6733 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.6735 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.6933 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288220 train-accuracy:0.599691 valid-loss:1.275597 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.7518 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844084\n",
      "[INFO 24-02-22 06:46:16.7519 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.7519 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.844084 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.7525 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.7525 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.7527 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.7587 UTC hyperparameters_optimizer.cc:582] [349/500] Score: -0.844084 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:16.7641 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323341 train-accuracy:0.599691 valid-loss:1.301286 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.7876 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.628221 train-accuracy:0.868624 valid-loss:0.833106 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.7876 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.7877 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.832464 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.7880 UTC hyperparameters_optimizer.cc:582] [350/500] Score: -0.832464 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:16.7887 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.7887 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.7888 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.8030 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322808 train-accuracy:0.599691 valid-loss:1.303474 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.8952 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.83767\n",
      "[INFO 24-02-22 06:46:16.8953 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.8955 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.837670 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.8965 UTC hyperparameters_optimizer.cc:582] [351/500] Score: -0.83767 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:16.8983 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.8983 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.8985 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.9160 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323189 train-accuracy:0.599691 valid-loss:1.301968 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.9905 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881786\n",
      "[INFO 24-02-22 06:46:16.9905 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.9908 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.881786 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.9921 UTC hyperparameters_optimizer.cc:582] [352/500] Score: -0.881786 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:16.9945 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.9946 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.9948 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.9986 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.264080 train-accuracy:0.599691 valid-loss:1.259534 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.0217 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857238\n",
      "[INFO 24-02-22 06:46:17.0217 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.0218 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.857238 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:17.0228 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.0230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.0233 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.0254 UTC hyperparameters_optimizer.cc:582] [353/500] Score: -0.857238 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:17.0281 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859625\n",
      "[INFO 24-02-22 06:46:17.0284 UTC gradient_boosted_trees.cc:271] Truncates the model to 154 tree(s) i.e. 154  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.0288 UTC gradient_boosted_trees.cc:334] Final model num-trees:154 valid-loss:0.859625 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:17.0297 UTC hyperparameters_optimizer.cc:582] [354/500] Score: -0.859625 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:17.0316 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.0317 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.0321 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.0353 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326163 train-accuracy:0.599691 valid-loss:1.303270 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.0432 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325445 train-accuracy:0.599691 valid-loss:1.301339 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.3157 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859246\n",
      "[INFO 24-02-22 06:46:17.3157 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.3160 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.859246 valid-accuracy:0.803030\n",
      "[INFO[INFO 24-02-22 06:46:17.3177 UTC hyperparameters_optimizer.cc:582] [355/500] Score: -0.859246 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      " 24-02-22 06:46:17.3177 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.3181 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.3226 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.3400 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322551 train-accuracy:0.599691 valid-loss:1.301024 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.4794 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838753\n",
      "[INFO 24-02-22 06:46:17.4794 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.4796 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.838753 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:17.4802 UTC hyperparameters_optimizer.cc:582] [356/500] Score: -0.838753 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:17.4807 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.4807 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.4812 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.4821 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880835\n",
      "[INFO 24-02-22 06:46:17.4822 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.4824 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.880835 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:17.4832 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.4832 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.4833 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.4852 UTC hyperparameters_optimizer.cc:582] [357/500] Score: -0.880835 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:17.4915 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239646 train-accuracy:0.599691 valid-loss:1.237198 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.5001 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230207 train-accuracy:0.599691 valid-loss:1.240547 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.6028 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902397\n",
      "[INFO 24-02-22 06:46:17.6028 UTC gradient_boosted_trees.cc:271] Truncates the model to 97 tree(s) i.e. 97  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.6030 UTC gradient_boosted_trees.cc:334] Final model num-trees:97 valid-loss:0.902397 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:17.6040 UTC hyperparameters_optimizer.cc:582] [358/500] Score: -0.902397 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:17.6046 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.6046 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.6061 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.6095 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328171 train-accuracy:0.599691 valid-loss:1.303988 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.6458 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.885739\n",
      "[INFO 24-02-22 06:46:17.6458 UTC gradient_boosted_trees.cc:271] Truncates the model to 99 tree(s) i.e. 99  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.6460 UTC gradient_boosted_trees.cc:334] Final model num-trees:99 valid-loss:0.885739 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:17.6468 UTC hyperparameters_optimizer.cc:582] [359/500] Score: -0.885739 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:17.6479 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.6479 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.6486 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.6670 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.830544\n",
      "[INFO 24-02-22 06:46:17.6671 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.6671 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.830544 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:17.6674 UTC hyperparameters_optimizer.cc:582] [360/500] Score: -0.830544 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:17.6679 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.6679 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.6682 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.6683 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223510 train-accuracy:0.599691 valid-loss:1.244706 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.6754 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.264934 train-accuracy:0.599691 valid-loss:1.259652 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.7150 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866232\n",
      "[INFO 24-02-22 06:46:17.7151 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.7153 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.866232 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:17.7162 UTC hyperparameters_optimizer.cc:582] [361/500] Score: -0.866232 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:17.7163 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.7163 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.7169 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.7316 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245019 train-accuracy:0.599691 valid-loss:1.242678 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.0477 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.84578\n",
      "[INFO 24-02-22 06:46:18.0478 UTC gradient_boosted_trees.cc:271] Truncates the model to 84 tree(s) i.e. 84  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.0478 UTC gradient_boosted_trees.cc:334] Final model num-trees:84 valid-loss:0.845780 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.0481 UTC hyperparameters_optimizer.cc:582] [362/500] Score: -0.84578 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:18.0500 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.0500 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.0508 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.0735 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285256 train-accuracy:0.599691 valid-loss:1.265318 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.2835 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.833452\n",
      "[INFO 24-02-22 06:46:18.2836 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.2839 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.833452 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:18.2844 UTC hyperparameters_optimizer.cc:582] [363/500] Score: -0.833452 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:18.2858 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.2858 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.2861 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.2884 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302732 train-accuracy:0.599691 valid-loss:1.286804 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.3187 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.792538\n",
      "[INFO 24-02-22 06:46:18.3188 UTC gradient_boosted_trees.cc:271] Truncates the model to 214 tree(s) i.e. 214  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.3189 UTC gradient_boosted_trees.cc:334] Final model num-trees:214 valid-loss:0.792538 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.3202 UTC hyperparameters_optimizer.cc:582] [364/500] Score: -0.792538 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:18.3207 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.3207 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.3218 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.3286 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.252630 train-accuracy:0.599691 valid-loss:1.251546 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.3318 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.877442\n",
      "[INFO 24-02-22 06:46:18.3319 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.3323 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.877442 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:18.3325 UTC hyperparameters_optimizer.cc:582] [365/500] Score: -0.877442 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:18.3329 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.3329 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.3334 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.3415 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299160 train-accuracy:0.599691 valid-loss:1.282474 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.3472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.894494\n",
      "[INFO 24-02-22 06:46:18.3472 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.3473 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.894494 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.3479 UTC hyperparameters_optimizer.cc:582] [366/500] Score: -0.894494 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:18.3493 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.3495 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.3512 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.3698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295236 train-accuracy:0.599691 valid-loss:1.279608 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.4066 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825456\n",
      "[INFO 24-02-22 06:46:18.4066 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.4069 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.825456 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.4085 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.4088 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.4094 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.4123 UTC hyperparameters_optimizer.cc:582] [367/500] Score: -0.825456 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:18.4161 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326971 train-accuracy:0.599691 valid-loss:1.301426 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.4337 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.879201\n",
      "[INFO 24-02-22 06:46:18.4338 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.4343 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.879201 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:18.4359 UTC hyperparameters_optimizer.cc:582] [368/500] Score: -0.879201 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:18.4369 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.4369 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.4371 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.4441 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328662 train-accuracy:0.599691 valid-loss:1.305328 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.4509 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876821\n",
      "[INFO 24-02-22 06:46:18.4510 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.4513 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.876821 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:18.4517 UTC hyperparameters_optimizer.cc:582] [369/500] Score: -0.876821 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:18.4522 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.4522 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.4526 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.4707 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288248 train-accuracy:0.599691 valid-loss:1.286268 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.6493 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902616\n",
      "[INFO 24-02-22 06:46:18.6493 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.6497 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.902616 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:18.6500 UTC hyperparameters_optimizer.cc:582] [370/500] Score: -0.902616 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:18.6507 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.6507 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.6508 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.6605 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298123 train-accuracy:0.599691 valid-loss:1.282281 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.6962 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.624892 train-accuracy:0.873261 valid-loss:0.833572 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.6963 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.6963 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.833572 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.6967 UTC hyperparameters_optimizer.cc:582] [371/500] Score: -0.833572 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:18.6975 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.6976 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.6978 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.7042 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247753 train-accuracy:0.599691 valid-loss:1.252946 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.7295 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865795\n",
      "[INFO 24-02-22 06:46:18.7295 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.7297 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.865795 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.7354 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.7355 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.7357 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.7388 UTC hyperparameters_optimizer.cc:582] [372/500] Score: -0.865795 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:18.7464 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.265835 train-accuracy:0.599691 valid-loss:1.259168 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.9211 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827191\n",
      "[INFO 24-02-22 06:46:18.9211 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.9212 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.827191 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.9215 UTC hyperparameters_optimizer.cc:582] [373/500] Score: -0.827191 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:18.9219 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.9233 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.9239 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.9408 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285470 train-accuracy:0.599691 valid-loss:1.280667 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.0810 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842725\n",
      "[INFO 24-02-22 06:46:19.0810 UTC gradient_boosted_trees.cc:271] Truncates the model to 153 tree(s) i.e. 153  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.0811 UTC gradient_boosted_trees.cc:334] Final model num-trees:153 valid-loss:0.842725 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:19.0823 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.0823 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.0825 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.0854 UTC hyperparameters_optimizer.cc:582] [374/500] Score: -0.842725 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:19.0907 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322655 train-accuracy:0.599691 valid-loss:1.298650 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.1786 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.831007\n",
      "[INFO 24-02-22 06:46:19.1789 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.1798 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.831007 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:19.1802 UTC hyperparameters_optimizer.cc:582] [375/500] Score: -0.831007 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:19.1808 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.1808 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.1811 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.1901 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241142 train-accuracy:0.599691 valid-loss:1.227674 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.3059 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825049\n",
      "[INFO 24-02-22 06:46:19.3060 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.3061 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.825049 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:19.3066 UTC hyperparameters_optimizer.cc:582] [376/500] Score: -0.825049 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:19.3068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.3068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.3071 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.3201 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321941 train-accuracy:0.599691 valid-loss:1.298497 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.4405 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.813229\n",
      "[INFO 24-02-22 06:46:19.4406 UTC gradient_boosted_trees.cc:271] Truncates the model to 102 tree(s) i.e. 102  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.4406 UTC gradient_boosted_trees.cc:334] Final model num-trees:102 valid-loss:0.813229 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:19.4408 UTC hyperparameters_optimizer.cc:582] [377/500] Score: -0.813229 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:19.4413 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.4413 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.4415 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.4424 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329393 train-accuracy:0.599691 valid-loss:1.305255 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.5023 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840959\n",
      "[INFO 24-02-22 06:46:19.5023 UTC gradient_boosted_trees.cc:271] Truncates the model to 151 tree(s) i.e. 151  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.5026 UTC gradient_boosted_trees.cc:334] Final model num-trees:151 valid-loss:0.840959 valid-accuracy:0.787879\n",
      "[[INFO 24-02-22 06:46:19.5047 UTC hyperparameters_optimizer.cc:582] [378/500] Score: -0.840959 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "INFO 24-02-22 06:46:19.5048 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.5054 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.5060 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.5168 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296846 train-accuracy:0.599691 valid-loss:1.282393 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.5856 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.715470 train-accuracy:0.851623 valid-loss:0.874445 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:19.5856 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.5856 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.873263 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:19.5859 UTC hyperparameters_optimizer.cc:582] [379/500] Score: -0.873263 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:19.5874 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.5874 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.5878 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.6124 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322317 train-accuracy:0.599691 valid-loss:1.299272 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.6553 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.828491\n",
      "[INFO 24-02-22 06:46:19.6553 UTC gradient_boosted_trees.cc:271] Truncates the model to 221 tree(s) i.e. 221  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.6554 UTC gradient_boosted_trees.cc:334] Final model num-trees:221 valid-loss:0.828491 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:19.6562 UTC hyperparameters_optimizer.cc:582] [380/500] Score: -0.828491 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:19.6581 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.6581 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.6583 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.6709 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293467 train-accuracy:0.599691 valid-loss:1.278218 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.7256 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806593\n",
      "[INFO 24-02-22 06:46:19.7257 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.7259 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.806593 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:19.7267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.7267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.7268 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.7280 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.831233\n",
      "[INFO 24-02-22 06:46:19.7281 UTC gradient_boosted_trees.cc:271] Truncates the model to 164 tree(s) i.e. 164  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.7281 UTC gradient_boosted_trees.cc:334] Final model num-trees:164 valid-loss:0.831233 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:19.7286 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.7286 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.7287 UTC hyperparameters_optimizer.cc:582] [381/500] Score: -0.806593 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:19.7291 UTC hyperparameters_optimizer.cc:582] [382/500] Score: -0.831233 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:19.7305 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.7375 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321594 train-accuracy:0.599691 valid-loss:1.299985 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.7409 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324193 train-accuracy:0.599691 valid-loss:1.302485 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.8852 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834233\n",
      "[INFO 24-02-22 06:46:19.8852 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.8853 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.834233 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:19.8855 UTC hyperparameters_optimizer.cc:582] [383/500] Score: -0.834233 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:19.8862 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.8862 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.8864 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.8900 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902774\n",
      "[INFO 24-02-22 06:46:19.8900 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.8902 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.902774 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:19.8918 UTC hyperparameters_optimizer.cc:582] [384/500] Score: -0.902774 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:19.8955 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.8955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.8958 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.8998 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326739 train-accuracy:0.599691 valid-loss:1.300533 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.9050 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226218 train-accuracy:0.599691 valid-loss:1.237393 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.0426 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823503\n",
      "[INFO 24-02-22 06:46:20.0426 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.0429 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.823503 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.0445 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.0446 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.0447 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.0454 UTC hyperparameters_optimizer.cc:582] [385/500] Score: -0.823503 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.0496 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326783 train-accuracy:0.599691 valid-loss:1.302539 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.0519 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.786696\n",
      "[INFO 24-02-22 06:46:20.0519 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.0521 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.786696 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.0527 UTC hyperparameters_optimizer.cc:582] [386/500] Score: -0.786696 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.0531 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.0531 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.0533 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.0742 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321941 train-accuracy:0.599691 valid-loss:1.298165 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.1443 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866231\n",
      "[INFO 24-02-22 06:46:20.1443 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.1446 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.866231 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.1452 UTC hyperparameters_optimizer.cc:582] [387/500] Score: -0.866231 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.1458 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.1458 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.1464 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.1546 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.900502\n",
      "[INFO 24-02-22 06:46:20.1546 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.1549 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.900502 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:20.1558 UTC hyperparameters_optimizer.cc:582] [388/500] Score: -0.900502 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:20.1582 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.1583 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.1584 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.1620 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288385 train-accuracy:0.599691 valid-loss:1.271633 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.1733 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229096 train-accuracy:0.599691 valid-loss:1.246819 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.1855 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857059\n",
      "[INFO 24-02-22 06:46:20.1855 UTC gradient_boosted_trees.cc:271] Truncates the model to 132 tree(s) i.e. 132  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.1858 UTC gradient_boosted_trees.cc:334] Final model num-trees:132 valid-loss:0.857059 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.1866 UTC hyperparameters_optimizer.cc:582] [389/500] Score: -0.857059 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:20.1870 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.1870 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.1877 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.1911 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825327\n",
      "[INFO 24-02-22 06:46:20.1911 UTC gradient_boosted_trees.cc:271] Truncates the model to 169 tree(s) i.e. 169  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.1915 UTC gradient_boosted_trees.cc:334] Final model num-trees:169 valid-loss:0.825327 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:20.1935 UTC hyperparameters_optimizer.cc:582] [390/500] Score: -0.825327 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.1954 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.1955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.1959 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.2085 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319999 train-accuracy:0.599691 valid-loss:1.298808 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.2164 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236396 train-accuracy:0.599691 valid-loss:1.248073 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.2636 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852652\n",
      "[INFO 24-02-22 06:46:20.2636 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.2638 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.852652 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.2646 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.2646 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.2648 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.2652 UTC hyperparameters_optimizer.cc:582] [391/500] Score: -0.852652 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:20.2706 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262147 train-accuracy:0.599691 valid-loss:1.259999 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.4671 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.654482 train-accuracy:0.873261 valid-loss:0.824180 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:20.4673 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.4676 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.824180 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:20.4689 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.4689 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.4691 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.4719 UTC hyperparameters_optimizer.cc:582] [392/500] Score: -0.82418 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.4863 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237808 train-accuracy:0.599691 valid-loss:1.252180 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.7984 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832637\n",
      "[INFO 24-02-22 06:46:20.7985 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.7985 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.832637 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.7990 UTC hyperparameters_optimizer.cc:582] [393/500] Score: -0.832637 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:20.8004 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.8006 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.8013 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.8144 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289524 train-accuracy:0.599691 valid-loss:1.275626 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.9586 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.826534\n",
      "[INFO 24-02-22 06:46:20.9586 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.9587 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.826534 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:20.9593 UTC hyperparameters_optimizer.cc:582] [394/500] Score: -0.826534 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:20.9597 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.9597 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.9602 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.9654 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266406 train-accuracy:0.599691 valid-loss:1.252495 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.0836 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836621\n",
      "[INFO 24-02-22 06:46:21.0836 UTC gradient_boosted_trees.cc:271] Truncates the model to 253 tree(s) i.e. 253  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.0837 UTC gradient_boosted_trees.cc:334] Final model num-trees:253 valid-loss:0.836621 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:21.0851 UTC hyperparameters_optimizer.cc:582] [395/500] Score: -0.836621 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.0883 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.0891 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.0893 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.1156 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285809 train-accuracy:0.599691 valid-loss:1.278593 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.1219 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880037\n",
      "[INFO 24-02-22 06:46:21.1219 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.1221 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.880037 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.1226 UTC hyperparameters_optimizer.cc:582] [396/500] Score: -0.880037 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.1233 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.1235 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.1237 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.1367 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230668 train-accuracy:0.599691 valid-loss:1.244447 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.1560 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.795838\n",
      "[INFO 24-02-22 06:46:21.1561 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.1561 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.795838 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.1563 UTC hyperparameters_optimizer.cc:582] [397/500] Score: -0.795838 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:21.1568 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.1568 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.1570 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.1745 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319552 train-accuracy:0.599691 valid-loss:1.299159 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.1877 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850958\n",
      "[INFO 24-02-22 06:46:21.1877 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.1880 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.850958 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.1885 UTC hyperparameters_optimizer.cc:582] [398/500] Score: -0.850958 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:21.1896 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.1896 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.1897 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.1976 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325568 train-accuracy:0.599691 valid-loss:1.304047 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.2467 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86593\n",
      "[INFO 24-02-22 06:46:21.2467 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.2471 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.865930 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.2484 UTC hyperparameters_optimizer.cc:582] [399/500] Score: -0.86593 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:21.2536 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.2566 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.2568 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.2681 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231959 train-accuracy:0.599691 valid-loss:1.246595 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.3297 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857582\n",
      "[INFO 24-02-22 06:46:21.3298 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.3299 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.857582 valid-accuracy:0.818182\n",
      "[INFO[INFO 24-02-22 06:46:21.3327 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.3327 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.3329 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      " 24-02-22 06:46:21.3357 UTC hyperparameters_optimizer.cc:582] [400/500] Score: -0.857582 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.3533 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233756 train-accuracy:0.599691 valid-loss:1.240359 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.4477 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883494\n",
      "[INFO 24-02-22 06:46:21.4486 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.4488 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.883494 valid-accuracy:0.803030\n",
      "[INFO[ 24-02-22 06:46:21.4511 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "INFO[INFO 24-02-22 06:46:21.4511 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      " 24-02-22 06:46:21.4511 UTC hyperparameters_optimizer.cc:582] [401/500] Score: -0.883494 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.4518 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.4522 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.534927 train-accuracy:0.908810 valid-loss:0.849025 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.4522 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.4522 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.848618 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.4528 UTC hyperparameters_optimizer.cc:582] [402/500] Score: -0.848618 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:21.4532 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.4532 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.4537 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.4616 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246449 train-accuracy:0.599691 valid-loss:1.243552 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.4785 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321153 train-accuracy:0.599691 valid-loss:1.300486 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.5138 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.887463\n",
      "[INFO 24-02-22 06:46:21.5138 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.5142 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.887463 valid-accuracy:0.787879\n",
      "[[INFO 24-02-22 06:46:21.5154 UTC hyperparameters_optimizer.cc:582] [403/500] Score: -0.887463 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "INFO 24-02-22 06:46:21.5157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.5157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.5163 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.5366 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240764 train-accuracy:0.599691 valid-loss:1.243603 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.5528 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.821433\n",
      "[INFO 24-02-22 06:46:21.5529 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.5529 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.821433 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:21.5532 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.5533 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.5534 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.5555 UTC hyperparameters_optimizer.cc:582] [404/500] Score: -0.821433 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.5687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244959 train-accuracy:0.599691 valid-loss:1.238667 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.6488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.898132\n",
      "[INFO 24-02-22 06:46:21.6496 UTC gradient_boosted_trees.cc:271] Truncates the model to 114 tree(s) i.e. 114  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.6500 UTC gradient_boosted_trees.cc:334] Final model num-trees:114 valid-loss:0.898132 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.6509 UTC hyperparameters_optimizer.cc:582] [405/500] Score: -0.898132 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.6553 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.6554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.6556 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.6595 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242661 train-accuracy:0.599691 valid-loss:1.244442 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.7142 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891879\n",
      "[INFO 24-02-22 06:46:21.7142 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.7144 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.891879 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.7187 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.7187 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.7188 UTC hyperparameters_optimizer.cc:582] [406/500] Score: -0.891879 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.7189 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.7271 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297469 train-accuracy:0.599691 valid-loss:1.277336 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.8221 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873443\n",
      "[INFO 24-02-22 06:46:21.8247 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.8250 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.873443 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.8257 UTC hyperparameters_optimizer.cc:582] [407/500] Score: -0.873443 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:21.8299 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.8300 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.8302 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.8555 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289101 train-accuracy:0.599691 valid-loss:1.272415 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.8571 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.885702\n",
      "[INFO 24-02-22 06:46:21.8571 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.8573 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.885702 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.8576 UTC hyperparameters_optimizer.cc:582] [408/500] Score: -0.885702 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.8583 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.8584 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.8585 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.8647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298066 train-accuracy:0.599691 valid-loss:1.275231 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.9242 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.853916\n",
      "[INFO 24-02-22 06:46:21.9243 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.9245 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.853916 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:21.9251 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.9251 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.9252 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.9255 UTC hyperparameters_optimizer.cc:582] [409/500] Score: -0.853916 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:21.9377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297151 train-accuracy:0.599691 valid-loss:1.283573 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.9761 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.878809\n",
      "[INFO 24-02-22 06:46:21.9761 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.9764 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.878809 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.9766 UTC hyperparameters_optimizer.cc:582] [410/500] Score: -0.878809 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.9773 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.9773 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.9775 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.9852 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.251805 train-accuracy:0.599691 valid-loss:1.258704 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.3630 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867171\n",
      "[INFO 24-02-22 06:46:22.3631 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.3632 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.867171 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:22.3635 UTC hyperparameters_optimizer.cc:582] [411/500] Score: -0.867171 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:22.3638 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.3638 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.3640 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.3727 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848085\n",
      "[INFO 24-02-22 06:46:22.3727 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.3728 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.848085 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:22.3731 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238693 train-accuracy:0.599691 valid-loss:1.229094 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.3733 UTC hyperparameters_optimizer.cc:582] [412/500] Score: -0.848085 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.3742 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.3743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.3745 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.3833 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286572 train-accuracy:0.599691 valid-loss:1.277108 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.4666 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.800145\n",
      "[INFO 24-02-22 06:46:22.4666 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.4667 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.800145 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:22.4670 UTC hyperparameters_optimizer.cc:582] [413/500] Score: -0.800145 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.4675 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.4675 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.4677 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.4770 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322770 train-accuracy:0.599691 valid-loss:1.298749 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.6330 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825449\n",
      "[INFO 24-02-22 06:46:22.6330 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.6332 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.825449 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:22.6336 UTC hyperparameters_optimizer.cc:582] [414/500] Score: -0.825449 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:22.6340 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.6340 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.6345 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.6387 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81754\n",
      "[INFO 24-02-22 06:46:22.6388 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.6389 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.817540 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:22.6392 UTC hyperparameters_optimizer.cc:582] [415/500] Score: -0.81754 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.6397 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.6397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.6399 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.6479 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292776 train-accuracy:0.599691 valid-loss:1.281058 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.6619 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232047 train-accuracy:0.599691 valid-loss:1.246513 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.7635 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.833198\n",
      "[INFO 24-02-22 06:46:22.7635 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.7636 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.833198 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:22.7639 UTC hyperparameters_optimizer.cc:582] [416/500] Score: -0.833198 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:22.7642 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.7643 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.7646 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.7748 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237687 train-accuracy:0.599691 valid-loss:1.245790 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.8380 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85852\n",
      "[INFO 24-02-22 06:46:22.8381 UTC gradient_boosted_trees.cc:271] Truncates the model to 157 tree(s) i.e. 157  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.8382 UTC gradient_boosted_trees.cc:334] Final model num-trees:157 valid-loss:0.858520 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:22.8393 UTC hyperparameters_optimizer.cc:582] [417/500] Score: -0.85852 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.8399 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.8399 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.8409 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.8654 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224034 train-accuracy:0.599691 valid-loss:1.254949 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.9304 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.794096\n",
      "[INFO 24-02-22 06:46:22.9305 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.9306 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.794096 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:22.9309 UTC hyperparameters_optimizer.cc:582] [418/500] Score: -0.794096 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.9358 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.9358 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.9360 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.9664 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281505 train-accuracy:0.599691 valid-loss:1.273863 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.0148 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838417\n",
      "[INFO 24-02-22 06:46:23.0148 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.0150 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.838417 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:23.0153 UTC hyperparameters_optimizer.cc:582] [419/500] Score: -0.838417 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:23.0157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.0157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.0159 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.0328 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238188 train-accuracy:0.599691 valid-loss:1.241760 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.0373 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874696\n",
      "[INFO 24-02-22 06:46:23.0373 UTC gradient_boosted_trees.cc:271] Truncates the model to 99 tree(s) i.e. 99  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.0375 UTC gradient_boosted_trees.cc:334] Final model num-trees:99 valid-loss:0.874696 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:23.0387 UTC hyperparameters_optimizer.cc:582] [420/500] Score: -0.874696 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:23.0393 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.0393 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.0403 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.0606 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89632\n",
      "[INFO 24-02-22 06:46:23.0607 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.0609 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.896320 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:23.0614 UTC hyperparameters_optimizer.cc:582] [421/500] Score: -0.89632 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:23.0624 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.0625 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.0626 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.0657 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288667 train-accuracy:0.599691 valid-loss:1.278169 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.0713 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286981 train-accuracy:0.599691 valid-loss:1.278010 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.1125 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.861326\n",
      "[INFO 24-02-22 06:46:23.1126 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.1130 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.861326 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:23.1141 UTC hyperparameters_optimizer.cc:582] [422/500] Score: -0.861326 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.1157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.1157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.1159 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.1206 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.253101 train-accuracy:0.599691 valid-loss:1.259169 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.2247 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81219\n",
      "[INFO 24-02-22 06:46:23.2247 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.2248 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.812190 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:23.2253 UTC hyperparameters_optimizer.cc:582] [423/500] Score: -0.81219 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:23.2257 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.2257 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.2262 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.2365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324982 train-accuracy:0.599691 valid-loss:1.301121 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.4051 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843925\n",
      "[INFO 24-02-22 06:46:23.4051 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.4053 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.843925 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.4057 UTC hyperparameters_optimizer.cc:582] [424/500] Score: -0.843925 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:23.4068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.4068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.4081 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.4314 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285247 train-accuracy:0.599691 valid-loss:1.279247 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.4810 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864816\n",
      "[INFO 24-02-22 06:46:23.4810 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.4813 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.864816 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:23.4827 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.4827 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.4829 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.4856 UTC hyperparameters_optimizer.cc:582] [425/500] Score: -0.864816 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:23.5016 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287991 train-accuracy:0.599691 valid-loss:1.271756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.5707 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.841302\n",
      "[INFO 24-02-22 06:46:23.5716 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.5717 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.841302 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.5720 UTC hyperparameters_optimizer.cc:582] [426/500] Score: -0.841302 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.5726 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.5726 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.5728 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.5827 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325438 train-accuracy:0.599691 valid-loss:1.298811 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.6417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824109\n",
      "[INFO 24-02-22 06:46:23.6417 UTC gradient_boosted_trees.cc:271] Truncates the model to 195 tree(s) i.e. 195  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.6420 UTC gradient_boosted_trees.cc:334] Final model num-trees:195 valid-loss:0.824109 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.6436 UTC hyperparameters_optimizer.cc:582] [427/500] Score: -0.824109 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:23.6451 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.6454 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.6514 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.6683 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236242 train-accuracy:0.599691 valid-loss:1.237008 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.6811 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.893199\n",
      "[INFO 24-02-22 06:46:23.6811 UTC gradient_boosted_trees.cc:271] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.6814 UTC gradient_boosted_trees.cc:334] Final model num-trees:116 valid-loss:0.893199 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.6837 UTC hyperparameters_optimizer.cc:582] [428/500] Score: -0.893199 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:23.6851 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.6851 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.6865 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.6957 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326845 train-accuracy:0.599691 valid-loss:1.303097 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.7177 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.854581\n",
      "[INFO 24-02-22 06:46:23.7177 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.7179 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.854581 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:23.7199 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.7200 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.7203 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.7221 UTC hyperparameters_optimizer.cc:582] [429/500] Score: -0.854581 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:23.7583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322730 train-accuracy:0.599691 valid-loss:1.301670 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.7773 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864495\n",
      "[INFO 24-02-22 06:46:23.7773 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.7776 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.864495 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.7779 UTC hyperparameters_optimizer.cc:582] [430/500] Score: -0.864495 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.7782 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.7782 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.7785 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.7854 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891506\n",
      "[INFO 24-02-22 06:46:23.7856 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.7859 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.891506 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:23.7868 UTC hyperparameters_optimizer.cc:582] [431/500] Score: -0.891506 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.7875 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.7875 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.7877 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.7980 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240787 train-accuracy:0.599691 valid-loss:1.236858 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.8078 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242117 train-accuracy:0.599691 valid-loss:1.256775 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.9564 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.861981\n",
      "[INFO 24-02-22 06:46:23.9564 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.9565 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.861981 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.9569 UTC hyperparameters_optimizer.cc:582] [432/500] Score: -0.861981 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.9575 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.9575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.9578 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.9732 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284100 train-accuracy:0.599691 valid-loss:1.273701 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.1422 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.863748\n",
      "[INFO 24-02-22 06:46:24.1422 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.1429 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.863748 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.1432 UTC hyperparameters_optimizer.cc:582] [433/500] Score: -0.863748 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:24.1436 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.1436 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.1438 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.1563 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243992 train-accuracy:0.599691 valid-loss:1.223522 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.1708 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.901162\n",
      "[INFO 24-02-22 06:46:24.1708 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.1711 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.901162 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:24.1713 UTC hyperparameters_optimizer.cc:582] [434/500] Score: -0.901162 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:24.1719 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.1719 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.1723 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.1818 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324823 train-accuracy:0.599691 valid-loss:1.300802 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.3383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881871\n",
      "[INFO 24-02-22 06:46:24.3383 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.3392 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.881871 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:24.3398 UTC hyperparameters_optimizer.cc:582] [435/500] Score: -0.881871 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:24.3407 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.3407 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.3409 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.3603 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322295 train-accuracy:0.599691 valid-loss:1.301339 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.3890 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.8915\n",
      "[INFO 24-02-22 06:46:24.3890 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.3893 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.891500 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.3907 UTC hyperparameters_optimizer.cc:582] [436/500] Score: -0.8915 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:24.3945 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.3945 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.3948 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.4123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292122 train-accuracy:0.599691 valid-loss:1.279078 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.4747 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842558\n",
      "[INFO 24-02-22 06:46:24.4747 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.4749 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.842558 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.4751 UTC hyperparameters_optimizer.cc:582] [437/500] Score: -0.842558 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:24.4758 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.4758 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.4760 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.4871 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239358 train-accuracy:0.599691 valid-loss:1.238617 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.5395 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.889452\n",
      "[INFO 24-02-22 06:46:24.5398 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.5403 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.889452 valid-accuracy:0.803030\n",
      "[[INFO 24-02-22 06:46:24.5446 UTC hyperparameters_optimizer.cc:582] [438/500] Score: -0.889452 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "INFO 24-02-22 06:46:24.5457 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.5459 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.5474 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.5837 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325090 train-accuracy:0.599691 valid-loss:1.301567 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.7716 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865291\n",
      "[INFO 24-02-22 06:46:24.7717 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.7719 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.865291 valid-accuracy:0.818182\n",
      "[[INFO 24-02-22 06:46:24.7730 UTC hyperparameters_optimizer.cc:582] [439/500] Score: -0.865291 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "INFO 24-02-22 06:46:24.7735 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.7736 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.7741 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.7851 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321913 train-accuracy:0.599691 valid-loss:1.298923 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.8323 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.829923\n",
      "[INFO 24-02-22 06:46:24.8323 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.8326 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.829923 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:24.8335 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.8335 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.8341 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.8349 UTC hyperparameters_optimizer.cc:582] [440/500] Score: -0.829923 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:24.8556 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242171 train-accuracy:0.599691 valid-loss:1.255534 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.9141 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836829\n",
      "[INFO 24-02-22 06:46:24.9141 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.9142 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.836829 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.9145 UTC hyperparameters_optimizer.cc:582] [441/500] Score: -0.836829 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:24.9151 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.9152 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.9153 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.9214 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257563 train-accuracy:0.599691 valid-loss:1.251756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.9743 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836194\n",
      "[INFO 24-02-22 06:46:24.9745 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.9746 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.836194 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.9751 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.9751 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.9753 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.9787 UTC hyperparameters_optimizer.cc:582] [442/500] Score: -0.836194 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:24.9924 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233687 train-accuracy:0.599691 valid-loss:1.242509 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.0363 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849935\n",
      "[INFO 24-02-22 06:46:25.0363 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.0365 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.849935 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.0371 UTC hyperparameters_optimizer.cc:582] [443/500] Score: -0.849935 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:25.0383 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.0383 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.0386 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.0509 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286755 train-accuracy:0.599691 valid-loss:1.285917 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.1218 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85228\n",
      "[INFO 24-02-22 06:46:25.1218 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.1220 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.852280 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.1227 UTC hyperparameters_optimizer.cc:582] [444/500] Score: -0.85228 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:25.1232 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.1232 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.1237 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.1343 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326922 train-accuracy:0.599691 valid-loss:1.300154 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.1385 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848336\n",
      "[INFO 24-02-22 06:46:25.1387 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.1392 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.848336 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:25.1396 UTC hyperparameters_optimizer.cc:582] [445/500] Score: -0.848336 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:25.1402 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.1404 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.1409 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.1828 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284817 train-accuracy:0.599691 valid-loss:1.274918 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.2947 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.856491\n",
      "[INFO 24-02-22 06:46:25.2947 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.2949 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.856491 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:25.2953 UTC hyperparameters_optimizer.cc:582] [446/500] Score: -0.856491 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:25.2959 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.2960 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.2966 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.3094 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288903 train-accuracy:0.599691 valid-loss:1.276387 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.7421 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.892933\n",
      "[INFO 24-02-22 06:46:25.7422 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.7424 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.892933 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.7427 UTC hyperparameters_optimizer.cc:582] [447/500] Score: -0.892933 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:25.7437 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.7438 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.7440 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.7631 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320679 train-accuracy:0.599691 valid-loss:1.300279 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.7836 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855831\n",
      "[INFO 24-02-22 06:46:25.7837 UTC gradient_boosted_trees.cc:271] Truncates the model to 134 tree(s) i.e. 134  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.7840 UTC gradient_boosted_trees.cc:334] Final model num-trees:134 valid-loss:0.855831 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:25.7848 UTC hyperparameters_optimizer.cc:582] [448/500] Score: -0.855831 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:25.7854 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.7854 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.7861 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.7959 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288772 train-accuracy:0.599691 valid-loss:1.266201 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.8007 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855176\n",
      "[INFO 24-02-22 06:46:25.8007 UTC gradient_boosted_trees.cc:271] Truncates the model to 188 tree(s) i.e. 188  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.8008 UTC gradient_boosted_trees.cc:334] Final model num-trees:188 valid-loss:0.855176 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.8016 UTC hyperparameters_optimizer.cc:582] [449/500] Score: -0.855176 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:25.8031 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.8032 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.8034 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.8139 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293512 train-accuracy:0.599691 valid-loss:1.280251 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.9333 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.892938\n",
      "[INFO 24-02-22 06:46:25.9337 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.9343 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.892938 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:25.9349 UTC hyperparameters_optimizer.cc:582] [450/500] Score: -0.892938 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:25.9361 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.9363 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.9368 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.9486 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.80558\n",
      "[INFO 24-02-22 06:46:25.9486 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.9486 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.805580 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.9488 UTC hyperparameters_optimizer.cc:582] [451/500] Score: -0.80558 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:25.9494 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.9494 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.9499 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.9577 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283808 train-accuracy:0.599691 valid-loss:1.277540 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.9581 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288613 train-accuracy:0.599691 valid-loss:1.275549 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.1126 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845328\n",
      "[INFO 24-02-22 06:46:26.1126 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.1128 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.845328 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:26.1131 UTC hyperparameters_optimizer.cc:582] [452/500] Score: -0.845328 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:26.1136 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.1136 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.1139 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.1381 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321220 train-accuracy:0.599691 valid-loss:1.299968 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.1719 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868953\n",
      "[INFO 24-02-22 06:46:26.1720 UTC gradient_boosted_trees.cc:271] Truncates the model to 170 tree(s) i.e. 170  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.1722 UTC gradient_boosted_trees.cc:334] Final model num-trees:170 valid-loss:0.868953 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:26.1740 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.1741 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.1743 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.1754 UTC hyperparameters_optimizer.cc:582] [453/500] Score: -0.868953 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:26.1946 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283893 train-accuracy:0.599691 valid-loss:1.284861 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.2176 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827858\n",
      "[INFO 24-02-22 06:46:26.2176 UTC gradient_boosted_trees.cc:271] Truncates the model to 222 tree(s) i.e. 222  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.2177 UTC gradient_boosted_trees.cc:334] Final model num-trees:222 valid-loss:0.827858 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:26.2188 UTC hyperparameters_optimizer.cc:582] [454/500] Score: -0.827858 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:26.2192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.2192 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.2203 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.2355 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245432 train-accuracy:0.599691 valid-loss:1.245759 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.3612 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880723\n",
      "[INFO 24-02-22 06:46:26.3612 UTC gradient_boosted_trees.cc:271] Truncates the model to 85 tree(s) i.e. 85  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.3614 UTC gradient_boosted_trees.cc:334] Final model num-trees:85 valid-loss:0.880723 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:26.3622 UTC hyperparameters_optimizer.cc:582] [455/500] Score: -0.880723 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:26.3640 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.3640 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.3642 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.3788 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293177 train-accuracy:0.599691 valid-loss:1.277127 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.4582 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846272\n",
      "[INFO 24-02-22 06:46:26.4601 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.4603 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.846272 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:26.4607 UTC hyperparameters_optimizer.cc:582] [456/500] Score: -0.846272 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:26.4613 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.4613 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.4616 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.4806 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322742 train-accuracy:0.599691 valid-loss:1.297766 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.5734 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862691\n",
      "[INFO 24-02-22 06:46:26.5734 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.5736 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.862691 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:26.5748 UTC hyperparameters_optimizer.cc:582] [457/500] Score: -0.862691 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:26.5781 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.5781 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.5783 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.5868 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247157 train-accuracy:0.599691 valid-loss:1.239475 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.5902 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836121\n",
      "[INFO 24-02-22 06:46:26.5902 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.5903 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.836121 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:26.5904 UTC hyperparameters_optimizer.cc:582] [458/500] Score: -0.836121 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:26.5908 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.5908 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.5909 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.6109 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290028 train-accuracy:0.599691 valid-loss:1.274383 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.6593 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842044\n",
      "[INFO 24-02-22 06:46:26.6595 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.6597 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.842044 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:26.6601 UTC hyperparameters_optimizer.cc:582] [459/500] Score: -0.842044 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:26.6605 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.6606 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.6609 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.6832 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240245 train-accuracy:0.599691 valid-loss:1.246634 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.7165 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864741\n",
      "[INFO 24-02-22 06:46:26.7166 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.7169 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.864741 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:26.7179 UTC hyperparameters_optimizer.cc:582] [460/500] Score: -0.864741 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:26.7192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.7193 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.7196 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.7347 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832839\n",
      "[INFO 24-02-22 06:46:26.7349 UTC gradient_boosted_trees.cc:271] Truncates the model to 90 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.7350 UTC gradient_boosted_trees.cc:334] Final model num-trees:90 valid-loss:0.832839 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:26.7356 UTC hyperparameters_optimizer.cc:582] [461/500] Score: -0.832839 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:26.7363 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.7363 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.7365 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.7374 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224136 train-accuracy:0.599691 valid-loss:1.226326 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.7542 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285819 train-accuracy:0.599691 valid-loss:1.270400 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.9847 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.476155 train-accuracy:0.935085 valid-loss:0.851135 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:26.9847 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.9848 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.851135 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:26.9854 UTC hyperparameters_optimizer.cc:582] [462/500] Score: -0.851135 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:26.9858 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.9858 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.9866 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.0076 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320010 train-accuracy:0.599691 valid-loss:1.299249 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.1606 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825564\n",
      "[INFO 24-02-22 06:46:27.1606 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.1607 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.825564 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:27.1619 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.1619 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.1621 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.1625 UTC hyperparameters_optimizer.cc:582] [463/500] Score: -0.825564 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.1746 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290290 train-accuracy:0.599691 valid-loss:1.279000 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.2646 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827447\n",
      "[INFO 24-02-22 06:46:27.2646 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.2648 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.827447 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.2653 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.2653 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.2656 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO[INFO 24-02-22 06:46:27.2687 UTC hyperparameters_optimizer.cc:582] [464/500] Score:  24-02-22 06:46:27.2687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.258473 train-accuracy:0.599691 valid-loss:1.257301 valid-accuracy:0.636364\n",
      "-0.827447 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.4488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881123\n",
      "[INFO 24-02-22 06:46:27.4489 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.4492 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.881123 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:27.4498 UTC hyperparameters_optimizer.cc:582] [465/500] Score: -0.881123 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.4510 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.4510 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.4513 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.4677 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323012 train-accuracy:0.599691 valid-loss:1.297698 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.4995 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836968\n",
      "[INFO 24-02-22 06:46:27.4996 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.5001 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.836968 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.5008 UTC hyperparameters_optimizer.cc:582] [466/500] Score: -0.836968 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:27.5021 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.5021 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.5023 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.5109 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290443 train-accuracy:0.599691 valid-loss:1.269418 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.5417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.905929\n",
      "[INFO 24-02-22 06:46:27.5418 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.5423 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.905929 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:27.5433 UTC hyperparameters_optimizer.cc:582] [467/500] Score: -0.905929 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.5437 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.5437 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.5440 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.5543 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295290 train-accuracy:0.599691 valid-loss:1.283301 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.6998 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873533\n",
      "[INFO 24-02-22 06:46:27.6998 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.7000 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.873533 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.7003 UTC hyperparameters_optimizer.cc:582] [468/500] Score: -0.873533 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.7008 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.7008 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.7045 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.7077 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304326 train-accuracy:0.599691 valid-loss:1.288304 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.7097 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.780587\n",
      "[INFO 24-02-22 06:46:27.7098 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.7099 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.780587 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:27.7103 UTC hyperparameters_optimizer.cc:582] [469/500] Score: -0.780587 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:27.7110 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.7110 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.7112 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.7222 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.895371\n",
      "[INFO 24-02-22 06:46:27.7223 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.7225 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.895371 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:27.7235 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.7236 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.7238 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.7254 UTC hyperparameters_optimizer.cc:582] [470/500] Score: -0.895371 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:27.7283 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299755 train-accuracy:0.599691 valid-loss:1.287562 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.7324 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323426 train-accuracy:0.599691 valid-loss:1.299440 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.7659 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.804027\n",
      "[INFO 24-02-22 06:46:27.7659 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.7659 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.804027 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:27.7661 UTC hyperparameters_optimizer.cc:582] [471/500] Score: -0.804027 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:27.7665 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.7665 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.7667 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.7730 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263929 train-accuracy:0.599691 valid-loss:1.260704 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.8360 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849266\n",
      "[INFO 24-02-22 06:46:27.8360 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.8362 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.849266 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.8372 UTC hyperparameters_optimizer.cc:582] [472/500] Score: -0.849266 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.8390 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.8390 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.8392 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.8613 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323587 train-accuracy:0.599691 valid-loss:1.297065 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.8774 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865638\n",
      "[INFO 24-02-22 06:46:27.8775 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.8776 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.865638 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.8783 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.8783 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.8784 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.8787 UTC hyperparameters_optimizer.cc:582] [473/500] Score: -0.865638 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:27.8964 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320758 train-accuracy:0.599691 valid-loss:1.297540 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.0078 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.831037\n",
      "[INFO 24-02-22 06:46:28.0078 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.0080 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.831037 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.0084 UTC hyperparameters_optimizer.cc:582] [474/500] Score: -0.831037 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:28.0097 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.0097 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.0099 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.0158 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297254 train-accuracy:0.599691 valid-loss:1.282973 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.0660 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868684\n",
      "[INFO 24-02-22 06:46:28.0661 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.0662 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.868684 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:28.0668 UTC hyperparameters_optimizer.cc:582] [475/500] Score: -0.868684 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:28.0679 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.0679 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.0681 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.0821 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285197 train-accuracy:0.599691 valid-loss:1.273829 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.0859 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.894032\n",
      "[INFO 24-02-22 06:46:28.0859 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.0863 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.894032 valid-accuracy:0.772727\n",
      "[[INFO 24-02-22 06:46:28.0873 UTC hyperparameters_optimizer.cc:582] [476/500] Score: -0.894032 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "INFO 24-02-22 06:46:28.0879 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.0879 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.0886 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.0975 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292784 train-accuracy:0.599691 valid-loss:1.277535 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.4533 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.861533\n",
      "[INFO 24-02-22 06:46:28.4534 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.4535 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.861533 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.4550 UTC hyperparameters_optimizer.cc:582] [477/500] Score: -0.861533 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:28.4554 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.4554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.4558 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.4702 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324074 train-accuracy:0.599691 valid-loss:1.301806 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.4887 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850325\n",
      "[INFO 24-02-22 06:46:28.4887 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.4888 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.850325 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.4897 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.4897 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.4900 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.4921 UTC hyperparameters_optimizer.cc:582] [478/500] Score: -0.850325 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:28.5008 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295223 train-accuracy:0.599691 valid-loss:1.273200 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.5063 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.82017\n",
      "[INFO 24-02-22 06:46:28.5063 UTC gradient_boosted_trees.cc:271] Truncates the model to 232 tree(s) i.e. 232  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.5063 UTC gradient_boosted_trees.cc:334] Final model num-trees:232 valid-loss:0.820170 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:28.5068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.5068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.5070 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.5087 UTC hyperparameters_optimizer.cc:582] [479/500] Score: -0.82017 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:28.5201 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294247 train-accuracy:0.599691 valid-loss:1.275443 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.5890 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.847658\n",
      "[INFO 24-02-22 06:46:28.5890 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.5891 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.847658 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.5894 UTC hyperparameters_optimizer.cc:582] [480/500] Score: -0.847658 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:28.5905 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.5906 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.5907 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.6066 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230309 train-accuracy:0.599691 valid-loss:1.246516 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.9206 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874587\n",
      "[INFO 24-02-22 06:46:28.9220 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.9222 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.874587 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.9233 UTC hyperparameters_optimizer.cc:582] [481/500] Score: -0.874587 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:28.9270 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.9271 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.9273 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.9501 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226547 train-accuracy:0.599691 valid-loss:1.244866 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:29.0542 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.88806\n",
      "[INFO 24-02-22 06:46:29.0543 UTC gradient_boosted_trees.cc:271] Truncates the model to 94 tree(s) i.e. 94  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.0547 UTC gradient_boosted_trees.cc:334] Final model num-trees:94 valid-loss:0.888060 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:29.0560 UTC hyperparameters_optimizer.cc:582] [482/500] Score: -0.88806 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:29.0576 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:29.0577 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:29.0581 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:29.0589 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.797545\n",
      "[INFO 24-02-22 06:46:29.0589 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.0589 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.797545 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:29.0594 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:29.0594 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:29.0595 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:29.0621 UTC hyperparameters_optimizer.cc:582] [483/500] Score: -0.797545 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:29.0710 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288085 train-accuracy:0.599691 valid-loss:1.281139 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:29.0804 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293229 train-accuracy:0.599691 valid-loss:1.288878 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:29.1884 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852276\n",
      "[INFO 24-02-22 06:46:29.1885 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.1886 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.852276 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:29.1891 UTC hyperparameters_optimizer.cc:582] [484/500] Score: -0.852276 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:29.1913 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:29.1914 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:29.1917 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:29.2071 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287935 train-accuracy:0.599691 valid-loss:1.279650 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:29.2286 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857383\n",
      "[INFO 24-02-22 06:46:29.2286 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.2289 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.857383 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:29.2299 UTC hyperparameters_optimizer.cc:582] [485/500] Score: -0.857383 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:29.3029 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864463\n",
      "[INFO 24-02-22 06:46:29.3029 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.3031 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.864463 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:29.3039 UTC hyperparameters_optimizer.cc:582] [486/500] Score: -0.864463 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:29.4366 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.916912\n",
      "[INFO 24-02-22 06:46:29.4366 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.4368 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.916912 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:29.4372 UTC hyperparameters_optimizer.cc:582] [487/500] Score: -0.916912 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:29.6237 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.797799\n",
      "[INFO 24-02-22 06:46:29.6237 UTC gradient_boosted_trees.cc:271] Truncates the model to 223 tree(s) i.e. 223  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.6238 UTC gradient_boosted_trees.cc:334] Final model num-trees:223 valid-loss:0.797799 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:29.6247 UTC hyperparameters_optimizer.cc:582] [488/500] Score: -0.797799 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:29.7488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81823\n",
      "[INFO 24-02-22 06:46:29.7489 UTC gradient_boosted_trees.cc:271] Truncates the model to 93 tree(s) i.e. 93  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.7491 UTC gradient_boosted_trees.cc:334] Final model num-trees:93 valid-loss:0.818230 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:29.7496 UTC hyperparameters_optimizer.cc:582] [489/500] Score: -0.81823 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:29.7574 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843279\n",
      "[INFO 24-02-22 06:46:29.7575 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.7576 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.843279 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:29.7580 UTC hyperparameters_optimizer.cc:582] [490/500] Score: -0.843279 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:29.8056 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.869204\n",
      "[INFO 24-02-22 06:46:29.8056 UTC gradient_boosted_trees.cc:271] Truncates the model to 88 tree(s) i.e. 88  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.8059 UTC gradient_boosted_trees.cc:334] Final model num-trees:88 valid-loss:0.869204 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:29.8068 UTC hyperparameters_optimizer.cc:582] [491/500] Score: -0.869204 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:29.8870 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.869227\n",
      "[INFO 24-02-22 06:46:29.8870 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.8872 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.869227 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:29.8873 UTC hyperparameters_optimizer.cc:582] [492/500] Score: -0.869227 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:29.9372 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867664\n",
      "[INFO 24-02-22 06:46:29.9372 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.9376 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.867664 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:29.9387 UTC hyperparameters_optimizer.cc:582] [493/500] Score: -0.867664 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:30.1014 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.826458\n",
      "[INFO 24-02-22 06:46:30.1014 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.1015 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.826458 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:30.1018 UTC hyperparameters_optimizer.cc:582] [494/500] Score: -0.826458 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:30.1414 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864924\n",
      "[INFO 24-02-22 06:46:30.1415 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.1418 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.864924 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:30.1428 UTC hyperparameters_optimizer.cc:582] [495/500] Score: -0.864924 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:30.1910 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.897969\n",
      "[INFO 24-02-22 06:46:30.1910 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.1913 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.897969 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:30.1917 UTC hyperparameters_optimizer.cc:582] [496/500] Score: -0.897969 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:30.2421 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864362\n",
      "[INFO 24-02-22 06:46:30.2421 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.2422 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.864362 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:30.2426 UTC hyperparameters_optimizer.cc:582] [497/500] Score: -0.864362 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:30.3246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834547\n",
      "[INFO 24-02-22 06:46:30.3247 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.3249 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.834547 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:30.3258 UTC hyperparameters_optimizer.cc:582] [498/500] Score: -0.834547 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:30.6013 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85364\n",
      "[INFO 24-02-22 06:46:30.6013 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.6014 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.853640 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:30.6020 UTC hyperparameters_optimizer.cc:582] [499/500] Score: -0.85364 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:30.9567 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.829806\n",
      "[INFO 24-02-22 06:46:30.9568 UTC gradient_boosted_trees.cc:271] Truncates the model to 174 tree(s) i.e. 174  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.9569 UTC gradient_boosted_trees.cc:334] Final model num-trees:174 valid-loss:0.829806 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:30.9578 UTC hyperparameters_optimizer.cc:582] [500/500] Score: -0.829806 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:30.9639 UTC hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  value {\n",
      "    categorical: \"SPARSE_OBLIQUE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_projection_density_factor\"\n",
      "  value {\n",
      "    real: 3\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_normalization\"\n",
      "  value {\n",
      "    categorical: \"NONE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_weights\"\n",
      "  value {\n",
      "    categorical: \"BINARY\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  value {\n",
      "    categorical: \"CART\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  value {\n",
      "    categorical: \"BEST_FIRST_GLOBAL\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_num_nodes\"\n",
      "  value {\n",
      "    integer: 32\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sampling_method\"\n",
      "  value {\n",
      "    categorical: \"RANDOM\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"subsample\"\n",
      "  value {\n",
      "    real: 0.6\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  value {\n",
      "    real: 0.1\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 5\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  value {\n",
      "    categorical: \"true\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  value {\n",
      "    real: 0.5\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:46:30.9662 UTC kernel.cc:919] Export model in log directory: /tmp/tmpf8og66t6 with prefix 99a97f2c4fb549ac\n",
      "[INFO 24-02-22 06:46:30.9695 UTC kernel.cc:937] Save model in resources\n",
      "[INFO 24-02-22 06:46:30.9733 UTC abstract_model.cc:881] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 0.758798\n",
      "\n",
      "Accuracy: 0.818182  CI95[W][0 1]\n",
      "ErrorRate: : 0.181818\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36   6\n",
      "2   6  18\n",
      "Total: 66\n",
      "\n",
      "\n",
      "[INFO 24-02-22 06:46:30.9830 UTC kernel.cc:1233] Loading model from path /tmp/tmpf8og66t6/model/ with prefix 99a97f2c4fb549ac\n",
      "[INFO 24-02-22 06:46:30.9871 UTC decision_forest.cc:660] Model loaded with 21 root(s), 1167 node(s), and 9 input feature(s).\n",
      "[INFO 24-02-22 06:46:30.9871 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-02-22 06:46:30.9871 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:45.245856\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x704c301cf910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner2 = tfdf.tuner.RandomSearch(num_trials=500, use_predefined_hps=True)\n",
    "\n",
    "# Define and train the model.\n",
    "tuned_model2 = tfdf.keras.GradientBoostedTreesModel(tuner=tuner2)\n",
    "tuned_model2.fit(train_ds, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the TF-DF hyper-parameter tuner: 0.7978\n"
     ]
    }
   ],
   "source": [
    "tuned_model2.compile([\"accuracy\"])\n",
    "tuned_test_accuracy2 = tuned_model2.evaluate(test_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy with the TF-DF hyper-parameter tuner: {tuned_test_accuracy2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_rfm = tuned_model2.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('titanic/test.csv')\n",
    "answer = pd.DataFrame({\"PassengerId\" : t[\"PassengerId\"], \"Survived\":np.round(predictions_rfm,0).astype('int').ravel()})\n",
    "answer.to_csv('titanic/predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1 (1.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (9):\n",
      "\tAge\n",
      "\tEmbarked_C\n",
      "\tEmbarked_Q\n",
      "\tEmbarked_S\n",
      "\tFare\n",
      "\tPclass\n",
      "\tPeople\n",
      "\tSex_female\n",
      "\tSex_male\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.        \"Age\"  0.480781 ################\n",
      "    2.       \"Fare\"  0.233748 ##\n",
      "    3. \"Embarked_C\"  0.229072 ##\n",
      "    4. \"Embarked_Q\"  0.212467 #\n",
      "    5.     \"Pclass\"  0.204518 #\n",
      "    6. \"Embarked_S\"  0.203581 #\n",
      "    7. \"Sex_female\"  0.190493 \n",
      "    8.   \"Sex_male\"  0.187266 \n",
      "    9.     \"People\"  0.184621 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.        \"Age\" 40.000000 ################\n",
      "    2.       \"Fare\"  9.000000 ##\n",
      "    3. \"Embarked_C\"  7.000000 #\n",
      "    4.     \"Pclass\"  7.000000 #\n",
      "    5. \"Sex_female\"  6.000000 \n",
      "    6. \"Embarked_Q\"  5.000000 \n",
      "    7. \"Embarked_S\"  4.000000 \n",
      "    8.   \"Sex_male\"  4.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.        \"Age\" 576.000000 ################\n",
      "    2.       \"Fare\" 150.000000 ###\n",
      "    3. \"Embarked_C\" 143.000000 ###\n",
      "    4. \"Embarked_Q\" 91.000000 ##\n",
      "    5. \"Embarked_S\" 83.000000 ##\n",
      "    6.     \"Pclass\" 35.000000 \n",
      "    7.     \"People\" 26.000000 \n",
      "    8. \"Sex_female\" 11.000000 \n",
      "    9.   \"Sex_male\"  9.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.        \"Age\" 704597.971906 ################\n",
      "    2. \"Sex_female\" 449054.584518 #########\n",
      "    3. \"Embarked_C\" 369300.695390 ########\n",
      "    4.       \"Fare\" 178456.741431 ###\n",
      "    5.     \"Pclass\" 160581.892920 ###\n",
      "    6. \"Embarked_Q\" 130410.905733 ##\n",
      "    7.   \"Sex_male\" 113611.533708 ##\n",
      "    8. \"Embarked_S\" 82894.168039 #\n",
      "    9.     \"People\" 24160.364469 \n",
      "\n",
      "\n",
      "Hyperparameter optimizer:\n",
      "\n",
      "Best parameters: min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5\n",
      "Num steps: 1100\n",
      "Best score: -0.481402\n",
      "\n",
      "Step #0 score:-0.645815 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #1 score:-0.585609 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #2 score:-0.599763 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #3 score:-0.568930 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #4 score:-0.634661 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #5 score:-0.615607 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #6 score:-0.601437 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #7 score:-0.664715 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #8 score:-0.714605 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #9 score:-0.629326 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #10 score:-0.643946 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #11 score:-0.503908 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #12 score:-0.653731 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #13 score:-0.677357 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #14 score:-0.676131 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #15 score:-0.586386 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #16 score:-0.593186 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #17 score:-0.617288 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #18 score:-0.637020 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #19 score:-0.606755 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #20 score:-0.566428 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #21 score:-0.642750 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #22 score:-0.602530 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #23 score:-0.631400 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #24 score:-0.618578 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #25 score:-0.693484 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #26 score:-0.593831 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #27 score:-0.662786 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #28 score:-0.584920 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #29 score:-0.588046 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #30 score:-0.639925 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #31 score:-0.559566 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #32 score:-0.613429 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #33 score:-0.643561 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #34 score:-0.640006 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #35 score:-0.631039 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #36 score:-0.661270 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #37 score:-0.640317 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #38 score:-0.666041 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #39 score:-0.598319 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #40 score:-0.646619 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #41 score:-0.649778 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #42 score:-0.662044 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #43 score:-0.612097 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #44 score:-0.666539 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #45 score:-0.766761 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #46 score:-0.620427 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #47 score:-0.715716 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #48 score:-0.664302 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #49 score:-0.664295 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #50 score:-0.608074 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #51 score:-0.651693 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #52 score:-0.805334 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #53 score:-0.640271 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #54 score:-0.676364 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #55 score:-0.589980 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #56 score:-0.552127 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #57 score:-0.603467 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #58 score:-0.717200 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #59 score:-0.606969 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #60 score:-0.651592 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #61 score:-0.638965 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #62 score:-0.598334 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #63 score:-0.629838 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #64 score:-0.646786 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #65 score:-0.641507 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #66 score:-0.602530 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #67 score:-0.559765 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #68 score:-0.679317 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #69 score:-0.554702 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #70 score:-0.643361 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #71 score:-0.686589 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #72 score:-0.627231 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #73 score:-0.596326 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #74 score:-0.561884 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #75 score:-0.656476 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #76 score:-0.662947 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #77 score:-0.579348 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #78 score:-0.641401 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #79 score:-0.599048 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #80 score:-0.636102 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #81 score:-0.640009 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #82 score:-0.588897 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #83 score:-0.711419 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #84 score:-0.666699 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #85 score:-0.655131 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #86 score:-0.640531 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #87 score:-0.638013 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #88 score:-0.681733 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #89 score:-0.587596 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #90 score:-0.579884 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #91 score:-0.647353 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #92 score:-0.656947 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #93 score:-0.610321 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #94 score:-0.593423 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #95 score:-0.605527 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #96 score:-0.624682 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #97 score:-0.598807 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #98 score:-0.671101 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #99 score:-0.603022 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #100 score:-0.637813 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #101 score:-0.677585 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #102 score:-0.595298 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #103 score:-0.656367 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #104 score:-0.575557 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #105 score:-0.684891 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #106 score:-0.640009 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #107 score:-0.661047 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #108 score:-0.571258 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #109 score:-0.631749 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #110 score:-0.645773 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #111 score:-0.549677 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #112 score:-0.582806 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #113 score:-0.669472 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #114 score:-0.639900 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #115 score:-0.564717 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #116 score:-0.629376 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #117 score:-0.658020 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #118 score:-0.627014 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #119 score:-0.613530 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #120 score:-0.822489 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #121 score:-0.581505 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #122 score:-0.620094 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #123 score:-0.652279 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #124 score:-0.655113 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #125 score:-0.553490 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #126 score:-0.642726 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #127 score:-0.626014 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #128 score:-0.671986 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #129 score:-0.639237 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #130 score:-0.646227 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #131 score:-0.484448 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #132 score:-0.626700 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #133 score:-0.627543 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #134 score:-0.642666 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #135 score:-0.680645 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #136 score:-0.633698 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #137 score:-0.614333 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #138 score:-0.597476 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #139 score:-0.594182 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #140 score:-0.619649 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #141 score:-0.631588 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #142 score:-0.634664 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #143 score:-0.655209 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #144 score:-0.653877 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #145 score:-0.627401 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #146 score:-0.598999 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #147 score:-0.622344 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #148 score:-0.630440 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #149 score:-0.663697 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #150 score:-0.690625 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #151 score:-0.633112 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #152 score:-0.622736 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #153 score:-0.644741 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #154 score:-0.684591 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #155 score:-0.628030 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #156 score:-0.665994 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #157 score:-0.669680 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #158 score:-0.591658 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #159 score:-0.645021 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #160 score:-0.615304 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #161 score:-0.665059 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #162 score:-0.674371 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #163 score:-0.682262 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #164 score:-0.700419 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #165 score:-0.607977 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #166 score:-0.621692 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #167 score:-0.662283 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #168 score:-0.648901 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #169 score:-0.677989 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #170 score:-0.595065 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #171 score:-0.649326 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #172 score:-0.622477 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #173 score:-0.663058 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #174 score:-0.643666 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #175 score:-0.676862 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #176 score:-0.644350 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #177 score:-0.623624 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #178 score:-0.675383 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #179 score:-0.584911 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #180 score:-0.651041 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #181 score:-0.624666 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #182 score:-0.543816 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #183 score:-0.646839 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #184 score:-0.560026 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #185 score:-0.586447 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #186 score:-0.653785 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #187 score:-0.629333 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #188 score:-0.576655 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #189 score:-0.649184 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #190 score:-0.639879 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #191 score:-0.634097 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #192 score:-0.638393 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #193 score:-0.634816 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #194 score:-0.619892 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #195 score:-0.576481 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #196 score:-0.556867 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #197 score:-0.624300 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #198 score:-0.605375 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #199 score:-0.570653 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #200 score:-0.621858 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #201 score:-0.631691 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #202 score:-0.637541 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #203 score:-0.634937 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #204 score:-0.601864 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #205 score:-0.683953 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #206 score:-0.642792 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #207 score:-0.638097 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #208 score:-0.590543 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #209 score:-0.646519 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #210 score:-0.676301 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #211 score:-0.634097 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #212 score:-0.604342 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #213 score:-0.609086 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #214 score:-0.640701 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #215 score:-0.661219 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #216 score:-0.690635 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #217 score:-0.643361 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #218 score:-0.593643 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #219 score:-0.653081 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #220 score:-0.638097 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #221 score:-0.619375 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #222 score:-0.548150 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #223 score:-0.635861 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #224 score:-0.581865 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #225 score:-0.705775 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #226 score:-0.561038 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #227 score:-0.640669 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #228 score:-0.645628 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #229 score:-0.620100 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #230 score:-0.664239 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #231 score:-0.567090 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #232 score:-0.647355 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #233 score:-0.704299 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #234 score:-0.668482 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #235 score:-0.636488 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #236 score:-0.599953 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #237 score:-0.639398 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #238 score:-0.632438 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #239 score:-0.553541 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #240 score:-0.649065 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #241 score:-0.575577 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #242 score:-0.547343 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #243 score:-0.548625 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #244 score:-0.630608 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #245 score:-0.602836 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #246 score:-0.650486 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #247 score:-0.716784 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #248 score:-0.587780 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #249 score:-0.576442 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #250 score:-0.716255 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #251 score:-0.657890 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #252 score:-0.643030 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #253 score:-0.577275 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #254 score:-0.730107 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #255 score:-0.525454 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #256 score:-0.574905 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #257 score:-0.611073 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #258 score:-0.566698 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #259 score:-0.655736 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #260 score:-0.646468 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #261 score:-0.635395 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #262 score:-0.655862 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #263 score:-0.617232 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #264 score:-0.648661 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #265 score:-0.601573 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #266 score:-0.638922 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #267 score:-0.686185 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #268 score:-0.571873 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #269 score:-0.600764 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #270 score:-0.660915 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #271 score:-0.589818 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #272 score:-0.749716 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #273 score:-0.651127 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #274 score:-0.622065 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #275 score:-0.654726 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #276 score:-0.847052 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #277 score:-0.649589 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #278 score:-0.624791 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #279 score:-0.619533 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #280 score:-0.640886 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #281 score:-0.643775 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #282 score:-0.685192 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #283 score:-0.681752 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #284 score:-0.629114 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #285 score:-0.648945 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #286 score:-0.646662 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #287 score:-0.632866 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #288 score:-0.633866 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #289 score:-0.636323 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #290 score:-0.642619 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #291 score:-0.647414 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #292 score:-0.610210 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #293 score:-0.660354 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #294 score:-0.699986 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #295 score:-0.551815 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #296 score:-0.636490 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #297 score:-0.626416 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #298 score:-0.571546 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #299 score:-0.655346 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #300 score:-0.739866 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #301 score:-0.601420 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #302 score:-0.614684 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #303 score:-0.602668 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #304 score:-0.613454 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #305 score:-0.645295 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #306 score:-0.674591 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #307 score:-0.644853 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #308 score:-0.588574 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #309 score:-0.637641 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #310 score:-0.648206 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #311 score:-0.682810 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #312 score:-0.624847 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #313 score:-0.676403 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #314 score:-0.597307 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #315 score:-0.632512 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #316 score:-0.621407 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #317 score:-0.619798 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #318 score:-0.635511 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #319 score:-0.658055 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #320 score:-0.670339 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #321 score:-0.641970 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #322 score:-0.581195 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #323 score:-0.643179 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #324 score:-0.643617 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #325 score:-0.721029 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #326 score:-0.665115 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #327 score:-0.660770 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #328 score:-0.585931 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #329 score:-0.681982 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #330 score:-0.669408 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #331 score:-0.600919 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #332 score:-0.678578 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #333 score:-0.606689 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #334 score:-0.661819 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #335 score:-0.597063 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #336 score:-0.603301 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #337 score:-0.607654 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #338 score:-0.660747 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #339 score:-0.673941 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #340 score:-0.591906 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #341 score:-0.639281 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #342 score:-0.660360 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #343 score:-0.597921 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #344 score:-0.508148 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #345 score:-0.603391 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #346 score:-0.623886 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #347 score:-0.632352 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #348 score:-0.638393 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #349 score:-0.561060 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #350 score:-0.644097 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #351 score:-0.660188 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #352 score:-0.642909 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #353 score:-0.691353 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #354 score:-0.619076 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #355 score:-0.666967 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #356 score:-0.601603 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #357 score:-0.639534 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #358 score:-0.640095 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #359 score:-0.589210 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #360 score:-0.666243 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #361 score:-0.593871 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #362 score:-0.588897 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #363 score:-0.599618 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #364 score:-0.610989 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #365 score:-0.660734 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #366 score:-0.571491 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #367 score:-0.611401 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #368 score:-0.656066 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #369 score:-0.645746 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #370 score:-0.582241 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #371 score:-0.657438 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #372 score:-0.603737 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #373 score:-0.601927 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #374 score:-0.616415 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #375 score:-0.661219 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #376 score:-0.574196 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #377 score:-0.615418 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #378 score:-0.567367 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #379 score:-0.659832 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #380 score:-0.622333 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #381 score:-0.626599 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #382 score:-0.639241 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #383 score:-0.662834 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #384 score:-0.641816 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #385 score:-0.630030 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #386 score:-0.615004 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #387 score:-0.649211 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #388 score:-0.646081 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #389 score:-0.600869 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #390 score:-0.651144 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #391 score:-0.632075 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #392 score:-0.617728 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #393 score:-0.614473 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #394 score:-0.652409 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #395 score:-0.665398 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #396 score:-0.710151 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #397 score:-0.618336 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #398 score:-0.678976 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #399 score:-0.623125 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #400 score:-0.660087 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #401 score:-0.637671 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #402 score:-0.523470 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #403 score:-0.634506 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #404 score:-0.569205 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #405 score:-0.592396 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #406 score:-0.609601 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #407 score:-0.629034 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #408 score:-0.582871 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #409 score:-0.561494 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #410 score:-0.614571 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #411 score:-0.637383 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #412 score:-0.621387 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #413 score:-0.610151 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #414 score:-0.640554 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #415 score:-0.596103 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #416 score:-0.585172 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #417 score:-0.631661 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #418 score:-0.661939 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #419 score:-0.817640 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #420 score:-0.631426 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #421 score:-0.692347 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #422 score:-0.621795 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #423 score:-0.615357 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #424 score:-0.764579 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #425 score:-0.618467 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #426 score:-0.673177 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #427 score:-0.664885 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #428 score:-0.597427 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #429 score:-0.634404 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #430 score:-0.708706 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #431 score:-0.636596 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #432 score:-0.569890 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #433 score:-0.599368 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #434 score:-0.598749 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #435 score:-0.606046 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #436 score:-0.641375 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #437 score:-0.577672 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #438 score:-0.653734 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #439 score:-0.575536 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #440 score:-0.638409 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #441 score:-0.640886 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #442 score:-0.567182 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #443 score:-0.643922 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #444 score:-0.629708 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #445 score:-0.617541 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #446 score:-0.653450 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #447 score:-0.580403 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #448 score:-0.638751 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #449 score:-0.683639 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #450 score:-0.639249 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #451 score:-0.678140 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #452 score:-0.657731 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #453 score:-0.643030 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #454 score:-0.667432 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #455 score:-0.600541 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #456 score:-0.673468 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #457 score:-0.608508 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #458 score:-0.648956 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #459 score:-0.616620 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #460 score:-0.642907 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #461 score:-0.637673 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #462 score:-0.658727 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #463 score:-0.587321 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #464 score:-0.682391 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #465 score:-0.621788 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #466 score:-0.608194 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #467 score:-0.611209 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #468 score:-0.655213 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #469 score:-0.636416 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #470 score:-0.655561 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #471 score:-0.619365 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #472 score:-0.597554 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #473 score:-0.648704 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #474 score:-0.634986 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #475 score:-0.649550 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #476 score:-0.572552 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #477 score:-0.702981 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #478 score:-0.517357 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #479 score:-0.614790 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #480 score:-0.566319 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #481 score:-0.659726 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #482 score:-0.600724 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #483 score:-0.604731 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #484 score:-0.656628 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #485 score:-0.601433 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #486 score:-0.618026 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #487 score:-0.690008 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #488 score:-0.535468 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #489 score:-0.575657 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #490 score:-0.547564 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #491 score:-0.625140 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #492 score:-0.665489 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #493 score:-0.591289 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #494 score:-0.621864 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #495 score:-0.714661 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #496 score:-0.680486 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #497 score:-0.640995 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #498 score:-0.604440 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #499 score:-0.624447 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #500 score:-0.676862 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #501 score:-0.591978 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #502 score:-0.605113 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #503 score:-0.638401 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #504 score:-0.663456 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #505 score:-0.662825 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #506 score:-0.579477 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #507 score:-0.623886 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #508 score:-0.591658 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #509 score:-0.650253 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #510 score:-0.669607 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #511 score:-0.672941 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #512 score:-0.639627 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #513 score:-0.730090 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #514 score:-0.629708 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #515 score:-0.624099 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #516 score:-0.547283 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #517 score:-0.589741 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #518 score:-0.643197 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #519 score:-0.625585 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #520 score:-0.641545 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #521 score:-0.640699 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #522 score:-0.547948 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #523 score:-0.615724 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #524 score:-0.624178 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #525 score:-0.727425 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #526 score:-0.656405 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #527 score:-0.603579 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #528 score:-0.658692 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #529 score:-0.663261 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #530 score:-0.551459 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #531 score:-0.596463 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #532 score:-0.650258 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #533 score:-0.644689 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #534 score:-0.643836 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #535 score:-0.563896 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #536 score:-0.631821 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #537 score:-0.635631 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #538 score:-0.661081 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #539 score:-0.546416 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #540 score:-0.612443 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #541 score:-0.661479 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #542 score:-0.679750 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #543 score:-0.633696 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #544 score:-0.650205 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #545 score:-0.627399 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #546 score:-0.666310 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #547 score:-0.635165 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #548 score:-0.671350 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #549 score:-0.613555 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #550 score:-0.655105 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #551 score:-0.658331 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #552 score:-0.634724 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #553 score:-0.617883 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #554 score:-0.703046 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #555 score:-0.588103 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #556 score:-0.634766 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #557 score:-0.612952 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #558 score:-0.695149 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #559 score:-0.602696 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #560 score:-0.665872 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #561 score:-0.640793 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #562 score:-0.639922 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #563 score:-0.623847 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #564 score:-0.649907 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #565 score:-0.690968 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #566 score:-0.662439 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #567 score:-0.642792 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #568 score:-0.643138 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #569 score:-0.661270 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #570 score:-0.662366 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #571 score:-0.634094 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #572 score:-0.607645 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #573 score:-0.620179 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #574 score:-0.668840 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #575 score:-0.656220 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #576 score:-0.664522 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #577 score:-0.589856 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #578 score:-0.593831 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #579 score:-0.616387 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #580 score:-0.611109 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #581 score:-0.636420 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #582 score:-0.579875 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #583 score:-0.565065 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #584 score:-0.570157 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #585 score:-0.628178 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #586 score:-0.653854 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #587 score:-0.595105 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #588 score:-0.627781 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #589 score:-0.588892 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #590 score:-0.664239 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #591 score:-0.675400 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #592 score:-0.628187 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #593 score:-0.634435 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #594 score:-0.691012 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #595 score:-0.650358 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #596 score:-0.693503 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #597 score:-0.657524 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #598 score:-0.602075 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #599 score:-0.551543 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #600 score:-0.657561 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #601 score:-0.671777 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #602 score:-0.668702 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #603 score:-0.647332 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #604 score:-0.659361 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #605 score:-0.585768 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #606 score:-0.698570 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #607 score:-0.636737 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #608 score:-0.662741 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #609 score:-0.668881 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #610 score:-0.589455 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #611 score:-0.647472 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #612 score:-0.635053 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #613 score:-0.688051 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #614 score:-0.559779 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #615 score:-0.651994 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #616 score:-0.636622 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #617 score:-0.576061 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #618 score:-0.618477 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #619 score:-0.609881 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #620 score:-0.589388 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #621 score:-0.691002 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #622 score:-0.627280 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #623 score:-0.590418 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #624 score:-0.607595 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #625 score:-0.639876 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #626 score:-0.586990 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #627 score:-0.724531 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #628 score:-0.668436 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #629 score:-0.669067 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #630 score:-0.664653 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #631 score:-0.660747 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #632 score:-0.650722 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #633 score:-0.568745 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #634 score:-0.625430 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #635 score:-0.583309 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #636 score:-0.630449 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #637 score:-0.614498 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #638 score:-0.623497 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #639 score:-0.625106 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #640 score:-0.656461 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #641 score:-0.559341 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #642 score:-0.655659 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #643 score:-0.658285 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #644 score:-0.553680 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #645 score:-0.680024 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #646 score:-0.690968 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #647 score:-0.609881 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #648 score:-0.731155 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #649 score:-0.601053 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #650 score:-0.631164 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #651 score:-0.609421 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #652 score:-0.581865 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #653 score:-0.632934 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #654 score:-0.570676 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #655 score:-0.639253 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #656 score:-0.629674 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #657 score:-0.684463 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #658 score:-0.654251 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #659 score:-0.623714 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #660 score:-0.637217 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #661 score:-0.651592 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #662 score:-0.648162 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #663 score:-0.630623 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #664 score:-0.641919 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #665 score:-0.625713 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #666 score:-0.624330 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #667 score:-0.665070 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #668 score:-0.675074 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #669 score:-0.645853 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #670 score:-0.623746 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #671 score:-0.606261 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #672 score:-0.615179 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #673 score:-0.605468 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #674 score:-0.666531 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #675 score:-0.638950 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #676 score:-0.655120 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #677 score:-0.647038 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #678 score:-0.650948 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #679 score:-0.648889 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #680 score:-0.607590 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #681 score:-0.587246 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #682 score:-0.587565 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #683 score:-0.581697 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #684 score:-0.663598 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #685 score:-0.592926 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #686 score:-0.600592 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #687 score:-0.622084 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #688 score:-0.484448 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #689 score:-0.650069 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #690 score:-0.628294 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #691 score:-0.586584 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #692 score:-0.635929 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #693 score:-0.604459 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #694 score:-0.639342 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #695 score:-0.648496 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #696 score:-0.754995 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #697 score:-0.603171 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #698 score:-0.687956 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #699 score:-0.619008 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #700 score:-0.638575 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #701 score:-0.654559 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #702 score:-0.771647 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #703 score:-0.615858 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #704 score:-0.651664 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #705 score:-0.652192 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #706 score:-0.519662 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #707 score:-0.609388 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #708 score:-0.633525 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #709 score:-0.793429 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #710 score:-0.575933 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #711 score:-0.729906 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #712 score:-0.653208 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #713 score:-0.646601 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #714 score:-0.651407 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #715 score:-0.624585 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #716 score:-0.660907 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #717 score:-0.682098 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #718 score:-0.646656 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #719 score:-0.642331 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #720 score:-0.619145 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #721 score:-0.606001 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #722 score:-0.690626 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #723 score:-0.625828 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #724 score:-0.605913 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #725 score:-0.621973 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #726 score:-0.613162 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #727 score:-0.563055 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #728 score:-0.643030 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #729 score:-0.507723 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #730 score:-0.659862 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #731 score:-0.637590 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #732 score:-0.608549 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #733 score:-0.661164 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #734 score:-0.627252 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #735 score:-0.660427 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #736 score:-0.641974 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #737 score:-0.574737 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #738 score:-0.630790 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #739 score:-0.634525 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #740 score:-0.663994 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #741 score:-0.560613 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #742 score:-0.607983 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #743 score:-0.655537 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #744 score:-0.641305 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #745 score:-0.634285 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #746 score:-0.609876 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #747 score:-0.578330 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #748 score:-0.634077 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #749 score:-0.564254 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #750 score:-0.617401 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #751 score:-0.622671 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #752 score:-0.642788 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #753 score:-0.680656 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #754 score:-0.481402 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #755 score:-0.604728 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #756 score:-0.621926 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #757 score:-0.737159 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #758 score:-0.713302 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #759 score:-0.707871 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #760 score:-0.600541 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #761 score:-0.709763 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #762 score:-0.718559 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #763 score:-0.556556 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #764 score:-0.621274 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #765 score:-0.593470 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #766 score:-0.644082 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #767 score:-0.629357 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #768 score:-0.660196 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #769 score:-0.675322 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #770 score:-0.636812 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #771 score:-0.633670 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #772 score:-0.628455 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #773 score:-0.593571 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #774 score:-0.611397 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #775 score:-0.665330 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #776 score:-0.639266 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #777 score:-0.662370 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #778 score:-0.648728 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #779 score:-0.599979 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #780 score:-0.578492 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #781 score:-0.696114 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #782 score:-0.630018 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #783 score:-0.651840 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #784 score:-0.561321 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #785 score:-0.624857 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #786 score:-0.628146 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #787 score:-0.617147 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #788 score:-0.717160 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #789 score:-0.617970 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #790 score:-0.633670 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #791 score:-0.618998 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #792 score:-0.636812 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #793 score:-0.650378 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #794 score:-0.640209 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #795 score:-0.634980 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #796 score:-0.634641 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #797 score:-0.647896 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #798 score:-0.752259 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #799 score:-0.651699 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #800 score:-0.631100 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #801 score:-0.603324 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #802 score:-0.643403 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #803 score:-0.646431 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #804 score:-0.650588 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #805 score:-0.542954 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #806 score:-0.648895 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #807 score:-0.715122 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #808 score:-0.627934 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #809 score:-0.543437 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #810 score:-0.649260 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #811 score:-0.622366 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #812 score:-0.614506 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #813 score:-0.564959 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #814 score:-0.632556 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #815 score:-0.675593 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #816 score:-0.646431 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #817 score:-0.658887 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #818 score:-0.646917 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #819 score:-0.650800 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #820 score:-0.554313 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #821 score:-0.624079 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #822 score:-0.779099 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #823 score:-0.683377 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #824 score:-0.576180 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #825 score:-0.585286 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #826 score:-0.665495 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #827 score:-0.706890 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #828 score:-0.589427 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #829 score:-0.674140 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #830 score:-0.594471 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #831 score:-0.644627 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #832 score:-0.654425 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #833 score:-0.624516 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #834 score:-0.699899 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #835 score:-0.597897 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #836 score:-0.657811 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #837 score:-0.633303 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #838 score:-0.621417 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #839 score:-0.630343 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #840 score:-0.604880 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #841 score:-0.733535 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #842 score:-0.612045 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #843 score:-0.599615 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #844 score:-0.565572 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #845 score:-0.632934 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #846 score:-0.577642 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #847 score:-0.603841 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #848 score:-0.643047 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #849 score:-0.617235 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #850 score:-0.672246 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #851 score:-0.621085 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #852 score:-0.626741 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #853 score:-0.609986 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #854 score:-0.651549 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #855 score:-0.612569 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #856 score:-0.615793 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #857 score:-0.626154 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #858 score:-0.646433 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #859 score:-0.682565 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #860 score:-0.612897 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #861 score:-0.645648 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #862 score:-0.625026 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #863 score:-0.660381 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #864 score:-0.558592 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #865 score:-0.616040 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #866 score:-0.668718 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #867 score:-0.633792 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #868 score:-0.670276 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #869 score:-0.542653 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #870 score:-0.637074 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #871 score:-0.648425 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #872 score:-0.560651 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #873 score:-0.604277 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #874 score:-0.619332 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #875 score:-0.624744 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #876 score:-0.650509 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #877 score:-0.582781 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #878 score:-0.620580 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #879 score:-0.646437 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #880 score:-0.633112 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #881 score:-0.632272 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #882 score:-0.589102 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #883 score:-0.641430 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #884 score:-0.659935 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #885 score:-0.624847 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #886 score:-0.674441 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #887 score:-0.648800 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #888 score:-0.650588 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #889 score:-0.608344 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #890 score:-0.651580 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #891 score:-0.633549 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #892 score:-0.666309 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #893 score:-0.569784 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #894 score:-0.632866 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #895 score:-0.654252 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #896 score:-0.633345 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #897 score:-0.569665 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #898 score:-0.695451 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #899 score:-0.638143 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #900 score:-0.620617 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #901 score:-0.659240 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #902 score:-0.615278 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #903 score:-0.627705 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #904 score:-0.671806 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #905 score:-0.639346 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #906 score:-0.598363 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #907 score:-0.686776 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #908 score:-0.628075 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #909 score:-0.622671 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #910 score:-0.724639 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #911 score:-0.650286 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #912 score:-0.586661 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #913 score:-0.605011 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #914 score:-0.595870 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #915 score:-0.638601 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #916 score:-0.600711 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #917 score:-0.655788 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #918 score:-0.609618 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #919 score:-0.638916 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #920 score:-0.602409 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #921 score:-0.709057 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #922 score:-0.634318 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #923 score:-0.634986 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #924 score:-0.639155 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #925 score:-0.620669 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #926 score:-0.646207 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #927 score:-0.688085 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #928 score:-0.665951 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #929 score:-0.622182 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #930 score:-0.661942 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #931 score:-0.632795 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #932 score:-0.538434 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #933 score:-0.624919 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #934 score:-0.565415 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #935 score:-0.668482 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #936 score:-0.574429 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #937 score:-0.625739 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #938 score:-0.643582 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #939 score:-0.578004 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #940 score:-0.592761 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #941 score:-0.662782 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #942 score:-0.651768 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #943 score:-0.631825 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #944 score:-0.671325 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #945 score:-0.675709 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #946 score:-0.639241 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #947 score:-0.655652 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #948 score:-0.581735 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #949 score:-0.615674 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #950 score:-0.673735 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #951 score:-0.632698 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #952 score:-0.599325 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #953 score:-0.674776 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #954 score:-0.629865 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #955 score:-0.633365 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #956 score:-0.678636 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #957 score:-0.645969 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #958 score:-0.622473 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #959 score:-0.515327 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #960 score:-0.656845 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #961 score:-0.611060 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #962 score:-0.592400 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #963 score:-0.625523 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #964 score:-0.667361 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #965 score:-0.647782 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #966 score:-0.632376 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #967 score:-0.601005 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #968 score:-0.649887 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #969 score:-0.648190 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #970 score:-0.665807 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #971 score:-0.609553 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #972 score:-0.642933 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #973 score:-0.630544 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #974 score:-0.684891 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #975 score:-0.581592 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #976 score:-0.733343 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #977 score:-0.601035 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #978 score:-0.680696 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #979 score:-0.707047 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #980 score:-0.635759 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #981 score:-0.601542 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #982 score:-0.690722 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #983 score:-0.671112 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #984 score:-0.690196 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #985 score:-0.615573 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #986 score:-0.714483 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #987 score:-0.556892 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #988 score:-0.639476 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #989 score:-0.650073 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #990 score:-0.681858 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #991 score:-0.610086 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #992 score:-0.621417 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #993 score:-0.636313 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #994 score:-0.675323 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #995 score:-0.684289 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #996 score:-0.635281 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #997 score:-0.669302 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #998 score:-0.637258 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #999 score:-0.649522 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1000 score:-0.617197 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1001 score:-0.658049 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1002 score:-0.664568 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1003 score:-0.522856 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1004 score:-0.679006 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1005 score:-0.648079 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1006 score:-0.631424 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1007 score:-0.691297 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1008 score:-0.635562 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1009 score:-0.663696 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1010 score:-0.679546 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1011 score:-0.619382 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1012 score:-0.660165 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1013 score:-0.694163 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1014 score:-0.732395 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1015 score:-0.651572 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1016 score:-0.640926 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1017 score:-0.655405 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1018 score:-0.656602 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1019 score:-0.608399 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1020 score:-0.680279 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1021 score:-0.629210 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1022 score:-0.631446 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1023 score:-0.629275 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1024 score:-0.574241 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1025 score:-0.688345 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1026 score:-0.596278 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1027 score:-0.617850 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1028 score:-0.634650 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1029 score:-0.646249 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1030 score:-0.648426 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1031 score:-0.605278 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1032 score:-0.696710 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1033 score:-0.651958 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1034 score:-0.603750 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1035 score:-0.660203 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1036 score:-0.631210 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1037 score:-0.579912 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1038 score:-0.655094 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1039 score:-0.599897 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1040 score:-0.566341 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1041 score:-0.609728 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1042 score:-0.671655 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1043 score:-0.683510 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1044 score:-0.559248 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1045 score:-0.651177 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1046 score:-0.611864 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1047 score:-0.595714 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1048 score:-0.600869 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1049 score:-0.647179 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1050 score:-0.635304 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1051 score:-0.638244 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1052 score:-0.659034 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1053 score:-0.666694 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1054 score:-0.652707 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1055 score:-0.649608 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1056 score:-0.534674 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1057 score:-0.588889 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1058 score:-0.665817 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1059 score:-0.681593 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1060 score:-0.611919 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1061 score:-0.614729 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1062 score:-0.700034 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1063 score:-0.641797 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1064 score:-0.635315 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1065 score:-0.646568 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1066 score:-0.620043 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1067 score:-0.636212 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1068 score:-0.610658 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1069 score:-0.596326 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1070 score:-0.666790 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1071 score:-0.657965 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1072 score:-0.656367 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1073 score:-0.624528 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1074 score:-0.631913 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1075 score:-0.656996 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1076 score:-0.640239 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1077 score:-0.616124 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1078 score:-0.608347 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1079 score:-0.648678 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1080 score:-0.641283 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1081 score:-0.621317 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #1082 score:-0.617094 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1083 score:-0.579914 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1084 score:-0.633088 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1085 score:-0.609867 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1086 score:-0.657624 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1087 score:-0.605766 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1088 score:-0.598086 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1089 score:-0.637899 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1090 score:-0.574272 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1091 score:-0.676926 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1092 score:-0.723972 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1093 score:-0.665822 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1094 score:-0.558984 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1095 score:-0.629045 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1096 score:-0.669062 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1097 score:-0.639493 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1098 score:-0.623052 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1099 score:-0.632966 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 0.481402\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 82\n",
      "Total number of nodes: 2330\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 82 Average: 28.4146 StdDev: 4.43366\n",
      "Min: 17 Max: 31 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 17, 18)  2   2.44%   2.44%\n",
      "[ 18, 19)  0   0.00%   2.44%\n",
      "[ 19, 20)  6   7.32%   9.76% #\n",
      "[ 20, 21)  0   0.00%   9.76%\n",
      "[ 21, 22)  4   4.88%  14.63% #\n",
      "[ 22, 23)  0   0.00%  14.63%\n",
      "[ 23, 24)  6   7.32%  21.95% #\n",
      "[ 24, 25)  0   0.00%  21.95%\n",
      "[ 25, 26)  3   3.66%  25.61% #\n",
      "[ 26, 27)  0   0.00%  25.61%\n",
      "[ 27, 28)  0   0.00%  25.61%\n",
      "[ 28, 29)  0   0.00%  25.61%\n",
      "[ 29, 30)  3   3.66%  29.27% #\n",
      "[ 30, 31)  0   0.00%  29.27%\n",
      "[ 31, 31] 58  70.73% 100.00% ##########\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 1206 Average: 4.60116 StdDev: 1.36746\n",
      "Min: 1 Max: 6 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)  21   1.74%   1.74%\n",
      "[ 2, 3)  75   6.22%   7.96% ##\n",
      "[ 3, 4) 180  14.93%  22.89% ####\n",
      "[ 4, 5) 264  21.89%  44.78% ######\n",
      "[ 5, 6) 214  17.74%  62.52% #####\n",
      "[ 6, 6] 452  37.48% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 1206 Average: 0 StdDev: 0\n",
      "Min: 0 Max: 0 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 0, 0] 1206 100.00% 100.00% ##########\n",
      "\n",
      "Attribute in nodes:\n",
      "\t576 : Age [NUMERICAL]\n",
      "\t150 : Fare [NUMERICAL]\n",
      "\t143 : Embarked_C [NUMERICAL]\n",
      "\t91 : Embarked_Q [NUMERICAL]\n",
      "\t83 : Embarked_S [NUMERICAL]\n",
      "\t35 : Pclass [NUMERICAL]\n",
      "\t26 : People [NUMERICAL]\n",
      "\t11 : Sex_female [NUMERICAL]\n",
      "\t9 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t40 : Age [NUMERICAL]\n",
      "\t9 : Fare [NUMERICAL]\n",
      "\t7 : Pclass [NUMERICAL]\n",
      "\t7 : Embarked_C [NUMERICAL]\n",
      "\t6 : Sex_female [NUMERICAL]\n",
      "\t5 : Embarked_Q [NUMERICAL]\n",
      "\t4 : Sex_male [NUMERICAL]\n",
      "\t4 : Embarked_S [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t120 : Age [NUMERICAL]\n",
      "\t29 : Fare [NUMERICAL]\n",
      "\t25 : Embarked_C [NUMERICAL]\n",
      "\t15 : Pclass [NUMERICAL]\n",
      "\t13 : Embarked_S [NUMERICAL]\n",
      "\t12 : Embarked_Q [NUMERICAL]\n",
      "\t6 : Sex_female [NUMERICAL]\n",
      "\t4 : Sex_male [NUMERICAL]\n",
      "\t1 : People [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t229 : Age [NUMERICAL]\n",
      "\t55 : Fare [NUMERICAL]\n",
      "\t52 : Embarked_C [NUMERICAL]\n",
      "\t34 : Embarked_Q [NUMERICAL]\n",
      "\t26 : Embarked_S [NUMERICAL]\n",
      "\t18 : Pclass [NUMERICAL]\n",
      "\t9 : People [NUMERICAL]\n",
      "\t7 : Sex_female [NUMERICAL]\n",
      "\t6 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t345 : Age [NUMERICAL]\n",
      "\t92 : Embarked_C [NUMERICAL]\n",
      "\t87 : Fare [NUMERICAL]\n",
      "\t54 : Embarked_Q [NUMERICAL]\n",
      "\t48 : Embarked_S [NUMERICAL]\n",
      "\t22 : Pclass [NUMERICAL]\n",
      "\t15 : People [NUMERICAL]\n",
      "\t9 : Sex_female [NUMERICAL]\n",
      "\t6 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t576 : Age [NUMERICAL]\n",
      "\t150 : Fare [NUMERICAL]\n",
      "\t143 : Embarked_C [NUMERICAL]\n",
      "\t91 : Embarked_Q [NUMERICAL]\n",
      "\t83 : Embarked_S [NUMERICAL]\n",
      "\t35 : Pclass [NUMERICAL]\n",
      "\t26 : People [NUMERICAL]\n",
      "\t11 : Sex_female [NUMERICAL]\n",
      "\t9 : Sex_male [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t1124 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t82 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t225 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t436 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t678 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t1124 : ObliqueCondition\n",
      "\n",
      "Training logs:\n",
      "Number of iteration to final model: 82\n",
      "\tIter:1 train-loss:1.163775 valid-loss:1.131190  train-accuracy:0.757946 valid-accuracy:0.767123\n",
      "\tIter:2 train-loss:1.043927 valid-loss:1.002614  train-accuracy:0.804401 valid-accuracy:0.808219\n",
      "\tIter:3 train-loss:0.959685 valid-loss:0.905966  train-accuracy:0.834963 valid-accuracy:0.863014\n",
      "\tIter:4 train-loss:0.898672 valid-loss:0.836608  train-accuracy:0.843521 valid-accuracy:0.890411\n",
      "\tIter:5 train-loss:0.848150 valid-loss:0.790985  train-accuracy:0.849633 valid-accuracy:0.904110\n",
      "\tIter:6 train-loss:0.811976 valid-loss:0.761388  train-accuracy:0.849633 valid-accuracy:0.904110\n",
      "\tIter:16 train-loss:0.611618 valid-loss:0.595033  train-accuracy:0.888753 valid-accuracy:0.890411\n",
      "\tIter:26 train-loss:0.492851 valid-loss:0.518746  train-accuracy:0.910758 valid-accuracy:0.917808\n",
      "\tIter:36 train-loss:0.413215 valid-loss:0.504503  train-accuracy:0.938875 valid-accuracy:0.917808\n",
      "\tIter:46 train-loss:0.352192 valid-loss:0.514836  train-accuracy:0.949878 valid-accuracy:0.904110\n",
      "\tIter:56 train-loss:0.307182 valid-loss:0.505045  train-accuracy:0.962103 valid-accuracy:0.904110\n",
      "\tIter:66 train-loss:0.264389 valid-loss:0.491744  train-accuracy:0.968215 valid-accuracy:0.904110\n",
      "\tIter:76 train-loss:0.238156 valid-loss:0.492671  train-accuracy:0.974328 valid-accuracy:0.904110\n",
      "\tIter:86 train-loss:0.213843 valid-loss:0.497076  train-accuracy:0.975550 valid-accuracy:0.904110\n",
      "\tIter:96 train-loss:0.187752 valid-loss:0.511678  train-accuracy:0.979218 valid-accuracy:0.890411\n",
      "\tIter:106 train-loss:0.169169 valid-loss:0.526256  train-accuracy:0.979218 valid-accuracy:0.890411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
