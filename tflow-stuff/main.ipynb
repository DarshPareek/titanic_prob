{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('titanic/train.csv')\n",
    "test_data = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['People'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['People'] = test_data['SibSp'] + test_data['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Size'] = train_data['Name'] .apply(lambda x : len(x))\n",
    "test_data['Size'] = test_data['Name'] .apply(lambda x : len(x))\n",
    "train_data = train_data.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch','Ticket', 'Cabin'])\n",
    "test_data = test_data.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch','Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'People',\n",
       "       'Size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mode()[0])\n",
    "test_data['Age'] = train_data['Age'].fillna(train_data['Age'].mode()[0])\n",
    "train_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\n",
    "test_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n",
    "test_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data, dtype='int')\n",
    "test_data = pd.get_dummies(test_data, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['Survived'])\n",
    "y_train = train_data['Survived'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Age', 'Fare', 'People', 'Size', 'Sex_female', 'Sex_male',\n",
       "       'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(10,)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  for i in range(hp.Int('No. of Layers', min_value=1, max_value=7, step=1)):\n",
    "    model.add(keras.layers.Dense(units=hp.Int('n '+str(i), min_value = 32, max_value=512, step=32), activation='relu'))\n",
    "  dr = hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)\n",
    "  model.add(keras.layers.Dropout(dr))\n",
    "  model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.BinaryCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     directory='my_dir',\n",
    "                     factor = 70,\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.832402229309082\n",
      "\n",
      "Best val_accuracy So Far: 0.8491619825363159\n",
      "Total elapsed time: 00h 03m 37s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 1, dropout was 0.30000000000000004 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=35, validation_split=0.2, callbacks=[stop_early])\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('No. of Layers')}, dropout was {best_hps.get('dropout')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1.8222 - accuracy: 0.6236 - val_loss: 0.4528 - val_accuracy: 0.7933\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.7008 - val_loss: 0.4431 - val_accuracy: 0.7933\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.6031 - accuracy: 0.7570 - val_loss: 0.4569 - val_accuracy: 0.7989\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6287 - accuracy: 0.7542 - val_loss: 0.3854 - val_accuracy: 0.8156\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5655 - accuracy: 0.7177 - val_loss: 0.4111 - val_accuracy: 0.8156\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7626 - val_loss: 0.4189 - val_accuracy: 0.8212\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7430 - val_loss: 0.4480 - val_accuracy: 0.8045\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7697 - val_loss: 0.4237 - val_accuracy: 0.8156\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7739 - val_loss: 0.3854 - val_accuracy: 0.8212\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7935 - val_loss: 0.3888 - val_accuracy: 0.8045\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7921 - val_loss: 0.3915 - val_accuracy: 0.8101\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7711 - val_loss: 0.3788 - val_accuracy: 0.8324\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7879 - val_loss: 0.3757 - val_accuracy: 0.8212\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7893 - val_loss: 0.3818 - val_accuracy: 0.8212\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7935 - val_loss: 0.4109 - val_accuracy: 0.8324\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7781 - val_loss: 0.3964 - val_accuracy: 0.8212\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7809 - val_loss: 0.3807 - val_accuracy: 0.8101\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7907 - val_loss: 0.3946 - val_accuracy: 0.8268\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7879 - val_loss: 0.4048 - val_accuracy: 0.8380\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8076 - val_loss: 0.3733 - val_accuracy: 0.8156\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8104 - val_loss: 0.3647 - val_accuracy: 0.8380\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7865 - val_loss: 0.3875 - val_accuracy: 0.8324\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7781 - val_loss: 0.3793 - val_accuracy: 0.8212\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7893 - val_loss: 0.4095 - val_accuracy: 0.8324\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.8006 - val_loss: 0.3734 - val_accuracy: 0.8324\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7978 - val_loss: 0.3874 - val_accuracy: 0.8212\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7921 - val_loss: 0.3986 - val_accuracy: 0.8268\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7781 - val_loss: 0.3920 - val_accuracy: 0.8212\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7978 - val_loss: 0.3684 - val_accuracy: 0.8212\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7949 - val_loss: 0.3890 - val_accuracy: 0.8212\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.7739 - val_loss: 0.4125 - val_accuracy: 0.8212\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7879 - val_loss: 0.6484 - val_accuracy: 0.7542\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7725 - val_loss: 0.4466 - val_accuracy: 0.8268\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7921 - val_loss: 0.3960 - val_accuracy: 0.8156\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.8076 - val_loss: 0.3719 - val_accuracy: 0.8436\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7893 - val_loss: 0.3741 - val_accuracy: 0.8324\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.8020 - val_loss: 0.3709 - val_accuracy: 0.8268\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8174 - val_loss: 0.4372 - val_accuracy: 0.7989\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7907 - val_loss: 0.4383 - val_accuracy: 0.8212\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8160 - val_loss: 0.3987 - val_accuracy: 0.8156\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7837 - val_loss: 0.4077 - val_accuracy: 0.8156\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.8076 - val_loss: 0.3608 - val_accuracy: 0.8380\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.8076 - val_loss: 0.3661 - val_accuracy: 0.8101\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8230 - val_loss: 0.4248 - val_accuracy: 0.8324\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.8048 - val_loss: 0.4447 - val_accuracy: 0.8101\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.3725 - val_accuracy: 0.8324\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.8034 - val_loss: 0.4029 - val_accuracy: 0.8268\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7949 - val_loss: 0.3736 - val_accuracy: 0.8268\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7949 - val_loss: 0.3805 - val_accuracy: 0.8212\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7978 - val_loss: 0.3614 - val_accuracy: 0.8436\n",
      "Best epoch: 35\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.8402 - accuracy: 0.6180 - val_loss: 0.6013 - val_accuracy: 0.7654\n",
      "Epoch 2/35\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.9950 - accuracy: 0.6868 - val_loss: 0.5124 - val_accuracy: 0.7709\n",
      "Epoch 3/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.7430 - val_loss: 0.6360 - val_accuracy: 0.7598\n",
      "Epoch 4/35\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6725 - accuracy: 0.7402 - val_loss: 0.4328 - val_accuracy: 0.7765\n",
      "Epoch 5/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7739 - val_loss: 0.4002 - val_accuracy: 0.8268\n",
      "Epoch 6/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7697 - val_loss: 0.5775 - val_accuracy: 0.7765\n",
      "Epoch 7/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7823 - val_loss: 0.4089 - val_accuracy: 0.8268\n",
      "Epoch 8/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7584 - val_loss: 0.4642 - val_accuracy: 0.8212\n",
      "Epoch 9/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7781 - val_loss: 0.3961 - val_accuracy: 0.8268\n",
      "Epoch 10/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7683 - val_loss: 0.4104 - val_accuracy: 0.8045\n",
      "Epoch 11/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8006 - val_loss: 0.4146 - val_accuracy: 0.8101\n",
      "Epoch 12/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7851 - val_loss: 0.3680 - val_accuracy: 0.8101\n",
      "Epoch 13/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7921 - val_loss: 0.3870 - val_accuracy: 0.8212\n",
      "Epoch 14/35\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7711 - val_loss: 0.4188 - val_accuracy: 0.8212\n",
      "Epoch 15/35\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7949 - val_loss: 0.4177 - val_accuracy: 0.8101\n",
      "Epoch 16/35\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7711 - val_loss: 0.4013 - val_accuracy: 0.7989\n",
      "Epoch 17/35\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7893 - val_loss: 0.3903 - val_accuracy: 0.8156\n",
      "Epoch 18/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7725 - val_loss: 0.3944 - val_accuracy: 0.8212\n",
      "Epoch 19/35\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7963 - val_loss: 0.4082 - val_accuracy: 0.8212\n",
      "Epoch 20/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.8034 - val_loss: 0.4149 - val_accuracy: 0.8101\n",
      "Epoch 21/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8048 - val_loss: 0.3682 - val_accuracy: 0.8268\n",
      "Epoch 22/35\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7963 - val_loss: 0.3792 - val_accuracy: 0.8212\n",
      "Epoch 23/35\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.8020 - val_loss: 0.3838 - val_accuracy: 0.8268\n",
      "Epoch 24/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7935 - val_loss: 0.3973 - val_accuracy: 0.8212\n",
      "Epoch 25/35\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7963 - val_loss: 0.3791 - val_accuracy: 0.8212\n",
      "Epoch 26/35\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.8160 - val_loss: 0.3729 - val_accuracy: 0.8101\n",
      "Epoch 27/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7949 - val_loss: 0.3990 - val_accuracy: 0.8156\n",
      "Epoch 28/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7907 - val_loss: 0.3903 - val_accuracy: 0.8492\n",
      "Epoch 29/35\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7992 - val_loss: 0.3723 - val_accuracy: 0.8380\n",
      "Epoch 30/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7949 - val_loss: 0.3810 - val_accuracy: 0.8212\n",
      "Epoch 31/35\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8062 - val_loss: 0.3647 - val_accuracy: 0.8101\n",
      "Epoch 32/35\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.8020 - val_loss: 0.3706 - val_accuracy: 0.8268\n",
      "Epoch 33/35\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.8034 - val_loss: 0.3694 - val_accuracy: 0.8212\n",
      "Epoch 34/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8104 - val_loss: 0.3840 - val_accuracy: 0.8324\n",
      "Epoch 35/35\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8272 - val_loss: 0.3692 - val_accuracy: 0.8324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x704aa297a850>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.75000006], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = F1Score()\n",
    "y_true = y_train[:178].to_numpy().reshape(178,1)\n",
    "y_pred = np.round(hypermodel.predict(X_train[:178])).astype('int')\n",
    "m.update_state(y_true, y_pred)\n",
    "res = m.result()\n",
    "res.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 726us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = hypermodel.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = np.round(predictions,0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('titanic/test.csv')\n",
    "# print(t[\"PassengerId\"].shape, survived.shape)\n",
    "answer = pd.DataFrame({\"PassengerId\" : t[\"PassengerId\"], \"Survived\":survived.ravel()})\n",
    "answer.to_csv('titanic/predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No. of Layers': 1,\n",
       " 'n 0': 384,\n",
       " 'dropout': 0.2,\n",
       " 'learning_rate': 0.01,\n",
       " 'n 1': 480,\n",
       " 'n 2': 64,\n",
       " 'n 3': 288,\n",
       " 'n 4': 64,\n",
       " 'n 5': 128,\n",
       " 'n 6': 192,\n",
       " 'n 7': 224,\n",
       " 'n 8': 64,\n",
       " 'n 9': 288,\n",
       " 'n 10': 384,\n",
       " 'tuner/epochs': 100,\n",
       " 'tuner/initial_epoch': 2,\n",
       " 'tuner/bracket': 1,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0015'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow_decision_forests.keras import pd_dataframe_to_tf_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd_dataframe_to_tf_dataset(train_data, label='Survived')\n",
    "test_ds = test_data.insert(column=\"Survived\",value=[0]*418, loc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>People</th>\n",
       "      <th>Size</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age     Fare  People  Size  Sex_female  Sex_male  Embarked_C  \\\n",
       "0         3  22.0   7.2500       1    16           0         1           0   \n",
       "1         3  38.0  71.2833       2    32           1         0           1   \n",
       "2         2  26.0   7.9250       1    25           0         1           0   \n",
       "3         3  35.0  53.1000       1    16           0         1           0   \n",
       "4         3  35.0   8.0500       3    44           1         0           0   \n",
       "..      ...   ...      ...     ...   ...         ...       ...         ...   \n",
       "413       3  24.0   0.0000       1    18           0         1           0   \n",
       "414       1  44.0   7.9250       1    28           1         0           0   \n",
       "415       3  24.0   8.0500       1    28           0         1           0   \n",
       "416       3  34.0  32.5000       1    19           0         1           0   \n",
       "417       3  18.0  13.0000       3    24           0         1           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  Survived  \n",
       "0             0           1         0  \n",
       "1             0           0         0  \n",
       "2             0           1         0  \n",
       "3             0           1         0  \n",
       "4             0           1         0  \n",
       "..          ...         ...       ...  \n",
       "413           0           1         0  \n",
       "414           0           1         0  \n",
       "415           0           1         0  \n",
       "416           0           1         0  \n",
       "417           0           1         0  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds = pd_dataframe_to_tf_dataset(train_data[:178], label='Survived')\n",
    "test_ds = pd_dataframe_to_tf_dataset(test_data, label='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp8emijaf_ as temporary training directory\n",
      "Warning: Model constructor argument validation_split=0.2 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument validation_split=0.2 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.110156. Found 713 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.085700\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-22 06:48:38.1120 UTC kernel.cc:1233] Loading model from path /tmp/tmp8emijaf_/model/ with prefix cce4213c9f9e4ee2\n",
      "[INFO 24-02-22 06:48:38.1404 UTC decision_forest.cc:660] Model loaded with 300 root(s), 37318 node(s), and 9 input feature(s).\n",
      "[INFO 24-02-22 06:48:38.1404 UTC abstract_model.cc:1344] Engine \"RandomForestOptPred\" built\n",
      "[INFO 24-02-22 06:48:38.1404 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x704bdc60b950>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tfdf.keras.RandomForestModel()\n",
    "model.fit(train_ds, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy without hyper-parameter tuning: 0.8202\n"
     ]
    }
   ],
   "source": [
    "model.compile([\"accuracy\"])\n",
    "test_accuracy = model.evaluate(test_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy without hyper-parameter tuning: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_decision_forests.component.tuner.tuner.SearchSpace at 0x70493c4c9610>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = tfdf.tuner.RandomSearch(num_trials=1100)\n",
    "tuner.choice(\"min_examples\", [2, 5, 7, 10, 14, 21])\n",
    "tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
    "local_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\n",
    "local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8, 10, 12, 14])\n",
    "global_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\n",
    "global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256, 512])\n",
    "tuner.choice(\"use_hessian_gain\", [True, False])\n",
    "tuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30])\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
    "tuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\n",
    "oblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\n",
    "oblique_space.choice(\"sparse_oblique_normalization\",\n",
    "                     [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\n",
    "oblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\n",
    "oblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5, 2.0, 2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpmzhz5c9s as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'Pclass': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'Age': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'Fare': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'People': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'Size': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'Sex_female': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'Sex_male': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>, 'Embarked_C': <tf.Tensor 'data_7:0' shape=(None,) dtype=int64>, 'Embarked_Q': <tf.Tensor 'data_8:0' shape=(None,) dtype=int64>, 'Embarked_S': <tf.Tensor 'data_9:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_10:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'Pclass': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Age': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Fare': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'People': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Size': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'Sex_female': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'Sex_male': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'Embarked_C': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'Embarked_Q': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>), 'Embarked_S': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_9:0' shape=(None,) dtype=float32>)}\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x704bdc458a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-02-22 07:36:33.0283 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 07:36:33.0283 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 07:36:33.0283 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x704bdc458a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.121300. Found 891 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-22 07:36:33.1665 UTC kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-02-22 07:36:33.1665 UTC kernel.cc:772] Collect training examples\n",
      "[INFO 24-02-22 07:36:33.1665 UTC kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-02-22 07:36:33.1666 UTC kernel.cc:391] Number of batches: 1\n",
      "[INFO 24-02-22 07:36:33.1666 UTC kernel.cc:392] Number of examples: 891\n",
      "[INFO 24-02-22 07:36:33.1666 UTC kernel.cc:792] Training dataset:\n",
      "Number of records: 891\n",
      "Number of columns: 11\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 10 (90.9091%)\n",
      "\tCATEGORICAL: 1 (9.09091%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 10 (90.9091%)\n",
      "\t0: \"Age\" NUMERICAL mean:28.567 min:0.42 max:80 sd:13.1922\n",
      "\t1: \"Embarked_C\" NUMERICAL mean:0.188552 min:0 max:1 sd:0.391152\n",
      "\t2: \"Embarked_Q\" NUMERICAL mean:0.0864198 min:0 max:1 sd:0.280983\n",
      "\t3: \"Embarked_S\" NUMERICAL mean:0.725028 min:0 max:1 sd:0.4465\n",
      "\t4: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n",
      "\t5: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n",
      "\t6: \"People\" NUMERICAL mean:1.9046 min:1 max:11 sd:1.61255\n",
      "\t7: \"Sex_female\" NUMERICAL mean:0.352413 min:0 max:1 sd:0.477722\n",
      "\t8: \"Sex_male\" NUMERICAL mean:0.647587 min:0 max:1 sd:0.477722\n",
      "\t9: \"Size\" NUMERICAL mean:26.9652 min:12 max:82 sd:9.2764\n",
      "\n",
      "CATEGORICAL: 1 (9.09091%)\n",
      "\t10: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-02-22 07:36:33.1666 UTC kernel.cc:808] Configure learner\n",
      "[WARNING 24-02-22 07:36:33.1668 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 07:36:33.1668 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 07:36:33.1668 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-22 07:36:33.1668 UTC kernel.cc:822] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Embarked_C$\"\n",
      "features: \"^Embarked_Q$\"\n",
      "features: \"^Embarked_S$\"\n",
      "features: \"^Fare$\"\n",
      "features: \"^Pclass$\"\n",
      "features: \"^People$\"\n",
      "features: \"^Sex_female$\"\n",
      "features: \"^Sex_male$\"\n",
      "features: \"^Size$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "    features: \"^Age$\"\n",
      "    features: \"^Embarked_C$\"\n",
      "    features: \"^Embarked_Q$\"\n",
      "    features: \"^Embarked_S$\"\n",
      "    features: \"^Fare$\"\n",
      "    features: \"^Pclass$\"\n",
      "    features: \"^People$\"\n",
      "    features: \"^Sex_female$\"\n",
      "    features: \"^Sex_male$\"\n",
      "    features: \"^Size$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: CLASSIFICATION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 6\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: -1\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      shrinkage: 0.1\n",
      "      loss: DEFAULT\n",
      "      validation_set_ratio: 0.1\n",
      "      validation_interval_in_trees: 1\n",
      "      early_stopping: VALIDATION_LOSS_INCREASE\n",
      "      early_stopping_num_trees_look_ahead: 30\n",
      "      l2_regularization: 0\n",
      "      lambda_loss: 1\n",
      "      mart {\n",
      "      }\n",
      "      adapt_subsample_for_maximum_training_duration: false\n",
      "      l1_regularization: 0\n",
      "      use_hessian_gain: false\n",
      "      l2_regularization_categorical: 1\n",
      "      stochastic_gradient_boosting {\n",
      "        ratio: 1\n",
      "      }\n",
      "      apply_link_function: true\n",
      "      compute_permutation_variable_importance: false\n",
      "      binary_focal_loss_options {\n",
      "        misprediction_exponent: 2\n",
      "        positive_sample_coefficient: 0.5\n",
      "      }\n",
      "      early_stopping_initial_iteration: 10\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 1100\n",
      "    }\n",
      "  }\n",
      "  search_space {\n",
      "    fields {\n",
      "      name: \"min_examples\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: 2\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 5\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 7\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 10\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 14\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 21\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"categorical_algorithm\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"CART\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"RANDOM\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"growing_strategy\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"LOCAL\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"BEST_FIRST_GLOBAL\"\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"max_depth\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            integer: 3\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 4\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 5\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 6\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 8\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 10\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 12\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 14\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"LOCAL\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"max_num_nodes\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            integer: 16\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 32\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 64\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 128\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 256\n",
      "          }\n",
      "          possible_values {\n",
      "            integer: 512\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"BEST_FIRST_GLOBAL\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"use_hessian_gain\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"true\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"false\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"shrinkage\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          real: 0.02\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.05\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.1\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.15\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.2\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.25\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.3\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"num_candidate_attributes_ratio\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          real: 0.2\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.5\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.9\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"split_axis\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          categorical: \"AXIS_ALIGNED\"\n",
      "        }\n",
      "        possible_values {\n",
      "          categorical: \"SPARSE_OBLIQUE\"\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_normalization\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            categorical: \"NONE\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"STANDARD_DEVIATION\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"MIN_MAX\"\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_weights\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            categorical: \"BINARY\"\n",
      "          }\n",
      "          possible_values {\n",
      "            categorical: \"CONTINUOUS\"\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      children {\n",
      "        name: \"sparse_oblique_num_projections_exponent\"\n",
      "        discrete_candidates {\n",
      "          possible_values {\n",
      "            real: 1\n",
      "          }\n",
      "          possible_values {\n",
      "            real: 1.5\n",
      "          }\n",
      "          possible_values {\n",
      "            real: 2\n",
      "          }\n",
      "          possible_values {\n",
      "            real: 2.5\n",
      "          }\n",
      "        }\n",
      "        parent_discrete_values {\n",
      "          possible_values {\n",
      "            categorical: \"SPARSE_OBLIQUE\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 07:36:33.1669 UTC kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmpmzhz5c9s/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-02-22 07:36:33.1672 UTC kernel.cc:887] Train model\n",
      "[INFO 24-02-22 07:36:33.1674 UTC hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 2\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 7\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 14\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 21\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"LOCAL\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"BEST_FIRST_GLOBAL\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_depth\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 5\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 6\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 8\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 10\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 12\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 14\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"LOCAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_num_nodes\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 16\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 32\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 64\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 128\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 256\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 512\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"BEST_FIRST_GLOBAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"false\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.02\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.05\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.1\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.15\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.25\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.3\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.5\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.9\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_num_projections_exponent\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 1.5\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2.5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 07:36:33.1675 UTC hyperparameters_optimizer.cc:500] Start local tuner with 16 thread(s)\n",
      "[INFO 24-02-22 07:36:33.1684 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.1684 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.1684 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.1684 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO[INFO 24-02-22 07:36:33.1685 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-22 07:36:33.1685 UTC gradient_boosted_trees.cc:[591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "INFO[INFO 24-02-22 07:36:33.1685 UTC gradient_boosted_trees.cc: 24-02-22 07:36:33.1685 UTC [gradient_boosted_trees.ccINFO1218] [INFO:1218]  24-02-22 07:36:33.1685 UTC Training gradient boosted tree on 891 example(s) and Training gradient boosted tree on 10 feature(s).\n",
      "gradient_boosted_trees.cc: 24-02-22 07:36:33.1685 UTC gradient_boosted_trees.cc891591] Default loss set to BINOMIAL_LOG_LIKELIHOOD example(s) and 10 feature(s).\n",
      ":591] \n",
      "Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-22 07:36:33.1685 UTC gradient_boosted_trees.cc:1218 24-02-22 07:36:33.1685 UTC gradient_boosted_trees.cc:] [Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "INFO 24-02-22 07:36:33.1686 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-22 07:36:33.1686 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-22 07:36:33.1686 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-22 07:36:33.1686 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      " 24-02-22 07:36:33.1686 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.1686 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.1687 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.1687 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO[INFO 24-02-22 07:36:33.1687 UTC [[INFOINFO 24-02-22 07:36:33.1687 UTC gradient_boosted_trees.cc:591] Default loss set to [INFO 24-02-22 07:36:33.1687 UTC BINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-22 07:36:33.1688 UTC [gradient_boosted_trees.cc:1261] gradient_boosted_trees.cc[INFOgradient_boosted_trees.cc:1261]  24-02-22 07:36:33.1687 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and  24-02-22 07:36:33.1688 UTC 73[INFO:591818 24-02-22 07:36:33.1688 UTC  examples used for training and 73 examples used for validation\n",
      "[INFOgradient_boosted_trees.cc:1261] ] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "818 examples used for validation\n",
      " 24-02-22 07:36:33.1688 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 818 examples used for training and 73 examples used for validation[73 examples used for validation\n",
      " examples used for training and INFO 24-02-22 07:36:33.1688 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.1688 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.1689 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "\n",
      "73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.1689 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.1689 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.1690 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD[INFO 24-02-22 07:36:33.1690 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "\n",
      "[INFO 24-02-22 07:36:33.1690 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.1691 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.1692 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[ 24-02-22 07:36:33.1697 UTC gradient_boosted_trees.ccINFO:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD 24-02-22 07:36:33.1697 UTC gradient_boosted_trees.cc:591] Default loss set to \n",
      "[INFO 24-02-22 07:36:33.1698 UTC gradient_boosted_trees.ccBINOMIAL_LOG_LIKELIHOOD\n",
      ":1218] Training gradient boosted tree on 891[INFO example(s) and  24-02-22 07:36:33.1698 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 89110 feature(s).\n",
      " example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.1700 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.1700 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.1709 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.064740 train-accuracy:0.834963 valid-loss:1.079134 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:33.1714 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186279 train-accuracy:0.612469 valid-loss:1.149359 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.1718 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.066976 train-accuracy:0.804401 valid-loss:1.052080 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:33.1722 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316115 train-accuracy:0.612469 valid-loss:1.275300 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.1722 UTC gradient_boosted_trees.cc:1638] \tnum-trees:2 train-loss:0.896455 train-accuracy:0.867971 valid-loss:0.952103 valid-accuracy:0.835616\n",
      "INFO 24-02-22 07:36:33.1751 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.1751 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.1753 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.1754 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.1771 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315650 train-accuracy:0.612469 valid-loss:1.274837 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.1779 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.163603 train-accuracy:0.612469 valid-loss:1.156719 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.1797 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.089932 train-accuracy:0.841076 valid-loss:1.064572 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:33.1859 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084220 train-accuracy:0.842298 valid-loss:1.051565 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:33.1885 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156803 train-accuracy:0.612469 valid-loss:1.137262 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.1888 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.048033 train-accuracy:0.826406 valid-loss:1.016420 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:33.1975 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292848 train-accuracy:0.612469 valid-loss:1.253248 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.2086 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.123366 train-accuracy:0.805623 valid-loss:1.081019 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:33.2165 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.181870 train-accuracy:0.612469 valid-loss:1.154598 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.2404 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.976158 train-accuracy:0.898533 valid-loss:0.987120 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:33.2447 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6853\n",
      "[INFO 24-02-22 07:36:33.2447 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:36:33.2450 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.685300 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:33.2458 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.2458 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.2459 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.2479 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226556 train-accuracy:0.612469 valid-loss:1.193661 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.2484 UTC hyperparameters_optimizer.cc:582] [1/1100] Score: -0.6853 / -0.6853 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:33.2607 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209443 train-accuracy:0.612469 valid-loss:1.210325 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.2713 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.135165 train-accuracy:0.784841 valid-loss:1.085417 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:33.3206 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675935\n",
      "[INFO 24-02-22 07:36:33.3206 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:36:33.3209 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.675935 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:33.3216 UTC hyperparameters_optimizer.cc:582] [2/1100] Score: -0.675935 / -0.675935 HParams: [INFO 24-02-22 07:36:33.3217 UTC fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.3217 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.3219 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.3476 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.069539 train-accuracy:0.853301 valid-loss:1.089902 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:33.3724 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.702657\n",
      "[INFO 24-02-22 07:36:33.3724 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:36:33.3726 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.702657 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:33.3730 UTC hyperparameters_optimizer.cc:582] [3/1100] Score: -0.702657 / -0.675935 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:33.3737 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.3737 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.3739 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.3854 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669214\n",
      "[INFO 24-02-22 07:36:33.3854 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:33.3856 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.669214 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:33.3860 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.3860 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.3861 UTC hyperparameters_optimizer.cc:582] [4/1100] Score: -0.669214 / -0.669214 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:33.3863 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.4608 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679279\n",
      "[INFO 24-02-22 07:36:33.4609 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:36:33.4612 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.679279 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:33.4613 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274004 train-accuracy:0.612469 valid-loss:1.250857 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.4620 UTC hyperparameters_optimizer.cc:582] [5/1100] Score: -0.679279 / -0.669214 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:33.4635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.4635 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.4637 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.4846 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.031351 train-accuracy:0.850856 valid-loss:1.079921 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:33.5183 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.254560 train-accuracy:0.612469 valid-loss:1.254388 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:33.6249 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.724159\n",
      "[INFO 24-02-22 07:36:33.6273 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:36:33.6278 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.724159 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:33.6282 UTC hyperparameters_optimizer.cc:582] [6/1100] Score: -0.724159 / -0.669214 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:33.6307 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.6312 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.6314 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.6905 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.123451 train-accuracy:0.814181 valid-loss:1.095763 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:36:33.8825 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649782\n",
      "[INFO 24-02-22 07:36:33.8825 UTC gradient_boosted_trees.cc:271] Truncates the model to 227 tree(s) i.e. 227  iteration(s).\n",
      "[INFO 24-02-22 07:36:33.8826 UTC gradient_boosted_trees.cc:334] Final model num-trees:227 valid-loss:0.649782 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:33.8855 UTC hyperparameters_optimizer.cc:582] [7/1100] Score: -0.649782 / -0.649782 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:33.8859 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:33.8859 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:33.8862 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:33.8992 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.038756 train-accuracy:0.866748 valid-loss:1.081636 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:36:34.0798 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691553\n",
      "[INFO 24-02-22 07:36:34.0798 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.0801 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.691553 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:34.0804 UTC hyperparameters_optimizer.cc:582] [8/1100] Score: -0.691553 / -0.649782 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:34.0811 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.0811 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.0813 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.0827 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646197\n",
      "[INFO 24-02-22 07:36:34.0827 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.0829 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.646197 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:34.0834 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.0834 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.0836 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.0857 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.066720 train-accuracy:0.837408 valid-loss:1.036679 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:34.0873 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284126 train-accuracy:0.612469 valid-loss:1.233602 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.0885 UTC hyperparameters_optimizer.cc:582] [9/1100] Score: -0.646197 / -0.646197 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:34.1017 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.592812\n",
      "[INFO 24-02-22 07:36:34.1019 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.1023 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.592812 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:34.1028 UTC hyperparameters_optimizer.cc:582] [10/1100] Score: -0.592812 / -0.592812 HParams: [INFO 24-02-22 07:36:34.1028 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.1028 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:34.1030 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.1102 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121455 train-accuracy:0.825183 valid-loss:1.056355 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:34.1347 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692451\n",
      "[INFO 24-02-22 07:36:34.1347 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.1349 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.692451 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:34.1352 UTC hyperparameters_optimizer.cc:582] [11/1100] Score: -0.692451 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:34.1357 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.1359 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.1362 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.1477 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.137303 train-accuracy:0.612469 valid-loss:1.127096 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.2506 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673384\n",
      "[INFO 24-02-22 07:36:34.2506 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:34.2507 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:34.2507 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.673384 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:34.2511 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.2511 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.2521 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.2551 UTC hyperparameters_optimizer.cc:582] [12/1100] Score: -0.673384 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:34.2730 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.717845\n",
      "[INFO 24-02-22 07:36:34.2731 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.2732 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.717845 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:34.2734 UTC hyperparameters_optimizer.cc:582] [13/1100] Score: -0.717845 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:34.2743 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.2743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.2747 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.2772 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.192741 train-accuracy:0.612469 valid-loss:1.152177 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.3122 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284070 train-accuracy:0.612469 valid-loss:1.244166 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.3493 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68385\n",
      "[INFO 24-02-22 07:36:34.3494 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.3495 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.683850 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:34.3498 UTC hyperparameters_optimizer.cc:582] [14/1100] Score: -0.68385 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:34.3512 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.3513 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.3521 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.3698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314093 train-accuracy:0.612469 valid-loss:1.271763 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.5372 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718592\n",
      "[INFO 24-02-22 07:36:34.5373 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:34.5379 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:34.5379 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.718592 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:34.5387 UTC hyperparameters_optimizer.cc:582] [15/1100] Score: -0.718592 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:34.5395 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.5397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.5402 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.5439 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240467 train-accuracy:0.612469 valid-loss:1.187535 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.5621 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671454\n",
      "[INFO 24-02-22 07:36:34.5623 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.5631 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.671454 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:34.5635 UTC hyperparameters_optimizer.cc:582] [16/1100] Score: -0.671454 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:34.5641 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.5641 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.5644 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.5753 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654652\n",
      "[INFO 24-02-22 07:36:34.5753 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.5756 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.654652 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:34.5769 UTC hyperparameters_optimizer.cc:582] [17/1100] Score: -0.654652 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:34.5781 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.5782 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.5785 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.5865 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.198153 train-accuracy:0.612469 valid-loss:1.158143 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.5981 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274874 train-accuracy:0.612469 valid-loss:1.246648 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.6150 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.749455\n",
      "[INFO 24-02-22 07:36:34.6150 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.6152 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.749455 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:34.6155 UTC hyperparameters_optimizer.cc:582] [18/1100] Score: -0.749455 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:34.6162 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.6162 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.6164 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.6229 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184769 train-accuracy:0.612469 valid-loss:1.181778 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.6884 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651632\n",
      "[INFO 24-02-22 07:36:34.6884 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.6886 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.651632 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:34.6889 UTC hyperparameters_optimizer.cc:582] [19/1100] Score: -0.651632 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:34.6894 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.6894 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.6896 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.7352 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130031 train-accuracy:0.612469 valid-loss:1.139707 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.7503 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649599\n",
      "[INFO 24-02-22 07:36:34.7503 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.7524 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.649599 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:34.7531 UTC hyperparameters_optimizer.cc:582] [20/1100] Score: -0.649599 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:34.7553 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.7554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.7556 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.8161 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313200 train-accuracy:0.612469 valid-loss:1.272511 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.9387 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685289\n",
      "[INFO 24-02-22 07:36:34.9388 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.9394 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.685289 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:34.9399 UTC hyperparameters_optimizer.cc:582] [21/1100] Score: -0.685289 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:34.9409 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.9409 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.9411 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.9450 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673582\n",
      "[INFO 24-02-22 07:36:34.9450 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:34.9451 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.673582 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:34.9453 UTC hyperparameters_optimizer.cc:582] [22/1100] Score: -0.673582 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:34.9457 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:34.9457 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:34.9460 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:34.9484 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230256 train-accuracy:0.612469 valid-loss:1.191931 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:34.9665 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225725 train-accuracy:0.612469 valid-loss:1.189000 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:35.0657 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692028\n",
      "[INFO 24-02-22 07:36:35.0657 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:36:35.0674 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.692028 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:35.0694 UTC hyperparameters_optimizer.cc:582] [23/1100] Score: -0.692028 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:35.0752 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661803\n",
      "[INFO 24-02-22 07:36:35.0753 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:36:35.0755 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.661803 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:35.0756 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:35.0757 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:35.0759 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:35.0759 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:35.0760 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:35.0761 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:35.0783 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316892 train-accuracy:0.612469 valid-loss:1.275386 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:35.0784 UTC hyperparameters_optimizer.cc:582] [24/1100] Score: -0.661803 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:35.0948 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.076666 train-accuracy:0.826406 valid-loss:1.010013 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:35.1102 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646465\n",
      "[INFO 24-02-22 07:36:35.1102 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:36:35.1104 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.646465 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:35.1107 UTC hyperparameters_optimizer.cc:582] [25/1100] Score: -0.646465 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:35.1112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:35.1112 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:35.1116 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:35.1215 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.062981 train-accuracy:0.845966 valid-loss:1.067039 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:35.4988 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673446\n",
      "[INFO 24-02-22 07:36:35.4988 UTC gradient_boosted_trees.cc:271] Truncates the model to 162 tree(s) i.e. 162  iteration(s).\n",
      "[INFO 24-02-22 07:36:35.4989 UTC gradient_boosted_trees.cc:334] Final model num-trees:162 valid-loss:0.673446 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:35.5001 UTC hyperparameters_optimizer.cc:582] [26/1100] Score: -0.673446 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:35.5008 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:35.5008 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:35.5018 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:35.5752 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285623 train-accuracy:0.612469 valid-loss:1.245817 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:35.6786 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656986\n",
      "[INFO 24-02-22 07:36:35.6787 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:36:35.6790 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.656986 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:35.6795 UTC hyperparameters_optimizer.cc:582] [27/1100] Score: -0.656986 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:35.6800 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:35.6800 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:35.6804 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:35.6829 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.126259 train-accuracy:0.800734 valid-loss:1.072448 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:35.8778 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647651\n",
      "[INFO 24-02-22 07:36:35.8810 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:36:35.8811 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.647651 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:35.8813 UTC hyperparameters_optimizer.cc:582] [28/1100] Score: -0.647651 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:35.8816 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:35.8816 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:35.8818 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-22 07:36:35.8879 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665425\n",
      "[INFO 24-02-22 07:36:35.8879 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 07:36:35.8880 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.665425 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:35.8881 UTC hyperparameters_optimizer.cc:582] [29/1100] Score: -0.665425 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:35.8883 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:35.8883 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:35.8885 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      " 24-02-22 07:36:35.8920 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.154876 train-accuracy:0.612469 valid-loss:1.146297 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:36.0626 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.054399 train-accuracy:0.815403 valid-loss:1.036070 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:36.1779 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635782\n",
      "[INFO 24-02-22 07:36:36.1779 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:36:36.1783 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.635782 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:36.1790 UTC hyperparameters_optimizer.cc:582] [30/1100] Score: -0.635782 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:36.1795 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:36.1795 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:36.1799 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:36.1830 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311734 train-accuracy:0.612469 valid-loss:1.272028 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:36.2286 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718803\n",
      "[INFO 24-02-22 07:36:36.2287 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 07:36:36.2292 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.718803 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:36.2307 UTC hyperparameters_optimizer.cc:582] [31/1100] Score: -0.718803 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:36.2322 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:36.2322 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:36.2324 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:36.2389 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257552 train-accuracy:0.612469 valid-loss:1.212643 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:36.4917 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718168\n",
      "[INFO 24-02-22 07:36:36.4917 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:36.4921 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:36.4921 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.718168 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:36.4923 UTC hyperparameters_optimizer.cc:582] [32/1100] Score: -0.718168 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:36.4928 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:36.4928 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:36.4930 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:36.5483 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112788 train-accuracy:0.784841 valid-loss:1.077400 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:36.6005 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617196\n",
      "[INFO 24-02-22 07:36:36.6006 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:36.6007 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.617196 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:36.6009 UTC hyperparameters_optimizer.cc:582] [33/1100] Score: -0.617196 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:36.6013 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:36.6013 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:36.6016 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:36.6425 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658897\n",
      "[INFO 24-02-22 07:36:36.6425 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 07:36:36.6428 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.658897 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:36.6445 UTC hyperparameters_optimizer.cc:582] [34/1100] Score: -0.658897 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:36.6449 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:36.6449 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:36.6462 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:36.6527 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190528 train-accuracy:0.612469 valid-loss:1.137003 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:36.6530 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225515 train-accuracy:0.612469 valid-loss:1.195507 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:36.6799 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.693729\n",
      "[INFO 24-02-22 07:36:36.6799 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 07:36:36.6799 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.693729 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:36.6801 UTC hyperparameters_optimizer.cc:582] [35/1100] Score: -0.693729 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:36.6803 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:36.6803 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:36.6805 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:36.7415 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.022678 train-accuracy:0.871638 valid-loss:1.002682 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:36.8760 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671848\n",
      "[INFO 24-02-22 07:36:36.8760 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 07:36:36.8762 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.671848 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:36.8770 UTC hyperparameters_optimizer.cc:582] [36/1100] Score: -0.671848 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:36.8775 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:36.8775 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:36.8784 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:36.8843 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.089760 train-accuracy:0.833741 valid-loss:1.098012 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:36.8893 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654505\n",
      "[INFO 24-02-22 07:36:36.8893 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 07:36:36.8895 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.654505 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:36.8899 UTC hyperparameters_optimizer.cc:582] [37/1100] Score: -0.654505 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:36.8912 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:36.8916 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:36.8921 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:37.0162 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.984855 train-accuracy:0.878973 valid-loss:1.023416 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:37.0264 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639079\n",
      "[INFO 24-02-22 07:36:37.0264 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:36:37.0267 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.639079 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:37.0271 UTC hyperparameters_optimizer.cc:582] [38/1100] Score: -0.639079 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:37.0276 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:37.0276 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:37.0281 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:37.0782 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668354\n",
      "[INFO 24-02-22 07:36:37.0783 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:37.0793 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.668354 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:37.0800 UTC hyperparameters_optimizer.cc:582] [39/1100] Score: -0.668354 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:37.0832 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:37.0833 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:37.0835 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:37.0868 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310338 train-accuracy:0.612469 valid-loss:1.273277 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:37.0930 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.034610 train-accuracy:0.847188 valid-loss:1.025592 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:37.1692 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.704501\n",
      "[INFO 24-02-22 07:36:37.1692 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:36:37.1703 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.704501 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:37.1711 UTC hyperparameters_optimizer.cc:582] [40/1100] Score: -0.704501 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:37.1738 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:37.1738 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:37.1747 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:37.2675 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275117 train-accuracy:0.612469 valid-loss:1.249480 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:37.5301 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681562\n",
      "[INFO 24-02-22 07:36:37.5301 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 24-02-22 07:36:37.5305 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.681562 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:37.5322 UTC hyperparameters_optimizer.cc:582] [41/1100] Score: -0.681562 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:37.5361 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:37.5361 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:37.5365 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:37.5870 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247181 train-accuracy:0.612469 valid-loss:1.193795 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:37.5934 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701668\n",
      "[INFO 24-02-22 07:36:37.5934 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:36:37.5938 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.701668 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:37.5951 UTC hyperparameters_optimizer.cc:582] [42/1100] Score: -0.701668 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:37.5955 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:37.5955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:37.5958 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:37.5969 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130193 train-accuracy:0.810513 valid-loss:1.070828 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:37.6444 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652806\n",
      "[INFO 24-02-22 07:36:37.6444 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:36:37.6445 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.652806 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:37.6447 UTC hyperparameters_optimizer.cc:582] [43/1100] Score: -0.652806 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:37.6452 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:37.6452 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:37.6454 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:37.6688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187339 train-accuracy:0.612469 valid-loss:1.160099 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:38.0081 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63932\n",
      "[INFO 24-02-22 07:36:38.0081 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 07:36:38.0081 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.639320 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:38.0084 UTC hyperparameters_optimizer.cc:582] [44/1100] Score: -0.63932 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:38.0087 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:38.0087 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:38.0090 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:38.0626 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.179523 train-accuracy:0.612469 valid-loss:1.137385 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:38.9024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.804309\n",
      "[INFO 24-02-22 07:36:38.9024 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:38.9029 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:38.9029 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.804309 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:38.9041 UTC hyperparameters_optimizer.cc:582] [45/1100] Score: -0.804309 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:38.9051 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:38.9052 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:38.9053 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:38.9136 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284838 train-accuracy:0.612469 valid-loss:1.243685 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:38.9394 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.69077\n",
      "[INFO 24-02-22 07:36:38.9395 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:36:38.9397 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.690770 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:38.9400 UTC hyperparameters_optimizer.cc:582] [46/1100] Score: -0.69077 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:38.9405 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:38.9405 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:38.9408 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:38.9594 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285179 train-accuracy:0.612469 valid-loss:1.245173 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:38.9613 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692168\n",
      "[INFO 24-02-22 07:36:38.9613 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:36:38.9615 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.692168 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:38.9616 UTC hyperparameters_optimizer.cc:582] [47/1100] Score: -0.692168 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:38.9621 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:38.9621 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:38.9624 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:38.9703 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234409 train-accuracy:0.612469 valid-loss:1.196911 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:39.0150 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664167\n",
      "[INFO 24-02-22 07:36:39.0150 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.0151 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.664167 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:39.0152 UTC hyperparameters_optimizer.cc:582] [48/1100] Score: -0.664167 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:39.0155 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.0156 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.0158 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.0249 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.978145 train-accuracy:0.918093 valid-loss:1.052123 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:39.2828 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703857\n",
      "[INFO 24-02-22 07:36:39.2828 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:39.2831 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:39.2831 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.703857 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:39.2833 UTC hyperparameters_optimizer.cc:582] [49/1100] Score: -0.703857 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:39.2837 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.2837 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.2839 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.2871 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234267 train-accuracy:0.612469 valid-loss:1.191808 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:39.3405 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630165\n",
      "[INFO 24-02-22 07:36:39.3405 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.3408 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.630165 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:39.3413 UTC hyperparameters_optimizer.cc:582] [50/1100] Score: -0.630165 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:39.3439 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.3439 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.3441 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.3578 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.104772 train-accuracy:0.836186 valid-loss:1.040666 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:39.4048 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685302\n",
      "[INFO 24-02-22 07:36:39.4048 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.4050 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.685302 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:39.4054 UTC hyperparameters_optimizer.cc:582] [51/1100] Score: -0.685302 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:39.4063 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.4063 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.4065 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.4272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155126 train-accuracy:0.803178 valid-loss:1.095904 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:39.5021 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695666\n",
      "[INFO 24-02-22 07:36:39.5021 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.5023 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.695666 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:39.5027 UTC hyperparameters_optimizer.cc:582] [52/1100] Score: -0.695666 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:39.5035 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.5035 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.5037 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.5045 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.300191 train-accuracy:0.612469 valid-loss:1.257292 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:39.5435 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666224\n",
      "[INFO 24-02-22 07:36:39.5435 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:39.5452 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:39.5452 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.666224 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:39.5484 UTC hyperparameters_optimizer.cc:582] [53/1100] Score: -0.666224 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:39.5507 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.5510 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.5515 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.5643 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.213890 train-accuracy:0.612469 valid-loss:1.185849 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:39.6241 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685889\n",
      "[INFO 24-02-22 07:36:39.6242 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.6243 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.685889 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:39.6248 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.6248 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.6252 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.6254 UTC hyperparameters_optimizer.cc:582] [54/1100] Score: -0.685889 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:39.6343 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085558 train-accuracy:0.799511 valid-loss:1.053434 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:39.6404 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679348\n",
      "[INFO 24-02-22 07:36:39.6406 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.6411 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.679348 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:36:39.6424 UTC hyperparameters_optimizer.cc:582] [55/1100] Score: -0.679348 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:36:39.6429 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.6430 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.6437 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.6686 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.171520 train-accuracy:0.612469 valid-loss:1.152787 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:39.7010 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.693036\n",
      "[INFO 24-02-22 07:36:39.7010 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.7023 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.693036 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:39.7037 UTC hyperparameters_optimizer.cc:582] [56/1100] Score: -0.693036 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:39.7048 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.7086 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.7099 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.7183 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157459 train-accuracy:0.761614 valid-loss:1.117958 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:39.8608 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.722179\n",
      "[INFO 24-02-22 07:36:39.8608 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.8629 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.722179 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:39.8657 UTC hyperparameters_optimizer.cc:582] [57/1100] Score: -0.722179 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:39.8733 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.8733 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.8737 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.8877 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226753 train-accuracy:0.612469 valid-loss:1.204740 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:39.9118 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701481\n",
      "[INFO 24-02-22 07:36:39.9118 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:39.9119 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:39.9119 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.701481 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:39.9121 UTC hyperparameters_optimizer.cc:582] [58/1100] Score: -0.701481 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:39.9125 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.9125 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.9127 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:39.9137 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.166429 train-accuracy:0.810513 valid-loss:1.110644 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:39.9741 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636347\n",
      "[INFO 24-02-22 07:36:39.9741 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:36:39.9742 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.636347 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:39.9744 UTC hyperparameters_optimizer.cc:582] [59/1100] Score: -0.636347 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:39.9748 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:39.9748 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:39.9751 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.0143 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672605\n",
      "[INFO 24-02-22 07:36:40.0144 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.0147 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.672605 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:40.0150 UTC hyperparameters_optimizer.cc:582] [60/1100] Score: -0.672605 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:40.0155 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.0155 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.0157 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.0370 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222448 train-accuracy:0.612469 valid-loss:1.191909 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.0949 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261376 train-accuracy:0.612469 valid-loss:1.233669 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.2759 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663479\n",
      "[INFO 24-02-22 07:36:40.2759 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.2767 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.663479 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:40.2772 UTC hyperparameters_optimizer.cc:582] [61/1100] Score: -0.663479 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:40.2783 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.2783 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.2787 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.2851 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313653 train-accuracy:0.612469 valid-loss:1.271615 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.3110 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680194\n",
      "[INFO 24-02-22 07:36:40.3110 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.3111 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.680194 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:40.3116 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.3116 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.3118 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[[INFO 24-02-22 07:36:40.3128 UTC hyperparameters_optimizer.cc:582] [62/1100] Score: -0.680194 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:36:40.3130 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296531 train-accuracy:0.612469 valid-loss:1.249816 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.4909 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676637\n",
      "[INFO 24-02-22 07:36:40.4909 UTC gradient_boosted_trees.cc:271] Truncates the model to 158 tree(s) i.e. 158  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.4910 UTC gradient_boosted_trees.cc:334] Final model num-trees:158 valid-loss:0.676637 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:40.4912 UTC hyperparameters_optimizer.cc:582] [63/1100] Score: -0.676637 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:40.4920 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.4921 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.4924 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.5009 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.755143\n",
      "[INFO 24-02-22 07:36:40.5009 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.5012 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.755143 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:36:40.5022 UTC hyperparameters_optimizer.cc:582] [64/1100] Score: -0.755143 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:36:40.5026 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.5026 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.5028 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.5279 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277697 train-accuracy:0.612469 valid-loss:1.236883 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.5312 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658426\n",
      "[INFO 24-02-22 07:36:40.5313 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.5313 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.658426 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:40.5316 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.5316 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.5317 UTC hyperparameters_optimizer.cc:582] [65/1100] Score: -0.658426 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:40.5319 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.5394 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668565\n",
      "[INFO 24-02-22 07:36:40.5394 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.5396 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176568 train-accuracy:0.612469 valid-loss:1.138409 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.5397 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.668565 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:40.5403 UTC hyperparameters_optimizer.cc:582] [66/1100] Score: -0.668565 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:40.5417 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.5418 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.5420 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.5482 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176402 train-accuracy:0.612469 valid-loss:1.136908 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.5648 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312276 train-accuracy:0.612469 valid-loss:1.271637 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.6192 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681793\n",
      "[INFO 24-02-22 07:36:40.6193 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.6196 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.681793 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:40.6217 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.6218 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.6220 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.6251 UTC hyperparameters_optimizer.cc:582] [67/1100] Score: -0.681793 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:40.6682 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.199751 train-accuracy:0.612469 valid-loss:1.151685 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.8195 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653113\n",
      "[INFO 24-02-22 07:36:40.8195 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.8197 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.653113 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:40.8201 UTC hyperparameters_optimizer.cc:582] [68/1100] Score: -0.653113 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:40.8206 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.8206 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.8208 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.8771 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.194058 train-accuracy:0.612469 valid-loss:1.156732 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:40.9796 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718681\n",
      "[INFO 24-02-22 07:36:40.9797 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:40.9799 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.718681 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:40.9802 UTC hyperparameters_optimizer.cc:582] [69/1100] Score: -0.718681 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:40.9809 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:40.9810 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:40.9812 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:40.9874 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.069764 train-accuracy:0.817848 valid-loss:1.060764 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:41.0072 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623663\n",
      "[INFO 24-02-22 07:36:41.0072 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.0076 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.623663 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:41.0080 UTC hyperparameters_optimizer.cc:582] [70/1100] Score: -0.623663 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:41.0096 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.0096 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.0098 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.0642 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085549 train-accuracy:0.854523 valid-loss:1.052064 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:41.1868 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653316\n",
      "[INFO 24-02-22 07:36:41.1868 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.1870 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.653316 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:41.1875 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.1875 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.1877 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.1884 UTC hyperparameters_optimizer.cc:582] [71/1100] Score: -0.653316 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:41.1904 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284285 train-accuracy:0.612469 valid-loss:1.241691 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.2398 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653757\n",
      "[INFO 24-02-22 07:36:41.2398 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:41.2400 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:41.2400 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.653757 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:41.2402 UTC hyperparameters_optimizer.cc:582] [72/1100] Score: -0.653757 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:41.2406 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.2406 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.2409 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.2499 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176610 train-accuracy:0.612469 valid-loss:1.152451 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.2570 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677809\n",
      "[INFO 24-02-22 07:36:41.2570 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.2572 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.677809 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:41.2579 UTC hyperparameters_optimizer.cc:582] [73/1100] Score: -0.677809 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:41.2589 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.2590 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.2594 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.2670 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679002\n",
      "[INFO 24-02-22 07:36:41.2670 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.2672 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240735 train-accuracy:0.612469 valid-loss:1.200832 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.2676 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.679002 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:41.2687 UTC hyperparameters_optimizer.cc:582] [74/1100] Score: -0.679002 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:41.2704 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.2705 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.2707 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.2725 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246377 train-accuracy:0.612469 valid-loss:1.202414 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.3817 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64529\n",
      "[INFO 24-02-22 07:36:41.3818 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.3821 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.645290 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:41.3824 UTC hyperparameters_optimizer.cc:582] [75/1100] Score: -0.64529 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:41.3830 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.3830 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.3839 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.3866 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287483 train-accuracy:0.612469 valid-loss:1.248060 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.3889 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678401\n",
      "[INFO 24-02-22 07:36:41.3890 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.3892 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.678401 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:41.3896 UTC hyperparameters_optimizer.cc:582] [76/1100] Score: -0.678401 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:41.3904 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.3904 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.3908 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.3942 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.052426 train-accuracy:0.839853 valid-loss:1.028511 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:41.3971 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66189\n",
      "[INFO 24-02-22 07:36:41.3972 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.3973 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.661890 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:41.3982 UTC hyperparameters_optimizer.cc:582] [77/1100] Score: -0.66189 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:41.4012 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.4012 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.4015 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.4247 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.008191 train-accuracy:0.881418 valid-loss:1.012808 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:41.4853 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639738\n",
      "[INFO 24-02-22 07:36:41.4853 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.4854 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.639738 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:41.4861 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.4861 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.4863 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.4884 UTC hyperparameters_optimizer.cc:582] [78/1100] Score: -0.639738 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:41.4991 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162416 train-accuracy:0.612469 valid-loss:1.152695 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.5143 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686409\n",
      "[INFO 24-02-22 07:36:41.5144 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:41.5146 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:41.5146 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.686409 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:41.5148 UTC hyperparameters_optimizer.cc:582] [79/1100] Score: -0.686409 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:41.5155 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.5155 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.5163 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.5260 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.192141 train-accuracy:0.612469 valid-loss:1.151932 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.5796 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689058\n",
      "[INFO 24-02-22 07:36:41.5797 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:41.5800 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:41.5800 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.689058 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:41.5802 UTC hyperparameters_optimizer.cc:582] [80/1100] Score: -0.689058 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:41.5809 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.5809 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.5811 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.5826 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316830 train-accuracy:0.612469 valid-loss:1.274480 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.6174 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643566\n",
      "[INFO 24-02-22 07:36:41.6174 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.6179 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.643566 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:41.6183 UTC hyperparameters_optimizer.cc:582] [81/1100] Score: -0.643566 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:41.6189 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.6189 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.6192 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.6449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282026 train-accuracy:0.612469 valid-loss:1.240866 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.6654 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670741\n",
      "[INFO 24-02-22 07:36:41.6654 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.6656 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.670741 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:41.6662 UTC hyperparameters_optimizer.cc:582] [82/1100] Score: -0.670741 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:41.6680 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.6680 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.6683 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.6709 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314432 train-accuracy:0.612469 valid-loss:1.271350 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.7423 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688762\n",
      "[INFO 24-02-22 07:36:41.7423 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.7425 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.688762 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:41.7432 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.7432 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.7434 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.7474 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317597 train-accuracy:0.612469 valid-loss:1.273997 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.7484 UTC hyperparameters_optimizer.cc:582] [83/1100] Score: -0.688762 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:41.9062 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.599365 train-accuracy:0.900978 valid-loss:0.663170 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:41.9062 UTC gradient_boosted_trees.cc:271] Truncates the model to 291 tree(s) i.e. 291  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.9062 UTC gradient_boosted_trees.cc:334] Final model num-trees:291 valid-loss:0.662637 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:41.9070 UTC hyperparameters_optimizer.cc:582] [84/1100] Score: -0.662637 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:41.9086 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.9087 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.9089 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.9134 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314527 train-accuracy:0.612469 valid-loss:1.270168 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:41.9221 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663779\n",
      "[INFO 24-02-22 07:36:41.9221 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:36:41.9223 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.663779 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:36:41.9226 UTC hyperparameters_optimizer.cc:582] [85/1100] Score: -0.663779 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:41.9249 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:41.9278 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:41.9281 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:41.9565 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280271 train-accuracy:0.612469 valid-loss:1.243201 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:42.0573 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675723\n",
      "[INFO 24-02-22 07:36:42.0606 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:36:42.0610 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.675723 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:42.0613 UTC hyperparameters_optimizer.cc:582] [86/1100] Score: -0.675723 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:42.0639 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.0639 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.0641 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.0753 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.087783 train-accuracy:0.808068 valid-loss:1.054739 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:42.1607 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669142\n",
      "[INFO 24-02-22 07:36:42.1608 UTC gradient_boosted_trees.cc:271] Truncates the model to 142 tree(s) i.e. 142  iteration(s).\n",
      "[INFO 24-02-22 07:36:42.1610 UTC gradient_boosted_trees.cc:334] Final model num-trees:142 valid-loss:0.669142 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:42.1622 UTC hyperparameters_optimizer.cc:582] [87/1100] Score: -0.669142 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:42.1653 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.1655 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.1658 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.2458 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180202 train-accuracy:0.612469 valid-loss:1.130882 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:42.3634 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.7056\n",
      "[INFO 24-02-22 07:36:42.3635 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:42.3637 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:42.3637 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.705600 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:42.3643 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.3643 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.3645 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.3651 UTC hyperparameters_optimizer.cc:582] [88/1100] Score: -0.7056 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:42.3959 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063478 train-accuracy:0.837408 valid-loss:1.110772 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:36:42.4284 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.730862\n",
      "[INFO 24-02-22 07:36:42.4284 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:42.4287 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:42.4287 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.730862 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:42.4291 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.4291 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.4295 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.4324 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.108459 train-accuracy:0.803178 valid-loss:1.081063 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:42.4351 UTC hyperparameters_optimizer.cc:582] [89/1100] Score: -0.730862 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:42.5432 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672762\n",
      "[INFO 24-02-22 07:36:42.5432 UTC gradient_boosted_trees.cc:271] Truncates the model to 176 tree(s) i.e. 176  iteration(s).\n",
      "[INFO 24-02-22 07:36:42.5433 UTC gradient_boosted_trees.cc:334] Final model num-trees:176 valid-loss:0.672762 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:42.5437 UTC hyperparameters_optimizer.cc:582] [90/1100] Score: -0.672762 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:42.5440 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.5440 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.5443 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.5709 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.143412 train-accuracy:0.754279 valid-loss:1.130084 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:36:42.5718 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6941\n",
      "[INFO 24-02-22 07:36:42.5718 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:42.5721 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.694100 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:42.5723 UTC hyperparameters_optimizer.cc:582] [91/1100] Score: -0.6941 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:42.5730 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.5730 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.5733 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.6492 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311930 train-accuracy:0.612469 valid-loss:1.271945 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:42.6741 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67655\n",
      "[INFO 24-02-22 07:36:42.6742 UTC gradient_boosted_trees.cc:271] Truncates the model to 140 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 24-02-22 07:36:42.6744 UTC gradient_boosted_trees.cc:334] Final model num-trees:140 valid-loss:0.676550 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:42.6750 UTC hyperparameters_optimizer.cc:582] [92/1100] Score: -0.67655 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:42.6766 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.6767 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.6771 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.6794 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280843 train-accuracy:0.612469 valid-loss:1.242116 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:42.8417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644822\n",
      "[INFO 24-02-22 07:36:42.8417 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:36:42.8418 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.644822 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:42.8420 UTC hyperparameters_optimizer.cc:582] [93/1100] Score: -0.644822 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:42.8425 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.8426 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.8435 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.8560 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291060 train-accuracy:0.612469 valid-loss:1.247120 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:42.9005 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656668\n",
      "[INFO 24-02-22 07:36:42.9006 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 07:36:42.9009 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.656668 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:42.9017 UTC hyperparameters_optimizer.cc:582] [94/1100] Score: -0.656668 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:42.9035 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.9035 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.9037 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.9383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883319\n",
      "[INFO 24-02-22 07:36:42.9383 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:36:42.9390 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.883319 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:42.9395 UTC hyperparameters_optimizer.cc:582] [95/1100] Score: -0.883319 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:42.9415 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:42.9415 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:42.9417 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:42.9691 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285812 train-accuracy:0.612469 valid-loss:1.247397 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:43.0331 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209996 train-accuracy:0.612469 valid-loss:1.204552 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:43.4286 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649751\n",
      "[INFO 24-02-22 07:36:43.4286 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 07:36:43.4289 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.649751 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:43.4296 UTC hyperparameters_optimizer.cc:582] [96/1100] Score: -0.649751 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:43.4300 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:43.4300 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:43.4302 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:43.4343 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146301 train-accuracy:0.743276 valid-loss:1.091223 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:36:43.4869 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669979\n",
      "[INFO 24-02-22 07:36:43.4869 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:36:43.4871 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.669979 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:43.4878 UTC hyperparameters_optimizer.cc:582] [97/1100] Score: -0.669979 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:43.4887 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:43.4887 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:43.4890 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:43.5212 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66969\n",
      "[INFO 24-02-22 07:36:43.5216 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:43.5218 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.669690 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:43.5220 UTC hyperparameters_optimizer.cc:582] [98/1100] Score: -0.66969 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:43.5224 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:43.5224 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:43.5226 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:43.5510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060241 train-accuracy:0.845966 valid-loss:1.080136 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:43.5712 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682121\n",
      "[INFO 24-02-22 07:36:43.5713 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:36:43.5714 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.682121 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:43.5738 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:43.5739 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:43.5741 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:43.5782 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085803 train-accuracy:0.810513 valid-loss:1.087526 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:43.5784 UTC hyperparameters_optimizer.cc:582] [99/1100] Score: -0.682121 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:43.5966 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240391 train-accuracy:0.612469 valid-loss:1.203060 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:43.6225 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.700661\n",
      "[INFO 24-02-22 07:36:43.6225 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:43.6228 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.700661 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:43.6230 UTC hyperparameters_optimizer.cc:582] [100/1100] Score: -0.700661 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:43.6238 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:43.6239 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:43.6252 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:43.6278 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315813 train-accuracy:0.612469 valid-loss:1.274636 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:43.7289 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699458\n",
      "[INFO 24-02-22 07:36:43.7289 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:43.7291 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:43.7292 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.699458 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:43.7294 UTC hyperparameters_optimizer.cc:582] [101/1100] Score: -0.699458 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:43.7299 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:43.7299 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:43.7301 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:43.7762 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162802 train-accuracy:0.612469 valid-loss:1.173946 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:43.9021 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690556\n",
      "[INFO 24-02-22 07:36:43.9021 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:36:43.9025 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.690556 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:43.9032 UTC hyperparameters_optimizer.cc:582] [102/1100] Score: -0.690556 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:43.9036 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:43.9036 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:43.9038 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:43.9501 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690227\n",
      "[INFO 24-02-22 07:36:43.9504 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:36:43.9507 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.690227 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:43.9523 UTC hyperparameters_optimizer.cc:582] [103/1100] Score: -0.690227 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:43.9543 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:43.9549 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:43.9551 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:43.9581 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225788 train-accuracy:0.612469 valid-loss:1.189141 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:43.9739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237395 train-accuracy:0.612469 valid-loss:1.195225 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:44.0340 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666362\n",
      "[INFO 24-02-22 07:36:44.0340 UTC gradient_boosted_trees.cc:271] Truncates the model to 172 tree(s) i.e. 172  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.0343 UTC gradient_boosted_trees.cc:334] Final model num-trees:172 valid-loss:0.666362 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:44.0357 UTC hyperparameters_optimizer.cc:582] [104/1100] Score: -0.666362 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:44.0377 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.0378 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.0381 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.0410 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287483 train-accuracy:0.612469 valid-loss:1.248060 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:44.1472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689041\n",
      "[INFO 24-02-22 07:36:44.1472 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.1481 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.689041 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:44.1499 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.1502 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.1507 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.1518 UTC hyperparameters_optimizer.cc:582] [105/1100] Score: -0.689041 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:44.1544 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313293 train-accuracy:0.612469 valid-loss:1.275101 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:44.2521 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683009\n",
      "[INFO 24-02-22 07:36:44.2521 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.2522 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.683009 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:44.2524 UTC hyperparameters_optimizer.cc:582] [106/1100] Score: -0.683009 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:44.2530 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.2530 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.2532 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.2549 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.101307 train-accuracy:0.784841 valid-loss:1.059771 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:44.2563 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670741\n",
      "[INFO 24-02-22 07:36:44.2564 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.2566 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.670741 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:44.2576 UTC hyperparameters_optimizer.cc:582] [107/1100] Score: -0.670741 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:44.2590 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.2592 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.2595 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.2631 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242287 train-accuracy:0.612469 valid-loss:1.191275 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:44.3445 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661702\n",
      "[INFO 24-02-22 07:36:44.3446 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.3446 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.661702 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:44.3448 UTC hyperparameters_optimizer.cc:582] [108/1100] Score: -0.661702 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:44.3452 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.3452 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.3454 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.4200 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233260 train-accuracy:0.612469 valid-loss:1.201579 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:44.4658 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668869\n",
      "[INFO 24-02-22 07:36:44.4662 UTC gradient_boosted_trees.cc:271] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.4667 UTC gradient_boosted_trees.cc:334] Final model num-trees:116 valid-loss:0.668869 valid-accuracy:0.863014\n",
      "[[INFO 24-02-22 07:36:44.4705 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.4706 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.4708 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "INFO 24-02-22 07:36:44.4719 UTC hyperparameters_optimizer.cc:582] [109/1100] Score: -0.668869 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:44.4759 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315600 train-accuracy:0.612469 valid-loss:1.274487 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:44.5053 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660532\n",
      "[INFO 24-02-22 07:36:44.5053 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.5054 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.660532 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:44.5059 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.5059 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.5061 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.5095 UTC hyperparameters_optimizer.cc:582] [110/1100] Score: -0.660532 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:44.5256 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.205544 train-accuracy:0.612469 valid-loss:1.175689 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:44.5673 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718125\n",
      "[INFO 24-02-22 07:36:44.5674 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.5675 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.718125 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:44.5681 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.5681 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.5683 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.5697 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.128958 train-accuracy:0.804401 valid-loss:1.088384 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:44.5717 UTC hyperparameters_optimizer.cc:582] [111/1100] Score: -0.718125 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:44.7000 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.737237\n",
      "[INFO 24-02-22 07:36:44.7000 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.7004 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.737237 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:44.7007 UTC hyperparameters_optimizer.cc:582] [112/1100] Score: -0.737237 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:44.7014 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.7014 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.7031 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.7080 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.608005\n",
      "[INFO 24-02-22 07:36:44.7080 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:36:44.7081 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.608005 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:44.7083 UTC hyperparameters_optimizer.cc:582] [113/1100] Score: -0.608005 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:44.7088 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:44.7088 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:44.7093 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:44.7192 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079817 train-accuracy:0.817848 valid-loss:1.056322 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:44.7500 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.919920 train-accuracy:0.935208 valid-loss:0.993042 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:45.1097 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.709639\n",
      "[INFO 24-02-22 07:36:45.1097 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:45.1100 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:45.1100 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.709639 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:45.1103 UTC hyperparameters_optimizer.cc:582] [114/1100] Score: -0.709639 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:45.1110 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:45.1110 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:45.1115 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:45.1324 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313823 train-accuracy:0.612469 valid-loss:1.272883 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:45.3799 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665347\n",
      "[INFO 24-02-22 07:36:45.3799 UTC gradient_boosted_trees.cc:271] Truncates the model to 145 tree(s) i.e. 145  iteration(s).\n",
      "[INFO 24-02-22 07:36:45.3800 UTC gradient_boosted_trees.cc:334] Final model num-trees:145 valid-loss:0.665347 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:45.3813 UTC hyperparameters_optimizer.cc:582] [115/1100] Score: [-0.665347 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:36:45.3822 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665973\n",
      "[INFO 24-02-22 07:36:45.3823 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:36:45.3826 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:45.3826 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:45.3828 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.665973 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:45.3830 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:45.3837 UTC hyperparameters_optimizer.cc:582] [116/1100] Score: -0.665973 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:45.3857 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:45.3857 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:45.3859 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:45.4137 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225123 train-accuracy:0.612469 valid-loss:1.192799 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:45.4463 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228852 train-accuracy:0.612469 valid-loss:1.195325 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:45.8211 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66313\n",
      "[INFO 24-02-22 07:36:45.8212 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:45.8213 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.663130 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:45.8217 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:45.8217 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:45.8220 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:45.8251 UTC hyperparameters_optimizer.cc:582] [117/1100] Score: -0.66313 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:45.9658 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.217064 train-accuracy:0.612469 valid-loss:1.190076 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:45.9780 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.725375\n",
      "[INFO 24-02-22 07:36:45.9780 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:45.9784 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.725375 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:45.9788 UTC hyperparameters_optimizer.cc:582] [118/1100] Score: -0.725375 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:45.9796 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:45.9796 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:45.9799 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:45.9834 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288266 train-accuracy:0.612469 valid-loss:1.249265 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:46.0257 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.720818\n",
      "[INFO 24-02-22 07:36:46.0257 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 07:36:46.0259 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.720818 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:46.0262 UTC hyperparameters_optimizer.cc:582] [119/1100] Score: -0.720818 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:46.0267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:46.0267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:46.0270 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:46.0349 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186418 train-accuracy:0.629584 valid-loss:1.131934 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:46.1290 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682291\n",
      "[INFO 24-02-22 07:36:46.1290 UTC gradient_boosted_trees.cc:271] Truncates the model to 102 tree(s) i.e. 102  iteration(s).\n",
      "[INFO 24-02-22 07:36:46.1291 UTC gradient_boosted_trees.cc:334] Final model num-trees:102 valid-loss:0.682291 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:46.1295 UTC hyperparameters_optimizer.cc:582] [120/1100] Score: -0.682291 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:46.1300 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:46.1300 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:46.1304 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:46.1724 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.064688 train-accuracy:0.832518 valid-loss:0.992078 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:46.5587 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631292\n",
      "[INFO 24-02-22 07:36:46.5587 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 07:36:46.5588 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.631292 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:36:46.5589 UTC hyperparameters_optimizer.cc:582] [121/1100] Score: -0.631292 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:46.5592 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:46.5592 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:46.5594 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:46.5906 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.038373 train-accuracy:0.822738 valid-loss:1.041446 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:46.6464 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68158\n",
      "[INFO 24-02-22 07:36:46.6464 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:36:46.6466 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.681580 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:46.6470 UTC hyperparameters_optimizer.cc:582] [122/1100] Score: -0.68158 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:46.6478 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:46.6479 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:46.6480 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:46.6688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221586 train-accuracy:0.612469 valid-loss:1.169961 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:46.9132 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850549\n",
      "[INFO 24-02-22 07:36:46.9132 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:46.9144 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:46.9144 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.850549 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:46.9151 UTC hyperparameters_optimizer.cc:582] [123/1100] Score: -0.850549 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:46.9178 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:46.9178 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:46.9180 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:46.9380 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312544 train-accuracy:0.612469 valid-loss:1.273468 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:47.4567 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659765\n",
      "[INFO 24-02-22 07:36:47.4567 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:36:47.4569 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.659765 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:47.4572 UTC hyperparameters_optimizer.cc:582] [124/1100] Score: -0.659765 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:47.4577 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:47.4577 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:47.4579 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:47.4830 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.173030 train-accuracy:0.612469 valid-loss:1.134880 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:47.9129 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.616124\n",
      "[INFO 24-02-22 07:36:47.9129 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 07:36:47.9135 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.616124 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:47.9149 UTC hyperparameters_optimizer.cc:582] [125/1100] Score: -0.616124 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:47.9156 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:47.9157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:47.9170 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:47.9661 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695875\n",
      "[INFO 24-02-22 07:36:47.9664 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:36:47.9666 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.695875 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:47.9674 UTC hyperparameters_optimizer.cc:582] [126/1100] Score: -0.695875 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:47.9692 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:47.9696 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:47.9700 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:47.9726 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114987 train-accuracy:0.768949 valid-loss:1.094284 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:36:47.9791 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313270 train-accuracy:0.612469 valid-loss:1.271832 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:48.0142 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.739018\n",
      "[INFO 24-02-22 07:36:48.0142 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:36:48.0146 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.739018 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:48.0151 UTC hyperparameters_optimizer.cc:582] [127/1100] Score: -0.739018 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:48.0158 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.0161 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.0166 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.0356 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096260 train-accuracy:0.800734 valid-loss:1.040524 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:36:48.0845 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657036\n",
      "[INFO 24-02-22 07:36:48.0845 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:36:48.0848 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.657036 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:48.0852 UTC hyperparameters_optimizer.cc:582] [128/1100] Score: -0.657036 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:48.0861 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.0862 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.0865 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.1024 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.982498 train-accuracy:0.872861 valid-loss:0.972983 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:48.2889 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639915\n",
      "[INFO 24-02-22 07:36:48.2889 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:36:48.2891 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.639915 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:48.2892 UTC hyperparameters_optimizer.cc:582] [129/1100] Score: -0.639915 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:48.2897 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.2897 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.2908 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.2929 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221349 train-accuracy:0.612469 valid-loss:1.173802 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:48.3689 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663765\n",
      "[INFO 24-02-22 07:36:48.3689 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:36:48.3691 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.663765 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:48.3694 UTC hyperparameters_optimizer.cc:582] [130/1100] Score: -0.663765 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:48.3700 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.3700 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.3704 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.4055 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246879 train-accuracy:0.612469 valid-loss:1.196695 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:48.6008 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655481\n",
      "[INFO 24-02-22 07:36:48.6008 UTC gradient_boosted_trees.cc:271] Truncates the model to 105 tree(s) i.e. 105  iteration(s).\n",
      "[INFO 24-02-22 07:36:48.6008 UTC gradient_boosted_trees.cc:334] Final model num-trees:105 valid-loss:0.655481 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:48.6021 UTC hyperparameters_optimizer.cc:582] [131/1100] Score: -0.655481 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:48.6027 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.6027 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.6029 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.6200 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655546\n",
      "[INFO 24-02-22 07:36:48.6203 UTC gradient_boosted_trees.cc:271] Truncates the model to 168 tree(s) i.e. 168  iteration(s).\n",
      "[INFO 24-02-22 07:36:48.6205 UTC gradient_boosted_trees.cc:334] Final model num-trees:168 valid-loss:0.655546 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:36:48.6229 UTC hyperparameters_optimizer.cc:582] [132/1100] Score: -0.655546 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:36:48.6241 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.6246 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.6260 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.6813 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313813 train-accuracy:0.612469 valid-loss:1.272688 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:48.6991 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234950 train-accuracy:0.612469 valid-loss:1.210051 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:48.7014 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632237\n",
      "[INFO 24-02-22 07:36:48.7014 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:36:48.7016 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.632237 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:48.7037 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.7037 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.7039 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.7070 UTC hyperparameters_optimizer.cc:582] [133/1100] Score: -0.632237 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:48.7728 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142522 train-accuracy:0.765281 valid-loss:1.136407 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:36:48.7915 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615891\n",
      "[INFO 24-02-22 07:36:48.7916 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 07:36:48.7916 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.615891 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:48.7918 UTC hyperparameters_optimizer.cc:582] [134/1100] Score: -0.615891 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:48.7921 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.7921 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.7923 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.8813 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155751 train-accuracy:0.612469 valid-loss:1.136299 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:48.9278 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.726122\n",
      "[INFO 24-02-22 07:36:48.9278 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:48.9286 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:48.9286 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.726122 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:48.9293 UTC hyperparameters_optimizer.cc:582] [135/1100] Score: -0.726122 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:48.9305 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:48.9305 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:48.9309 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:48.9585 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225257 train-accuracy:0.612469 valid-loss:1.195061 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:49.1203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640887\n",
      "[INFO 24-02-22 07:36:49.1203 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:36:49.1205 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.640887 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:49.1208 UTC hyperparameters_optimizer.cc:582] [136/1100] Score: -0.640887 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:49.1215 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:49.1215 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:49.1217 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:49.1819 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.712863\n",
      "[INFO 24-02-22 07:36:49.1819 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:36:49.1824 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.712863 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:49.1835 UTC hyperparameters_optimizer.cc:582] [137/1100] Score: -0.712863 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:49.1839 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:49.1840 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:49.1845 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:49.1893 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647198\n",
      "[INFO 24-02-22 07:36:49.1893 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 07:36:49.1894 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.647198 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:49.1898 UTC hyperparameters_optimizer.cc:582] [138/1100] Score: -0.647198 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:49.1904 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:49.1905 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:49.1907 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:49.1976 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.105073 train-accuracy:0.778729 valid-loss:1.085974 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:49.2123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.101848 train-accuracy:0.801956 valid-loss:1.098580 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:49.3157 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.019978 train-accuracy:0.869193 valid-loss:1.076213 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:49.5801 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.717445\n",
      "[INFO 24-02-22 07:36:49.5801 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:49.5825 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:49.5833 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.717445 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:49.5838 UTC hyperparameters_optimizer.cc:582] [139/1100] Score: -0.717445 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:49.5841 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:49.5841 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:49.5844 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:49.5939 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286979 train-accuracy:0.612469 valid-loss:1.246807 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:49.7927 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67985\n",
      "[INFO 24-02-22 07:36:49.7928 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:36:49.7930 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.679850 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:49.7934 UTC hyperparameters_optimizer.cc:582] [140/1100] Score: -0.67985 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:49.7950 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:49.7951 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:49.7955 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:49.8016 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230045 train-accuracy:0.612469 valid-loss:1.186798 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:49.9758 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678355\n",
      "[INFO 24-02-22 07:36:49.9765 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:36:49.9767 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.678355 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:49.9777 UTC hyperparameters_optimizer.cc:582] [141/1100] Score: -0.678355 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:49.9794 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:49.9794 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:49.9797 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.0208 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.163244 train-accuracy:0.806846 valid-loss:1.106686 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:50.1982 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671598\n",
      "[INFO 24-02-22 07:36:50.1982 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 07:36:50.1985 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.671598 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:50.2002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:50.2002 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:50.2004 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.2017 UTC hyperparameters_optimizer.cc:582] [142/1100] Score: -0.671598 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:50.2046 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222818 train-accuracy:0.612469 valid-loss:1.188851 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:50.3583 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679245\n",
      "[INFO 24-02-22 07:36:50.3584 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:36:50.3588 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.679245 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:50.3593 UTC hyperparameters_optimizer.cc:582] [143/1100] Score: -0.679245 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:50.3605 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:50.3605 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:50.3613 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.4032 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.138011 train-accuracy:0.842298 valid-loss:1.100118 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:50.4975 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64738\n",
      "[INFO 24-02-22 07:36:50.4975 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 07:36:50.4976 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.647380 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:50.4994 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:50.4994 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:50.4996 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.5051 UTC hyperparameters_optimizer.cc:582] [144/1100] Score: -0.64738 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:50.5427 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668658\n",
      "[INFO 24-02-22 07:36:50.5428 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:36:50.5430 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.668658 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:50.5435 UTC hyperparameters_optimizer.cc:582] [145/1100] Score: -0.668658 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:50.5446 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:50.5447 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:50.5470 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.5518 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.117415 train-accuracy:0.825183 valid-loss:1.105681 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:50.6096 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675677\n",
      "[INFO 24-02-22 07:36:50.6097 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 07:36:50.6099 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.675677 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:50.6110 UTC hyperparameters_optimizer.cc:582] [146/1100] Score: -0.675677 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:50.6135 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:50.6135 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:50.6138 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.6150 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291823 train-accuracy:0.612469 valid-loss:1.249402 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:50.6175 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155741 train-accuracy:0.612469 valid-loss:1.146936 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:50.6927 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685928\n",
      "[INFO 24-02-22 07:36:50.6928 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:36:50.6931 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.685928 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:50.6935 UTC hyperparameters_optimizer.cc:582] [147/1100] Score: -0.685928 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:50.6945 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:50.6946 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:50.6951 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.7042 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.088186 train-accuracy:0.837408 valid-loss:1.059902 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:50.7509 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669227\n",
      "[INFO 24-02-22 07:36:50.7512 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:36:50.7513 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.669227 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:50.7515 UTC hyperparameters_optimizer.cc:582] [148/1100] Score: -0.669227 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:50.7522 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:50.7523 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:50.7534 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.8128 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641961\n",
      "[INFO 24-02-22 07:36:50.8128 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 07:36:50.8129 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.641961 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:50.8133 UTC hyperparameters_optimizer.cc:582] [149/1100] Score: -0.641961 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:50.8135 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:50.8136 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:50.8140 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:50.8346 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281349 train-accuracy:0.612469 valid-loss:1.236242 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:50.8455 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.139825 train-accuracy:0.767726 valid-loss:1.098041 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:51.0079 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682307\n",
      "[INFO 24-02-22 07:36:51.0079 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:36:51.0088 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.682307 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:51.0105 UTC hyperparameters_optimizer.cc:582] [150/1100] Score: -0.682307 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:51.0144 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:51.0144 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:51.0147 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:51.0350 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155014 train-accuracy:0.788509 valid-loss:1.120760 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:51.1388 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645555\n",
      "[INFO 24-02-22 07:36:51.1388 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:51.1390 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.645555 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:51.1397 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:51.1397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:51.1408 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:51.1417 UTC hyperparameters_optimizer.cc:582] [151/1100] Score: -0.645555 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:51.1719 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.064976 train-accuracy:0.823961 valid-loss:1.051842 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:36:51.5742 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699117\n",
      "[INFO 24-02-22 07:36:51.5742 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:51.5744 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.699117 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:51.5747 UTC hyperparameters_optimizer.cc:582] [152/1100] Score: -0.699117 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:51.5751 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:51.5751 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:51.5769 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:51.5803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180490 train-accuracy:0.612469 valid-loss:1.126523 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:51.6972 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645283\n",
      "[INFO 24-02-22 07:36:51.6974 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:51.6976 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.645283 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:51.6978 UTC hyperparameters_optimizer.cc:582] [153/1100] Score: -0.645283 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:51.6999 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:51.7017 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:51.7019 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:51.7168 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.128497 train-accuracy:0.612469 valid-loss:1.147737 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:51.7619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643145\n",
      "[INFO 24-02-22 07:36:51.7619 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:51.7620 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.643145 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:51.7622 UTC hyperparameters_optimizer.cc:582] [154/1100] Score: -0.643145 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:51.7627 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:51.7627 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:51.7633 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:51.8344 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.061771 train-accuracy:0.815403 valid-loss:1.047440 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:51.9300 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634344\n",
      "[INFO 24-02-22 07:36:51.9300 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:51.9303 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.634344 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:36:51.9308 UTC hyperparameters_optimizer.cc:582] [155/1100] Score: -0.634344 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:36:51.9312 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:51.9312 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:51.9315 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:51.9403 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.307349 train-accuracy:0.612469 valid-loss:1.271173 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:52.2840 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703821\n",
      "[INFO 24-02-22 07:36:52.2840 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:36:52.2841 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.703821 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:52.2843 UTC hyperparameters_optimizer.cc:582] [156/1100] Score: -0.703821 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:52.2847 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:52.2847 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:52.2849 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:52.3423 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678119\n",
      "[INFO 24-02-22 07:36:52.3423 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:52.3425 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.678119 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:52.3429 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:52.3429 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:52.3431 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:52.3449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290568 train-accuracy:0.612469 valid-loss:1.247882 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:52.3451 UTC hyperparameters_optimizer.cc:582] [157/1100] Score: -0.678119 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:52.3784 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.054342 train-accuracy:0.854523 valid-loss:1.027327 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:52.4188 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.71317\n",
      "[INFO 24-02-22 07:36:52.4188 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:36:52.4202 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.713170 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:52.4211 UTC hyperparameters_optimizer.cc:582] [158/1100] Score: -0.71317 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:52.4233 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:52.4234 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:52.4237 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:52.4267 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060862 train-accuracy:0.831296 valid-loss:1.046824 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:52.5246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.728937\n",
      "[INFO 24-02-22 07:36:52.5246 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:52.5249 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:52.5250 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.728937 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:52.5251 UTC hyperparameters_optimizer.cc:582] [159/1100] Score: -0.728937 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:52.5267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:52.5267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:52.5269 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:52.5764 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62431\n",
      "[INFO 24-02-22 07:36:52.5764 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 07:36:52.5765 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.624310 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:52.5770 UTC hyperparameters_optimizer.cc:582] [160/1100] Score: -0.62431 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:52.5779 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:52.5779 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:52.5782 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:52.5819 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230175 train-accuracy:0.612469 valid-loss:1.190791 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:52.6152 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.127117 train-accuracy:0.755501 valid-loss:1.112467 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:52.7150 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687448\n",
      "[INFO 24-02-22 07:36:52.7165 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:36:52.7167 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.687448 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:52.7175 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:52.7175 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:52.7176 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:52.7189 UTC hyperparameters_optimizer.cc:582] [161/1100] Score: -0.687448 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:52.7273 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.024454 train-accuracy:0.864303 valid-loss:1.007216 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:52.7981 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.69538\n",
      "[INFO 24-02-22 07:36:52.7981 UTC gradient_boosted_trees.cc:271] Truncates the model to 129 tree(s) i.e. 129  iteration(s).\n",
      "[INFO 24-02-22 07:36:52.7994 UTC gradient_boosted_trees.cc:334] Final model num-trees:129 valid-loss:0.695380 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:52.8045 UTC hyperparameters_optimizer.cc:582] [162/1100] Score: -0.69538 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:52.8170 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:52.8170 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:52.8173 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:52.8242 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223103 train-accuracy:0.612469 valid-loss:1.196885 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:53.0430 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.791857\n",
      "[INFO 24-02-22 07:36:53.0465 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:53.0484 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:53.0484 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.791857 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:53.0488 UTC hyperparameters_optimizer.cc:582] [163/1100] Score: -0.791857 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:53.0491 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.0492 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.0493 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.0557 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.751156\n",
      "[INFO 24-02-22 07:36:53.0557 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:36:53.0560 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.751156 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:53.0563 UTC hyperparameters_optimizer.cc:582] [164/1100] Score: -0.751156 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:53.0568 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.0568 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.0571 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.0725 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.050479 train-accuracy:0.842298 valid-loss:1.008765 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:53.1074 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286425 train-accuracy:0.612469 valid-loss:1.239605 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:53.1117 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648722\n",
      "[INFO 24-02-22 07:36:53.1118 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:36:53.1119 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.648722 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:53.1124 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.1124 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.1126 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.1151 UTC hyperparameters_optimizer.cc:582] [165/1100] Score: -0.648722 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:53.1248 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278631 train-accuracy:0.612469 valid-loss:1.230206 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:53.2337 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681652\n",
      "[INFO 24-02-22 07:36:53.2337 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:36:53.2340 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.681652 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:53.2345 UTC hyperparameters_optimizer.cc:582] [166/1100] Score: -0.681652 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:53.2352 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.2352 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.2354 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.2383 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276104 train-accuracy:0.612469 valid-loss:1.245140 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:53.5040 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681154\n",
      "[INFO 24-02-22 07:36:53.5040 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 07:36:53.5046 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.681154 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:53.5061 UTC hyperparameters_optimizer.cc:582] [167/1100] Score: -0.681154 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:53.5088 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.5089 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.5092 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.5155 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241389 train-accuracy:0.612469 valid-loss:1.201027 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:53.6058 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.738028\n",
      "[INFO 24-02-22 07:36:53.6058 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:36:53.6067 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.738028 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:53.6077 UTC hyperparameters_optimizer.cc:582] [168/1100] Score: -0.738028 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:53.6093 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.6093 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.6095 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.6915 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094428 train-accuracy:0.869193 valid-loss:1.078643 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:53.8137 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642067\n",
      "[INFO 24-02-22 07:36:53.8137 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:36:53.8141 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.642067 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:53.8145 UTC hyperparameters_optimizer.cc:582] [169/1100] Score: -0.642067 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:53.8156 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.8156 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.8158 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.8560 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662373\n",
      "[INFO 24-02-22 07:36:53.8560 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:36:53.8564 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.662373 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:53.8574 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.8575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.8577 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.8584 UTC hyperparameters_optimizer.cc:582] [170/1100] Score: -0.662373 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:53.8688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285937 train-accuracy:0.612469 valid-loss:1.245345 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:53.8893 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309183 train-accuracy:0.612469 valid-loss:1.271584 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:53.9034 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676922\n",
      "[INFO 24-02-22 07:36:53.9061 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:53.9063 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:53.9063 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.676922 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:53.9068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.9068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.9070 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.9084 UTC hyperparameters_optimizer.cc:582] [171/1100] Score: -0.676922 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:53.9294 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257157 train-accuracy:0.612469 valid-loss:1.218202 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:53.9303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64659\n",
      "[INFO 24-02-22 07:36:53.9304 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:36:53.9305 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.646590 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:53.9309 UTC hyperparameters_optimizer.cc:582] [172/1100] Score: -0.64659 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:53.9331 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:53.9331 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:53.9333 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:53.9341 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225073 train-accuracy:0.612469 valid-loss:1.167497 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:54.0319 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634946\n",
      "[INFO 24-02-22 07:36:54.0320 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.0321 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.634946 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:54.0324 UTC hyperparameters_optimizer.cc:582] [173/1100] Score: -0.634946 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:54.0329 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.0332 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.0336 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.0424 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090160 train-accuracy:0.838631 valid-loss:1.058426 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:54.0609 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656198\n",
      "[INFO 24-02-22 07:36:54.0609 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.0610 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.656198 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:54.0618 UTC hyperparameters_optimizer.cc:582] [174/1100] Score: -0.656198 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:54.0625 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.0626 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.0639 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.0669 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084109 train-accuracy:0.784841 valid-loss:1.053257 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:54.1787 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.69248\n",
      "[INFO 24-02-22 07:36:54.1809 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.1812 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.692480 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:54.1817 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.1818 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.1819 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.1853 UTC hyperparameters_optimizer.cc:582] [175/1100] Score: -0.69248 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:54.1875 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317134 train-accuracy:0.612469 valid-loss:1.274258 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:54.2719 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647588\n",
      "[INFO 24-02-22 07:36:54.2719 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.2724 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.647588 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:54.2747 UTC hyperparameters_optimizer.cc:582] [176/1100] Score: -0.647588 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:54.2775 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.2775 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.2777 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.2834 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.045362 train-accuracy:0.826406 valid-loss:1.056839 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:36:54.3934 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670127\n",
      "[INFO 24-02-22 07:36:54.3935 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.3940 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.670127 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:54.3944 UTC hyperparameters_optimizer.cc:582] [177/1100] Score: -0.670127 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:54.3953 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.3954 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.3957 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.4253 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674356\n",
      "[INFO 24-02-22 07:36:54.4253 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:54.4255 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:54.4255 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.674356 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:54.4260 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.4260 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.4263 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.4284 UTC hyperparameters_optimizer.cc:582] [178/1100] Score: -0.674356 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:54.4346 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.140788 train-accuracy:0.799511 valid-loss:1.092594 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:54.4370 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247510 train-accuracy:0.612469 valid-loss:1.196141 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:54.4850 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.722068\n",
      "[INFO 24-02-22 07:36:54.4851 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:54.4855 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:54.4856 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.722068 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:54.4859 UTC hyperparameters_optimizer.cc:582] [179/1100] Score: -0.722068 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:54.4867 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.4868 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.4872 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.4928 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158086 train-accuracy:0.612469 valid-loss:1.131509 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:54.5867 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645329\n",
      "[INFO 24-02-22 07:36:54.5868 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.5873 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.645329 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:54.5886 UTC hyperparameters_optimizer.cc:582] [180/1100] Score: -0.645329 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:54.5906 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.5909 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.5914 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.6708 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142987 train-accuracy:0.765281 valid-loss:1.100802 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:36:54.8048 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.628718\n",
      "[INFO 24-02-22 07:36:54.8049 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.8051 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.628718 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:54.8054 UTC hyperparameters_optimizer.cc:582] [181/1100] Score: -0.628718 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:54.8061 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.8061 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.8065 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.8097 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151387 train-accuracy:0.764059 valid-loss:1.111168 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:36:54.9492 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661282\n",
      "[INFO 24-02-22 07:36:54.9493 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.9494 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.661282 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:36:54.9499 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.9500 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.9502 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.9503 UTC hyperparameters_optimizer.cc:582] [182/1100] Score: -0.661282 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:54.9535 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.195605 train-accuracy:0.612469 valid-loss:1.153511 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:54.9936 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659988\n",
      "[INFO 24-02-22 07:36:54.9949 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:54.9954 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.659988 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:54.9959 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:54.9959 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:54.9961 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:54.9989 UTC hyperparameters_optimizer.cc:582] [183/1100] Score: -0.659988 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:55.0115 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658993\n",
      "[INFO 24-02-22 07:36:55.0115 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:36:55.0117 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.658993 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:55.0124 UTC hyperparameters_optimizer.cc:582] [184/1100] Score: -0.658993 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:55.0140 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:55.0143 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:55.0148 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:55.0428 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.742609\n",
      "[INFO 24-02-22 07:36:55.0428 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:55.0430 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.742609 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:55.0433 UTC hyperparameters_optimizer.cc:582] [185/1100] Score: -0.742609 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:55.0438 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231465 train-accuracy:0.612469 valid-loss:1.190885 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:55.0439 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:55.0440 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:55.0443 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:55.0895 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.175287 train-accuracy:0.612469 valid-loss:1.149966 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:55.1268 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.117074 train-accuracy:0.797066 valid-loss:1.099747 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:55.2746 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670884\n",
      "[INFO 24-02-22 07:36:55.2746 UTC gradient_boosted_trees.cc:271] Truncates the model to 237 tree(s) i.e. 237  iteration(s).\n",
      "[INFO 24-02-22 07:36:55.2747 UTC gradient_boosted_trees.cc:334] Final model num-trees:237 valid-loss:0.670884 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:55.2753 UTC hyperparameters_optimizer.cc:582] [186/1100] Score: -0.670884 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:55.2764 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:55.2764 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:55.2766 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:55.2965 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.085344 train-accuracy:0.847188 valid-loss:1.054412 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:55.9060 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.811813\n",
      "[INFO 24-02-22 07:36:55.9061 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:55.9068 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:55.9068 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.811813 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:55.9073 UTC hyperparameters_optimizer.cc:582] [187/1100] Score: -0.811813 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:55.9091 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:55.9091 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:55.9093 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:55.9105 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094859 train-accuracy:0.804401 valid-loss:1.054045 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:55.9736 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672267\n",
      "[INFO 24-02-22 07:36:55.9736 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:36:55.9737 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.672267 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:55.9740 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:55.9740 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:55.9742 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:55.9751 UTC hyperparameters_optimizer.cc:582] [188/1100] Score: -0.672267 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:56.0009 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309205 train-accuracy:0.612469 valid-loss:1.271223 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:56.1507 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703345\n",
      "[INFO 24-02-22 07:36:56.1508 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:56.1511 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:56.1511 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.703345 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:56.1514 UTC hyperparameters_optimizer.cc:582] [189/1100] Score: -0.703345 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:56.1521 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.1522 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.1525 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.1606 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718684\n",
      "[INFO 24-02-22 07:36:56.1606 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.1607 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.718684 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:56.1609 UTC hyperparameters_optimizer.cc:582] [190/1100] Score: -0.718684 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }[INFO 24-02-22 07:36:56.1611 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.1612 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.1614 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "\n",
      "[INFO 24-02-22 07:36:56.1660 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223352 train-accuracy:0.612469 valid-loss:1.191292 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:56.1745 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257586 train-accuracy:0.612469 valid-loss:1.202893 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:56.3684 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664599\n",
      "[INFO 24-02-22 07:36:56.3684 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.3687 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.664599 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:56.3702 UTC hyperparameters_optimizer.cc:582] [191/1100] Score: -0.664599 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:56.3717 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.3717 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.3719 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.3722 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703361\n",
      "[INFO 24-02-22 07:36:56.3722 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.3727 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.703361 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:56.3735 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.3736 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.3737 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.3751 UTC hyperparameters_optimizer.cc:582] [192/1100] Score: -0.703361 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:56.3763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070940 train-accuracy:0.826406 valid-loss:1.045910 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:36:56.4312 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155613 train-accuracy:0.759169 valid-loss:1.122929 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:36:56.4897 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678216\n",
      "[INFO 24-02-22 07:36:56.4897 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.4900 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.678216 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:56.4902 UTC hyperparameters_optimizer.cc:582] [193/1100] Score: -0.678216 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:56.4910 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.4911 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.4913 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.4941 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.118205 train-accuracy:0.811736 valid-loss:1.107850 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:56.6108 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678811\n",
      "[INFO 24-02-22 07:36:56.6108 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.6110 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.678811 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:56.6113 UTC hyperparameters_optimizer.cc:582] [194/1100] Score: -0.678811 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:56.6120 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.6121 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.6125 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.6236 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654955\n",
      "[INFO 24-02-22 07:36:56.6236 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.6237 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.654955 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:56.6240 UTC hyperparameters_optimizer.cc:582] [195/1100] Score: -0.654955 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO[INFO 24-02-22 07:36:56.6251 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss:  24-02-22 07:36:56.6251 UTC gradient_boosted_trees.cc:0.682369591\n",
      "] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[ 24-02-22 07:36:56.6251 UTC gradient_boosted_trees.cc:271] Truncates the model to INFO 24-02-22 07:36:56.6252 UTC 23 tree(s) i.e. 23  iteration(s).\n",
      "gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.6255 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73[INFO examples used for validation\n",
      " 24-02-22 07:36:56.6255 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.682369 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:36:56.6262 UTC hyperparameters_optimizer.cc:582] [196/1100] Score: -0.682369 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:36:56.6267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.6267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.6270 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.6274 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233219 train-accuracy:0.612469 valid-loss:1.194941 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:56.6424 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.100873 train-accuracy:0.825183 valid-loss:1.096412 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:56.6842 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094428 train-accuracy:0.869193 valid-loss:1.078643 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:56.6891 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.70883\n",
      "[INFO 24-02-22 07:36:56.6891 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.6897 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.708830 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:56.6909 UTC hyperparameters_optimizer.cc:582] [197/1100] Score: -0.70883 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:56.6922 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.6922 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.6924 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.6977 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.113182 train-accuracy:0.776284 valid-loss:1.093094 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:56.7444 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653707\n",
      "[INFO 24-02-22 07:36:56.7444 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.7446 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.653707 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:36:56.7451 UTC hyperparameters_optimizer.cc:582] [198/1100] Score: -0.653707 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "INFO 24-02-22 07:36:56.7454 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.7454 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.7457 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.8550 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.168798 train-accuracy:0.612469 valid-loss:1.127674 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:56.8567 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651351\n",
      "[INFO 24-02-22 07:36:56.8568 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.8569 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.651351 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:56.8575 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.8575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.8577 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.8585 UTC hyperparameters_optimizer.cc:582] [199/1100] Score: -0.651351 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:56.8647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190401 train-accuracy:0.612469 valid-loss:1.181130 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:56.8929 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668863\n",
      "[INFO 24-02-22 07:36:56.8929 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.8931 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.668863 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:56.8934 UTC hyperparameters_optimizer.cc:582] [200/1100] Score: -0.668863 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:56.8940 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.8940 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.8943 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.8952 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.161644 train-accuracy:0.612469 valid-loss:1.093293 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:56.9520 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678311\n",
      "[INFO 24-02-22 07:36:56.9520 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.9521 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.678311 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:56.9523 UTC hyperparameters_optimizer.cc:582] [201/1100] Score: -0.678311 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:56.9526 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.9526 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.9529 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:56.9738 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657982\n",
      "[INFO 24-02-22 07:36:56.9738 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:56.9751 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.657982 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:56.9764 UTC hyperparameters_optimizer.cc:582] [202/1100] Score: -0.657982 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:56.9778 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:56.9780 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:56.9840 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:57.0098 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.256030 train-accuracy:0.612469 valid-loss:1.242209 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:57.0098 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257586 train-accuracy:0.612469 valid-loss:1.202893 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:57.3303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.737216\n",
      "[INFO 24-02-22 07:36:57.3304 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:57.3321 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.737216 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:57.3351 UTC hyperparameters_optimizer.cc:582] [203/1100] Score: -0.737216 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:57.3385 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:57.3386 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:57.3389 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:57.3640 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314181 train-accuracy:0.612469 valid-loss:1.272506 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:57.4576 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.698708\n",
      "[INFO 24-02-22 07:36:57.4577 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:57.4582 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:57.4582 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.698708 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:57.4593 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:57.4593 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:57.4598 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:57.4618 UTC hyperparameters_optimizer.cc:582] [204/1100] Score: -0.698708 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:57.4640 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281688 train-accuracy:0.612469 valid-loss:1.247615 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:57.6996 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663763\n",
      "[INFO 24-02-22 07:36:57.6996 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 07:36:57.7000 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.663763 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:57.7010 UTC hyperparameters_optimizer.cc:582] [205/1100] Score: -0.663763 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:57.7030 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:57.7030 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:57.7032 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:57.7037 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655825\n",
      "[INFO 24-02-22 07:36:57.7038 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:36:57.7038 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.655825 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:57.7039 UTC hyperparameters_optimizer.cc:582] [206/1100] Score: -0.655825 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:57.7042 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:57.7042 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:57.7044 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:57.7066 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.048118 train-accuracy:0.864303 valid-loss:1.021544 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:57.7251 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311017 train-accuracy:0.612469 valid-loss:1.273227 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:57.7644 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658419\n",
      "[INFO 24-02-22 07:36:57.7645 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 07:36:57.7646 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.658419 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:57.7653 UTC hyperparameters_optimizer.cc:582] [207/1100] Score: -0.658419 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:57.7658 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:57.7660 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:57.7664 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:57.8253 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666539\n",
      "[INFO 24-02-22 07:36:57.8253 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:36:57.8256 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.666539 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:57.8258 UTC hyperparameters_optimizer.cc:582] [208/1100] Score: -0.666539 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:57.8262 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:57.8262 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:57.8264 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:57.8293 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238246 train-accuracy:0.612469 valid-loss:1.209297 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:57.8739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207559 train-accuracy:0.612469 valid-loss:1.228581 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:57.9893 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673256\n",
      "[INFO 24-02-22 07:36:57.9893 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 07:36:57.9895 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.673256 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:57.9903 UTC hyperparameters_optimizer.cc:582] [209/1100] Score: -0.673256 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:57.9909 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:57.9909 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:57.9917 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:58.0174 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222448 train-accuracy:0.612469 valid-loss:1.191909 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:58.0332 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67699\n",
      "[INFO 24-02-22 07:36:58.0342 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:36:58.0344 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.676990 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:58.0348 UTC hyperparameters_optimizer.cc:582] [210/1100] Score: -0.67699 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:58.0365 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:58.0366 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:58.0368 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:58.0393 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159613 train-accuracy:0.759169 valid-loss:1.129408 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:58.1617 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659499\n",
      "[INFO 24-02-22 07:36:58.1633 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:36:58.1635 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.659499 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:58.1641 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:58.1641 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:58.1644 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:58.1644 UTC hyperparameters_optimizer.cc:582] [211/1100] Score: -0.659499 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:58.1667 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.118386 train-accuracy:0.789731 valid-loss:1.079604 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:36:58.1974 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718857\n",
      "[INFO 24-02-22 07:36:58.2053 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:36:58.2054 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.718857 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:58.2059 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:58.2059 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:58.2061 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:58.2089 UTC hyperparameters_optimizer.cc:582] [212/1100] Score: -0.718857 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:58.2179 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.075170 train-accuracy:0.843521 valid-loss:1.037164 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:58.5907 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665519\n",
      "[INFO 24-02-22 07:36:58.5908 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:58.5911 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.665519 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:58.5913 UTC hyperparameters_optimizer.cc:582] [213/1100] Score: -0.665519 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:58.5945 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:58.5948 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:58.5950 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:58.6048 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153954 train-accuracy:0.756724 valid-loss:1.127166 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:36:58.9118 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.732391\n",
      "[INFO 24-02-22 07:36:58.9121 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:58.9123 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:58.9123 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.732391 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:58.9125 UTC hyperparameters_optimizer.cc:582] [214/1100] Score: -0.732391 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:36:58.9135 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:58.9135 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:58.9138 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:58.9839 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.104721 train-accuracy:0.816626 valid-loss:1.050643 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:36:59.0522 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655825\n",
      "[INFO 24-02-22 07:36:59.0522 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.0523 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.655825 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:59.0525 UTC hyperparameters_optimizer.cc:582] [215/1100] Score: -0.655825 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:59.0531 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.0531 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.0535 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.0823 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229612 train-accuracy:0.612469 valid-loss:1.199995 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:59.2583 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659242\n",
      "[INFO 24-02-22 07:36:59.2583 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.2585 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.659242 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:36:59.2587 UTC hyperparameters_optimizer.cc:582] [216/1100] Score: -0.659242 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:59.2593 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.2593 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.2596 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.2620 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244125 train-accuracy:0.612469 valid-loss:1.208539 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:59.2656 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671945\n",
      "[INFO 24-02-22 07:36:59.2656 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.2660 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.671945 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:59.2664 UTC hyperparameters_optimizer.cc:582] [217/1100] Score: -0.671945 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:59.2671 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.2672 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.2675 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.2704 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.150945 train-accuracy:0.767726 valid-loss:1.115327 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:59.2754 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683135\n",
      "[INFO 24-02-22 07:36:59.2754 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.2756 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.683135 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:59.2759 UTC hyperparameters_optimizer.cc:582] [218/1100] Score: -0.683135 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:59.2764 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.2764 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.2767 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.3226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314399 train-accuracy:0.612469 valid-loss:1.270992 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:59.4285 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691566\n",
      "[INFO 24-02-22 07:36:59.4286 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.4294 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.691566 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:59.4297 UTC hyperparameters_optimizer.cc:582] [219/1100] Score: -0.691566 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:59.4304 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.4304 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.4306 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.4322 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305534 train-accuracy:0.612469 valid-loss:1.270767 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:59.5078 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.698708\n",
      "[INFO 24-02-22 07:36:59.5078 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:36:59.5082 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:36:59.5082 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.698708 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:59.5085 UTC hyperparameters_optimizer.cc:582] [220/1100] Score: -0.698708 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:59.5093 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.5094 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.5098 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.5200 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643566\n",
      "[INFO 24-02-22 07:36:59.5200 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.5202 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.643566 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:59.5207 UTC hyperparameters_optimizer.cc:582] [221/1100] Score: -0.643566 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:36:59.5210 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.5210 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.5215 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.5420 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.036503 train-accuracy:0.932763 valid-loss:1.139379 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:36:59.5531 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638274\n",
      "[INFO 24-02-22 07:36:59.5532 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.5534 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.638274 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:36:59.5538 UTC hyperparameters_optimizer.cc:582] [222/1100] Score: -0.638274 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:36:59.5548 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.5548 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.5552 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.5753 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188928 train-accuracy:0.612469 valid-loss:1.139315 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:59.6338 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695954\n",
      "[INFO 24-02-22 07:36:59.6338 UTC gradient_boosted_trees.cc:271] Truncates the model to 114 tree(s) i.e. 114  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.6348 UTC gradient_boosted_trees.cc:334] Final model num-trees:114 valid-loss:0.695954 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:59.6496 UTC hyperparameters_optimizer.cc:582] [223/1100] Score: -0.695954 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:36:59.6697 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182464 train-accuracy:0.612469 valid-loss:1.151669 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:36:59.6808 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.6808 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.6810 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.7115 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.030098 train-accuracy:0.848411 valid-loss:0.996657 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:36:59.7319 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626767\n",
      "[INFO 24-02-22 07:36:59.7319 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:36:59.7322 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.626767 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:36:59.7325 UTC hyperparameters_optimizer.cc:582] [224/1100] Score: -0.626767 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:36:59.7334 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:36:59.7335 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:36:59.7339 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:36:59.7425 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.138534 train-accuracy:0.773839 valid-loss:1.085534 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:37:00.0201 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652409\n",
      "[INFO 24-02-22 07:37:00.0202 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:00.0204 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:00.0204 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.652409 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:00.0206 UTC hyperparameters_optimizer.cc:582] [225/1100] Score: -0.652409 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:00.0221 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:00.0221 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:00.0223 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:00.0479 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187016 train-accuracy:0.612469 valid-loss:1.152406 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:00.2460 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631124\n",
      "[INFO 24-02-22 07:37:00.2460 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:00.2462 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.631124 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:00.2465 UTC hyperparameters_optimizer.cc:582] [226/1100] Score: -0.631124 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:00.2471 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:00.2471 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:00.2475 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:00.2902 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.095673 train-accuracy:0.800734 valid-loss:1.035836 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:00.6230 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673364\n",
      "[INFO 24-02-22 07:37:00.6230 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 07:37:00.6234 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.673364 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:00.6253 UTC hyperparameters_optimizer.cc:582] [227/1100] Score: -0.673364 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:00.6286 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:00.6286 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:00.6288 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:00.6300 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159935 train-accuracy:0.794621 valid-loss:1.126971 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:00.6996 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691439\n",
      "[INFO 24-02-22 07:37:00.6997 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:37:00.6997 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.691439 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:00.6999 UTC hyperparameters_optimizer.cc:582] [228/1100] Score: -0.691439 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:00.7004 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:00.7004 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:00.7007 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:00.7532 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094498 train-accuracy:0.612469 valid-loss:1.128783 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:00.7696 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.708261\n",
      "[INFO 24-02-22 07:37:00.7702 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:00.7704 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:00.7704 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.708261 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:00.7708 UTC hyperparameters_optimizer.cc:582] [229/1100] Score: -0.708261 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:00.7711 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:00.7711 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:00.7713 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:00.7974 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640782\n",
      "[INFO 24-02-22 07:37:00.7975 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:00.7977 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.640782 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:00.8007 UTC hyperparameters_optimizer.cc:582] [230/1100] Score: -0.640782 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:00.8012 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:00.8012 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:00.8014 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:00.8661 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.011535 train-accuracy:0.865526 valid-loss:1.010164 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:00.8732 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.785087\n",
      "[INFO 24-02-22 07:37:00.8732 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:00.8750 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.785087 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:00.8764 UTC hyperparameters_optimizer.cc:582] [231/1100] Score: -0.785087 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:00.8795 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:00.8796 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:00.8805 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:00.8834 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.100478 train-accuracy:0.808068 valid-loss:1.071728 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:00.9877 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.994504 train-accuracy:0.927873 valid-loss:1.079749 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:00.9915 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670556\n",
      "[INFO 24-02-22 07:37:00.9915 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:00.9917 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:00.9917 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.670556 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:00.9919 UTC hyperparameters_optimizer.cc:582] [232/1100] Score: -0.670556 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:00.9939 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:00.9940 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:00.9941 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:00.9962 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295491 train-accuracy:0.612469 valid-loss:1.251656 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:01.3526 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640196\n",
      "[INFO 24-02-22 07:37:01.3526 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 07:37:01.3528 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.640196 valid-accuracy:0.904110\n",
      "[[INFO 24-02-22 07:37:01.3541 UTC hyperparameters_optimizer.cc:582] [233/1100] Score: -0.640196 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:37:01.3549 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:01.3549 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:01.3569 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-22 07:37:01.3622 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.623146\n",
      "[INFO 24-02-22 07:37:01.3624 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:01.3626 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.623146 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:01.3632 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:01.3632 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:01.3634 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      " 24-02-22 07:37:01.3617 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060311 train-accuracy:0.878973 valid-loss:1.072887 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:01.3652 UTC hyperparameters_optimizer.cc:582] [234/1100] Score: -0.623146 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:01.3704 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278931 train-accuracy:0.612469 valid-loss:1.243387 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:01.4313 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664468\n",
      "[INFO 24-02-22 07:37:01.4313 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 07:37:01.4313 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.664468 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:01.4316 UTC hyperparameters_optimizer.cc:582] [235/1100] Score: -0.664468 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:01.4353 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:01.4353 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:01.4356 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:01.4387 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311152 train-accuracy:0.612469 valid-loss:1.273380 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:01.5691 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.774872\n",
      "[INFO 24-02-22 07:37:01.5691 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:01.5694 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:01.5694 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.774872 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:01.5698 UTC hyperparameters_optimizer.cc:582] [236/1100] Score: -0.774872 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:01.5702 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:01.5703 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:01.5704 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:01.5790 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.067698 train-accuracy:0.826406 valid-loss:1.048831 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:01.6000 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656781\n",
      "[INFO 24-02-22 07:37:01.6000 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 07:37:01.6002 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.656781 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:01.6011 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:01.6011 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:01.6013 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:01.6053 UTC hyperparameters_optimizer.cc:582] [237/1100] Score: -0.656781 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:01.6458 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.120201 train-accuracy:0.612469 valid-loss:1.140624 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:01.8303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67889\n",
      "[INFO 24-02-22 07:37:01.8304 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 07:37:01.8306 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.678890 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:01.8326 UTC hyperparameters_optimizer.cc:582] [238/1100] Score: -0.67889 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:01.8360 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:01.8360 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:01.8363 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:01.8455 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314866 train-accuracy:0.612469 valid-loss:1.275352 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:01.9981 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.742805\n",
      "[INFO 24-02-22 07:37:01.9981 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:01.9984 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:01.9984 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.742805 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:01.9991 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:01.9991 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:01.9993 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.0018 UTC hyperparameters_optimizer.cc:582] [239/1100] Score: -0.742805 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:02.0132 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.198941 train-accuracy:0.612469 valid-loss:1.154649 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:02.0786 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646879\n",
      "[INFO 24-02-22 07:37:02.0828 UTC gradient_boosted_trees.cc:271] Truncates the model to 162 tree(s) i.e. 162  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.0836 UTC gradient_boosted_trees.cc:334] Final model num-trees:162 valid-loss:0.646879 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:02.0879 UTC hyperparameters_optimizer.cc:582] [240/1100] Score: -0.646879 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:02.0897 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.0897 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.0910 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.2326 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.308494 train-accuracy:0.612469 valid-loss:1.270277 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:02.3666 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689758\n",
      "[INFO 24-02-22 07:37:02.3666 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.3667 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.689758 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:02.3669 UTC hyperparameters_optimizer.cc:582] [241/1100] Score: -0.689758 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:02.3672 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.3672 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.3674 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.3695 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224188 train-accuracy:0.612469 valid-loss:1.161328 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:02.4204 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664137\n",
      "[INFO 24-02-22 07:37:02.4204 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.4204 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.664137 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:02.4208 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.4208 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.4211 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.4218 UTC hyperparameters_optimizer.cc:582] [242/1100] Score: -0.664137 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:02.4242 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151042 train-accuracy:0.797066 valid-loss:1.102587 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:02.4773 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.758743\n",
      "[INFO 24-02-22 07:37:02.4773 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.4788 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.758743 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:02.4818 UTC hyperparameters_optimizer.cc:582] [243/1100] Score: -0.758743 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:02.4882 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.4884 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.4887 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.4897 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266932 train-accuracy:0.612469 valid-loss:1.222473 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:02.5254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663587\n",
      "[INFO 24-02-22 07:37:02.5254 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.5255 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.663587 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:02.5259 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.5259 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.5262 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.5284 UTC hyperparameters_optimizer.cc:582] [244/1100] Score: -0.663587 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:02.5351 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666434\n",
      "[INFO 24-02-22 07:37:02.5351 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.5353 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.666434 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:02.5356 UTC hyperparameters_optimizer.cc:582] [245/1100] Score: -0.666434 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:02.5363 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.5363 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.5399 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.5420 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313344 train-accuracy:0.612469 valid-loss:1.275926 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:02.5474 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.154485 train-accuracy:0.772616 valid-loss:1.104562 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:02.6239 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666422\n",
      "[INFO 24-02-22 07:37:02.6239 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.6239 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.666422 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:02.6242 UTC hyperparameters_optimizer.cc:582] [246/1100] Score: -0.666422 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:02.6244 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.6244 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.6249 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.6321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277268 train-accuracy:0.612469 valid-loss:1.232122 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:02.6737 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.616662\n",
      "[INFO 24-02-22 07:37:02.6738 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.6740 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.616662 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:02.6745 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.6745 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.6746 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.6751 UTC hyperparameters_optimizer.cc:582] [247/1100] Score: -0.616662 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:02.7437 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313138 train-accuracy:0.612469 valid-loss:1.271790 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:02.8313 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643777\n",
      "[INFO 24-02-22 07:37:02.8314 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.8315 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.643777 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:02.8318 UTC hyperparameters_optimizer.cc:582] [248/1100] Score: -0.643777 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:02.8321 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.8322 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.8325 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.8956 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281871 train-accuracy:0.612469 valid-loss:1.244157 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:02.9093 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.617022\n",
      "[INFO 24-02-22 07:37:02.9094 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:02.9095 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.617022 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:02.9099 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:02.9099 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:02.9101 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:02.9119 UTC hyperparameters_optimizer.cc:582] [249/1100] Score: -0.617022 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:02.9364 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.041570 train-accuracy:0.847188 valid-loss:1.015057 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:03.1774 UTC gradient_boosted_trees.cc:1638] \tnum-trees:69 train-loss:0.299890 train-accuracy:0.965770 valid-loss:0.701475 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:03.2209 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661474\n",
      "[INFO 24-02-22 07:37:03.2210 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 07:37:03.2213 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.661474 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:03.2224 UTC hyperparameters_optimizer.cc:582] [250/1100] Score: -0.661474 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:03.2228 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.2229 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:03.2235 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.3197 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.106817 train-accuracy:0.797066 valid-loss:1.101373 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:03.4958 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653715\n",
      "[INFO 24-02-22 07:37:03.4958 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 07:37:03.4961 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.653715 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:03.4969 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690438\n",
      "[INFO 24-02-22 07:37:03.4969 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:03.4974 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.690438 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:03.4979 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.4979 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:03.4981 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.4988 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.4988 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:03.4990 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.5011 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.027099 train-accuracy:0.863081 valid-loss:1.055566 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:03.5017 UTC hyperparameters_optimizer.cc:582] [251/1100] Score: -0.653715 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:03.5038 UTC hyperparameters_optimizer.cc:582] [252/1100] Score: -0.690438 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:03.5183 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.192791 train-accuracy:0.612469 valid-loss:1.155576 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:03.6207 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.74246\n",
      "[INFO 24-02-22 07:37:03.6208 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:03.6210 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:03.6211 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.742460 valid-accuracy:0.849315\n",
      "[[INFO 24-02-22 07:37:03.6217 UTC hyperparameters_optimizer.cc:582] [253/1100] Score: -0.74246 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }INFO 24-02-22 07:37:03.6218 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.6218 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "\n",
      "[INFO 24-02-22 07:37:03.6223 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.6261 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233148 train-accuracy:0.612469 valid-loss:1.198329 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:03.6489 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.611799\n",
      "[INFO 24-02-22 07:37:03.6490 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:37:03.6492 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.611799 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:03.6495 UTC hyperparameters_optimizer.cc:582] [254/1100] Score: -0.611799 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:03.6500 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.6500 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:03.6503 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.6528 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079515 train-accuracy:0.795844 valid-loss:1.022720 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:37:03.6635 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667689\n",
      "[INFO 24-02-22 07:37:03.6637 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 07:37:03.6658 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.667689 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:03.6667 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.6667 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:03.6669 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.6687 UTC hyperparameters_optimizer.cc:582] [255/1100] Score: -0.667689 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:03.6935 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230222 train-accuracy:0.612469 valid-loss:1.181449 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:03.7756 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.70337\n",
      "[INFO 24-02-22 07:37:03.7756 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:03.7759 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.703370 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:03.7761 UTC hyperparameters_optimizer.cc:582] [256/1100] Score: -0.70337 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:03.7775 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.7775 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:03.7777 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.7831 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.124937 train-accuracy:0.762836 valid-loss:1.092539 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:37:03.8871 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.746112\n",
      "[INFO 24-02-22 07:37:03.8872 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:03.8888 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:03.8888 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.746112 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:03.8894 UTC hyperparameters_optimizer.cc:582] [257/1100] Score: -0.746112 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:03.8925 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.8926 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:03.8928 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.8951 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.194943 train-accuracy:0.612469 valid-loss:1.151149 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:03.9335 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643579\n",
      "[INFO 24-02-22 07:37:03.9335 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:03.9336 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.643579 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:03.9341 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:03.9341 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:03.9345 UTC hyperparameters_optimizer.cc:582] [258/1100] Score: -0.643579 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:03.9348 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:03.9840 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.273290 train-accuracy:0.612469 valid-loss:1.238696 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:04.0352 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669832\n",
      "[INFO 24-02-22 07:37:04.0352 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:37:04.0354 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.669832 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:04.0357 UTC hyperparameters_optimizer.cc:582] [259/1100] Score: -0.669832 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:04.0364 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:04.0364 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:04.0366 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:04.0500 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684525\n",
      "[INFO 24-02-22 07:37:04.0501 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:04.0503 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:04.0504 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.684525 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:04.0506 UTC hyperparameters_optimizer.cc:582] [260/1100] Score: -0.684525 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:04.0513 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:04.0514 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:04.0518 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:04.0568 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287538 train-accuracy:0.612469 valid-loss:1.241369 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:04.1293 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.269909 train-accuracy:0.612469 valid-loss:1.238711 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:04.1747 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646845\n",
      "[INFO 24-02-22 07:37:04.1747 UTC gradient_boosted_trees.cc:271] Truncates the model to 170 tree(s) i.e. 170  iteration(s).\n",
      "[INFO 24-02-22 07:37:04.1750 UTC gradient_boosted_trees.cc:334] Final model num-trees:170 valid-loss:0.646845 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:04.1771 UTC hyperparameters_optimizer.cc:582] [261/1100] Score: -0.646845 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:04.1794 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:04.1794 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:04.1797 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:04.2279 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.068623 train-accuracy:0.825183 valid-loss:1.011911 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:04.3806 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.761645\n",
      "[INFO 24-02-22 07:37:04.3806 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:04.3825 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.761645 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:04.3833 UTC hyperparameters_optimizer.cc:582] [262/1100] Score: -0.761645 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:04.3872 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:04.3872 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:04.3881 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:04.4612 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.067848 train-accuracy:0.820293 valid-loss:1.033960 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:04.5573 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668986\n",
      "[INFO 24-02-22 07:37:04.5573 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:04.5575 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.668986 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:04.5578 UTC hyperparameters_optimizer.cc:582] [263/1100] Score: -0.668986 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:04.5583 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:04.5583 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:04.5587 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:04.5633 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.049300 train-accuracy:0.836186 valid-loss:1.050968 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:04.7370 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677871\n",
      "[INFO 24-02-22 07:37:04.7370 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 07:37:04.7372 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.677871 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:04.7376 UTC hyperparameters_optimizer.cc:582] [264/1100] Score: -0.677871 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:04.7385 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:04.7386 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:04.7389 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:04.7803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290371 train-accuracy:0.612469 valid-loss:1.243847 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:04.7928 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648722\n",
      "[INFO 24-02-22 07:37:04.7963 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:04.7977 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.648722 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:04.7990 UTC hyperparameters_optimizer.cc:582] [265/1100] Score: -0.648722 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:04.8018 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:04.8018 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:04.8020 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:04.8249 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278908 train-accuracy:0.612469 valid-loss:1.248966 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:05.0434 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646108\n",
      "[INFO 24-02-22 07:37:05.0434 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 07:37:05.0438 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.646108 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:05.0456 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.0456 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.0458 UTC hyperparameters_optimizer.cc:582] [266/1100] Score: -0.646108 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:05.0479 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:05.0505 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.216841 train-accuracy:0.612469 valid-loss:1.179103 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:05.1166 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661591\n",
      "[INFO 24-02-22 07:37:05.1166 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:05.1168 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.661591 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:05.1175 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.1175 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.1178 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:05.1184 UTC hyperparameters_optimizer.cc:582] [267/1100] Score: -0.661591 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:05.1235 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.046089 train-accuracy:0.859413 valid-loss:0.991095 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:05.2025 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694428\n",
      "[INFO 24-02-22 07:37:05.2026 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:05.2029 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.694428 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:05.2035 UTC hyperparameters_optimizer.cc:582] [268/1100] Score: -0.694428 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:05.2043 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.2044 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.2046 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:05.2119 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311285 train-accuracy:0.612469 valid-loss:1.269410 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:05.2700 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638227\n",
      "[INFO 24-02-22 07:37:05.2701 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:05.2705 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:05.2705 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.638227 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:05.2713 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.2713 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.2715 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:05.2717 UTC hyperparameters_optimizer.cc:582] [269/1100] Score: -0.638227 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:05.2760 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184647 train-accuracy:0.612469 valid-loss:1.134466 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:05.3207 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690396\n",
      "[INFO 24-02-22 07:37:05.3207 UTC gradient_boosted_trees.cc:271] Truncates the model to 157 tree(s) i.e. 157  iteration(s).\n",
      "[INFO 24-02-22 07:37:05.3210 UTC gradient_boosted_trees.cc:334] Final model num-trees:157 valid-loss:0.690396 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:05.3250 UTC hyperparameters_optimizer.cc:582] [270/1100] Score: -0.690396 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:05.3254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.598754\n",
      "[INFO 24-02-22 07:37:05.3254 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:05.3256 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.598754 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:05.3258 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.3259 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.3261 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.3261 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.3263 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:05.3279 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:05.3318 UTC hyperparameters_optimizer.cc:582] [271/1100] Score: -0.598754 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:05.3377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063501 train-accuracy:0.877751 valid-loss:1.047626 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:05.3559 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122944 train-accuracy:0.831296 valid-loss:1.085277 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:05.3942 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.731068\n",
      "[INFO 24-02-22 07:37:05.3944 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:37:05.3947 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.731068 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:05.3952 UTC hyperparameters_optimizer.cc:582] [272/1100] Score: -0.731068 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:05.3957 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.3957 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.3960 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:05.4023 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239300 train-accuracy:0.612469 valid-loss:1.195041 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:05.7949 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635016\n",
      "[INFO 24-02-22 07:37:05.7950 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:05.7953 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.635016 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:05.7955 UTC hyperparameters_optimizer.cc:582] [273/1100] Score: -0.635016 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:05.7962 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.7962 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.7965 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:05.7991 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314911 train-accuracy:0.612469 valid-loss:1.273712 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:05.9698 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.698333\n",
      "[INFO 24-02-22 07:37:05.9699 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:37:05.9701 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.698333 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:05.9706 UTC hyperparameters_optimizer.cc:582] [274/1100] Score: -0.698333 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:05.9715 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:05.9716 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:05.9720 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:06.0080 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275799 train-accuracy:0.612469 valid-loss:1.240367 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:06.1543 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665045\n",
      "[INFO 24-02-22 07:37:06.1543 UTC gradient_boosted_trees.cc:271] Truncates the model to 151 tree(s) i.e. 151  iteration(s).\n",
      "[INFO 24-02-22 07:37:06.1544 UTC gradient_boosted_trees.cc:334] Final model num-trees:151 valid-loss:0.665045 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:06.1557 UTC hyperparameters_optimizer.cc:582] [275/1100] Score: -0.665045 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:06.1570 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:06.1570 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:06.1573 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:06.1810 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312925 train-accuracy:0.612469 valid-loss:1.273352 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:06.3354 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655709\n",
      "[INFO 24-02-22 07:37:06.3354 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 07:37:06.3359 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.655709 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:06.3375 UTC hyperparameters_optimizer.cc:582] [276/1100] Score: -0.655709 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:06.3413 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:06.3413 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:06.3416 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:06.3743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.160589 train-accuracy:0.612469 valid-loss:1.150782 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:06.7994 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661431\n",
      "[INFO 24-02-22 07:37:06.7994 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:37:06.7996 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.661431 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:06.8002 UTC hyperparameters_optimizer.cc:582] [277/1100] Score: -0.661431 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:06.8009 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:06.8009 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:06.8011 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:06.8073 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315528 train-accuracy:0.612469 valid-loss:1.274264 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:06.9773 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686062\n",
      "[INFO 24-02-22 07:37:06.9773 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 07:37:06.9775 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.686062 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:06.9784 UTC hyperparameters_optimizer.cc:582] [278/1100] Score: -0.686062 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:06.9792 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:06.9792 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:06.9796 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:06.9827 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.166784 train-accuracy:0.612469 valid-loss:1.162761 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:07.0440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651026\n",
      "[INFO 24-02-22 07:37:07.0440 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 07:37:07.0441 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.651026 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:07.0447 UTC hyperparameters_optimizer.cc:582] [279/1100] Score: -0.651026 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:07.0451 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:07.0451 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:07.0457 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:07.0686 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.160105 train-accuracy:0.612469 valid-loss:1.151052 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:07.1087 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644087\n",
      "[INFO 24-02-22 07:37:07.1090 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:07.1093 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.644087 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:07.1097 UTC hyperparameters_optimizer.cc:582] [280/1100] Score: -0.644087 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:07.1102 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:07.1104 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:07.1109 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:07.1252 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679928\n",
      "[INFO 24-02-22 07:37:07.1253 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:07.1255 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.679928 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:07.1258 UTC hyperparameters_optimizer.cc:582] [281/1100] Score: -0.679928 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:07.1265 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:07.1265 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:07.1267 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:07.1299 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277662 train-accuracy:0.612469 valid-loss:1.237665 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:07.1377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.215062 train-accuracy:0.612469 valid-loss:1.207798 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:07.3686 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664793\n",
      "[INFO 24-02-22 07:37:07.3686 UTC gradient_boosted_trees.cc:271] Truncates the model to 56 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 24-02-22 07:37:07.3688 UTC gradient_boosted_trees.cc:334] Final model num-trees:56 valid-loss:0.664793 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:07.3694 UTC hyperparameters_optimizer.cc:582] [282/1100] Score: -0.664793 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:07.3710 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:07.3711 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:07.3714 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:07.3741 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122378 train-accuracy:0.762836 valid-loss:1.096239 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:37:07.4920 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646322\n",
      "[INFO 24-02-22 07:37:07.4953 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:07.4958 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.646322 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:07.4960 UTC hyperparameters_optimizer.cc:582] [283/1100] Score: -0.646322 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:07.4983 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:07.4985 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:07.4988 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:07.5234 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.038695 train-accuracy:0.831296 valid-loss:1.006656 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:07.7143 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687487\n",
      "[INFO 24-02-22 07:37:07.7144 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:07.7146 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.687487 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:07.7148 UTC hyperparameters_optimizer.cc:582] [284/1100] Score: -0.687487 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:07.7152 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:07.7152 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:07.7154 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:07.7557 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.979866 train-accuracy:0.886308 valid-loss:1.019498 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:07.8171 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.740478\n",
      "[INFO 24-02-22 07:37:07.8171 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:07.8175 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.740478 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:07.8180 UTC hyperparameters_optimizer.cc:582] [285/1100] Score: -0.740478 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:07.8214 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:07.8214 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:07.8216 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:07.8375 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209582 train-accuracy:0.612469 valid-loss:1.156518 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:08.1451 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653159\n",
      "[INFO 24-02-22 07:37:08.1451 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.1454 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.653159 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:08.1456 UTC hyperparameters_optimizer.cc:582] [286/1100] Score: -0.653159 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:08.1462 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.1462 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.1468 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.1500 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083472 train-accuracy:0.830073 valid-loss:1.053901 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:08.2638 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669263\n",
      "[INFO 24-02-22 07:37:08.2638 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.2642 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.669263 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:08.2646 UTC hyperparameters_optimizer.cc:582] [287/1100] Score: -0.669263 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:08.2651 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.2652 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.2654 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.2934 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.027129 train-accuracy:0.896088 valid-loss:1.029244 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:08.2962 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687283\n",
      "[INFO 24-02-22 07:37:08.2963 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.2966 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.687283 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:08.2975 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.2975 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.2977 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.2984 UTC hyperparameters_optimizer.cc:582] [288/1100] Score: -0.687283 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:08.3069 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.166885 train-accuracy:0.612469 valid-loss:1.141753 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:08.3392 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666075\n",
      "[INFO 24-02-22 07:37:08.3392 UTC gradient_boosted_trees.cc:271] Truncates the model to 196 tree(s) i.e. 196  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.3394 UTC gradient_boosted_trees.cc:334] Final model num-trees:196 valid-loss:0.666075 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:08.3415 UTC hyperparameters_optimizer.cc:582] [289/1100] Score: -0.666075 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:08.3446 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.3465 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.3467 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.3632 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685805\n",
      "[INFO 24-02-22 07:37:08.3632 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.3640 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.685805 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:08.3667 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.3667 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.3669 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.3692 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284924 train-accuracy:0.612469 valid-loss:1.240106 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:08.3718 UTC hyperparameters_optimizer.cc:582] [290/1100] Score: -0.685805 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:08.4329 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130442 train-accuracy:0.814181 valid-loss:1.103627 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:08.4459 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650704\n",
      "[INFO 24-02-22 07:37:08.4459 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.4461 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.650704 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:08.4468 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.4470 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[[INFO 24-02-22 07:37:08.4474 UTC hyperparameters_optimizer.cc:582] [291/1100] Score: -0.650704 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:37:08.4477 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.4664 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.105731 train-accuracy:0.825183 valid-loss:1.044922 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:08.4767 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667359\n",
      "[INFO 24-02-22 07:37:08.4769 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.4776 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.667359 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:08.4787 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.4788 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.4790 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.4817 UTC hyperparameters_optimizer.cc:582] [292/1100] Score: -0.667359 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:08.5963 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.016047 train-accuracy:0.850856 valid-loss:1.052679 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:08.6266 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694411\n",
      "[INFO 24-02-22 07:37:08.6266 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.6270 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.694411 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:08.6281 UTC hyperparameters_optimizer.cc:582] [293/1100] Score: -0.694411 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:08.6289 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.6290 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.6306 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.6324 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.150482 train-accuracy:0.799511 valid-loss:1.111772 valid-accuracy:0.808219\n",
      "[INFO[INFO 24-02-22 07:37:08.7447 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641447\n",
      "[INFO 24-02-22 07:37:08.7447 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.7449 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646565\n",
      "[INFO 24-02-22 07:37:08.7449 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      " 24-02-22 07:37:08.7449 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.641447 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:08.7451 UTC hyperparameters_optimizer.cc:582] [294/1100] Score: -0.641447 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:08.7457 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.7457 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.7460 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.7482 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.646565 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:08.7491 UTC hyperparameters_optimizer.cc:582] [295/1100] Score: -0.646565 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:08.7496 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.7496 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.7517 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.7534 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.178137 train-accuracy:0.612469 valid-loss:1.133464 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:08.7852 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.101200 train-accuracy:0.789731 valid-loss:1.089150 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:08.8146 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689275\n",
      "[INFO 24-02-22 07:37:08.8146 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.8150 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.689275 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:08.8159 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.8159 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.8161 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.8176 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316730 train-accuracy:0.612469 valid-loss:1.274968 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:08.8184 UTC hyperparameters_optimizer.cc:582] [296/1100] Score: -0.689275 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:08.9525 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66132\n",
      "[INFO 24-02-22 07:37:08.9526 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 07:37:08.9526 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.661320 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:08.9528 UTC hyperparameters_optimizer.cc:582] [297/1100] Score: -0.66132 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:08.9532 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:08.9532 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:08.9534 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:08.9570 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190582 train-accuracy:0.612469 valid-loss:1.168570 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.1260 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678842\n",
      "[INFO 24-02-22 07:37:09.1260 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.1262 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.678842 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:09.1265 UTC hyperparameters_optimizer.cc:582] [298/1100] Score: -0.678842 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:09.1270 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.1270 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.1272 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.1293 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.715875\n",
      "[INFO 24-02-22 07:37:09.1295 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.1306 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.715875 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:09.1313 UTC hyperparameters_optimizer.cc:582] [299/1100] Score: -0.715875 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:09.1326 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.1328 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.1331 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.1343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670652\n",
      "[INFO 24-02-22 07:37:09.1343 UTC gradient_boosted_trees.cc:271] Truncates the model to 182 tree(s) i.e. 182  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.1344 UTC gradient_boosted_trees.cc:334] Final model num-trees:182 valid-loss:0.670652 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:09.1352 UTC hyperparameters_optimizer.cc:582] [300/1100] Score: -0.670652 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:09.1370 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.1370 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.1372 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.1374 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239154 train-accuracy:0.612469 valid-loss:1.196253 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.1416 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.268916 train-accuracy:0.612469 valid-loss:1.249853 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.1729 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.267660 train-accuracy:0.612469 valid-loss:1.241257 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.2929 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679786\n",
      "[INFO 24-02-22 07:37:09.2930 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.2931 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.679786 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:09.2936 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.2936 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.2938 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.2971 UTC hyperparameters_optimizer.cc:582] [301/1100] Score: -0.679786 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:09.2995 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682508\n",
      "[INFO 24-02-22 07:37:09.2995 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.2997 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.682508 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:09.2999 UTC hyperparameters_optimizer.cc:582] [302/1100] Score: -0.682508 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:09.3004 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.3005 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.3008 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.3036 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.078975 train-accuracy:0.809291 valid-loss:1.044532 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:09.3711 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276106 train-accuracy:0.612469 valid-loss:1.240494 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.4375 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701161\n",
      "[INFO 24-02-22 07:37:09.4375 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:09.4379 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:09.4379 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.701161 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:09.4383 UTC hyperparameters_optimizer.cc:582] [303/1100] Score: -0.701161 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:09.4394 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.4394 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.4397 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.4433 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291507 train-accuracy:0.612469 valid-loss:1.244276 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.5535 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.749407\n",
      "[INFO 24-02-22 07:37:09.5536 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.5543 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.749407 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:09.5552 UTC hyperparameters_optimizer.cc:582] [304/1100] Score: -0.749407 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:09.5555 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.5556 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.5559 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.7327 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.256955 train-accuracy:0.612469 valid-loss:1.234969 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.8323 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658666\n",
      "[INFO 24-02-22 07:37:09.8324 UTC gradient_boosted_trees.cc:271] Truncates the model to 81 tree(s) i.e. 81  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.8324 UTC gradient_boosted_trees.cc:334] Final model num-trees:81 valid-loss:0.658666 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:09.8327 UTC hyperparameters_optimizer.cc:582] [305/1100] Score: -0.658666 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:09.8348 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.8352 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.8354 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.8377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242740 train-accuracy:0.612469 valid-loss:1.210350 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.8433 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672464\n",
      "[INFO 24-02-22 07:37:09.8433 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.8435 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.672464 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:09.8447 UTC hyperparameters_optimizer.cc:582] [306/1100] Score: -0.672464 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:09.8457 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.8459 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.8465 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.9036 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177568 train-accuracy:0.612469 valid-loss:1.121560 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:09.9433 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636993\n",
      "[INFO 24-02-22 07:37:09.9433 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:09.9438 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.636993 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:09.9448 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:09.9448 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:09.9450 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:09.9485 UTC hyperparameters_optimizer.cc:582] [307/1100] Score: -0.636993 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:09.9634 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305591 train-accuracy:0.612469 valid-loss:1.270928 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:10.0083 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677842\n",
      "[INFO 24-02-22 07:37:10.0083 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:10.0085 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.677842 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:10.0087 UTC hyperparameters_optimizer.cc:582] [308/1100] Score: -0.677842 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:10.0090 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:10.0090 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:10.0095 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:10.0188 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660379\n",
      "[INFO 24-02-22 07:37:10.0188 UTC gradient_boosted_trees.cc:271] Truncates the model to 92 tree(s) i.e. 92  iteration(s).\n",
      "[INFO 24-02-22 07:37:10.0189 UTC gradient_boosted_trees.cc:334] Final model num-trees:92 valid-loss:0.660379 valid-accuracy:0.917808\n",
      "[[INFO 24-02-22 07:37:10.0193 UTC [INFO 24-02-22 07:37:10.0194 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:10.0194 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "INFO 24-02-22 07:37:10.0194 UTC hyperparameters_optimizer.cc:582] [309/1100] Score: gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209910 train-accuracy:0.612469 valid-loss:1.197736 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:10.0199 UTC gradient_boosted_trees.cc:1261] -0.660379 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:10.0269 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314929 train-accuracy:0.612469 valid-loss:1.273308 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:10.4429 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676516\n",
      "[INFO 24-02-22 07:37:10.4429 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:10.4431 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:10.4431 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.676516 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:10.4433 UTC hyperparameters_optimizer.cc:582] [310/1100] Score: -0.676516 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:10.4438 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:10.4438 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:10.4441 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:10.4616 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692663\n",
      "[INFO 24-02-22 07:37:10.4617 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:37:10.4627 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.692663 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:10.4647 UTC hyperparameters_optimizer.cc:582] [311/1100] Score: -0.692663 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:10.4665 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:10.4665 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:10.4681 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:10.4816 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219733 train-accuracy:0.612469 valid-loss:1.213703 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:10.5489 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314581 train-accuracy:0.612469 valid-loss:1.272145 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:10.5699 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.760021\n",
      "[INFO 24-02-22 07:37:10.5699 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:10.5714 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:10.5714 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.760021 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:10.5722 UTC hyperparameters_optimizer.cc:582] [312/1100] Score: -0.760021 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:10.5740 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:10.5740 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:10.5761 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:10.5871 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224019 train-accuracy:0.612469 valid-loss:1.182045 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:10.7672 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674045\n",
      "[INFO 24-02-22 07:37:10.7673 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:37:10.7677 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.674045 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:10.7683 UTC hyperparameters_optimizer.cc:582] [313/1100] Score: -0.674045 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:10.7691 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:10.7691 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:10.7697 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:10.7810 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315404 train-accuracy:0.612469 valid-loss:1.274659 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:10.8503 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.716132\n",
      "[INFO 24-02-22 07:37:10.8503 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:37:10.8507 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.716132 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:10.8522 UTC hyperparameters_optimizer.cc:582] [314/1100] Score: -0.716132 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:10.8539 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:10.8539 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:10.8542 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:10.8549 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235496 train-accuracy:0.612469 valid-loss:1.189563 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:10.9376 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672126\n",
      "[INFO 24-02-22 07:37:10.9376 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 07:37:10.9377 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.672126 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:10.9380 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:10.9380 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:10.9382 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:10.9411 UTC hyperparameters_optimizer.cc:582] [315/1100] Score: -0.672126 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:10.9428 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236316 train-accuracy:0.612469 valid-loss:1.190139 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:11.0246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680443\n",
      "[INFO 24-02-22 07:37:11.0246 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:37:11.0247 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.680443 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:11.0249 UTC hyperparameters_optimizer.cc:582] [316/1100] Score: -0.680443 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:11.0252 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:11.0252 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:11.0254 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:11.0279 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.145057 train-accuracy:0.743276 valid-loss:1.090127 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:37:11.0858 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680138\n",
      "[INFO 24-02-22 07:37:11.0858 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:11.0860 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:11.0860 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.680138 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:11.0863 UTC hyperparameters_optimizer.cc:582] [317/1100] Score: -0.680138 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:11.0871 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:11.0871 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:11.0873 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:11.0910 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.160732 train-accuracy:0.612469 valid-loss:1.151405 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:11.1235 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667535\n",
      "[INFO 24-02-22 07:37:11.1235 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:37:11.1239 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.667535 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:11.1243 UTC hyperparameters_optimizer.cc:582] [318/1100] Score: -0.667535 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:11.1250 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:11.1250 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:11.1254 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:11.1591 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310156 train-accuracy:0.612469 valid-loss:1.270594 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:11.2403 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.70585\n",
      "[INFO 24-02-22 07:37:11.2403 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:11.2407 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.705850 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:11.2410 UTC hyperparameters_optimizer.cc:582] [319/1100] Score: -0.70585 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:11.2430 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:11.2431 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:11.2435 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:11.2724 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311071 train-accuracy:0.612469 valid-loss:1.272991 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:11.3494 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.758722\n",
      "[INFO 24-02-22 07:37:11.3494 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:11.3497 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.758722 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:11.3499 UTC hyperparameters_optimizer.cc:582] [320/1100] Score: -0.758722 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:11.3503 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:11.3503 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:11.3505 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:11.3754 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668408\n",
      "[INFO 24-02-22 07:37:11.3755 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 07:37:11.3757 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.668408 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:11.3767 UTC hyperparameters_optimizer.cc:582] [321/1100] Score: -0.668408 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:11.3862 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:11.3862 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:11.3864 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:11.4166 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.086470 train-accuracy:0.836186 valid-loss:1.051450 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:11.4545 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.193904 train-accuracy:0.612469 valid-loss:1.159283 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:11.9159 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.614896\n",
      "[INFO 24-02-22 07:37:11.9159 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:11.9163 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.614896 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:11.9166 UTC hyperparameters_optimizer.cc:582] [322/1100] Score: -0.614896 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:11.9176 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:11.9176 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:11.9178 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:11.9209 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278517 train-accuracy:0.612469 valid-loss:1.239760 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:12.0166 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640163\n",
      "[INFO 24-02-22 07:37:12.0167 UTC gradient_boosted_trees.cc:271] Truncates the model to 96 tree(s) i.e. 96  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.0168 UTC gradient_boosted_trees.cc:334] Final model num-trees:96 valid-loss:0.640163 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:12.0177 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.0177 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.0178 UTC hyperparameters_optimizer.cc:582] [323/1100] Score: -0.640163[ / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }INFO 24-02-22 07:37:12.0183 UTC gradient_boosted_trees.cc:1261\n",
      "] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.0374 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.199524 train-accuracy:0.612469 valid-loss:1.143742 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:12.2204 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646595\n",
      "[INFO 24-02-22 07:37:12.2206 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.2208 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.646595 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:12.2233 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.2233 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.2235 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.2282 UTC hyperparameters_optimizer.cc:582] [324/1100] Score: -0.646595 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:12.2448 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.105142 train-accuracy:0.836186 valid-loss:1.065736 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:12.2508 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684348\n",
      "[INFO 24-02-22 07:37:12.2509 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.2513 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.684348 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:12.2538 UTC hyperparameters_optimizer.cc:582] [325/1100] Score: -0.684348 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:12.2579 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.2591 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.2594 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.2867 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310584 train-accuracy:0.612469 valid-loss:1.271750 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:12.4063 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634893\n",
      "[INFO 24-02-22 07:37:12.4063 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.4066 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.634893 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:12.4071 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.4071 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.4074 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.4085 UTC hyperparameters_optimizer.cc:582] [326/1100] Score: -0.634893 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:12.4103 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283467 train-accuracy:0.612469 valid-loss:1.242107 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:12.4228 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651399\n",
      "[INFO 24-02-22 07:37:12.4228 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.4231 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.651399 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:12.4248 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.4248 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.4251 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.4258 UTC hyperparameters_optimizer.cc:582] [327/1100] Score: -0.651399 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:12.4332 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.126170 train-accuracy:0.764059 valid-loss:1.072637 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:12.5393 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6876\n",
      "[INFO 24-02-22 07:37:12.5393 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.5398 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.687600 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:12.5409 UTC hyperparameters_optimizer.cc:582] [328/1100] Score: -0.6876 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:12.5441 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.5442 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.5444 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.6367 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229577 train-accuracy:0.612469 valid-loss:1.183582 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:12.7453 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649243\n",
      "[INFO 24-02-22 07:37:12.7454 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.7455 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.649243 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:12.7467 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.7467 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.7469 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.7470 UTC hyperparameters_optimizer.cc:582] [329/1100] Score: -0.649243 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:12.7538 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67024\n",
      "[INFO 24-02-22 07:37:12.7538 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.7539 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.670240 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:12.7543 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.7543 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.7546 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.7547 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.60915\n",
      "[INFO 24-02-22 07:37:12.7548 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:12.7549 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.609150 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:12.7551 UTC hyperparameters_optimizer.cc:582] [330/1100] Score: -0.67024 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:12.7552 UTC hyperparameters_optimizer.cc:582] [331/1100] Score: -0.60915 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:12.7558 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:12.7558 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:12.7560 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:12.7594 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.166532 train-accuracy:0.612469 valid-loss:1.133264 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:12.7635 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281518 train-accuracy:0.612469 valid-loss:1.247036 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:12.7737 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188084 train-accuracy:0.612469 valid-loss:1.140594 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:13.0154 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.705659\n",
      "[INFO 24-02-22 07:37:13.0156 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:37:13.0162 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.705659 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:13.0171 UTC hyperparameters_optimizer.cc:582] [332/1100] Score: -0.705659 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:13.0251 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:13.0252 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:13.0254 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:13.0585 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679072\n",
      "[INFO 24-02-22 07:37:13.0586 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:13.0587 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:13.0587 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.679072 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:13.0593 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:13.0593 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[[INFO 24-02-22 07:37:13.0597 UTC hyperparameters_optimizer.cc:582] [333/1100] Score: -0.679072 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:37:13.0598 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:13.0614 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289212 train-accuracy:0.612469 valid-loss:1.248348 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:13.1393 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.204717 train-accuracy:0.612469 valid-loss:1.189879 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:13.2684 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660641\n",
      "[INFO 24-02-22 07:37:13.2684 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 07:37:13.2685 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.660641 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:13.2690 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:13.2690 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:13.2692 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:13.2693 UTC hyperparameters_optimizer.cc:582] [334/1100] Score: -0.660641 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:13.2739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103349 train-accuracy:0.822738 valid-loss:1.102386 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:13.2831 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.71107\n",
      "[INFO 24-02-22 07:37:13.2832 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 07:37:13.2848 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.711070 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:37:13.2951 UTC hyperparameters_optimizer.cc:582] [335/1100] Score: -0.71107 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:37:13.2984 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:13.2984 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:13.3101 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:13.3192 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279357 train-accuracy:0.612469 valid-loss:1.238875 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:13.3595 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652041\n",
      "[INFO 24-02-22 07:37:13.3595 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:13.3609 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.652041 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:13.3635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:13.3635 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:13.3638 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:13.3664 UTC hyperparameters_optimizer.cc:582] [336/1100] Score: -0.652041 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:13.4739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.107677 train-accuracy:0.793399 valid-loss:1.068899 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:13.4837 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652503\n",
      "[INFO 24-02-22 07:37:13.4837 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 07:37:13.4839 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.652503 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:13.4847 UTC hyperparameters_optimizer.cc:582] [337/1100] Score: -0.652503 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:13.4849 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:13.4849 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:13.4856 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:13.5861 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096576 train-accuracy:0.808068 valid-loss:1.055084 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:13.8581 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647731\n",
      "[INFO 24-02-22 07:37:13.8581 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:13.8583 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.647731 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:13.8589 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:13.8590 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:13.8592 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:13.8593 UTC hyperparameters_optimizer.cc:582] [338/1100] Score: -0.647731 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:13.9325 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.179523 train-accuracy:0.612469 valid-loss:1.137385 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:14.1298 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664951\n",
      "[INFO 24-02-22 07:37:14.1301 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:37:14.1314 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.664951 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:14.1328 UTC hyperparameters_optimizer.cc:582] [339/1100] Score: -0.664951 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:14.1348 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:14.1348 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:14.1351 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:14.1379 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286165 train-accuracy:0.612469 valid-loss:1.244508 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:14.2056 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687234\n",
      "[INFO 24-02-22 07:37:14.2087 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 07:37:14.2089 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.687234 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:14.2096 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:14.2096 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:14.2098 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:14.2129 UTC hyperparameters_optimizer.cc:582] [340/1100] Score: -0.687234 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:14.2407 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.028719 train-accuracy:0.863081 valid-loss:1.013444 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:14.4254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656251\n",
      "[INFO 24-02-22 07:37:14.4254 UTC gradient_boosted_trees.cc:271] Truncates the model to 142 tree(s) i.e. 142  iteration(s).\n",
      "[INFO 24-02-22 07:37:14.4256 UTC gradient_boosted_trees.cc:334] Final model num-trees:142 valid-loss:0.656251 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:14.4272 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:14.4273 UTC hyperparameters_optimizer.cc:582] [341/1100] Score: -0.656251 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:14.4274 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:14.4300 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:14.4402 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243022 train-accuracy:0.612469 valid-loss:1.201154 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:14.6696 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660846\n",
      "[INFO 24-02-22 07:37:14.6697 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 07:37:14.6701 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.660846 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:14.6708 UTC hyperparameters_optimizer.cc:582] [342/1100] Score: -0.660846 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:14.6721 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:14.6721 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:14.6723 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:14.6751 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.168101 train-accuracy:0.612469 valid-loss:1.148768 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:14.8530 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65443\n",
      "[INFO 24-02-22 07:37:14.8531 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:37:14.8535 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.654430 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:14.8540 UTC hyperparameters_optimizer.cc:582] [343/1100] Score: -0.65443 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:14.8557 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:14.8557 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:14.8559 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:14.8833 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62563\n",
      "[INFO 24-02-22 07:37:14.8833 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:37:14.8834 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.625630 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:14.8840 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:14.8840 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:14.8842 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:14.8853 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314691 train-accuracy:0.612469 valid-loss:1.272805 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:14.8868 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.099520 train-accuracy:0.800734 valid-loss:1.061883 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:14.8885 UTC hyperparameters_optimizer.cc:582] [344/1100] Score: -0.62563 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:14.9589 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682071\n",
      "[INFO 24-02-22 07:37:14.9594 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:14.9640 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.682071 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:14.9662 UTC hyperparameters_optimizer.cc:582] [345/1100] Score: -0.682071 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:14.9664 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:14.9665 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:14.9667 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:14.9704 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242108 train-accuracy:0.612469 valid-loss:1.203870 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:15.0975 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666031\n",
      "[INFO 24-02-22 07:37:15.0992 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:37:15.0994 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.666031 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:15.0997 UTC hyperparameters_optimizer.cc:582] [346/1100] Score: -0.666031 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:15.1010 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:15.1010 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:15.1011 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:15.1035 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070940 train-accuracy:0.826406 valid-loss:1.045910 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:15.2234 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678216\n",
      "[INFO 24-02-22 07:37:15.2241 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:15.2244 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.678216 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:15.2246 UTC hyperparameters_optimizer.cc:582] [347/1100] Score: -0.678216 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:15.2261 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:15.2262 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:15.2264 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:15.2941 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122483 train-accuracy:0.830073 valid-loss:1.092120 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:15.3496 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.771816\n",
      "[INFO 24-02-22 07:37:15.3496 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:15.3501 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:15.3502 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.771816 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:15.3509 UTC hyperparameters_optimizer.cc:582] [348/1100] Score: -0.771816 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:15.3514 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:15.3514 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:15.3517 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:15.3771 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312290 train-accuracy:0.612469 valid-loss:1.270683 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:15.4730 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.720509\n",
      "[INFO 24-02-22 07:37:15.4730 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:15.4734 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.720509 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:15.4739 UTC hyperparameters_optimizer.cc:582] [349/1100] Score: -0.720509 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:15.4748 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:15.4748 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:15.4751 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:15.4777 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.087287 train-accuracy:0.799511 valid-loss:1.051090 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:15.6005 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676382\n",
      "[INFO 24-02-22 07:37:15.6037 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:15.6039 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.676382 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:15.6041 UTC hyperparameters_optimizer.cc:582] [350/1100] Score: -0.676382 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:15.6051 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:15.6051 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:15.6054 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:15.6301 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283717 train-accuracy:0.612469 valid-loss:1.244165 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:16.2923 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654984\n",
      "[INFO 24-02-22 07:37:16.2924 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:37:16.2926 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.654984 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:16.2929 UTC hyperparameters_optimizer.cc:582] [351/1100] Score: -0.654984 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:16.2936 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:16.2936 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:16.2938 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:16.3088 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158502 train-accuracy:0.745721 valid-loss:1.113795 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:37:16.4089 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677679\n",
      "[INFO 24-02-22 07:37:16.4090 UTC gradient_boosted_trees.cc:271] Truncates the model to 172 tree(s) i.e. 172  iteration(s).\n",
      "[INFO 24-02-22 07:37:16.4093 UTC gradient_boosted_trees.cc:334] Final model num-trees:172 valid-loss:0.677679 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:16.4122 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:16.4122 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:16.4124 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:16.4128 UTC hyperparameters_optimizer.cc:582] [352/1100] Score: -0.677679 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:16.5003 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277496 train-accuracy:0.612469 valid-loss:1.237957 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:16.8804 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674956\n",
      "[INFO 24-02-22 07:37:16.8804 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 07:37:16.8808 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.674956 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:16.8829 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:16.8830 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:16.8831 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:16.8851 UTC hyperparameters_optimizer.cc:582] [353/1100] Score: -0.674956 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:16.9397 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279938 train-accuracy:0.612469 valid-loss:1.238750 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:17.0157 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631094\n",
      "[INFO 24-02-22 07:37:17.0181 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:17.0182 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.631094 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:17.0190 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:17.0190 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:17.0192 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:17.0217 UTC hyperparameters_optimizer.cc:582] [354/1100] Score: -0.631094 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:17.0232 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313956 train-accuracy:0.612469 valid-loss:1.273583 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:17.3683 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651082\n",
      "[INFO 24-02-22 07:37:17.3700 UTC gradient_boosted_trees.cc:271] Truncates the model to 227 tree(s) i.e. 227  iteration(s).\n",
      "[INFO 24-02-22 07:37:17.3702 UTC gradient_boosted_trees.cc:334] Final model num-trees:227 valid-loss:0.651082 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:17.3746 UTC hyperparameters_optimizer.cc:582] [355/1100] Score: -0.651082 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:17.3774 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:17.3774 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:17.3776 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:17.4456 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.208052 train-accuracy:0.612469 valid-loss:1.179417 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:17.5746 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640195\n",
      "[INFO 24-02-22 07:37:17.5746 UTC gradient_boosted_trees.cc:271] Truncates the model to 154 tree(s) i.e. 154  iteration(s).\n",
      "[INFO 24-02-22 07:37:17.5749 UTC gradient_boosted_trees.cc:334] Final model num-trees:154 valid-loss:0.640195 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:17.5771 UTC hyperparameters_optimizer.cc:582] [356/1100] Score: -0.640195 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:17.5827 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:17.5827 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:17.5830 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:17.5903 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.149798 train-accuracy:0.790954 valid-loss:1.132576 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:17.8545 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653316\n",
      "[INFO 24-02-22 07:37:17.8545 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:17.8547 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.653316 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:17.8554 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:17.8555 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:17.8557 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:17.8584 UTC hyperparameters_optimizer.cc:582] [357/1100] Score: -0.653316 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:17.9000 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650586\n",
      "[INFO 24-02-22 07:37:17.9000 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 24-02-22 07:37:17.9002 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.650586 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:17.9009 UTC hyperparameters_optimizer.cc:582] [358/1100] Score: -0.650586 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:17.9024 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:17.9024 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:17.9026 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:17.9076 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081182 train-accuracy:0.819071 valid-loss:1.052130 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:17.9419 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.092173 train-accuracy:0.831296 valid-loss:1.040929 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:17.9514 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666036\n",
      "[INFO 24-02-22 07:37:17.9517 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:17.9519 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:17.9519 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.666036 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:17.9524 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:17.9525 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:17.9527 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:17.9537 UTC hyperparameters_optimizer.cc:582] [359/1100] Score: -0.666036 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:17.9727 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643905\n",
      "[INFO 24-02-22 07:37:17.9728 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 07:37:17.9729 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.643905 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:17.9735 UTC hyperparameters_optimizer.cc:582] [360/1100] Score: -0.643905 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:17.9743 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:17.9743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:17.9745 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:17.9827 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309205 train-accuracy:0.612469 valid-loss:1.271223 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:17.9975 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.730169\n",
      "[INFO 24-02-22 07:37:17.9975 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:17.9977 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.730169 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:17.9979 UTC hyperparameters_optimizer.cc:582] [361/1100] Score: -0.730169 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:17.9985 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:17.9986 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:17.9990 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:18.0000 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156645 train-accuracy:0.783619 valid-loss:1.083257 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:18.0231 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.088425 train-accuracy:0.833741 valid-loss:1.082802 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:18.2546 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.720067\n",
      "[INFO 24-02-22 07:37:18.2547 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:37:18.2548 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.720067 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:18.2549 UTC hyperparameters_optimizer.cc:582] [362/1100] Score: -0.720067 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:18.2554 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:18.2554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:18.2556 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:18.2870 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309669 train-accuracy:0.612469 valid-loss:1.274654 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:18.5765 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61135\n",
      "[INFO 24-02-22 07:37:18.5765 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 07:37:18.5767 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.611350 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:18.5772 UTC hyperparameters_optimizer.cc:582] [363/1100] Score: -0.61135 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:18.5779 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:18.5782 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:18.5784 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:18.5861 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155824 train-accuracy:0.759169 valid-loss:1.114279 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:18.9540 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655272\n",
      "[INFO 24-02-22 07:37:18.9542 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:18.9546 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.655272 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:18.9550 UTC hyperparameters_optimizer.cc:582] [364/1100] Score: -0.655272 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:18.9554 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:18.9554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:18.9557 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:18.9596 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207767 train-accuracy:0.612469 valid-loss:1.155828 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:19.0639 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687463\n",
      "[INFO 24-02-22 07:37:19.0640 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.0642 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.687463 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:19.0645 UTC hyperparameters_optimizer.cc:582] [365/1100] Score: -0.687463 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:19.0651 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.0651 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.0655 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.0688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228273 train-accuracy:0.612469 valid-loss:1.198938 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:19.1063 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651812\n",
      "[INFO 24-02-22 07:37:19.1063 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.1066 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.651812 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:19.1072 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.1073 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.1075 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.1084 UTC hyperparameters_optimizer.cc:582] [366/1100] Score: -0.651812 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:19.1214 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232437 train-accuracy:0.612469 valid-loss:1.193015 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:19.1578 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680652\n",
      "[INFO 24-02-22 07:37:19.1578 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.1578 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.680652 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:19.1580 UTC hyperparameters_optimizer.cc:582] [367/1100] Score: -0.680652 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:19.1582 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.1582 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.1618 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.1910 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.730212\n",
      "[INFO 24-02-22 07:37:19.1911 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.1913 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.730212 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:19.1916 UTC hyperparameters_optimizer.cc:582] [368/1100] Score: -0.730212 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:19.1923 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.1925 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.1930 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.1967 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132354 train-accuracy:0.753056 valid-loss:1.100682 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:37:19.2516 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229574 train-accuracy:0.612469 valid-loss:1.185615 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:19.2726 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659632\n",
      "[INFO 24-02-22 07:37:19.2726 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.2728 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.659632 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:19.2735 UTC hyperparameters_optimizer.cc:582] [369/1100] Score: -0.659632 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:19.2737 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.2738 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.2744 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.2814 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284648 train-accuracy:0.612469 valid-loss:1.242078 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:19.2816 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644343\n",
      "[INFO 24-02-22 07:37:19.2817 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.2818 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.644343 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:19.2821 UTC hyperparameters_optimizer.cc:582] [370/1100] Score: -0.644343 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:19.2826 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.2826 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.2830 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.2916 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65076\n",
      "[INFO 24-02-22 07:37:19.2917 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.2920 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.650760 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:19.2933 UTC hyperparameters_optimizer.cc:582] [371/1100] Score: -0.65076 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:19.2955 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.2956 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.2965 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.3047 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313618 train-accuracy:0.612469 valid-loss:1.273501 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:19.3193 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.117529 train-accuracy:0.832518 valid-loss:1.110227 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:19.3488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629775\n",
      "[INFO 24-02-22 07:37:19.3489 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:19.3493 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:19.3493 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.629775 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:19.3496 UTC hyperparameters_optimizer.cc:582] [372/1100] Score: -0.629775 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:19.3507 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.3508 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.3513 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.3533 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186173 train-accuracy:0.612469 valid-loss:1.155102 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:19.4011 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646031\n",
      "[INFO 24-02-22 07:37:19.4028 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.4031 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.646031 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:19.4042 UTC hyperparameters_optimizer.cc:582] [373/1100] Score: -0.646031 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:19.4070 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.4070 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.4072 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.4130 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242645 train-accuracy:0.612469 valid-loss:1.185535 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:19.5446 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662142\n",
      "[INFO 24-02-22 07:37:19.5446 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 07:37:19.5447 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.662142 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:19.5456 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:19.5456 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:19.5458 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:19.5485 UTC hyperparameters_optimizer.cc:582] [374/1100] Score: -0.662142 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:19.6294 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152142 train-accuracy:0.764059 valid-loss:1.115851 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:37:20.0107 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659468\n",
      "[INFO 24-02-22 07:37:20.0107 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 07:37:20.0108 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.659468 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:20.0116 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:20.0116 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:20.0118 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:20.0124 UTC hyperparameters_optimizer.cc:582] [375/1100] Score: -0.659468 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:20.0361 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.193651 train-accuracy:0.612469 valid-loss:1.163430 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:20.0795 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659683\n",
      "[INFO 24-02-22 07:37:20.0795 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:37:20.0798 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.659683 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:37:20.0804 UTC hyperparameters_optimizer.cc:582] [376/1100] Score: -0.659683 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:37:20.0808 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:20.0810 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:20.0814 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:20.1115 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311741 train-accuracy:0.612469 valid-loss:1.272486 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:20.4716 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664282\n",
      "[INFO 24-02-22 07:37:20.4716 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 07:37:20.4718 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.664282 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:20.4732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:20.4732 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:20.4734 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:20.4745 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289368 train-accuracy:0.612469 valid-loss:1.247761 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:20.4751 UTC hyperparameters_optimizer.cc:582] [377/1100] Score: -0.664282 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:20.4959 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.702331\n",
      "[INFO 24-02-22 07:37:20.4959 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:20.4962 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:20.4962 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.702331 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:20.4966 UTC hyperparameters_optimizer.cc:582] [378/1100] Score: -0.702331 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:20.4975 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:20.4977 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:20.4982 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:20.6747 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66259\n",
      "[INFO 24-02-22 07:37:20.6747 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 07:37:20.6748 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.662590 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:20.6751 UTC hyperparameters_optimizer.cc:582] [379/1100] Score: -0.66259 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:20.6766 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:20.6767 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:20.6770 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:20.6820 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.121243 train-accuracy:0.808068 valid-loss:1.072919 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:20.6893 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.880187 train-accuracy:0.952323 valid-loss:1.022104 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:20.8977 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686772\n",
      "[INFO 24-02-22 07:37:20.8977 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:20.8979 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.686772 valid-accuracy:0.863014\n",
      "[[INFO 24-02-22 07:37:20.8984 UTC hyperparameters_optimizer.cc:582] [380/1100] Score: -0.686772 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:37:20.8985 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:20.8985 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:20.8987 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:20.9182 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.047999 train-accuracy:0.831296 valid-loss:1.030979 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:21.3444 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682721\n",
      "[INFO 24-02-22 07:37:21.3444 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:37:21.3445 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.682721 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:21.3450 UTC hyperparameters_optimizer.cc:582] [381/1100] Score: -0.682721 / -0.592812 HParams: [INFO 24-02-22 07:37:21.3451 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:37:21.3451 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:21.3455 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:21.3715 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.116201 train-accuracy:0.792176 valid-loss:1.095666 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:21.3893 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660451\n",
      "[INFO 24-02-22 07:37:21.3894 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 07:37:21.3896 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.660451 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:21.3901 UTC hyperparameters_optimizer.cc:582] [382/1100] Score: -0.660451 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:21.3985 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:21.3985 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:21.3988 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:21.4092 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.115963 train-accuracy:0.847188 valid-loss:1.087611 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:21.7868 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.713935\n",
      "[INFO 24-02-22 07:37:21.7869 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:21.7872 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:21.7873 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.713935 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:21.7876 UTC hyperparameters_optimizer.cc:582] [383/1100] Score: -0.713935 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:21.7889 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:21.7891 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:21.7893 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:21.8158 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664367\n",
      "[INFO 24-02-22 07:37:21.8159 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:37:21.8164 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.664367 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:21.8172 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:21.8172 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:21.8174 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:21.8184 UTC hyperparameters_optimizer.cc:582] [384/1100] Score: -0.664367 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:21.8263 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295060 train-accuracy:0.612469 valid-loss:1.248657 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:21.8607 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311877 train-accuracy:0.612469 valid-loss:1.272579 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:21.9796 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653329\n",
      "[INFO 24-02-22 07:37:21.9796 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:21.9797 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.653329 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:21.9799 UTC hyperparameters_optimizer.cc:582] [385/1100] Score: -0.653329 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:21.9805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:21.9805 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:21.9807 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:21.9828 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241735 train-accuracy:0.612469 valid-loss:1.193640 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:22.0225 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685235\n",
      "[INFO 24-02-22 07:37:22.0225 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:37:22.0231 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.685235 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:22.0241 UTC hyperparameters_optimizer.cc:582] [386/1100] Score: -0.685235 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:22.0265 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:22.0265 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:22.0267 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:22.0391 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309671 train-accuracy:0.612469 valid-loss:1.269461 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:22.1402 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688984\n",
      "[INFO 24-02-22 07:37:22.1403 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:37:22.1404 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.688984 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:22.1410 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:22.1411 UTC hyperparameters_optimizer.cc:582] [387/1100] Score: -0.688984[INFO 24-02-22 07:37:22.1412 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      " / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:22.1415 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:22.1492 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228829 train-accuracy:0.612469 valid-loss:1.202513 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:22.4721 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626542\n",
      "[INFO 24-02-22 07:37:22.4721 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:22.4723 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.626542 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:22.4727 UTC hyperparameters_optimizer.cc:582] [388/1100] Score: -0.626542 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:22.4733 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:22.4735 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:22.4741 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:22.4785 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207424 train-accuracy:0.612469 valid-loss:1.156442 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:22.5102 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692159\n",
      "[INFO 24-02-22 07:37:22.5103 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:22.5106 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.692159 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:22.5112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:22.5112 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:22.5115 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:22.5139 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236932 train-accuracy:0.612469 valid-loss:1.191942 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:22.5151 UTC hyperparameters_optimizer.cc:582] [389/1100] Score: -0.692159 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:22.5845 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685232\n",
      "[INFO 24-02-22 07:37:22.5845 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:22.5847 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.685232 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:22.5851 UTC hyperparameters_optimizer.cc:582] [390/1100] Score: -0.685232 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:22.5874 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:22.5887 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:22.5889 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:22.6825 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657725\n",
      "[INFO 24-02-22 07:37:22.6825 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:37:22.6827 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.657725 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:22.6830 UTC hyperparameters_optimizer.cc:582] [391/1100] Score: -0.657725 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:22.6833 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:22.6833 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:22.6835 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:22.6867 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.091168 train-accuracy:0.800734 valid-loss:1.074703 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:37:22.7021 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.005678 train-accuracy:0.878973 valid-loss:1.030810 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:22.7287 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656545\n",
      "[INFO 24-02-22 07:37:22.7287 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:37:22.7288 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.656545 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:22.7290 UTC hyperparameters_optimizer.cc:582] [392/1100] Score: -0.656545 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:22.7294 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:22.7294 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:22.7297 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:22.7346 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.200898 train-accuracy:0.612469 valid-loss:1.189012 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:22.8069 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694094\n",
      "[INFO 24-02-22 07:37:22.8069 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:22.8071 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:22.8071 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.694094 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:22.8075 UTC hyperparameters_optimizer.cc:582] [393/1100] Score: -0.694094 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:22.8079 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:22.8079 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:22.8081 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:22.8866 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.050750 train-accuracy:0.823961 valid-loss:1.010823 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:23.0384 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659261\n",
      "[INFO 24-02-22 07:37:23.0385 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:37:23.0387 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.659261 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:23.0399 UTC hyperparameters_optimizer.cc:582] [394/1100] Score: -0.659261 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:23.0419 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:23.0419 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:23.0421 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:23.0497 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694124\n",
      "[INFO 24-02-22 07:37:23.0497 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:23.0512 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.694124 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:23.0528 UTC hyperparameters_optimizer.cc:582] [395/1100] Score: -0.694124 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:23.0574 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:23.0574 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:23.0576 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:23.0673 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313462 train-accuracy:0.612469 valid-loss:1.272391 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:23.1442 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226147 train-accuracy:0.612469 valid-loss:1.184460 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:23.5591 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640175\n",
      "[INFO 24-02-22 07:37:23.5591 UTC gradient_boosted_trees.cc:271] Truncates the model to 162 tree(s) i.e. 162  iteration(s).\n",
      "[INFO 24-02-22 07:37:23.5595 UTC gradient_boosted_trees.cc:334] Final model num-trees:162 valid-loss:0.640175 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:37:23.5636 UTC hyperparameters_optimizer.cc:582] [396/1100] Score: -0.640175 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:37:23.5657 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:23.5657 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:23.5683 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:23.5692 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321016 train-accuracy:0.612469 valid-loss:1.279095 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:23.6590 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662977\n",
      "[INFO 24-02-22 07:37:23.6590 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 07:37:23.6595 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.662977 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:23.6629 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:23.6629 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:23.6631 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:23.6660 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673621\n",
      "[INFO 24-02-22 07:37:23.6660 UTC gradient_boosted_trees.cc:271] Truncates the model to 213 tree(s) i.e. 213  iteration(s).\n",
      "[INFO 24-02-22 07:37:23.6661 UTC gradient_boosted_trees.cc:334] Final model num-trees:213 valid-loss:0.673621 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:23.6665 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:23.6665 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:23.6666 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:23.6686 UTC hyperparameters_optimizer.cc:582] [397/1100] Score: -0.662977 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:23.6709 UTC hyperparameters_optimizer.cc:582] [398/1100] Score: -0.673621 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:23.6913 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.150916 train-accuracy:0.784841 valid-loss:1.085363 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:23.7177 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673364\n",
      "[INFO 24-02-22 07:37:23.7177 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 07:37:23.7182 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.673364 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:23.7217 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:23.7217 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:23.7220 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:23.7251 UTC hyperparameters_optimizer.cc:582] [399/1100] Score: -0.673364 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:23.7261 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315076 train-accuracy:0.612469 valid-loss:1.274563 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:23.7384 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312501 train-accuracy:0.612469 valid-loss:1.275484 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:23.8266 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.703530 train-accuracy:0.864303 valid-loss:0.666344 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:23.8289 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 07:37:23.8290 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.666120 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:23.8293 UTC hyperparameters_optimizer.cc:582] [400/1100] Score: -0.66612 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:23.8297 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:23.8297 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:23.8302 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:23.8334 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.135345 train-accuracy:0.743276 valid-loss:1.086013 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:37:23.9396 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665536\n",
      "[INFO 24-02-22 07:37:23.9414 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:23.9415 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.665536 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:23.9418 UTC hyperparameters_optimizer.cc:582] [401/1100] Score: -0.665536 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:23.9430 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:23.9431 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:23.9433 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:23.9458 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313108 train-accuracy:0.612469 valid-loss:1.275294 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:24.0219 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676043\n",
      "[INFO 24-02-22 07:37:24.0219 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 07:37:24.0223 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.676043 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:24.0237 UTC hyperparameters_optimizer.cc:582] [402/1100] Score: -0.676043 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:24.0255 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:24.0255 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:24.0260 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:24.0618 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.082308 train-accuracy:0.786064 valid-loss:1.074597 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:37:24.5716 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656892\n",
      "[INFO 24-02-22 07:37:24.5717 UTC gradient_boosted_trees.cc:271] Truncates the model to 219 tree(s) i.e. 219  iteration(s).\n",
      "[INFO 24-02-22 07:37:24.5719 UTC gradient_boosted_trees.cc:334] Final model num-trees:219 valid-loss:0.656892 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:24.5741 UTC hyperparameters_optimizer.cc:582] [403/1100] Score: -0.656892 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:24.5747 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:24.5747 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:24.5785 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:24.5825 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162699 train-accuracy:0.742054 valid-loss:1.132438 valid-accuracy:0.726027\n",
      "[INFO 24-02-22 07:37:24.7152 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655218\n",
      "[INFO 24-02-22 07:37:24.7159 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:24.7160 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.655218 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:24.7164 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:24.7164 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:24.7166 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:24.7187 UTC hyperparameters_optimizer.cc:582] [404/1100] Score: -0.655218 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:24.8352 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262357 train-accuracy:0.612469 valid-loss:1.240204 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:24.9521 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626919\n",
      "[INFO 24-02-22 07:37:24.9522 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 07:37:24.9524 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.626919 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:24.9528 UTC hyperparameters_optimizer.cc:582] [405/1100] Score: -0.626919 / -0.592812 HParams: [INFO 24-02-22 07:37:24.9528 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687581\n",
      "[INFO 24-02-22 07:37:24.9528 UTC gradient_boosted_trees.ccfields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      ":271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 07:37:24.9530 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.687581 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:24.9533 UTC hyperparameters_optimizer.cc:582] [406/1100] Score: -0.687581 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:24.9537 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:24.9538 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:24.9539 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:24.9539 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:24.9540 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:24.9542 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:24.9596 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190951 train-accuracy:0.612469 valid-loss:1.146850 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:24.9608 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311877 train-accuracy:0.612469 valid-loss:1.273643 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:25.2143 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673394\n",
      "[INFO 24-02-22 07:37:25.2143 UTC gradient_boosted_trees.cc:271] Truncates the model to 130 tree(s) i.e. 130  iteration(s).\n",
      "[INFO 24-02-22 07:37:25.2150 UTC gradient_boosted_trees.cc:334] Final model num-trees:130 valid-loss:0.673394 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:25.2194 UTC hyperparameters_optimizer.cc:582] [407/1100] Score: -0.673394 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:25.2290 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:25.2290 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:25.2293 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:25.2433 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640865\n",
      "[INFO 24-02-22 07:37:25.2434 UTC gradient_boosted_trees.cc:271] Truncates the model to 183 tree(s) i.e. 183  iteration(s).\n",
      "[INFO 24-02-22 07:37:25.2435 UTC gradient_boosted_trees.cc:334] Final model num-trees:183 valid-loss:0.640865 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:25.2453 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:25.2453 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:25.2455 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:25.2492 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279253 train-accuracy:0.612469 valid-loss:1.241179 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:25.2543 UTC hyperparameters_optimizer.cc:582] [408/1100] Score: -0.640865 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:25.2580 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063501 train-accuracy:0.801956 valid-loss:1.063805 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:25.2702 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630848\n",
      "[INFO 24-02-22 07:37:25.2702 UTC gradient_boosted_trees.cc:271] Truncates the model to 241 tree(s) i.e. 241  iteration(s).\n",
      "[INFO 24-02-22 07:37:25.2705 UTC gradient_boosted_trees.cc:334] Final model num-trees:241 valid-loss:0.630848 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:25.2722 UTC hyperparameters_optimizer.cc:582] [409/1100] Score: -0.630848 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:25.2753 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:25.2753 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:25.2756 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:25.2812 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.086944 train-accuracy:0.784841 valid-loss:1.004942 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:25.5357 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670021\n",
      "[INFO 24-02-22 07:37:25.5357 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:25.5359 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.670021 valid-accuracy:0.904110\n",
      "[[INFO 24-02-22 07:37:25.5363 UTC hyperparameters_optimizer.cc:582] [410/1100] Score: -0.670021 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }INFO 24-02-22 07:37:25.5366 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:25.5366 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on \n",
      "891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:25.5396 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:25.5411 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.163089 train-accuracy:0.786064 valid-loss:1.119063 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:25.6252 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672736\n",
      "[INFO 24-02-22 07:37:25.6253 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 07:37:25.6255 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.672736 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:25.6267 UTC hyperparameters_optimizer.cc:582] [411/1100] Score: -0.672736 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:25.6270 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:25.6270 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:25.6282 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:25.6401 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.726851\n",
      "[INFO 24-02-22 07:37:25.6402 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:25.6405 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:25.6406 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.726851 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:25.6411 UTC hyperparameters_optimizer.cc:582] [412/1100] Score: -0.726851 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:25.6416 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:25.6416 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:25.6419 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:25.6454 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235309 train-accuracy:0.612469 valid-loss:1.195967 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:25.6549 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656625\n",
      "[INFO 24-02-22 07:37:25.6549 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 07:37:25.6551 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.656625 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:25.6554 UTC hyperparameters_optimizer.cc:582] [413/1100] Score: -0.656625 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:25.6562 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:25.6564 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:25.6570 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:25.6735 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65046\n",
      "[INFO 24-02-22 07:37:25.6735 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 07:37:25.6736 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.650460 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:25.6740 UTC hyperparameters_optimizer.cc:582] [414/1100] Score: -0.65046 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:25.6748 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:25.6748 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:25.6751 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:25.6781 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.189395 train-accuracy:0.612469 valid-loss:1.150445 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:25.7125 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.048192 train-accuracy:0.848411 valid-loss:1.021342 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:25.8422 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.307740 train-accuracy:0.612469 valid-loss:1.272430 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:26.0265 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630717\n",
      "[INFO 24-02-22 07:37:26.0265 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 07:37:26.0267 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.630717 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:26.0275 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:26.0275 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:26.0277 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:26.0284 UTC hyperparameters_optimizer.cc:582] [415/1100] Score: -0.630717 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:26.0484 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.209549 train-accuracy:0.612469 valid-loss:1.160785 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:26.0866 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659613\n",
      "[INFO 24-02-22 07:37:26.0866 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 07:37:26.0872 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.659613 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:37:26.0919 UTC hyperparameters_optimizer.cc:582] [416/1100] Score: -0.659613 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:37:26.0949 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:26.0950 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:26.0971 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:26.2237 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674436\n",
      "[INFO 24-02-22 07:37:26.2237 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 07:37:26.2240 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.674436 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:26.2259 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:26.2259 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:26.2261 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:26.2284 UTC hyperparameters_optimizer.cc:582] [417/1100] Score: -0.674436 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:26.2416 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.940491 train-accuracy:0.922983 valid-loss:0.996624 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:26.2695 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.124363 train-accuracy:0.612469 valid-loss:1.161838 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:26.4590 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.767879\n",
      "[INFO 24-02-22 07:37:26.4591 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:26.4593 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:26.4593 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.767879 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:26.4597 UTC hyperparameters_optimizer.cc:582] [418/1100] Score: -0.767879 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:26.4616 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:26.4617 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:26.4619 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:26.4835 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281334 train-accuracy:0.612469 valid-loss:1.244686 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:26.5649 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655523\n",
      "[INFO 24-02-22 07:37:26.5650 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:37:26.5651 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.655523 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:26.5655 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:26.5655 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:26.5659 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:26.5684 UTC hyperparameters_optimizer.cc:582] [419/1100] Score: -0.655523 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:26.6677 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280053 train-accuracy:0.612469 valid-loss:1.249208 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:26.8110 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.707702\n",
      "[INFO 24-02-22 07:37:26.8111 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:26.8114 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.707702 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:26.8117 UTC hyperparameters_optimizer.cc:582] [420/1100] Score: -0.707702 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:26.8122 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:26.8122 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:26.8125 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:26.8388 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312425 train-accuracy:0.612469 valid-loss:1.272049 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:26.8617 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.775147\n",
      "[INFO 24-02-22 07:37:26.8618 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:26.8627 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:26.8627 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.775147 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:26.8641 UTC hyperparameters_optimizer.cc:582] [421/1100] Score: -0.775147 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:26.8650 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:26.8650 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:26.8652 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:26.8828 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276760 train-accuracy:0.612469 valid-loss:1.238208 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:27.0407 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67146\n",
      "[INFO 24-02-22 07:37:27.0408 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 07:37:27.0409 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.671460 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:27.0411 UTC hyperparameters_optimizer.cc:582] [422/1100] Score: -0.67146 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:27.0416 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:27.0416 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:27.0440 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:27.0705 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282753 train-accuracy:0.612469 valid-loss:1.240925 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:27.1486 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.723316\n",
      "[INFO 24-02-22 07:37:27.1487 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:37:27.1491 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.723316 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:27.1495 UTC hyperparameters_optimizer.cc:582] [423/1100] Score: -0.723316 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:27.1506 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:27.1506 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:27.1514 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:27.2235 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223600 train-accuracy:0.612469 valid-loss:1.190308 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:27.3275 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663839\n",
      "[INFO 24-02-22 07:37:27.3275 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:37:27.3278 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.663839 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:27.3281 UTC hyperparameters_optimizer.cc:582] [424/1100] Score: -0.663839 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:27.3292 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:27.3292 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:27.3294 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:27.3456 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67263\n",
      "[INFO 24-02-22 07:37:27.3456 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 07:37:27.3458 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.672630 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:27.3464 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:27.3464 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[[INFO 24-02-22 07:37:27.3468 UTC hyperparameters_optimizer.cc:582] [425/1100] Score: -0.67263 / -0.592812 HParams: INFO 24-02-22 07:37:27.3469 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:27.3523 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298850 train-accuracy:0.612469 valid-loss:1.256748 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:27.3596 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.101519 train-accuracy:0.784841 valid-loss:1.045256 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:27.8707 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662839\n",
      "[INFO 24-02-22 07:37:27.8707 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:27.8708 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.662839 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:27.8709 UTC hyperparameters_optimizer.cc:582] [426/1100] Score: -0.662839 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:27.8716 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:27.8716 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:27.8718 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:27.8786 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207711 train-accuracy:0.612469 valid-loss:1.174255 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:27.9393 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665087\n",
      "[INFO 24-02-22 07:37:27.9396 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:27.9398 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.665087 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:27.9401 UTC hyperparameters_optimizer.cc:582] [427/1100] Score: -0.665087 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:27.9429 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:27.9430 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:27.9432 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:28.0614 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309923 train-accuracy:0.612469 valid-loss:1.273002 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:28.2303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.696596\n",
      "[INFO 24-02-22 07:37:28.2303 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 07:37:28.2306 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.696596 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:28.2309 UTC hyperparameters_optimizer.cc:582] [428/1100] Score: -0.696596 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:28.2310 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.733958\n",
      "[INFO 24-02-22 07:37:28.2310 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:28.2312 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:28.2312 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.733958 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:28.2316 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:28.2316 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:28.2316 UTC hyperparameters_optimizer.cc:582] [429/1100] Score: -0.733958 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:28.2319 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:28.2319 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:28.2319 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:28.2321 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:28.2402 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235488 train-accuracy:0.612469 valid-loss:1.189267 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:28.2544 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.220264 train-accuracy:0.612469 valid-loss:1.195251 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:28.6632 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657407\n",
      "[INFO 24-02-22 07:37:28.6633 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:37:28.6634 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.657407 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:28.6640 UTC hyperparameters_optimizer.cc:582] [430/1100] Score: -0.657407 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:28.6644 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:28.6645 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:28.6653 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:28.6765 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291333 train-accuracy:0.612469 valid-loss:1.248162 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:28.8554 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631192\n",
      "[INFO 24-02-22 07:37:28.8554 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:28.8557 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.631192 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:28.8561 UTC hyperparameters_optimizer.cc:582] [431/1100] Score: -0.631192 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:28.8571 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:28.8571 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:28.8573 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:28.8796 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122944 train-accuracy:0.831296 valid-loss:1.085277 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:29.3120 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654118\n",
      "[INFO 24-02-22 07:37:29.3120 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 07:37:29.3122 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.654118 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:29.3128 UTC hyperparameters_optimizer.cc:582] [432/1100] Score: -0.654118 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:29.3143 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:29.3143 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:29.3146 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:29.3223 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.195874 train-accuracy:0.612469 valid-loss:1.147829 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:29.7043 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.696117\n",
      "[INFO 24-02-22 07:37:29.7044 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 07:37:29.7046 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.696117 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:29.7050 UTC hyperparameters_optimizer.cc:582] [433/1100] Score: -0.696117 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:29.7058 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:29.7059 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:29.7063 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:29.7921 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112211 train-accuracy:0.841076 valid-loss:1.094342 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:29.8093 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629426\n",
      "[INFO 24-02-22 07:37:29.8093 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:37:29.8094 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.629426 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:29.8100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:29.8100 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:29.8102 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:29.8112 UTC hyperparameters_optimizer.cc:582] [434/1100] Score: -0.629426 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:29.8163 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312840 train-accuracy:0.612469 valid-loss:1.273572 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:30.0295 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679986\n",
      "[INFO 24-02-22 07:37:30.0325 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 07:37:30.0331 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.679986 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:30.0343 UTC hyperparameters_optimizer.cc:582] [435/1100] Score: -0.679986 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:30.0348 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:30.0348 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:30.0377 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:30.0393 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.719019\n",
      "[INFO 24-02-22 07:37:30.0394 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:30.0404 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.719019 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:30.0408 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238013 train-accuracy:0.612469 valid-loss:1.197591 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:30.0456 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:30.0466 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:30.0468 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:30.0484 UTC hyperparameters_optimizer.cc:582] [436/1100] Score: -0.719019 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:30.1293 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.044507 train-accuracy:0.830073 valid-loss:1.026244 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:30.2712 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669819\n",
      "[INFO 24-02-22 07:37:30.2714 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:37:30.2716 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.669819 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:30.2721 UTC hyperparameters_optimizer.cc:582] [437/1100] Score: -0.669819 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:30.2750 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:30.2752 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:30.2754 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:30.2781 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090935 train-accuracy:0.808068 valid-loss:1.065681 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:30.3401 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64708\n",
      "[INFO 24-02-22 07:37:30.3402 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 07:37:30.3402 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.647080 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:30.3406 UTC hyperparameters_optimizer.cc:582] [438/1100] Score: -0.64708 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:30.3414 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:30.3414 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:30.3416 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:30.4284 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.080954 train-accuracy:0.889976 valid-loss:1.084911 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:30.4672 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.72012\n",
      "[INFO 24-02-22 07:37:30.4672 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:30.4673 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.720120 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:30.4675 UTC hyperparameters_optimizer.cc:582] [439/1100] Score: -0.72012 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:30.4688 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:30.4689 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:30.4690 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:30.4722 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.104346 train-accuracy:0.800734 valid-loss:1.127746 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:37:30.5481 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661431\n",
      "[INFO 24-02-22 07:37:30.5482 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:37:30.5484 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.661431 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:30.5489 UTC hyperparameters_optimizer.cc:582] [440/1100] Score: -0.661431 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:30.5500 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:30.5502 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:30.5505 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:30.5594 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158781 train-accuracy:0.777506 valid-loss:1.090465 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:30.6486 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680528\n",
      "[INFO 24-02-22 07:37:30.6486 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:30.6490 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.680528 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:30.6495 UTC hyperparameters_optimizer.cc:582] [441/1100] Score: -0.680528 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:30.6506 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:30.6506 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:30.6508 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:30.6609 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.204252 train-accuracy:0.612469 valid-loss:1.155737 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:31.1282 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701783\n",
      "[INFO 24-02-22 07:37:31.1282 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 07:37:31.1283 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.701783 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:31.1287 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:31.1287 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:31.1289 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:31.1317 UTC hyperparameters_optimizer.cc:582] [442/1100] Score: -0.701783 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:31.1371 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.097205 train-accuracy:0.783619 valid-loss:1.056239 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:31.3137 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647269\n",
      "[INFO 24-02-22 07:37:31.3138 UTC gradient_boosted_trees.cc:271] Truncates the model to 142 tree(s) i.e. 142  iteration(s).\n",
      "[INFO 24-02-22 07:37:31.3140 UTC gradient_boosted_trees.cc:334] Final model num-trees:142 valid-loss:0.647269 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:31.3153 UTC hyperparameters_optimizer.cc:582] [443/1100] Score: -0.647269 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:31.3158 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:31.3159 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:31.3171 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:31.3190 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.203404 train-accuracy:0.612469 valid-loss:1.158772 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:31.4569 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668485\n",
      "[INFO 24-02-22 07:37:31.4569 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 07:37:31.4570 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.668485 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:31.4573 UTC hyperparameters_optimizer.cc:582] [444/1100] Score: -0.668485 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:31.4577 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:31.4578 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:31.4581 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:31.4852 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624253\n",
      "[INFO 24-02-22 07:37:31.4852 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:37:31.4853 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.624253 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:31.4855 UTC hyperparameters_optimizer.cc:582] [445/1100] Score: -0.624253 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:31.4859 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:31.4859 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:31.4861 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:31.5016 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649138\n",
      "[INFO 24-02-22 07:37:31.5017 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:37:31.5089 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.649138 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:31.5092 UTC hyperparameters_optimizer.cc:582] [446/1100] Score: -0.649138 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:31.5100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:31.5100 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:31.5101 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:31.5172 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283229 train-accuracy:0.612469 valid-loss:1.241725 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:31.5274 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668749\n",
      "[INFO 24-02-22 07:37:31.5274 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:31.5286 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:31.5286 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.668749 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:31.5295 UTC hyperparameters_optimizer.cc:582] [447/1100] Score: -0.668749 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:31.5300 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:31.5300 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:31.5302 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:31.5640 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312708 train-accuracy:0.612469 valid-loss:1.272892 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:31.5652 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.111557 train-accuracy:0.831296 valid-loss:1.074139 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:31.5800 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311345 train-accuracy:0.612469 valid-loss:1.274088 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:31.8492 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657499\n",
      "[INFO 24-02-22 07:37:31.8493 UTC gradient_boosted_trees.cc:271] Truncates the model to 79 tree(s) i.e. 79  iteration(s).\n",
      "[INFO 24-02-22 07:37:31.8494 UTC gradient_boosted_trees.cc:334] Final model num-trees:79 valid-loss:0.657499 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:31.8501 UTC hyperparameters_optimizer.cc:582] [448/1100] Score: -0.657499 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:31.8514 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:31.8515 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:31.8518 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:31.8542 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282876 train-accuracy:0.612469 valid-loss:1.243920 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:32.0972 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648658\n",
      "[INFO 24-02-22 07:37:32.0972 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 07:37:32.0974 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.648658 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:32.0981 UTC hyperparameters_optimizer.cc:582] [449/1100] Score: -0.648658 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:32.0995 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:32.0995 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:32.0998 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:32.1198 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.043989 train-accuracy:0.853301 valid-loss:1.014998 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:32.1311 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631244\n",
      "[INFO 24-02-22 07:37:32.1311 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:37:32.1333 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.631244 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:32.1374 UTC hyperparameters_optimizer.cc:582] [450/1100] Score: -0.631244 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:32.1500 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:32.1501 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:32.1504 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:32.1595 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.216576 train-accuracy:0.612469 valid-loss:1.192671 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:32.6271 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66638\n",
      "[INFO 24-02-22 07:37:32.6271 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:37:32.6274 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.666380 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:32.6282 UTC hyperparameters_optimizer.cc:582] [451/1100] Score: -0.66638 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:32.6290 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:32.6291 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:32.6293 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:32.6368 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280025 train-accuracy:0.612469 valid-loss:1.237554 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:32.9666 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695744\n",
      "[INFO 24-02-22 07:37:32.9666 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:32.9669 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.695744 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:32.9672 UTC hyperparameters_optimizer.cc:582] [452/1100] Score: -0.695744 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:32.9677 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:32.9677 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:32.9680 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:32.9753 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676657\n",
      "[INFO 24-02-22 07:37:32.9753 UTC gradient_boosted_trees.cc:271] Truncates the model to 175 tree(s) i.e. 175  iteration(s).\n",
      "[INFO 24-02-22 07:37:32.9754 UTC gradient_boosted_trees.cc:334] Final model num-trees:175 valid-loss:0.676657 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:32.9756 UTC hyperparameters_optimizer.cc:582] [453/1100] Score: -0.676657 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:32.9762 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:32.9762 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:32.9764 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:32.9803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.027099 train-accuracy:0.863081 valid-loss:1.055566 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:33.0999 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.038180 train-accuracy:0.860636 valid-loss:1.048765 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:33.1011 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.74246\n",
      "[INFO 24-02-22 07:37:33.1011 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:33.1013 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:33.1013 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.742460 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:33.1016 UTC hyperparameters_optimizer.cc:582] [454/1100] Score: -0.74246 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:33.1021 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.1022 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.1023 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.1031 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321016 train-accuracy:0.612469 valid-loss:1.279095 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:33.1262 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645237\n",
      "[INFO 24-02-22 07:37:33.1262 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.1265 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.645237 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:33.1268 UTC hyperparameters_optimizer.cc:582] [455/1100] Score: -0.645237 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:33.1275 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.1275 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.1277 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.1296 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158888 train-accuracy:0.748166 valid-loss:1.123685 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:37:33.1782 UTC gradient_boosted_trees.cc:1638] \tnum-trees:87 train-loss:0.881905 train-accuracy:0.828851 valid-loss:0.815481 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:33.2457 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654743\n",
      "[INFO 24-02-22 07:37:33.2457 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.2458 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.654743 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:33.2463 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.2463 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.2465 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.2484 UTC hyperparameters_optimizer.cc:582] [456/1100] Score: -0.654743 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:33.2494 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282460 train-accuracy:0.612469 valid-loss:1.239620 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:33.3342 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.724039\n",
      "[INFO 24-02-22 07:37:33.3342 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:33.3347 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:33.3348 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.724039 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:33.3351 UTC hyperparameters_optimizer.cc:582] [457/1100] Score: -0.724039 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:33.3366 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.3367 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.3369 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.3444 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279749 train-accuracy:0.612469 valid-loss:1.239312 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:33.3798 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.723773 train-accuracy:0.858191 valid-loss:0.682738 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:33.3799 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.3799 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.682095 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:33.3802 UTC hyperparameters_optimizer.cc:582] [458/1100] Score: -0.682095 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:33.3805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.3806 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.3810 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.3874 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290847 train-accuracy:0.612469 valid-loss:1.245062 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:33.4860 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643723\n",
      "[INFO 24-02-22 07:37:33.4860 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.4862 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.643723 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:33.4869 UTC hyperparameters_optimizer.cc:582] [459/1100] Score: -0.643723 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:33.4883 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.4883 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.4888 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.4892 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.715792\n",
      "[INFO 24-02-22 07:37:33.4892 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.4899 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.715792 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:33.4914 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.4914 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.4916 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232955 train-accuracy:0.612469 valid-loss:1.199904 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:33.4916 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.4917 UTC hyperparameters_optimizer.cc:582] [460/1100] Score: -0.715792 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:33.5024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664348\n",
      "[INFO 24-02-22 07:37:33.5024 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.5027 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.664348 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:33.5034 UTC hyperparameters_optimizer.cc:582] [461/1100] Score: -0.664348 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:33.5040 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.5040 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.5047 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.5127 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236348 train-accuracy:0.612469 valid-loss:1.190065 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:33.5346 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.093304 train-accuracy:0.845966 valid-loss:1.039923 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:33.6733 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666171\n",
      "[INFO 24-02-22 07:37:33.6738 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.6766 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.666171 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:33.6770 UTC hyperparameters_optimizer.cc:582] [462/1100] Score: -0.666171 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:33.6774 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.6774 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.6777 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.6795 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.693873\n",
      "[INFO 24-02-22 07:37:33.6796 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.6798 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.693873 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:33.6804 UTC hyperparameters_optimizer.cc:582] [463/1100] Score: -0.693873 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:33.6809 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.6809 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.6811 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.6819 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.179396 train-accuracy:0.612469 valid-loss:1.130350 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:33.7020 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.098352 train-accuracy:0.826406 valid-loss:1.057526 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:33.7237 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.719664\n",
      "[INFO 24-02-22 07:37:33.7237 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.7238 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.719664 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:33.7239 UTC hyperparameters_optimizer.cc:582] [464/1100] Score: -0.719664 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:33.7242 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.7242 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.7244 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.7300 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288124 train-accuracy:0.612469 valid-loss:1.244307 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:33.7728 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681402\n",
      "[INFO 24-02-22 07:37:33.7729 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.7729 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.681402 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:33.7732 UTC hyperparameters_optimizer.cc:582] [465/1100] Score: -0.681402 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:33.7784 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.7785 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.7787 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.7810 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.076832 train-accuracy:0.838631 valid-loss:1.053970 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:33.9182 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674289\n",
      "[INFO 24-02-22 07:37:33.9182 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:33.9184 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.674289 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:33.9189 UTC hyperparameters_optimizer.cc:582] [466/1100] Score: -0.674289 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:33.9194 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:33.9194 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:33.9197 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:33.9420 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186831 train-accuracy:0.612469 valid-loss:1.158432 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:34.0721 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677801\n",
      "[INFO 24-02-22 07:37:34.0722 UTC gradient_boosted_trees.cc:271] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "[INFO 24-02-22 07:37:34.0725 UTC gradient_boosted_trees.cc:334] Final model num-trees:116 valid-loss:0.677801 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:34.0746 UTC hyperparameters_optimizer.cc:582] [467/1100] Score: -0.677801 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:34.0779 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.0779 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.0785 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.1067 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275966 train-accuracy:0.612469 valid-loss:1.247474 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:34.2231 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622339\n",
      "[INFO 24-02-22 07:37:34.2231 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-22 07:37:34.2234 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.622339 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:34.2246 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.2246 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.2248 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.2279 UTC hyperparameters_optimizer.cc:582] [468/1100] Score: -0.622339 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:34.2388 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.973626 train-accuracy:0.889976 valid-loss:1.049984 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:34.3375 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656285\n",
      "[INFO 24-02-22 07:37:34.3375 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 07:37:34.3376 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.656285 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:34.3380 UTC hyperparameters_optimizer.cc:582] [469/1100] Score: -0.656285 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:34.3392 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.3392 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.3395 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.3458 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242822 train-accuracy:0.612469 valid-loss:1.196241 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:34.5554 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630688\n",
      "[INFO 24-02-22 07:37:34.5554 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:34.5556 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.630688 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:34.5560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.5560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.5562 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.5563 UTC hyperparameters_optimizer.cc:582] [470/1100] Score: -0.630688 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:34.5597 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.034348 train-accuracy:0.837408 valid-loss:1.025384 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:34.5894 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.732334\n",
      "[INFO 24-02-22 07:37:34.5895 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:34.5899 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:34.5899 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.732334 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:34.5909 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.5909 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.5912 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.5921 UTC hyperparameters_optimizer.cc:582] [471/1100] Score: -0.732334 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:34.6002 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.733318\n",
      "[INFO 24-02-22 07:37:34.6003 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:34.6006 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.733318 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:34.6014 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.6014 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.6016 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.6025 UTC hyperparameters_optimizer.cc:582] [472/1100] Score: -0.733318 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO[INFO 24-02-22 07:37:34.6114 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182435 train-accuracy:0.612469 valid-loss:1.137729 valid-accuracy:0.657534\n",
      " 24-02-22 07:37:34.6151 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.149654 train-accuracy:0.764059 valid-loss:1.122386 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:34.7487 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.602119\n",
      "[INFO 24-02-22 07:37:34.7500 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:34.7502 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:34.7502 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.602119 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:34.7506 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.7506 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.7509 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.7525 UTC hyperparameters_optimizer.cc:582] [473/1100] Score: -0.602119 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:34.8383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676881\n",
      "[INFO 24-02-22 07:37:34.8384 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:37:34.8385 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.676881 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:34.8389 UTC hyperparameters_optimizer.cc:582] [474/1100] Score: -0.676881 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:34.8397 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.8398 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.8413 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.8510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063483 train-accuracy:0.864303 valid-loss:1.043603 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:34.8588 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.072465 train-accuracy:0.806846 valid-loss:1.032600 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:34.9316 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680674\n",
      "[INFO 24-02-22 07:37:34.9316 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:34.9360 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.680674 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:34.9375 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:34.9375 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:34.9377 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:34.9379 UTC hyperparameters_optimizer.cc:582] [475/1100] Score: -0.680674 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:35.0261 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102752 train-accuracy:0.786064 valid-loss:1.067858 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:35.0395 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648658\n",
      "[INFO 24-02-22 07:37:35.0395 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.0397 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.648658 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:35.0400 UTC hyperparameters_optimizer.cc:582] [476/1100] Score: -0.648658 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:35.0404 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.0404 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.0406 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.0454 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.148568 train-accuracy:0.770171 valid-loss:1.118677 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:37:35.1021 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673119\n",
      "[INFO 24-02-22 07:37:35.1021 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.1023 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.673119 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:35.1026 UTC hyperparameters_optimizer.cc:582] [477/1100] Score: -0.673119 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:35.1031 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.1031 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.1033 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.1261 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081146 train-accuracy:0.826406 valid-loss:1.049556 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:35.1849 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634533\n",
      "[INFO 24-02-22 07:37:35.1878 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.1881 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.634533 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:35.1885 UTC hyperparameters_optimizer.cc:582] [478/1100] Score: -0.634533 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:35.1889 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.1889 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.1892 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.1968 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.139023 train-accuracy:0.761614 valid-loss:1.123169 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:37:35.2304 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.706096\n",
      "[INFO 24-02-22 07:37:35.2304 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.2306 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.706096 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:35.2309 UTC hyperparameters_optimizer.cc:582] [479/1100] Score: -0.706096 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:35.2317 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.2317 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.2327 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.2342 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317108 train-accuracy:0.612469 valid-loss:1.275283 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:35.2740 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.714437\n",
      "[INFO 24-02-22 07:37:35.2740 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.2744 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.714437 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:35.2750 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.2751 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.2753 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.2784 UTC hyperparameters_optimizer.cc:582] [480/1100] Score: -0.714437 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:35.2822 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.063307 train-accuracy:0.853301 valid-loss:1.053858 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:35.3622 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670176\n",
      "[INFO 24-02-22 07:37:35.3622 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.3625 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.670176 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:35.3627 UTC hyperparameters_optimizer.cc:582] [481/1100] Score: -0.670176 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:35.3634 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.3634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.3636 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.3698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.255067 train-accuracy:0.612469 valid-loss:1.243549 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:35.4160 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644221\n",
      "[INFO 24-02-22 07:37:35.4167 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.4170 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.644221 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:35.4175 UTC hyperparameters_optimizer.cc:582] [482/1100] Score: -0.644221 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:35.4179 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.4180 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.4183 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.4247 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683562\n",
      "[INFO 24-02-22 07:37:35.4247 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.4265 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.683562 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:35.4278 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305204 train-accuracy:0.612469 valid-loss:1.270729 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:35.4290 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.4290 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.4292 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.4349 UTC hyperparameters_optimizer.cc:582] [483/1100] Score: -0.683562 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:35.5070 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280641 train-accuracy:0.612469 valid-loss:1.243080 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:35.6466 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644262\n",
      "[INFO 24-02-22 07:37:35.6467 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.6468 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.644262 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:35.6470 UTC hyperparameters_optimizer.cc:582] [484/1100] Score: -0.644262 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:35.6475 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.6475 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.6478 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.6508 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312185 train-accuracy:0.612469 valid-loss:1.273629 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:35.8070 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.475467 train-accuracy:0.927873 valid-loss:0.632689 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:35.8070 UTC gradient_boosted_trees.cc:271] Truncates the model to 291 tree(s) i.e. 291  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.8071 UTC gradient_boosted_trees.cc:334] Final model num-trees:291 valid-loss:0.631541 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:35.8083 UTC hyperparameters_optimizer.cc:582] [485/1100] Score: -0.631541 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:35.8107 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.8108 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.8110 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.8140 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159591 train-accuracy:0.612469 valid-loss:1.119172 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:35.9423 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689574\n",
      "[INFO 24-02-22 07:37:35.9423 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:37:35.9427 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.689574 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:35.9431 UTC hyperparameters_optimizer.cc:582] [486/1100] Score: -0.689574 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:35.9442 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:35.9442 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:35.9448 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:35.9472 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.111346 train-accuracy:0.790954 valid-loss:1.077026 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:36.0927 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.743993\n",
      "[INFO 24-02-22 07:37:36.0927 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.0958 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.743993 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:36.1064 UTC hyperparameters_optimizer.cc:582] [487/1100] Score: -0.743993 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:36.1162 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.1162 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.1172 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.1217 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242754 train-accuracy:0.612469 valid-loss:1.202645 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:36.1416 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.726839\n",
      "[INFO 24-02-22 07:37:36.1443 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.1446 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.726839 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:36.1458 UTC hyperparameters_optimizer.cc:582] [488/1100] Score: -0.726839 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:36.1552 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.1553 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.1557 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.1612 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084877 train-accuracy:0.794621 valid-loss:1.075166 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:36.2236 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663509\n",
      "[INFO 24-02-22 07:37:36.2238 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.2250 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.663509 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:36.2297 UTC hyperparameters_optimizer.cc:582] [489/1100] Score: -0.663509 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:36.2403 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.2404 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.2406 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.3028 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646759\n",
      "[INFO 24-02-22 07:37:36.3028 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.3030 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.646759 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:36.3033 UTC hyperparameters_optimizer.cc:582] [490/1100] Score: -0.646759 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:36.3040 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.3041 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.3044 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.3067 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.124146 train-accuracy:0.783619 valid-loss:1.089037 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:36.3157 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663858\n",
      "[INFO 24-02-22 07:37:36.3157 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.3159 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.663858 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:36.3164 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.3164 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.3169 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.3172 UTC hyperparameters_optimizer.cc:582] [491/1100] Score: -0.663858 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:36.3183 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.259799 train-accuracy:0.612469 valid-loss:1.207643 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:36.3262 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229419 train-accuracy:0.612469 valid-loss:1.181461 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:36.3366 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650292\n",
      "[INFO 24-02-22 07:37:36.3366 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:36.3370 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:36.3370 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.650292 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:36.3378 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.3378 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.3380 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.3417 UTC hyperparameters_optimizer.cc:582] [492/1100] Score: -0.650292 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:36.3454 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228040 train-accuracy:0.612469 valid-loss:1.192230 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:36.3976 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668051\n",
      "[INFO 24-02-22 07:37:36.3976 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.3978 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.668051 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:36.3980 UTC hyperparameters_optimizer.cc:582] [493/1100] Score: -0.668051 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:36.3986 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.3986 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.3989 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.4098 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690912\n",
      "[INFO 24-02-22 07:37:36.4098 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.4098 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.690912 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:36.4100 UTC hyperparameters_optimizer.cc:582] [494/1100] Score: -0.690912 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:36.4114 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.4115 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.4118 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.4194 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.068733 train-accuracy:0.828851 valid-loss:1.029770 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:36.4376 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.195238 train-accuracy:0.612469 valid-loss:1.189977 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:36.6615 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677971\n",
      "[INFO 24-02-22 07:37:36.6615 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.6619 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.677971 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:36.6628 UTC hyperparameters_optimizer.cc:582] [495/1100] Score: -0.677971 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:36.6649 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.6649 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.6652 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.7279 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701005\n",
      "[INFO 24-02-22 07:37:36.7279 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.7295 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.701005 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:36.7306 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280749 train-accuracy:0.612469 valid-loss:1.242951 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:36.7341 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681486\n",
      "[INFO 24-02-22 07:37:36.7341 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:36.7345 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:36.7345 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.681486 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:36.7352 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.7352 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.7354 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.7384 UTC hyperparameters_optimizer.cc:582] [496/1100] Score: -0.681486 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:36.7403 UTC hyperparameters_optimizer.cc:582] [497/1100] Score: -0.701005 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:36.7511 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677851\n",
      "[INFO 24-02-22 07:37:36.7511 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.7514 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.677851 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:36.7525 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.7525 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.7528 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.7633 UTC hyperparameters_optimizer.cc:582] [498/1100] Score: -0.677851 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:36.7637 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.7637 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.7642 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.7787 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.043062 train-accuracy:0.832518 valid-loss:1.053730 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:36.7820 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669612\n",
      "[INFO 24-02-22 07:37:36.7821 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:37:36.7841 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.669612 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:36.7851 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:36.7851 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:36.7853 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:36.7891 UTC hyperparameters_optimizer.cc:582] [499/1100] Score: -0.669612 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:36.8212 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.019277 train-accuracy:0.874083 valid-loss:0.995567 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:36.8216 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236591 train-accuracy:0.612469 valid-loss:1.192475 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:36.8224 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081053 train-accuracy:0.844743 valid-loss:1.103946 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:37.2802 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.737308\n",
      "[INFO 24-02-22 07:37:37.2803 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:37.2805 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:37.2805 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.737308 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:37.2811 UTC hyperparameters_optimizer.cc:582] [500/1100] Score: -0.737308 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:37.2816 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:37.2816 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:37.2819 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:37.2846 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084109 train-accuracy:0.784841 valid-loss:1.053257 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:37:37.4208 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.69248\n",
      "[INFO 24-02-22 07:37:37.4208 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:37:37.4210 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.692480 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:37.4212 UTC hyperparameters_optimizer.cc:582] [501/1100] Score: -0.69248 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:37.4221 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:37.4221 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:37.4225 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:37.5290 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.050647 train-accuracy:0.838631 valid-loss:1.025388 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:37.8388 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663239\n",
      "[INFO 24-02-22 07:37:37.8388 UTC gradient_boosted_trees.cc:271] Truncates the model to 162 tree(s) i.e. 162  iteration(s).\n",
      "[INFO 24-02-22 07:37:37.8389 UTC gradient_boosted_trees.cc:334] Final model num-trees:162 valid-loss:0.663239 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:37.8401 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:37.8401 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:37.8403 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:37.8428 UTC hyperparameters_optimizer.cc:582] [502/1100] Score: -0.663239 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:37.8485 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130480 train-accuracy:0.814181 valid-loss:1.093778 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:38.0234 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656726\n",
      "[INFO 24-02-22 07:37:38.0234 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:37:38.0236 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.656726 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:38.0239 UTC hyperparameters_optimizer.cc:582] [503/1100] Score: -0.656726 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:38.0246 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:38.0246 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:38.0251 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:38.0300 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.149248 train-accuracy:0.612469 valid-loss:1.147712 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:38.1879 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652376\n",
      "[INFO 24-02-22 07:37:38.1879 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:38.1881 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.652376 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:38.1885 UTC hyperparameters_optimizer.cc:582] [504/1100] Score: -0.652376 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:38.1888 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:38.1888 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:38.1891 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:38.2897 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.74791\n",
      "[INFO 24-02-22 07:37:38.2897 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:37:38.2904 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.747910 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:38.2912 UTC hyperparameters_optimizer.cc:582] [505/1100] Score: -0.74791 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:38.2940 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:38.2941 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:38.2945 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:38.2984 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162161 train-accuracy:0.612469 valid-loss:1.148208 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:38.3253 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.062396 train-accuracy:0.823961 valid-loss:1.056296 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:38.6957 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652929\n",
      "[INFO 24-02-22 07:37:38.6957 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:38.6964 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.652929 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:38.6979 UTC hyperparameters_optimizer.cc:582] [506/1100] Score: -0.652929 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:38.6984 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:38.6984 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:38.6992 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:38.7329 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.202749 train-accuracy:0.612469 valid-loss:1.187776 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:38.7491 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63741\n",
      "[INFO 24-02-22 07:37:38.7491 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:38.7494 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.637410 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:38.7497 UTC hyperparameters_optimizer.cc:582] [507/1100] Score: -0.63741 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:38.7504 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:38.7504 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:38.7508 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:38.7528 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242108 train-accuracy:0.612469 valid-loss:1.203870 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:38.8762 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666031\n",
      "[INFO 24-02-22 07:37:38.8783 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:37:38.8784 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.666031 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:38.8791 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:38.8791 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:38.8793 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:38.8809 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290568 train-accuracy:0.612469 valid-loss:1.247882 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:38.8820 UTC hyperparameters_optimizer.cc:582] [508/1100] Score: -0.666031 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:39.0883 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62431\n",
      "[INFO 24-02-22 07:37:39.0904 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 07:37:39.0905 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.624310 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:39.0908 UTC hyperparameters_optimizer.cc:582] [509/1100] Score: -0.62431 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:39.0926 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:39.0926 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:39.0928 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:39.1546 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229346 train-accuracy:0.612469 valid-loss:1.193741 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:39.7330 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.71593\n",
      "[INFO 24-02-22 07:37:39.7331 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:39.7334 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:39.7334 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.715930 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:39.7338 UTC hyperparameters_optimizer.cc:582] [510/1100] Score: -0.71593 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:39.7344 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:39.7345 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:39.7349 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:39.7407 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.050465 train-accuracy:0.855746 valid-loss:1.050851 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:39.8347 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.610452\n",
      "[INFO 24-02-22 07:37:39.8347 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:39.8350 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.610452 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:39.8354 UTC hyperparameters_optimizer.cc:582] [511/1100] Score: -0.610452 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:39.8355 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:39.8355 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:39.8358 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-22 07:37:39.8641 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158897 train-accuracy:0.612469 valid-loss:1.142882 valid-accuracy:0.657534\n",
      " 24-02-22 07:37:39.8651 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668183\n",
      "[INFO 24-02-22 07:37:39.8651 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:37:39.8655 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.668183 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:39.8660 UTC hyperparameters_optimizer.cc:582] [512/1100] Score: -0.668183 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:39.8672 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:39.8672 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:39.8674 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:39.8790 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188723 train-accuracy:0.612469 valid-loss:1.142560 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:39.9986 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685573\n",
      "[INFO 24-02-22 07:37:39.9986 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:39.9989 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.685573 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:39.9995 UTC hyperparameters_optimizer.cc:582] [513/1100] Score: -0.685573 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:40.0015 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:40.0032 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:40.0034 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:40.0989 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.077582 train-accuracy:0.836186 valid-loss:1.021501 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:40.2914 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672592\n",
      "[INFO 24-02-22 07:37:40.2914 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:40.2916 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.672592 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:40.2918 UTC hyperparameters_optimizer.cc:582] [514/1100] Score: -0.672592 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:40.2924 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:40.2924 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:40.2929 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:40.2952 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.197280 train-accuracy:0.612469 valid-loss:1.159936 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:40.3902 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.786937\n",
      "[INFO 24-02-22 07:37:40.3903 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:40.3908 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.786937 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:40.3919 UTC hyperparameters_optimizer.cc:582] [515/1100] Score: -0.786937 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:40.3961 UTC gradient_boosted_trees.cc:591] Default loss set to [INFOBINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-22 07:37:40.3989 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: [INFO0.680751\n",
      "[INFO 24-02-22 07:37:40.3990 UTC gradient_boosted_trees.cc 24-02-22 07:37:40.3990 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "\n",
      "[INFO 24-02-22 07:37:40.3991 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.680751 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:40.3993 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:40.3995 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:40.3995 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:40.3997 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:40.4019 UTC hyperparameters_optimizer.cc:582] [516/1100] Score: -0.680751 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:40.4097 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.072389 train-accuracy:0.803178 valid-loss:1.053169 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:40.4223 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186957 train-accuracy:0.803178 valid-loss:1.131050 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:40.7181 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68821\n",
      "[INFO 24-02-22 07:37:40.7181 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:40.7189 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.688210 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:40.7195 UTC hyperparameters_optimizer.cc:582] [517/1100] Score: -0.68821 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:40.7204 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:40.7204 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:40.7224 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:40.7566 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679925\n",
      "[INFO 24-02-22 07:37:40.7566 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:37:40.7569 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.679925 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:40.7576 UTC hyperparameters_optimizer.cc:582] [518/1100] Score: -0.679925 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:40.7582 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:40.7582 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:40.7586 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:40.7961 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.215765 train-accuracy:0.612469 valid-loss:1.203969 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:40.7988 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276739 train-accuracy:0.612469 valid-loss:1.235475 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:40.8398 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674273\n",
      "[INFO 24-02-22 07:37:40.8398 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:40.8401 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.674273 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:40.8409 UTC hyperparameters_optimizer.cc:582] [519/1100] Score: -0.674273 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:40.8416 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:40.8416 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:40.8419 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:40.8503 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155145 train-accuracy:0.778729 valid-loss:1.089470 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:40.9361 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.709199\n",
      "[INFO 24-02-22 07:37:40.9361 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:40.9362 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.709199 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:40.9367 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:40.9367 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:40.9372 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:40.9384 UTC hyperparameters_optimizer.cc:582] [520/1100] Score: -0.709199 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:40.9454 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.134529 train-accuracy:0.814181 valid-loss:1.086581 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:41.1595 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666255\n",
      "[INFO 24-02-22 07:37:41.1595 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:41.1600 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.666255 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:41.1612 UTC hyperparameters_optimizer.cc:582] [521/1100] Score: -0.666255 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:41.1629 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:41.1630 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:41.1634 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:41.2006 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667545\n",
      "[INFO 24-02-22 07:37:41.2006 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:37:41.2009 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.667545 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:41.2022 UTC hyperparameters_optimizer.cc:582] [522/1100] Score: -0.667545 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:41.2031 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:41.2032 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:41.2036 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:41.2050 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282530 train-accuracy:0.612469 valid-loss:1.248848 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:41.2622 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652754\n",
      "[INFO 24-02-22 07:37:41.2623 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 07:37:41.2627 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.652754 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:37:41.2641 UTC hyperparameters_optimizer.cc:582] [523/1100] Score: -0.652754 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "INFO 24-02-22 07:37:41.2647 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:41.2647 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:41.2653 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:41.2905 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652941\n",
      "[INFO 24-02-22 07:37:41.2905 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:41.2908 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.652941 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:41.2913 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:41.2913 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:41.2915 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:41.2951 UTC hyperparameters_optimizer.cc:582] [524/1100] Score: -0.652941 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:41.2989 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313498 train-accuracy:0.612469 valid-loss:1.272226 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:41.3078 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.150504 train-accuracy:0.821516 valid-loss:1.088955 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:41.3241 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.962642 train-accuracy:0.944988 valid-loss:1.045777 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:41.3635 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631777\n",
      "[INFO 24-02-22 07:37:41.3635 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:37:41.3635 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.631777 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:41.3637 UTC hyperparameters_optimizer.cc:582] [525/1100] Score: -0.631777 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:41.3640 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:41.3640 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:41.3643 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:41.3944 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309742 train-accuracy:0.612469 valid-loss:1.269998 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:42.0331 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661404\n",
      "[INFO 24-02-22 07:37:42.0331 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:42.0334 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.661404 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:42.0337 UTC hyperparameters_optimizer.cc:582] [526/1100] Score: -0.661404 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:42.0342 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:42.0342 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:42.0344 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:42.0428 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.189972 train-accuracy:0.777506 valid-loss:1.126811 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:42.2356 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645938\n",
      "[INFO 24-02-22 07:37:42.2356 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 07:37:42.2357 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.645938 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:42.2358 UTC hyperparameters_optimizer.cc:582] [527/1100] Score: -0.645938 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:42.2361 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:42.2361 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:42.2363 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:42.2553 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.168873 train-accuracy:0.612469 valid-loss:1.136389 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:42.6387 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666547\n",
      "[INFO 24-02-22 07:37:42.6387 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:42.6390 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.666547 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:37:42.6397 UTC hyperparameters_optimizer.cc:582] [528/1100] Score: -0.666547 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:37:42.6402 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:42.6404 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:42.6407 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:42.7020 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.138301 train-accuracy:0.784841 valid-loss:1.111714 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:42.8676 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685777\n",
      "[INFO 24-02-22 07:37:42.8676 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 07:37:42.8677 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.685777 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:42.8681 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:42.8681 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:42.8683 UTC hyperparameters_optimizer.cc:582] [529/1100] Score: -0.685777 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:42.8687 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:42.9496 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311966 train-accuracy:0.612469 valid-loss:1.271943 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:43.0546 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.742029\n",
      "[INFO 24-02-22 07:37:43.0547 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.0551 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.742029 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:43.0561 UTC hyperparameters_optimizer.cc:582] [530/1100] Score: -0.742029 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:43.0568 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.0568 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.0571 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.0602 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228952 train-accuracy:0.612469 valid-loss:1.190328 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:43.2376 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654903\n",
      "[INFO 24-02-22 07:37:43.2376 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.2379 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.654903 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:43.2386 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.2386 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.2389 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.2417 UTC hyperparameters_optimizer.cc:582] [531/1100] Score: -0.654903 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:43.2422 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277545 train-accuracy:0.612469 valid-loss:1.239868 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:43.2522 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678698\n",
      "[INFO 24-02-22 07:37:43.2522 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.2525 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.678698 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:43.2529 UTC hyperparameters_optimizer.cc:582] [532/1100] Score: -0.678698 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:43.2536 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.2537 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.2538 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.2763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122534 train-accuracy:0.821516 valid-loss:1.102320 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:43.2883 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674887\n",
      "[INFO 24-02-22 07:37:43.2883 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.2886 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.674887 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:43.2888 UTC hyperparameters_optimizer.cc:582] [533/1100] Score: -0.674887 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:43.2897 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.2897 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.2899 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.3576 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314112 train-accuracy:0.612469 valid-loss:1.272035 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:43.6328 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665305\n",
      "[INFO 24-02-22 07:37:43.6328 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.6333 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.665305 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:43.6343 UTC hyperparameters_optimizer.cc:582] [534/1100] Score: -0.665305 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:43.6368 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.6368 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.6371 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.6399 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315727 train-accuracy:0.612469 valid-loss:1.275081 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:43.6693 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667898\n",
      "[INFO 24-02-22 07:37:43.6693 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.6696 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.667898 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:43.6699 UTC hyperparameters_optimizer.cc:582] [535/1100] Score: -0.667898 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:43.6708 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.6708 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.6710 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.6736 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.091366 train-accuracy:0.803178 valid-loss:1.069384 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:43.7901 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687209\n",
      "[INFO 24-02-22 07:37:43.7901 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.7902 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.687209 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:43.7906 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.7906 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.7909 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.7917 UTC hyperparameters_optimizer.cc:582] [536/1100] Score: -0.687209 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:43.7931 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201512 train-accuracy:0.612469 valid-loss:1.157001 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:43.8135 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.595389\n",
      "[INFO 24-02-22 07:37:43.8135 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.8137 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.595389 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:43.8139 UTC hyperparameters_optimizer.cc:582] [537/1100] Score: -0.595389 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:43.8143 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.8143 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.8145 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.9031 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661543\n",
      "[INFO 24-02-22 07:37:43.9066 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:43.9067 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.661543 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:43.9069 UTC hyperparameters_optimizer.cc:582] [538/1100] Score: -0.661543 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:43.9090 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:43.9091 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:43.9093 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:43.9164 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313679 train-accuracy:0.612469 valid-loss:1.271827 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:43.9203 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.017906 train-accuracy:0.880196 valid-loss:1.031751 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:44.0439 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667127\n",
      "[INFO 24-02-22 07:37:44.0440 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:37:44.0442 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.667127 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:44.0447 UTC hyperparameters_optimizer.cc:582] [539/1100] Score: -0.667127 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:44.0455 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:44.0455 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:44.0458 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:44.1465 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.269965 train-accuracy:0.612469 valid-loss:1.234992 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:44.2772 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685213\n",
      "[INFO 24-02-22 07:37:44.2772 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:44.2774 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.685213 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:44.2780 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:44.2780 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:44.2782 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:44.2817 UTC hyperparameters_optimizer.cc:582] [540/1100] Score: -0.685213 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:44.2834 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236479 train-accuracy:0.612469 valid-loss:1.199430 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:44.3197 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.739932\n",
      "[INFO 24-02-22 07:37:44.3250 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:44.3254 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:44.3255 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.739932 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:44.3257 UTC hyperparameters_optimizer.cc:582] [541/1100] Score: -0.739932 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:44.3275 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:44.3275 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:44.3277 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:44.3338 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653615\n",
      "[INFO 24-02-22 07:37:44.3339 UTC gradient_boosted_trees.cc:271] Truncates the model to 178 tree(s) i.e. 178  iteration(s).\n",
      "[INFO 24-02-22 07:37:44.3341 UTC gradient_boosted_trees.cc:334] Final model num-trees:178 valid-loss:0.653615 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:44.3394 UTC hyperparameters_optimizer.cc:582] [542/1100] Score: -0.653615 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:44.3401 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:44.3401 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:44.3403 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:44.3553 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.136670 train-accuracy:0.775061 valid-loss:1.115965 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:44.3641 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221352 train-accuracy:0.612469 valid-loss:1.200149 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:44.5584 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682142\n",
      "[INFO 24-02-22 07:37:44.5584 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:44.5586 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.682142 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:44.5587 UTC hyperparameters_optimizer.cc:582] [543/1100] Score: -0.682142 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:44.5591 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:44.5592 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:44.5594 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:44.6237 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282190 train-accuracy:0.612469 valid-loss:1.244887 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:44.8968 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673587\n",
      "[INFO 24-02-22 07:37:44.8968 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:44.8972 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:44.8972 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.673587 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:44.8975 UTC hyperparameters_optimizer.cc:582] [544/1100] Score: -0.673587 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:44.8983 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:44.8983 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:44.8985 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:44.9075 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.138801 train-accuracy:0.789731 valid-loss:1.095568 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:45.2705 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672357\n",
      "[INFO 24-02-22 07:37:45.2705 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:45.2707 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:45.2707 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.672357 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:45.2710 UTC hyperparameters_optimizer.cc:582] [545/1100] Score: -0.672357 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:45.2714 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:45.2714 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:45.2717 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:45.2956 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.036017 train-accuracy:0.848411 valid-loss:1.037905 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:45.6336 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.607524\n",
      "[INFO 24-02-22 07:37:45.6336 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:45.6339 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.607524 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:45.6344 UTC hyperparameters_optimizer.cc:582] [546/1100] Score: -0.607524 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:45.6350 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:45.6351 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:45.6354 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:45.7178 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.032570 train-accuracy:0.826406 valid-loss:1.037647 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:46.1783 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673641\n",
      "[INFO 24-02-22 07:37:46.1784 UTC gradient_boosted_trees.cc:271] Truncates the model to 131 tree(s) i.e. 131  iteration(s).\n",
      "[INFO 24-02-22 07:37:46.1788 UTC gradient_boosted_trees.cc:334] Final model num-trees:131 valid-loss:0.673641 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:46.1818 UTC hyperparameters_optimizer.cc:582] [547/1100] Score: -0.673641 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:46.1825 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:46.1825 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:46.1827 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:46.1873 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187249 train-accuracy:0.612469 valid-loss:1.145315 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:46.2946 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663015\n",
      "[INFO 24-02-22 07:37:46.2946 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:37:46.2950 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.663015 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:46.2957 UTC hyperparameters_optimizer.cc:582] [548/1100] Score: -0.663015 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:46.2973 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:46.2973 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:46.2976 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:46.3126 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663303\n",
      "[INFO 24-02-22 07:37:46.3127 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 07:37:46.3129 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.663303 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:46.3146 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:46.3146 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:46.3148 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:46.3151 UTC hyperparameters_optimizer.cc:582] [549/1100] Score: -0.663303 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:46.3245 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234594 train-accuracy:0.612469 valid-loss:1.198591 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:46.3353 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.049846 train-accuracy:0.833741 valid-loss:1.028492 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:46.3604 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643575\n",
      "[INFO 24-02-22 07:37:46.3638 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:46.3640 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.643575 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:46.3644 UTC hyperparameters_optimizer.cc:582] [550/1100] Score: -0.643575 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:46.3649 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:46.3649 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:46.3651 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:46.3665 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287483 train-accuracy:0.612469 valid-loss:1.249270 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:46.3833 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.741392\n",
      "[INFO 24-02-22 07:37:46.3833 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:46.3838 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.741392 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:46.3846 UTC hyperparameters_optimizer.cc:582] [551/1100] Score: -0.741392 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:46.3853 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:46.3853 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:46.3855 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:46.3940 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286624 train-accuracy:0.612469 valid-loss:1.245079 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:46.6670 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658059\n",
      "[INFO 24-02-22 07:37:46.6679 UTC gradient_boosted_trees.cc:271] Truncates the model to 181 tree(s) i.e. 181  iteration(s).\n",
      "[INFO 24-02-22 07:37:46.6680 UTC gradient_boosted_trees.cc:334] Final model num-trees:181 valid-loss:0.658059 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:46.6685 UTC hyperparameters_optimizer.cc:582] [552/1100] Score: -0.658059 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:46.6689 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:46.6690 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:46.6695 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:46.7544 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.210186 train-accuracy:0.612469 valid-loss:1.187016 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:46.8475 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681963\n",
      "[INFO 24-02-22 07:37:46.8476 UTC gradient_boosted_trees.cc:271] Truncates the model to 145 tree(s) i.e. 145  iteration(s).\n",
      "[INFO 24-02-22 07:37:46.8480 UTC gradient_boosted_trees.cc:334] Final model num-trees:145 valid-loss:0.681963 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:46.8506 UTC hyperparameters_optimizer.cc:582] [553/1100] Score: -0.681963 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:46.8539 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680228\n",
      "[INFO 24-02-22 07:37:46.8539 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:37:46.8540 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.680228 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:46.8541 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:46.8541 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:46.8543 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:46.8544 UTC hyperparameters_optimizer.cc:582] [554/1100] Score: -0.680228 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:46.8550 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:46.8550 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:46.8552 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:46.8598 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.127226 train-accuracy:0.800734 valid-loss:1.119573 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:46.9193 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142987 train-accuracy:0.765281 valid-loss:1.100802 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:37:47.0210 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649454\n",
      "[INFO 24-02-22 07:37:47.0211 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 07:37:47.0213 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.649454 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:47.0218 UTC hyperparameters_optimizer.cc:582] [555/1100] Score: -0.649454 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:47.0229 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:47.0229 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:47.0231 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:47.0629 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.206079 train-accuracy:0.612469 valid-loss:1.198673 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:47.0633 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692704\n",
      "[INFO 24-02-22 07:37:47.0633 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:47.0637 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.692704 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:47.0640 UTC hyperparameters_optimizer.cc:582] [556/1100] Score: -0.692704 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:47.0647 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:47.0647 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:47.0650 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:47.1425 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.130031 train-accuracy:0.612469 valid-loss:1.139707 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:47.2885 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670647\n",
      "[INFO 24-02-22 07:37:47.2886 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 07:37:47.2887 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.670647 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:47.2893 UTC hyperparameters_optimizer.cc:582] [557/1100] Score: -0.670647 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:47.2901 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:47.2901 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:47.2904 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:47.3084 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070763 train-accuracy:0.831296 valid-loss:1.026674 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:47.9216 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669635\n",
      "[INFO 24-02-22 07:37:47.9216 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 07:37:47.9219 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.669635 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:47.9240 UTC hyperparameters_optimizer.cc:582] [558/1100] Score: -0.669635 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:47.9302 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:47.9303 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:47.9305 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:47.9327 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287168 train-accuracy:0.612469 valid-loss:1.247454 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:47.9748 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.715732\n",
      "[INFO 24-02-22 07:37:47.9748 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:47.9755 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:47.9756 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.715732 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:47.9765 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:47.9765 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:47.9767 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:47.9800 UTC hyperparameters_optimizer.cc:582] [559/1100] Score: -0.715732 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:48.0091 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201701 train-accuracy:0.612469 valid-loss:1.143608 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:48.1020 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695686\n",
      "[INFO 24-02-22 07:37:48.1020 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:48.1021 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.695686 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:48.1025 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:48.1025 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:48.1027 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:48.1051 UTC hyperparameters_optimizer.cc:582] [560/1100] Score: -0.695686 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:48.1102 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313936 train-accuracy:0.612469 valid-loss:1.273984 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:48.1836 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665628\n",
      "[INFO 24-02-22 07:37:48.1836 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 07:37:48.1839 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.665628 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:48.1847 UTC hyperparameters_optimizer.cc:582] [561/1100] Score: -0.665628 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:48.1877 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:48.1896 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:48.1898 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:48.1917 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.181282 train-accuracy:0.612469 valid-loss:1.139938 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:48.3455 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633285\n",
      "[INFO 24-02-22 07:37:48.3459 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:37:48.3461 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.633285 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:48.3464 UTC hyperparameters_optimizer.cc:582] [562/1100] Score: -0.633285 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:48.3482 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:48.3484 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:48.3486 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:48.3509 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.189827 train-accuracy:0.777506 valid-loss:1.134758 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:48.5790 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662971\n",
      "[INFO 24-02-22 07:37:48.5794 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:37:48.5795 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.662971 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:48.5796 UTC hyperparameters_optimizer.cc:582] [563/1100] Score: -0.662971 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:48.5803 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:48.5803 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:48.5805 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:48.5942 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.271173 train-accuracy:0.612469 valid-loss:1.246334 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:48.8860 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.773603\n",
      "[INFO 24-02-22 07:37:48.8860 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:48.8864 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:48.8864 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.773603 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:48.8866 UTC hyperparameters_optimizer.cc:582] [564/1100] Score: -0.773603 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:48.8872 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:48.8872 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:48.8874 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:48.8901 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311082 train-accuracy:0.612469 valid-loss:1.271920 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:49.3537 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670647\n",
      "[INFO 24-02-22 07:37:49.3537 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 07:37:49.3541 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.670647 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:37:49.3572 UTC hyperparameters_optimizer.cc:582] [565/1100] Score: -0.670647 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "INFO 24-02-22 07:37:49.3585 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:49.3586 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:49.3604 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:49.3773 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.972722 train-accuracy:0.926650 valid-loss:1.042281 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:49.4074 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67179\n",
      "[INFO 24-02-22 07:37:49.4075 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 07:37:49.4078 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.671790 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:49.4089 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:49.4089 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:49.4092 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:49.4117 UTC hyperparameters_optimizer.cc:582] [566/1100] Score: -0.67179 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:49.4191 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.082092 train-accuracy:0.808068 valid-loss:1.047516 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:49.4728 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668354\n",
      "[INFO 24-02-22 07:37:49.4728 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:49.4741 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.668354 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:49.4750 UTC hyperparameters_optimizer.cc:582] [567/1100] Score: -0.668354 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:49.4796 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:49.4797 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:49.4800 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:49.4956 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647422\n",
      "[INFO 24-02-22 07:37:49.4957 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 07:37:49.4959 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.647422 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:49.4969 UTC hyperparameters_optimizer.cc:582] [568/1100] Score: -0.647422 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:49.4984 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:49.4984 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:49.4986 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:49.5034 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619973\n",
      "[INFO 24-02-22 07:37:49.5034 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:49.5041 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.619973 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:49.5048 UTC hyperparameters_optimizer.cc:582] [569/1100] Score: -0.619973 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:49.5060 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:49.5060 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:49.5067 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:49.5089 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219493 train-accuracy:0.612469 valid-loss:1.190803 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:49.5275 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311017 train-accuracy:0.612469 valid-loss:1.273227 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:49.5695 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274747 train-accuracy:0.612469 valid-loss:1.236305 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:49.6170 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654453\n",
      "[INFO 24-02-22 07:37:49.6171 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:49.6180 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.654453 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:49.6188 UTC hyperparameters_optimizer.cc:582] [570/1100] Score: -0.654453 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:49.6201 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:49.6202 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:49.6204 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:49.6257 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.260908 train-accuracy:0.612469 valid-loss:1.235425 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:49.8886 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659837\n",
      "[INFO 24-02-22 07:37:49.8886 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:49.8891 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.659837 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:49.8895 UTC hyperparameters_optimizer.cc:582] [571/1100] Score: -0.659837 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:49.8913 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:49.8916 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:49.8919 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:49.8991 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157756 train-accuracy:0.792176 valid-loss:1.116027 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:50.0285 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.696291\n",
      "[INFO 24-02-22 07:37:50.0285 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:37:50.0292 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.696291 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:50.0309 UTC hyperparameters_optimizer.cc:582] [572/1100] Score: -0.696291 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:50.0350 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:50.0350 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:50.0352 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:50.1529 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102471 train-accuracy:0.828851 valid-loss:1.070251 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:50.2482 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67424\n",
      "[INFO 24-02-22 07:37:50.2482 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 07:37:50.2497 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.674240 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:50.2550 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:50.2550 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:50.2551 UTC hyperparameters_optimizer.cc:582] [573/1100] Score: -0.67424 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:50.2611 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:50.3517 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645967\n",
      "[INFO 24-02-22 07:37:50.3517 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 07:37:50.3518 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.645967 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:50.3524 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:50.3524 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:50.3528 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:50.3547 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.177807 train-accuracy:0.612469 valid-loss:1.141104 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:50.3551 UTC hyperparameters_optimizer.cc:582] [574/1100] Score: -0.645967 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:50.4212 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230987 train-accuracy:0.612469 valid-loss:1.193765 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:50.4890 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65547\n",
      "[INFO 24-02-22 07:37:50.4890 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:50.4910 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:50.4911 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.655470 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:50.4946 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:50.4946 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:50.4949 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:50.4951 UTC hyperparameters_optimizer.cc:582] [575/1100] Score: -0.65547 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:50.5591 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.128674 train-accuracy:0.808068 valid-loss:1.088033 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:50.6114 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652517\n",
      "[INFO 24-02-22 07:37:50.6115 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:37:50.6115 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.652517 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:50.6152 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:50.6153 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:50.6155 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:50.6213 UTC hyperparameters_optimizer.cc:582] [576/1100] Score: -0.652517 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:50.6895 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.135568 train-accuracy:0.792176 valid-loss:1.094077 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:51.0247 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659814\n",
      "[INFO 24-02-22 07:37:51.0247 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 07:37:51.0252 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.659814 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:51.0279 UTC hyperparameters_optimizer.cc:582] [577/1100] Score: -0.659814 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:51.0288 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:51.0288 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:51.0309 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:51.0329 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245536 train-accuracy:0.612469 valid-loss:1.203326 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:51.0960 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631928\n",
      "[INFO 24-02-22 07:37:51.0960 UTC gradient_boosted_trees.cc:271] Truncates the model to 94 tree(s) i.e. 94  iteration(s).\n",
      "[INFO 24-02-22 07:37:51.0962 UTC gradient_boosted_trees.cc:334] Final model num-trees:94 valid-loss:0.631928 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:51.0969 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:51.0970 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:51.0971 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:51.0984 UTC hyperparameters_optimizer.cc:582] [578/1100] Score: -0.631928 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:51.1585 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.124674 train-accuracy:0.809291 valid-loss:1.061596 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:51.4201 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636662\n",
      "[INFO 24-02-22 07:37:51.4201 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:51.4205 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.636662 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:51.4211 UTC hyperparameters_optimizer.cc:582] [579/1100] Score: -0.636662 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:51.4215 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:51.4215 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:51.4218 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:51.4726 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626767\n",
      "[INFO 24-02-22 07:37:51.4728 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:37:51.4730 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.626767 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:51.4737 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:51.4738 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[[INFO 24-02-22 07:37:51.4742 UTC hyperparameters_optimizer.cc:582] [580/1100] Score: -0.626767 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:37:51.4748 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:51.4958 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276106 train-accuracy:0.612469 valid-loss:1.240494 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:51.4999 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.978855 train-accuracy:0.883863 valid-loss:0.948107 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:51.5721 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.760867\n",
      "[INFO 24-02-22 07:37:51.5721 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:51.5738 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.760867 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:51.5775 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD[INFO\n",
      " 24-02-22 07:37:51.5775 UTC hyperparameters_optimizer.cc:582] [[581/1100] Score: -0.760867 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:37:51.5784 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:51.5795 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:51.6194 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222682 train-accuracy:0.612469 valid-loss:1.197447 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:52.1440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668437\n",
      "[INFO 24-02-22 07:37:52.1457 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:52.1464 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:52.1464 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.668437 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:52.1468 UTC hyperparameters_optimizer.cc:582] [582/1100] Score: -0.668437 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:52.1477 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:52.1477 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:52.1482 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:52.1531 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176367 train-accuracy:0.612469 valid-loss:1.154721 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:52.3853 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.696039\n",
      "[INFO 24-02-22 07:37:52.3874 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:37:52.3878 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.696039 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:52.3882 UTC hyperparameters_optimizer.cc:582] [583/1100] Score: -0.696039 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:52.3951 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:52.3951 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:52.3953 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:52.4184 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.073296 train-accuracy:0.832518 valid-loss:1.044381 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:52.8281 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677892\n",
      "[INFO 24-02-22 07:37:52.8281 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:52.8283 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.677892 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:52.8285 UTC hyperparameters_optimizer.cc:582] [584/1100] Score: -0.677892 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:52.8297 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:52.8297 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:52.8299 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:52.8376 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.185102 train-accuracy:0.612469 valid-loss:1.162812 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:52.9282 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631353\n",
      "[INFO 24-02-22 07:37:52.9282 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:52.9286 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:52.9286 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.631353 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:52.9289 UTC hyperparameters_optimizer.cc:582] [585/1100] Score: -0.631353 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:52.9297 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:52.9297 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:52.9299 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:52.9970 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247583 train-accuracy:0.612469 valid-loss:1.193634 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:53.2187 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682551\n",
      "[INFO 24-02-22 07:37:53.2187 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:53.2189 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.682551 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:53.2192 UTC hyperparameters_optimizer.cc:582] [586/1100] Score: -0.682551 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:53.2198 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:53.2198 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:53.2208 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:53.2278 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.220459 train-accuracy:0.612469 valid-loss:1.168939 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:53.5508 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68016\n",
      "[INFO 24-02-22 07:37:53.5509 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:53.5511 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.680160 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:53.5516 UTC hyperparameters_optimizer.cc:582] [587/1100] Score: -0.68016 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:53.5521 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:53.5522 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:53.5526 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:53.5529 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6668\n",
      "[INFO 24-02-22 07:37:53.5531 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:53.5533 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.666800 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:53.5535 UTC hyperparameters_optimizer.cc:582] [588/1100] Score: -0.6668 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:53.5539 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:53.5539 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:53.5541 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:53.5549 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187562 train-accuracy:0.612469 valid-loss:1.137924 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:53.5649 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.147508 train-accuracy:0.743276 valid-loss:1.109559 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:37:53.7094 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.650356\n",
      "[INFO 24-02-22 07:37:53.7094 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:37:53.7094 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.650356 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:53.7096 UTC hyperparameters_optimizer.cc:582] [589/1100] Score: -0.650356 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:53.7101 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:53.7101 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:53.7105 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:53.7172 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.074889 train-accuracy:0.823961 valid-loss:1.027845 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:53.7388 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67697\n",
      "[INFO 24-02-22 07:37:53.7388 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:53.7391 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.676970 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:53.7394 UTC hyperparameters_optimizer.cc:582] [590/1100] Score: -0.67697 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:53.7404 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:53.7405 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:53.7409 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:53.7423 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671006\n",
      "[INFO 24-02-22 07:37:53.7423 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 07:37:53.7423 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.671006 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:53.7427 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:53.7427 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:53.7429 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:53.7451 UTC hyperparameters_optimizer.cc:582] [591/1100] Score: -0.671006 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:53.7492 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162731 train-accuracy:0.612469 valid-loss:1.134412 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:53.7693 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070135 train-accuracy:0.838631 valid-loss:1.016774 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:53.8159 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684585\n",
      "[INFO 24-02-22 07:37:53.8164 UTC gradient_boosted_trees.cc:271] Truncates the model to 133 tree(s) i.e. 133  iteration(s).\n",
      "[INFO 24-02-22 07:37:53.8174 UTC gradient_boosted_trees.cc:334] Final model num-trees:133 valid-loss:0.684585 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:53.8283 UTC hyperparameters_optimizer.cc:582] [592/1100] Score: -0.684585 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:53.8297 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:53.8299 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:53.8304 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:53.8496 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278898 train-accuracy:0.612469 valid-loss:1.239114 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.0075 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691598\n",
      "[INFO 24-02-22 07:37:54.0075 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.0077 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.691598 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.0084 UTC hyperparameters_optimizer.cc:582] [593/1100] Score: -0.691598 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:54.0100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.0104 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.0106 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.0269 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.087344 train-accuracy:0.784841 valid-loss:1.032175 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:54.0333 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669302\n",
      "[INFO 24-02-22 07:37:54.0335 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.0338 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.669302 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:37:54.0344 UTC hyperparameters_optimizer.cc:582INFO 24-02-22 07:37:54.0345 UTC ] [594/1100] Score: -0.669302gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " / -0.592812[ HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }INFO 24-02-22 07:37:54.0348 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[\n",
      "INFO 24-02-22 07:37:54.0354 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.0555 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279853 train-accuracy:0.612469 valid-loss:1.243428 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.0937 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685428\n",
      "[INFO 24-02-22 07:37:54.0938 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.0940 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.685428 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.0943 UTC hyperparameters_optimizer.cc:582] [595/1100] Score: -0.685428 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:54.0949 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.0949 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.0952 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.0982 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.185075 train-accuracy:0.612469 valid-loss:1.140002 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.1445 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654902\n",
      "[INFO 24-02-22 07:37:54.1445 UTC gradient_boosted_trees.cc:271] Truncates the model to 78 tree(s) i.e. 78  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.1449 UTC gradient_boosted_trees.cc:334] Final model num-trees:78 valid-loss:0.654902 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:54.1483 UTC gradient_boosted_trees.cc[INFO 24-02-22 07:37:54.1487 UTC hyperparameters_optimizer.cc:582] [596/1100] Score: -0.654902 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      ":591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.1490 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.1502 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.1602 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278499 train-accuracy:0.612469 valid-loss:1.239514 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.2436 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649033\n",
      "[INFO 24-02-22 07:37:54.2437 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.2440 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.649033 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:54.2443 UTC hyperparameters_optimizer.cc:582] [597/1100] Score: -0.649033 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:54.2450 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.2454 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.2456 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.2523 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646073\n",
      "[INFO 24-02-22 07:37:54.2523 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.2526 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.646073 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.2532 UTC hyperparameters_optimizer.cc:582] [598/1100] Score: -0.646073 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:54.2543 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.2543 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.2548 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.2563 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291060 train-accuracy:0.612469 valid-loss:1.247120 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.2758 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671807\n",
      "[INFO 24-02-22 07:37:54.2758 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.2762 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.671807 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.2766 UTC hyperparameters_optimizer.cc:582] [599/1100] Score: -0.671807 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:54.2772 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.2772 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.2775 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.2776 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.171343 train-accuracy:0.612469 valid-loss:1.161137 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.2958 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228776 train-accuracy:0.612469 valid-loss:1.188950 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.2980 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676771\n",
      "[INFO 24-02-22 07:37:54.2980 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.2983 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.676771 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:54.2985 UTC hyperparameters_optimizer.cc:582] [600/1100] Score: -0.676771 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:54.2990 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.2990 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.2993 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.3411 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.019951 train-accuracy:0.845966 valid-loss:1.036303 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:54.6078 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.696421\n",
      "[INFO 24-02-22 07:37:54.6078 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.6080 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.696421 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.6086 UTC hyperparameters_optimizer.cc:582] [601/1100] Score: -0.696421 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:54.6097 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.6097 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.6101 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.6226 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658338\n",
      "[INFO 24-02-22 07:37:54.6226 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.6228 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.658338 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.6231 UTC hyperparameters_optimizer.cc:582] [602/1100] Score: -0.658338 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO[INFO 24-02-22 07:37:54.6246 UTC gradient_boosted_trees.cc 24-02-22 07:37:54.6246 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312322 train-accuracy:0.612469 valid-loss:1.269584 valid-accuracy:0.657534\n",
      ":591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.6246 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.6252 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.6560 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236377 train-accuracy:0.612469 valid-loss:1.202092 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.7813 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67889\n",
      "[INFO 24-02-22 07:37:54.7814 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.7817 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.678890 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.7835 UTC hyperparameters_optimizer.cc:582] [603/1100] Score: -0.67889 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:54.7843 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.7843 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.7856 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.7980 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317228 train-accuracy:0.612469 valid-loss:1.273391 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:54.9311 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692824\n",
      "[INFO 24-02-22 07:37:54.9311 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.9314 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.692824 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.9326 UTC hyperparameters_optimizer.cc:582] [604/1100] Score: -0.692824 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:54.9330 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.9330 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.9339 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.9456 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.171479 train-accuracy:0.766504 valid-loss:1.117394 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:54.9544 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66913\n",
      "[INFO 24-02-22 07:37:54.9544 UTC gradient_boosted_trees.cc:271] Truncates the model to 134 tree(s) i.e. 134  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.9545 UTC gradient_boosted_trees.cc:334] Final model num-trees:134 valid-loss:0.669130 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:54.9555 UTC hyperparameters_optimizer.cc:582] [605/1100] Score: -0.66913 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:54.9560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.9560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.9569 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.9702 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.032281 train-accuracy:0.850856 valid-loss:1.015334 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:54.9845 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.620261\n",
      "[INFO 24-02-22 07:37:54.9846 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.9849 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.620261 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:54.9852 UTC hyperparameters_optimizer.cc:582] [606/1100] Score: -0.620261 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:54.9858 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.9858 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.9861 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:54.9891 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.165946 train-accuracy:0.784841 valid-loss:1.108983 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:54.9982 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703447\n",
      "[INFO 24-02-22 07:37:54.9982 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:54.9983 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.703447 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:54.9984 UTC hyperparameters_optimizer.cc:582] [607/1100] Score: -0.703447 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:37:54.9987 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:54.9988 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:54.9990 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.0594 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316529 train-accuracy:0.612469 valid-loss:1.273355 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:55.5075 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.707613\n",
      "[INFO 24-02-22 07:37:55.5075 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:37:55.5078 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.707613 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:55.5081 UTC hyperparameters_optimizer.cc:582] [608/1100] Score: -0.707613 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:55.5086 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:55.5086 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:55.5089 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.5223 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.128906 train-accuracy:0.810513 valid-loss:1.075916 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:55.5563 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.788192\n",
      "[INFO 24-02-22 07:37:55.5563 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:55.5567 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:55.5567 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.788192 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:55.5570 UTC hyperparameters_optimizer.cc:582] [609/1100] Score: -0.788192 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:55.5577 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:55.5578 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:55.5580 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.6757 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.214520 train-accuracy:0.612469 valid-loss:1.186213 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:55.7087 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681778\n",
      "[INFO 24-02-22 07:37:55.7088 UTC gradient_boosted_trees.cc:271] Truncates the model to 80 tree(s) i.e. 80  iteration(s).\n",
      "[INFO 24-02-22 07:37:55.7088 UTC gradient_boosted_trees.cc:334] Final model num-trees:80 valid-loss:0.681778 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:55.7091 UTC hyperparameters_optimizer.cc:582] [610/1100] Score: -0.681778 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:55.7100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:55.7101 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:55.7103 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.7126 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285094 train-accuracy:0.612469 valid-loss:1.243894 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:55.7310 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682037\n",
      "[INFO 24-02-22 07:37:55.7310 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 07:37:55.7311 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.682037 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:55.7313 UTC hyperparameters_optimizer.cc:582] [611/1100] Score: -0.682037 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:55.7317 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:55.7317 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:55.7320 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.7357 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.120283 train-accuracy:0.775061 valid-loss:1.094050 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:37:55.8012 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631033\n",
      "[INFO 24-02-22 07:37:55.8012 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:37:55.8015 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.631033 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:55.8022 UTC hyperparameters_optimizer.cc:582] [612/1100] Score: -0.631033 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:55.8031 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:55.8031 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:55.8033 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.8057 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315669 train-accuracy:0.612469 valid-loss:1.275423 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:55.8116 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65429\n",
      "[INFO 24-02-22 07:37:55.8117 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:37:55.8118 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.654290 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:55.8120 UTC hyperparameters_optimizer.cc:582] [613/1100] Score: -0.65429 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:55.8123 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:55.8124 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:55.8127 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.8198 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151894 train-accuracy:0.765281 valid-loss:1.081931 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:37:55.9382 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659402\n",
      "[INFO 24-02-22 07:37:55.9382 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:37:55.9409 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.659402 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:55.9419 UTC hyperparameters_optimizer.cc:582] [614/1100] Score: -0.659402 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:55.9426 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:55.9426 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:55.9434 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.9456 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.200888 train-accuracy:0.612469 valid-loss:1.165182 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:55.9464 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668639\n",
      "[INFO 24-02-22 07:37:55.9464 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:55.9468 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:55.9469 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.668639 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:55.9476 UTC hyperparameters_optimizer.cc:582] [615/1100] Score: -0.668639 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:55.9482 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:55.9482 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:55.9485 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:55.9512 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289230 train-accuracy:0.612469 valid-loss:1.253152 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:56.0826 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664075\n",
      "[INFO 24-02-22 07:37:56.0843 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:56.0844 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:56.0845 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.664075 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:56.0845 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649115\n",
      "[INFO 24-02-22 07:37:56.0845 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.0846 UTC hyperparameters_optimizer.cc:582] [616/1100] Score: -0.664075 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:56.0847 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.649115 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:56.0849 UTC hyperparameters_optimizer.cc:582] [617/1100] Score: -0.649115 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.0854 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.0854 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.0856 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.0859 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.0859 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.0861 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.0883 UTC early_stopping.cc:53] [INFO 24-02-22 07:37:56.0883 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.135053 train-accuracy:0.776284 valid-loss:1.099661 valid-accuracy:0.821918\n",
      "Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.629303\n",
      "[INFO 24-02-22 07:37:56.0883 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.0885 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.629303 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:56.0894 UTC hyperparameters_optimizer.cc:582] [618/1100] Score: -0.629303 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.0929 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.0929 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.0931 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.0941 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.026246 train-accuracy:0.843521 valid-loss:1.030493 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:56.1202 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.615595\n",
      "[INFO 24-02-22 07:37:56.1202 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.1204 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.615595 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:56.1209 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.1209 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.1211 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.1218 UTC hyperparameters_optimizer.cc:582] [619/1100] Score: -0.615595 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:56.1244 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247510 train-accuracy:0.612469 valid-loss:1.196141 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:56.1425 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096559 train-accuracy:0.819071 valid-loss:1.063426 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:56.2605 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63491\n",
      "[INFO 24-02-22 07:37:56.2605 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.2607 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.634910 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:56.2613 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.2614 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.2615 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.2651 UTC hyperparameters_optimizer.cc:582] [620/1100] Score: -0.63491 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.2700 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663878\n",
      "[INFO 24-02-22 07:37:56.2701 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.2702 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234456 train-accuracy:0.612469 valid-loss:1.187086 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:56.2703 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.663878 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:56.2708 UTC hyperparameters_optimizer.cc:582] [621/1100] Score: -0.663878 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:56.2722 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.2722 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.2724 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.2774 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132873 train-accuracy:0.612469 valid-loss:1.120406 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:56.3000 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.704008\n",
      "[INFO 24-02-22 07:37:56.3003 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:56.3007 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:56.3007 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.704008 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:56.3010 UTC hyperparameters_optimizer.cc:582] [622/1100] Score: -0.704008 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.3029 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.3030 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.3032 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.3385 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649554\n",
      "[INFO 24-02-22 07:37:56.3385 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.3387 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.649554 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:56.3393 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.3393 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.3394 UTC hyperparameters_optimizer.cc:582] [623/1100] Score: -0.649554 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:56.3396 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.3527 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.069387 train-accuracy:0.905868 valid-loss:1.051261 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:56.3810 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646708\n",
      "[INFO 24-02-22 07:37:56.3810 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.3814 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.646708 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:56.3820 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667357\n",
      "[INFO 24-02-22 07:37:56.3820 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.3822 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.667357 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:56.3823 UTC hyperparameters_optimizer.cc:582] [624/1100] Score: -0.646708 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.3840 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.3840 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.3842 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.3842 UTC hyperparameters_optimizer.cc:582] [625/1100] Score: -0.667357 / -0.592812 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.3853 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.3853 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.3855 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.3865 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309989 train-accuracy:0.612469 valid-loss:1.272570 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:56.3865 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289861 train-accuracy:0.612469 valid-loss:1.246525 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:56.4156 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070659 train-accuracy:0.808068 valid-loss:1.023214 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:56.4448 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.588907\n",
      "[INFO 24-02-22 07:37:56.4448 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.4450 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.588907 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:56.4457 UTC hyperparameters_optimizer.cc:582] [626/1100] Score: -0.588907 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.4464 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.4464 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.4466 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.4542 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222279 train-accuracy:0.612469 valid-loss:1.173609 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:56.5051 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.704504\n",
      "[INFO 24-02-22 07:37:56.5052 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.5055 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.704504 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:56.5058 UTC hyperparameters_optimizer.cc:582] [627/1100] Score: -0.704504 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:56.5065 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.5065 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.5069 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.5106 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660885\n",
      "[INFO 24-02-22 07:37:56.5106 UTC gradient_boosted_trees.cc:271] Truncates the model to 134 tree(s) i.e. 134  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.5108 UTC gradient_boosted_trees.cc:334] Final model num-trees:134 valid-loss:0.660885 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:56.5123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.062775 train-accuracy:0.841076 valid-loss:1.009778 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:37:56.5124 UTC hyperparameters_optimizer.cc:582] [628/1100] Score: -0.660885 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:56.5130 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.5130 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.5142 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.5538 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664361\n",
      "[INFO 24-02-22 07:37:56.5539 UTC gradient_boosted_trees.cc:271] Truncates the model to 92 tree(s) i.e. 92  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.5540 UTC gradient_boosted_trees.cc:334] Final model num-trees:92 valid-loss:0.664361 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:56.5543 UTC hyperparameters_optimizer.cc:582] [629/1100] Score: -0.664361 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.5547 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.5547 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.5595 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.5793 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112432 train-accuracy:0.794621 valid-loss:1.123207 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:56.5808 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096365 train-accuracy:0.831296 valid-loss:1.062171 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:56.6330 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641881\n",
      "[INFO 24-02-22 07:37:56.6331 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.6333 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.641881 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:56.6335 UTC hyperparameters_optimizer.cc:582] [630/1100] Score: -0.641881 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.6385 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.6385 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.6387 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.6585 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.164659 train-accuracy:0.612469 valid-loss:1.138616 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:56.6885 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699155\n",
      "[INFO 24-02-22 07:37:56.6885 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:56.6905 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.699155 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:56.6920 UTC hyperparameters_optimizer.cc:582] [631/1100] Score: -0.699155 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:56.6957 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:56.6957 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:56.6960 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:56.7195 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219642 train-accuracy:0.612469 valid-loss:1.194149 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:57.0237 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654431\n",
      "[INFO 24-02-22 07:37:57.0238 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:37:57.0242 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.654431 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:57.0252 UTC hyperparameters_optimizer.cc:582] [632/1100] Score: -0.654431 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:57.0265 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:57.0265 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:57.0267 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:57.1648 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.607727\n",
      "[INFO 24-02-22 07:37:57.1649 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:57.1655 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.607727 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:57.1666 UTC hyperparameters_optimizer.cc:582] [633/1100] Score: -0.607727 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:57.1675 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:57.1675 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:57.1680 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:57.1715 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625639\n",
      "[INFO 24-02-22 07:37:57.1715 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:57.1718 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.625639 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:57.1721 UTC hyperparameters_optimizer.cc:582] [634/1100] Score: -0.625639 / -0.588907 HParams: [fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "INFO 24-02-22 07:37:57.1726 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:57.1726 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:57.1729 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:57.1892 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312755 train-accuracy:0.612469 valid-loss:1.273450 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:57.1953 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.301981 train-accuracy:0.612469 valid-loss:1.274364 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:57.2209 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302534 train-accuracy:0.612469 valid-loss:1.270254 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:57.5525 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665207\n",
      "[INFO 24-02-22 07:37:57.5525 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:57.5527 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.665207 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:57.5533 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:57.5534 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:57.5537 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:57.5551 UTC hyperparameters_optimizer.cc:582] [635/1100] Score: -0.665207 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:57.5567 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.640997\n",
      "[INFO 24-02-22 07:37:57.5567 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:57.5569 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.640997 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:57.5570 UTC hyperparameters_optimizer.cc:582] [636/1100] Score: -0.640997 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:57.5587 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO[INFO 24-02-22 07:37:57.5588 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on  24-02-22 07:37:57.5588 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079130 train-accuracy:0.841076 valid-loss:1.037299 valid-accuracy:0.849315\n",
      "891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:57.5590 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:57.5684 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176214 train-accuracy:0.612469 valid-loss:1.139474 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:57.7649 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649379\n",
      "[INFO 24-02-22 07:37:57.7719 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:37:57.7722 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.649379 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:57.7732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:57.7732 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:57.7734 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:57.7753 UTC hyperparameters_optimizer.cc:582] [637/1100] Score: -0.649379 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:57.8586 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151471 train-accuracy:0.765281 valid-loss:1.098287 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:37:57.8641 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653549\n",
      "[INFO 24-02-22 07:37:57.8673 UTC gradient_boosted_trees.cc:271] Truncates the model to 186 tree(s) i.e. 186  iteration(s).\n",
      "[INFO 24-02-22 07:37:57.8674 UTC gradient_boosted_trees.cc:334] Final model num-trees:186 valid-loss:0.653549 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:57.8678 UTC hyperparameters_optimizer.cc:582] [638/1100] Score: -0.653549 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:57.8699 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:57.8701 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:57.8704 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:57.8815 UTC [INFO 24-02-22 07:37:57.8822 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683191\n",
      "[INFO 24-02-22 07:37:57.8822 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:37:57.8824 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.683191 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:57.8826 UTC hyperparameters_optimizer.cc:582] [639/1100] Score: -0.683191 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:57.8831 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:57.8831 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:57.8833 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070588 train-accuracy:0.855746 valid-loss:1.070334 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:37:57.9183 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.271173 train-accuracy:0.612469 valid-loss:1.246334 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:58.1696 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676539\n",
      "[INFO 24-02-22 07:37:58.1696 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:58.1698 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:58.1698 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.676539 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:58.1699 UTC hyperparameters_optimizer.cc:582] [640/1100] Score: -0.676539 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:58.1703 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.1703 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.1706 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.2636 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313711 train-accuracy:0.612469 valid-loss:1.271772 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:58.3784 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660846\n",
      "[INFO 24-02-22 07:37:58.3784 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 07:37:58.3788 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.660846 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:58.3798 UTC hyperparameters_optimizer.cc:582] [641/1100] Score: -0.660846 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:58.3811 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.3811 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.3814 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.3842 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187410 train-accuracy:0.612469 valid-loss:1.144038 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:58.5272 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684706\n",
      "[INFO 24-02-22 07:37:58.5272 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:37:58.5275 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.684706 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:58.5282 UTC hyperparameters_optimizer.cc:582] [642/1100] Score: -0.684706 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:58.5288 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.5290 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.5295 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.5490 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643064\n",
      "[INFO 24-02-22 07:37:58.5490 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:37:58.5493 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.643064 valid-accuracy:0.931507\n",
      "[INFO 24-02-22 07:37:58.5498 UTC hyperparameters_optimizer.cc:582] [643/1100] Score: -0.643064 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:58.5507 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.5507 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.5510 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.5590 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.014761 train-accuracy:0.871638 valid-loss:1.019849 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:37:58.5684 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679084\n",
      "[INFO 24-02-22 07:37:58.5684 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:37:58.5688 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.679084 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:37:58.5695 UTC hyperparameters_optimizer.cc:582] [644/1100] Score: -0.679084 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:58.5702 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.5702 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.5705 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.5733 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.203113 train-accuracy:0.612469 valid-loss:1.169101 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:58.6284 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278052 train-accuracy:0.612469 valid-loss:1.235980 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:58.7169 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649513\n",
      "[INFO 24-02-22 07:37:58.7207 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:37:58.7225 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.649513 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:37:58.7230 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.7230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.7232 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.7256 UTC hyperparameters_optimizer.cc:582] [645/1100] Score: -0.649513 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:58.7597 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680984\n",
      "[INFO 24-02-22 07:37:58.7597 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 07:37:58.7599 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.680984 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:58.7613 UTC hyperparameters_optimizer.cc:582] [646/1100] Score: -0.680984 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:58.7620 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.7620 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.7634 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.7662 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.200888 train-accuracy:0.612469 valid-loss:1.165182 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:58.8103 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232036 train-accuracy:0.612469 valid-loss:1.190004 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:58.8151 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.697072\n",
      "[INFO 24-02-22 07:37:58.8151 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:37:58.8159 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.697072 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:58.8173 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.8173 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.8175 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.8204 UTC hyperparameters_optimizer.cc:582] [647/1100] Score: -0.697072 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:58.8338 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.078393 train-accuracy:0.834963 valid-loss:1.042362 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:58.9516 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649115\n",
      "[INFO 24-02-22 07:37:58.9517 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:37:58.9518 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.649115 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:58.9521 UTC hyperparameters_optimizer.cc:582] [648/1100] Score: -0.649115 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:37:58.9533 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:58.9533 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:58.9536 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:58.9896 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159444 train-accuracy:0.612469 valid-loss:1.131458 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:59.1875 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680694\n",
      "[INFO 24-02-22 07:37:59.1876 UTC gradient_boosted_trees.cc:271] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "[INFO 24-02-22 07:37:59.1881 UTC gradient_boosted_trees.cc:334] Final model num-trees:116 valid-loss:0.680694 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:59.1895 UTC hyperparameters_optimizer.cc:582] [649/1100] Score: -0.680694 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:59.1952 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:59.1955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:59.1958 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:59.2373 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646102\n",
      "[INFO 24-02-22 07:37:59.2373 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:37:59.2377 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.646102 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:59.2383 UTC hyperparameters_optimizer.cc:582] [650/1100] Score: -0.646102 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:59.2390 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:59.2392 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:59.2398 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:59.2589 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.150082 train-accuracy:0.823961 valid-loss:1.088955 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:37:59.2789 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180965 train-accuracy:0.612469 valid-loss:1.134215 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:59.6958 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658419\n",
      "[INFO 24-02-22 07:37:59.6958 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 07:37:59.6959 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.658419 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:59.6961 UTC hyperparameters_optimizer.cc:582] [651/1100] Score: -0.658419 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:37:59.6965 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:59.6965 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:59.6968 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:59.7043 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282475 train-accuracy:0.612469 valid-loss:1.247374 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:59.7375 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.696291\n",
      "[INFO 24-02-22 07:37:59.7375 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:37:59.7382 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.696291 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:59.7401 UTC hyperparameters_optimizer.cc:582] [652/1100] Score: -0.696291 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:37:59.7412 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:59.7412 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:59.7414 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:59.8492 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224668 train-accuracy:0.612469 valid-loss:1.206092 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:59.9264 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660011\n",
      "[INFO 24-02-22 07:37:59.9265 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:59.9267 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:59.9267 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.660011 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:37:59.9272 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:59.9272 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:59.9276 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:59.9317 UTC hyperparameters_optimizer.cc:582] [653/1100] Score: -0.660011 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:59.9526 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671161\n",
      "[INFO 24-02-22 07:37:59.9526 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:37:59.9530 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:37:59.9530 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.671161 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:37:59.9532 UTC hyperparameters_optimizer.cc:582] [654/1100] Score: -0.671161 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:37:59.9534 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295292 train-accuracy:0.612469 valid-loss:1.250433 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:37:59.9539 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:37:59.9539 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:37:59.9541 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:37:59.9573 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310294 train-accuracy:0.612469 valid-loss:1.271377 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:00.4065 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663706\n",
      "[INFO 24-02-22 07:38:00.4065 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:00.4070 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.663706 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:00.4073 UTC hyperparameters_optimizer.cc:582] [655/1100] Score: -0.663706 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:00.4084 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:00.4084 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:00.4087 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:00.4197 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681721\n",
      "[INFO 24-02-22 07:38:00.4197 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:38:00.4199 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.681721 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:00.4204 UTC hyperparameters_optimizer.cc:582] [656/1100] Score: -0.681721 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:00.4208 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:00.4208 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:00.4214 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:00.4242 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070578 train-accuracy:0.865526 valid-loss:1.045288 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:00.4361 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295840 train-accuracy:0.612469 valid-loss:1.251264 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:00.5573 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.733474\n",
      "[INFO 24-02-22 07:38:00.5573 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:00.5577 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.733474 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:00.5581 UTC hyperparameters_optimizer.cc:582] [657/1100] Score: -0.733474 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:00.5597 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:00.5598 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:00.5601 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:00.5679 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157459 train-accuracy:0.761614 valid-loss:1.117958 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:38:00.5847 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658195\n",
      "[INFO 24-02-22 07:38:00.5847 UTC gradient_boosted_trees.cc:271] Truncates the model to 132 tree(s) i.e. 132  iteration(s).\n",
      "[INFO 24-02-22 07:38:00.5851 UTC gradient_boosted_trees.cc:334] Final model num-trees:132 valid-loss:0.658195 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:00.5986 UTC gradient_boosted_trees.cc:[INFO591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-22 07:38:00.5986 UTC hyperparameters_optimizer.cc:582] [658/1100] Score: [INFO 24-02-22 07:38:00.5987 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "-0.658195 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:00.5994 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:00.7842 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.991854 train-accuracy:0.871638 valid-loss:1.020293 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:00.9083 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672605\n",
      "[INFO 24-02-22 07:38:00.9083 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:38:00.9085 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.672605 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:00.9091 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:00.9091 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:00.9093 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:00.9117 UTC hyperparameters_optimizer.cc:582] [659/1100] Score: -0.672605 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:00.9173 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094408 train-accuracy:0.809291 valid-loss:1.088627 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:01.1091 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625612\n",
      "[INFO 24-02-22 07:38:01.1091 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 07:38:01.1092 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.625612 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:01.1094 UTC hyperparameters_optimizer.cc:582] [660/1100] Score: -0.625612 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:01.1098 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:01.1099 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:01.1102 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:01.1178 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079489 train-accuracy:0.859413 valid-loss:1.036413 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:01.2408 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.743381\n",
      "[INFO 24-02-22 07:38:01.2409 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:01.2412 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:01.2412 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.743381 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:01.2414 UTC hyperparameters_optimizer.cc:582] [661/1100] Score: -0.743381 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:01.2427 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:01.2428 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:01.2430 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:01.2493 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.154485 train-accuracy:0.772616 valid-loss:1.104562 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:01.3378 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670857\n",
      "[INFO 24-02-22 07:38:01.3378 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 07:38:01.3380 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.670857 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:01.3395 UTC hyperparameters_optimizer.cc:582] [662/1100] Score: -0.670857 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:01.3423 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:01.3423 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:01.3425 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:01.3867 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.265524 train-accuracy:0.612469 valid-loss:1.238291 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:01.5254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652176\n",
      "[INFO 24-02-22 07:38:01.5254 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:01.5257 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.652176 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:01.5264 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:01.5264 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:01.5266 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:01.5284 UTC hyperparameters_optimizer.cc:582] [663/1100] Score: -0.652176 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:01.5381 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.107638 train-accuracy:0.800734 valid-loss:1.134096 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:01.6641 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656483\n",
      "[INFO 24-02-22 07:38:01.6642 UTC gradient_boosted_trees.cc:271] Truncates the model to 161 tree(s) i.e. 161  iteration(s).\n",
      "[INFO 24-02-22 07:38:01.6642 UTC gradient_boosted_trees.cc:334] Final model num-trees:161 valid-loss:0.656483 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:01.6648 UTC hyperparameters_optimizer.cc:582] [664/1100] Score: -0.656483 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:01.6652 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:01.6652 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:01.6657 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-22 07:38:01.6687 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss:  24-02-22 07:38:01.6688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187983 train-accuracy:0.612469 valid-loss:1.153109 valid-accuracy:0.657534\n",
      "0.63754\n",
      "[INFO 24-02-22 07:38:01.6690 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:01.6693 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.637540 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:01.6696 UTC hyperparameters_optimizer.cc:582] [665/1100] Score: -0.63754 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:01.6703 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:01.6704 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:01.6708 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:01.6757 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196854 train-accuracy:0.612469 valid-loss:1.156736 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:01.9015 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689065\n",
      "[INFO 24-02-22 07:38:01.9016 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:38:01.9018 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.689065 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:01.9022 UTC hyperparameters_optimizer.cc:582] [666/1100] Score: -0.689065 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:01.9029 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:01.9029 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:01.9031 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:01.9270 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225267 train-accuracy:0.612469 valid-loss:1.184045 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:01.9995 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651258\n",
      "[INFO 24-02-22 07:38:01.9995 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:38:01.9996 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.651258 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:01.9998 UTC hyperparameters_optimizer.cc:582] [667/1100] Score: -0.651258 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:02.0004 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:02.0006 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:02.0009 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:02.0041 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.129421 train-accuracy:0.771394 valid-loss:1.105520 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:02.0607 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.708847\n",
      "[INFO 24-02-22 07:38:02.0608 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:02.0612 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.708847 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:02.0616 UTC hyperparameters_optimizer.cc:582] [668/1100] Score: -0.708847 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:02.0627 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:02.0627 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:02.0629 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:02.0703 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.131159 train-accuracy:0.783619 valid-loss:1.071551 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:02.1367 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.626193\n",
      "[INFO 24-02-22 07:38:02.1367 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:02.1371 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.626193 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:02.1374 UTC hyperparameters_optimizer.cc:582] [669/1100] Score: -0.626193 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:02.1381 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:02.1381 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:02.1384 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:02.2009 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238918 train-accuracy:0.612469 valid-loss:1.203637 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:02.4328 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658186\n",
      "[INFO 24-02-22 07:38:02.4328 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:02.4331 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.658186 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:02.4334 UTC hyperparameters_optimizer.cc:582] [670/1100] Score: -0.658186 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:02.4342 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:02.4343 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:02.4345 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:02.4448 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.097780 train-accuracy:0.819071 valid-loss:1.036927 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:02.8139 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673961\n",
      "[INFO 24-02-22 07:38:02.8139 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 07:38:02.8146 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.673961 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:02.8186 UTC hyperparameters_optimizer.cc:582] [671/1100] Score: -0.673961 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:02.8233 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:02.8234 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:02.8237 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:02.8787 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.020698 train-accuracy:0.863081 valid-loss:1.049438 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:02.9500 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666694\n",
      "[INFO 24-02-22 07:38:02.9501 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:02.9506 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.666694 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:02.9520 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:02.9520 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:02.9522 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:02.9529 UTC hyperparameters_optimizer.cc:582] [672/1100] Score: -0.666694 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:02.9706 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694041\n",
      "[INFO 24-02-22 07:38:02.9707 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:02.9708 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.694041 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:02.9711 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:02.9712 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:02.9713 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:02.9718 UTC hyperparameters_optimizer.cc:582] [673/1100] Score: -0.694041 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:03.0037 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.057024 train-accuracy:0.819071 valid-loss:1.025769 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:03.0733 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661311\n",
      "[INFO 24-02-22 07:38:03.0733 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:03.0736 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.661311 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:38:03.0750 UTC hyperparameters_optimizer.cc:582] [674/1100] Score: -0.661311 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:38:03.0752 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:03.0754 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:03.0767 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:03.0778 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.179396 train-accuracy:0.612469 valid-loss:1.130350 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:03.0806 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.044770 train-accuracy:0.844743 valid-loss:1.066780 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:03.1339 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67543\n",
      "[INFO 24-02-22 07:38:03.1339 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:38:03.1340 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.675430 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:03.1343 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:03.1343 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:03.1345 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:03.1391 UTC hyperparameters_optimizer.cc:582] [675/1100] Score: -0.67543 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:03.1814 UTC gradient_boosted_trees.cc:1638] \tnum-trees:31 train-loss:0.377551 train-accuracy:0.985330 valid-loss:0.720883 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:03.2423 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315176 train-accuracy:0.612469 valid-loss:1.275023 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:03.3525 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6742\n",
      "[INFO 24-02-22 07:38:03.3525 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:38:03.3528 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.674200 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:03.3532 UTC hyperparameters_optimizer.cc:582] [676/1100] Score: -0.6742 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:03.3540 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:03.3541 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:03.3544 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:03.3655 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314490 train-accuracy:0.612469 valid-loss:1.273165 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:04.0721 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647303\n",
      "[INFO 24-02-22 07:38:04.0721 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 07:38:04.0722 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.647303 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:04.0724 UTC hyperparameters_optimizer.cc:582] [677/1100] Score: -0.647303 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:04.0728 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:04.0728 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:04.0731 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:04.0857 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277816 train-accuracy:0.612469 valid-loss:1.234209 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:04.1647 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.621344\n",
      "[INFO 24-02-22 07:38:04.1647 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:04.1649 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.621344 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:04.1689 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:04.1690 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:04.1692 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:04.1718 UTC hyperparameters_optimizer.cc:582] [678/1100] Score: -0.621344 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:04.2522 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232387 train-accuracy:0.612469 valid-loss:1.192070 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:04.3820 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644296\n",
      "[INFO 24-02-22 07:38:04.3820 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 07:38:04.3822 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.644296 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:04.3827 UTC hyperparameters_optimizer.cc:582] [679/1100] Score: -0.644296 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:04.3837 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:04.3840 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:04.3845 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:04.3986 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.989848 train-accuracy:0.875306 valid-loss:1.038870 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:04.5917 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649101\n",
      "[INFO 24-02-22 07:38:04.5918 UTC gradient_boosted_trees.cc:271] Truncates the model to 208 tree(s) i.e. 208  iteration(s).\n",
      "[INFO 24-02-22 07:38:04.5919 UTC gradient_boosted_trees.cc:334] Final model num-trees:208 valid-loss:0.649101 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:04.5929 UTC hyperparameters_optimizer.cc:582] [680/1100] Score: -0.649101 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:04.5946 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:04.5947 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:04.5952 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:04.6817 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219548 train-accuracy:0.612469 valid-loss:1.192367 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:04.8989 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.721189\n",
      "[INFO 24-02-22 07:38:04.8989 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:04.8995 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.721189 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:04.8999 UTC hyperparameters_optimizer.cc:582] [681/1100] Score: -0.721189 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:04.9008 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:04.9008 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:04.9026 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:04.9049 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152147 train-accuracy:0.800734 valid-loss:1.102328 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:04.9632 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622797\n",
      "[INFO 24-02-22 07:38:04.9638 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 07:38:04.9639 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.622797 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:04.9640 UTC hyperparameters_optimizer.cc:582] [682/1100] Score: -0.622797 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:04.9655 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:04.9655 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:04.9657 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:04.9740 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.116333 train-accuracy:0.811736 valid-loss:1.078245 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:05.0349 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.777651\n",
      "[INFO 24-02-22 07:38:05.0349 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:05.0354 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:05.0354 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.777651 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:05.0359 UTC hyperparameters_optimizer.cc:582] [683/1100] Score: -0.777651 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:05.0391 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:05.0403 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:05.0406 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:05.0500 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312567 train-accuracy:0.612469 valid-loss:1.273545 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:05.2210 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651872\n",
      "[INFO 24-02-22 07:38:05.2210 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 07:38:05.2212 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.651872 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:05.2221 UTC hyperparameters_optimizer.cc:582] [684/1100] Score: -0.651872 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:05.2246 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:05.2247 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:05.2250 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:05.3193 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084274 train-accuracy:0.815403 valid-loss:1.047005 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:05.3207 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675491\n",
      "[INFO 24-02-22 07:38:05.3207 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 07:38:05.3208 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.675491 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:05.3212 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:05.3212 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:05.3215 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:05.3231 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701417\n",
      "[INFO 24-02-22 07:38:05.3231 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:05.3233 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:05.3233 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.701417 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:05.3237 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:05.3237 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:05.3239 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:05.3251 UTC hyperparameters_optimizer.cc:582] [685/1100] Score: -0.675491 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:05.3253 UTC hyperparameters_optimizer.cc:582] [686/1100] Score: -0.701417 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:05.3312 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316031 train-accuracy:0.612469 valid-loss:1.274659 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:05.3316 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096260 train-accuracy:0.800734 valid-loss:1.040524 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:05.3920 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630556\n",
      "[INFO 24-02-22 07:38:05.3921 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:38:05.3923 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.630556 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:05.3927 UTC hyperparameters_optimizer.cc:582] [687/1100] Score: -0.630556 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:05.3932 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:05.3932 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:05.3936 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:05.4234 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.258464 train-accuracy:0.612469 valid-loss:1.210623 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:05.5258 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.627285\n",
      "[INFO 24-02-22 07:38:05.5258 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 07:38:05.5260 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.627285 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:05.5276 UTC hyperparameters_optimizer.cc:582] [688/1100] Score: -0.627285 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:05.5286 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:05.5286 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:05.5288 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:05.5380 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278463 train-accuracy:0.612469 valid-loss:1.238835 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:05.7147 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663765\n",
      "[INFO 24-02-22 07:38:05.7148 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:05.7150 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.663765 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:05.7156 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:05.7156 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:05.7160 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:05.7166 UTC hyperparameters_optimizer.cc:582] [689/1100] Score: -0.663765 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:05.7389 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.115573 train-accuracy:0.844743 valid-loss:1.107428 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:05.8284 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.704787\n",
      "[INFO 24-02-22 07:38:05.8284 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 07:38:05.8300 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.704787 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:05.8356 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:05.8356 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:05.8358 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:05.8383 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234721 train-accuracy:0.612469 valid-loss:1.204987 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:05.8384 UTC hyperparameters_optimizer.cc:582] [690/1100] Score: -0.704787 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:06.0147 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652984\n",
      "[INFO 24-02-22 07:38:06.0147 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.0151 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.652984 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:06.0162 UTC hyperparameters_optimizer.cc:582] [691/1100] Score: -0.652984 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:06.0169 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.0170 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.0172 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:06.0200 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313814 train-accuracy:0.612469 valid-loss:1.271890 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:06.3406 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667653\n",
      "[INFO 24-02-22 07:38:06.3406 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.3410 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.667653 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:06.3423 UTC hyperparameters_optimizer.cc:582] [692/1100] Score: -0.667653 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:06.3438 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.3440 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.3441 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671863\n",
      "[INFO 24-02-22 07:38:06.3442 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.3442 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:06.3447 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.671863 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:06.3459 UTC hyperparameters_optimizer.cc:582] [693/1100] Score: -0.671863 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:06.3465 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.3465 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.3476 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:06.3619 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.058077 train-accuracy:0.831296 valid-loss:1.039047 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:06.4650 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279433 train-accuracy:0.612469 valid-loss:1.250215 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:06.5148 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662222\n",
      "[INFO 24-02-22 07:38:06.5148 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.5153 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.662222 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:06.5174 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.5174 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.5176 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:06.5184 UTC hyperparameters_optimizer.cc:582] [694/1100] Score: -0.662222 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:06.5443 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.174286 train-accuracy:0.612469 valid-loss:1.141076 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:06.5489 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718378\n",
      "[INFO 24-02-22 07:38:06.5502 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.5522 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.718378 valid-accuracy:0.863014\n",
      "[INFO[INFO 24-02-22 07:38:06.5647 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.5648 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.5650 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      " 24-02-22 07:38:06.5684 UTC hyperparameters_optimizer.cc:582] [695/1100] Score: -0.718378 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:06.5704 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158010 train-accuracy:0.612469 valid-loss:1.163701 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:06.6813 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662596\n",
      "[INFO 24-02-22 07:38:06.6813 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.6815 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.662596 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:06.6822 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.6822 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.6823 UTC hyperparameters_optimizer.cc:582] [696/1100] Score: -0.662596 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:06.6826 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:06.6861 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285897 train-accuracy:0.612469 valid-loss:1.245038 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:06.7267 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677161\n",
      "[INFO 24-02-22 07:38:06.7267 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.7269 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.677161 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:38:06.7288 UTC hyperparameters_optimizer.cc:582] [697/1100] Score: -0.677161 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "INFO 24-02-22 07:38:06.7299 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.7301 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.7306 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:06.7746 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191260 train-accuracy:0.612469 valid-loss:1.159810 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:06.7861 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.725883\n",
      "[INFO 24-02-22 07:38:06.7861 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.7867 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.725883 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:06.7877 UTC hyperparameters_optimizer.cc:582] [698/1100] Score: -0.725883 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:06.7883 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.7883 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.7917 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:06.8114 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651897\n",
      "[INFO 24-02-22 07:38:06.8114 UTC gradient_boosted_trees.cc:271] Truncates the model to 158 tree(s) i.e. 158  iteration(s).\n",
      "[INFO 24-02-22 07:38:06.8116 UTC gradient_boosted_trees.cc:334] Final model num-trees:158 valid-loss:0.651897 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:06.8130 UTC hyperparameters_optimizer.cc:582] [699/1100] Score: -0.651897 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:06.8138 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:06.8140 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:06.8153 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:06.8544 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225893 train-accuracy:0.612469 valid-loss:1.187925 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:06.9027 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.134055 train-accuracy:0.795844 valid-loss:1.091923 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:06.9996 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671139\n",
      "[INFO 24-02-22 07:38:06.9997 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:07.0000 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:07.0000 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.671139 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:07.0007 UTC hyperparameters_optimizer.cc:582] [700/1100] Score: -0.671139 / -0.588907 HParams: [INFO 24-02-22 07:38:07.0008 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:07.0008 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:07.0013 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:07.0115 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312784 train-accuracy:0.612469 valid-loss:1.274300 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:07.1513 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683315\n",
      "[INFO 24-02-22 07:38:07.1519 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:07.1521 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:07.1521 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.683315 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:07.1523 UTC hyperparameters_optimizer.cc:582] [701/1100] Score: -0.683315 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:07.1527 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:07.1527 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:07.1529 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:07.1570 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.032760 train-accuracy:0.867971 valid-loss:1.015780 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:07.2900 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677114\n",
      "[INFO 24-02-22 07:38:07.2922 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:07.2925 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:07.2925 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.677114 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:07.2927 UTC hyperparameters_optimizer.cc:582] [702/1100] Score: -0.677114 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:07.2931 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:07.2932 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:07.2933 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:07.3021 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319158 train-accuracy:0.612469 valid-loss:1.277743 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:07.5036 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874412\n",
      "[INFO 24-02-22 07:38:07.5036 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:07.5041 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:07.5041 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.874412 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:07.5045 UTC hyperparameters_optimizer.cc:582] [703/1100] Score: -0.874412 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:07.5060 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:07.5060 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:07.5063 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:07.5272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152608 train-accuracy:0.756724 valid-loss:1.115850 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:38:07.9640 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652616\n",
      "[INFO 24-02-22 07:38:07.9640 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:07.9643 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.652616 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:07.9647 UTC hyperparameters_optimizer.cc:582] [704/1100] Score: -0.652616 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:07.9671 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:07.9671 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:07.9674 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:07.9705 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102054 train-accuracy:0.808068 valid-loss:1.059789 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:07.9852 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659738\n",
      "[INFO 24-02-22 07:38:07.9852 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 07:38:07.9852 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.659738 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:07.9854 UTC hyperparameters_optimizer.cc:582] [705/1100] Score: -0.659738 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:07.9857 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:07.9857 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:07.9860 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:07.9898 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.112192 train-accuracy:0.793399 valid-loss:1.083934 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:08.1081 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667054\n",
      "[INFO 24-02-22 07:38:08.1094 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:08.1096 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.667054 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:08.1098 UTC hyperparameters_optimizer.cc:582] [706/1100] Score: -0.667054 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:08.1102 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:08.1103 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:08.1106 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:08.1536 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.722315\n",
      "[INFO 24-02-22 07:38:08.1536 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:08.1539 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.722315 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:08.1543 UTC hyperparameters_optimizer.cc:582] [707/1100] Score: -0.722315 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:08.1549 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:08.1549 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:08.1553 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:08.1746 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.984674 train-accuracy:0.931540 valid-loss:1.092213 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:08.2006 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314468 train-accuracy:0.612469 valid-loss:1.273761 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:08.3493 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665031\n",
      "[INFO 24-02-22 07:38:08.3493 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:38:08.3495 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.665031 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:08.3498 UTC hyperparameters_optimizer.cc:582] [708/1100] Score: -0.665031 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:08.3504 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:08.3504 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:08.3506 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:08.3605 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083848 train-accuracy:0.811736 valid-loss:1.055227 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:08.5059 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644546\n",
      "[INFO 24-02-22 07:38:08.5059 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:08.5061 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.644546 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:08.5064 UTC hyperparameters_optimizer.cc:582] [709/1100] Score: -0.644546 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:08.5071 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:08.5071 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:08.5074 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:08.5234 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.212391 train-accuracy:0.612469 valid-loss:1.187847 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:08.8078 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681627\n",
      "[INFO 24-02-22 07:38:08.8079 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:08.8082 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:08.8082 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.681627 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:08.8085 UTC hyperparameters_optimizer.cc:582] [710/1100] Score: -0.681627 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:08.8093 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:08.8093 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:08.8097 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:08.8357 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224878 train-accuracy:0.612469 valid-loss:1.201522 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:08.9451 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659534\n",
      "[INFO 24-02-22 07:38:08.9451 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:38:08.9454 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.659534 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:08.9459 UTC hyperparameters_optimizer.cc:582] [711/1100] Score: -0.659534 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:08.9465 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:08.9466 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:08.9471 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:08.9502 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.125643 train-accuracy:0.794621 valid-loss:1.106408 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:09.0073 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681547\n",
      "[INFO 24-02-22 07:38:09.0074 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 07:38:09.0077 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.681547 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:09.0102 UTC hyperparameters_optimizer.cc:582] [712/1100] Score: -0.681547 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:09.0165 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.0165 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:09.0167 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:09.0238 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295371 train-accuracy:0.612469 valid-loss:1.252251 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:09.0904 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653301\n",
      "[INFO 24-02-22 07:38:09.0904 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:38:09.0906 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.653301 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:09.0912 UTC [INFO 24-02-22 07:38:09.0912 UTC hyperparameters_optimizer.cc:582] [713/1100] Score: -0.653301 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.0914 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:09.0917 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:09.1155 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316552 train-accuracy:0.612469 valid-loss:1.274295 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:09.1721 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.722281\n",
      "[INFO 24-02-22 07:38:09.1721 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:09.1738 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.722281 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:09.1747 UTC hyperparameters_optimizer.cc:582] [714/1100] Score: -0.722281 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:09.1786 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.1786 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:09.1792 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:09.2693 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132421 train-accuracy:0.782396 valid-loss:1.102128 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:09.4174 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663279\n",
      "[INFO 24-02-22 07:38:09.4174 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:38:09.4175 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.663279 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:09.4177 UTC hyperparameters_optimizer.cc:582] [715/1100] Score: -0.663279 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:09.4183 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.4183 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:09.4286 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:09.4389 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295617 train-accuracy:0.612469 valid-loss:1.253998 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:09.5376 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674602\n",
      "[INFO 24-02-22 07:38:09.5376 UTC gradient_boosted_trees.cc:271] Truncates the model to 247 tree(s) i.e. 247  iteration(s).\n",
      "[INFO 24-02-22 07:38:09.5377 UTC gradient_boosted_trees.cc:334] Final model num-trees:247 valid-loss:0.674602 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:09.5382 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.5382 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:09.5384 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:09.5384 UTC hyperparameters_optimizer.cc:582] [716/1100] Score: -0.674602 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:09.6178 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.702146\n",
      "[INFO 24-02-22 07:38:09.6179 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:38:09.6184 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.702146 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:09.6202 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.6202 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:09.6205 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:09.6251 UTC hyperparameters_optimizer.cc:582] [717/1100] Score: -0.702146 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:09.6301 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.096725 train-accuracy:0.799511 valid-loss:1.098867 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:09.6347 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.067672 train-accuracy:0.831296 valid-loss:1.046095 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:09.7913 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.732422\n",
      "[INFO 24-02-22 07:38:09.7913 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:09.7917 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:09.7917 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.732422 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:09.7920 UTC hyperparameters_optimizer.cc:582] [718/1100] Score: -0.732422 / -0.588907 HParams: [INFO 24-02-22 07:38:09.7925 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.7925 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:09.7930 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:09.8021 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.154496 train-accuracy:0.823961 valid-loss:1.097281 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:09.9822 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663284\n",
      "[INFO 24-02-22 07:38:09.9822 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:09.9824 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.663284 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:09.9826 UTC hyperparameters_optimizer.cc:582] [719/1100] Score: -0.663284 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:09.9829 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.9830 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:09.9832 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:09.9919 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.027873 train-accuracy:0.861858 valid-loss:1.017784 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:09.9973 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.732309\n",
      "[INFO 24-02-22 07:38:09.9974 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:09.9976 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.732309 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:09.9980 UTC hyperparameters_optimizer.cc:582] [720/1100] Score: -0.732309 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:09.9982 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:09.9982 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:09.9986 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.0027 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.996759 train-accuracy:0.872861 valid-loss:1.048894 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:10.1205 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661922\n",
      "[INFO 24-02-22 07:38:10.1205 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.1208 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.661922 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:10.1243 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.1244 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.1246 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.1284 UTC hyperparameters_optimizer.cc:582] [721/1100] Score: -0.661922 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:10.1353 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.256941 train-accuracy:0.612469 valid-loss:1.205518 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:10.2189 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.734293\n",
      "[INFO 24-02-22 07:38:10.2189 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.2198 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.734293 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:10.2204 UTC hyperparameters_optimizer.cc:582] [722/1100] Score: -0.734293 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:10.2232 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.2234 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.2238 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.3238 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65988\n",
      "[INFO 24-02-22 07:38:10.3239 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.3239 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.659880 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:10.3241 UTC hyperparameters_optimizer.cc:582] [723/1100] Score: -0.65988 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:10.3244 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.3244 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.3246 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.3272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.068938 train-accuracy:0.823961 valid-loss:1.063761 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:10.3302 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070321 train-accuracy:0.838631 valid-loss:1.023749 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:10.4814 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.71638\n",
      "[INFO 24-02-22 07:38:10.4815 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.4818 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.716380 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:10.4821 UTC hyperparameters_optimizer.cc:582] [724/1100] Score: -0.71638 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:10.4825 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.4825 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.4827 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.4955 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673163\n",
      "[INFO 24-02-22 07:38:10.4956 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.4956 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.673163 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:10.4959 UTC hyperparameters_optimizer.cc:582] [725/1100] Score: -0.673163 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:10.4965 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.4965 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.4968 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.5378 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.145819 train-accuracy:0.754279 valid-loss:1.085939 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:10.5462 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314261 train-accuracy:0.612469 valid-loss:1.271919 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:10.6071 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642912\n",
      "[INFO 24-02-22 07:38:10.6073 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.6077 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.642912 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:10.6080 UTC hyperparameters_optimizer.cc:582] [726/1100] Score: -0.642912 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:10.6085 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.6085 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.6090 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.6133 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.170045 train-accuracy:0.738386 valid-loss:1.127859 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:38:10.7241 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.622152\n",
      "[INFO 24-02-22 07:38:10.7241 UTC gradient_boosted_trees.cc:271] Truncates the model to 80 tree(s) i.e. 80  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.7242 UTC gradient_boosted_trees.cc:334] Final model num-trees:80 valid-loss:0.622152 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:10.7244 UTC hyperparameters_optimizer.cc:582] [727/1100] Score: -0.622152 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:10.7247 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.7247 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.7251 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.7283 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.027099 train-accuracy:0.863081 valid-loss:1.055566 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:10.8485 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655171\n",
      "[INFO 24-02-22 07:38:10.8485 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.8488 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.655171 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:10.8501 UTC hyperparameters_optimizer.cc:582] [728/1100] Score: -0.655171 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:10.8509 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.8509 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.8511 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.8698 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.74246\n",
      "[INFO 24-02-22 07:38:10.8699 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:10.8701 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:10.8701 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.742460 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:10.8706 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.8706 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.8708 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:10.8717 UTC hyperparameters_optimizer.cc:582] [729/1100] Score: -0.74246 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:10.8763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.206622 train-accuracy:0.612469 valid-loss:1.164068 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:10.9201 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.037733 train-accuracy:0.845966 valid-loss:1.045863 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:10.9459 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.711971\n",
      "[INFO 24-02-22 07:38:10.9459 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:38:10.9464 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.711971 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:10.9469 UTC hyperparameters_optimizer.cc:582] [730/1100] Score: -0.711971 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:10.9479 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:10.9479 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:10.9483 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:11.0190 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660979\n",
      "[INFO 24-02-22 07:38:11.0190 UTC gradient_boosted_trees.cc:271] Truncates the model to 197 tree(s) i.e. 197  iteration(s).\n",
      "[INFO 24-02-22 07:38:11.0191 UTC gradient_boosted_trees.cc:334] Final model num-trees:197 valid-loss:0.660979 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:11.0194 UTC hyperparameters_optimizer.cc:582] [731/1100] Score: -0.660979 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:11.0231 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:11.0231 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:11.0234 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:11.0259 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.109134 train-accuracy:0.833741 valid-loss:1.063428 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:11.0339 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.963059 train-accuracy:0.886308 valid-loss:1.060763 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:11.0464 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669412\n",
      "[INFO 24-02-22 07:38:11.0465 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:11.0470 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.669412 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:11.0472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680029\n",
      "[INFO 24-02-22 07:38:11.0472 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 07:38:11.0473 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.680029 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:11.0474 UTC hyperparameters_optimizer.cc:582] [732/1100] Score: -0.669412 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:11.0477 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:11.0477 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:11.0478 UTC hyperparameters_optimizer.cc:582] [733/1100] Score: -0.680029 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:11.0480 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:11.0489 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:11.0490 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:11.0494 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:11.0632 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313994 train-accuracy:0.612469 valid-loss:1.271350 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:11.0852 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.127133 train-accuracy:0.783619 valid-loss:1.047907 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:11.1980 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677352\n",
      "[INFO 24-02-22 07:38:11.1980 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:11.1982 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.677352 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:11.1987 UTC hyperparameters_optimizer.cc:582] [734/1100] Score: -0.677352 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:11.1994 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:11.1994 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:11.1996 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:11.2073 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.145446 train-accuracy:0.612469 valid-loss:1.148431 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:11.5357 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666857\n",
      "[INFO 24-02-22 07:38:11.5357 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 07:38:11.5359 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.666857 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:11.5369 UTC hyperparameters_optimizer.cc:582] [735/1100] Score: -0.666857 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:11.5385 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:11.5386 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:11.5389 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:11.6498 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.211933 train-accuracy:0.612469 valid-loss:1.198482 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:11.6960 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675049\n",
      "[INFO 24-02-22 07:38:11.6960 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:11.6967 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.675049 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:11.7010 UTC hyperparameters_optimizer.cc:582] [736/1100] Score: -0.675049 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:11.7015 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:11.7016 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:11.7019 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:11.7056 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292017 train-accuracy:0.612469 valid-loss:1.244304 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:12.2105 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660629\n",
      "[INFO 24-02-22 07:38:12.2105 UTC gradient_boosted_trees.cc:271] Truncates the model to 131 tree(s) i.e. 131  iteration(s).\n",
      "[INFO 24-02-22 07:38:12.2107 UTC gradient_boosted_trees.cc:334] Final model num-trees:131 valid-loss:0.660629 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:12.2114 UTC hyperparameters_optimizer.cc:582] [737/1100] Score: -0.660629 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:12.2119 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:12.2119 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:12.2124 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:12.3319 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.974684 train-accuracy:0.874083 valid-loss:1.039413 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:12.3750 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65247\n",
      "[INFO 24-02-22 07:38:12.3751 UTC gradient_boosted_trees.cc:271] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "[INFO 24-02-22 07:38:12.3751 UTC gradient_boosted_trees.cc:334] Final model num-trees:116 valid-loss:0.652470 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:12.3756 UTC hyperparameters_optimizer.cc:582] [738/1100] Score: -0.65247 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:12.3761 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:12.3761 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:12.3764 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:12.3796 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288383 train-accuracy:0.612469 valid-loss:1.250124 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:12.4204 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.697695\n",
      "[INFO 24-02-22 07:38:12.4204 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:12.4205 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.697695 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:12.4206 UTC hyperparameters_optimizer.cc:582] [739/1100] Score: -0.697695 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:12.4209 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:12.4209 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:12.4212 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:12.5325 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.142193 train-accuracy:0.779951 valid-loss:1.119371 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:38:12.6579 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646415\n",
      "[INFO 24-02-22 07:38:12.6580 UTC gradient_boosted_trees.cc:271] Truncates the model to 248 tree(s) i.e. 248  iteration(s).\n",
      "[INFO 24-02-22 07:38:12.6580 UTC gradient_boosted_trees.cc:334] Final model num-trees:248 valid-loss:0.646415 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:12.6586 UTC hyperparameters_optimizer.cc:582] [740/1100] Score: -0.646415 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:12.6597 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:12.6597 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:12.6600 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:12.6642 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.135751 train-accuracy:0.737164 valid-loss:1.121083 valid-accuracy:0.726027\n",
      "[INFO 24-02-22 07:38:12.8323 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68536\n",
      "[INFO 24-02-22 07:38:12.8324 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:12.8327 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:12.8327 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.685360 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:12.8329 UTC hyperparameters_optimizer.cc:582] [741/1100] Score: -0.68536 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:12.8343 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:12.8343 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:12.8346 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:12.8524 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.151861 train-accuracy:0.748166 valid-loss:1.123799 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:38:12.8952 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655193\n",
      "[INFO 24-02-22 07:38:12.8952 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 07:38:12.8954 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.655193 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:12.8969 UTC hyperparameters_optimizer.cc:582] [742/1100] Score: -0.655193 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:12.9009 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:12.9010 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:12.9012 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:12.9048 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221561 train-accuracy:0.612469 valid-loss:1.194268 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:12.9199 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68923\n",
      "[INFO 24-02-22 07:38:12.9199 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:12.9204 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.689230 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:12.9214 UTC hyperparameters_optimizer.cc:582] [743/1100] Score: -0.68923 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:12.9290 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:12.9290 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:12.9292 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:12.9870 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284344 train-accuracy:0.612469 valid-loss:1.239795 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:13.2469 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660336\n",
      "[INFO 24-02-22 07:38:13.2469 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:38:13.2474 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.660336 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:13.2481 UTC hyperparameters_optimizer.cc:582] [744/1100] Score: -0.660336 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:13.2498 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:13.2498 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:13.2500 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:13.2585 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132969 train-accuracy:0.794621 valid-loss:1.112315 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:38:13.3363 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678699\n",
      "[INFO 24-02-22 07:38:13.3363 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:13.3364 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.678699 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:13.3369 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:13.3369 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:13.3371 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:13.3371 UTC hyperparameters_optimizer.cc:582] [745/1100] Score: -0.678699 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:13.3705 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314607 train-accuracy:0.612469 valid-loss:1.276411 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:13.5881 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63747\n",
      "[INFO 24-02-22 07:38:13.5909 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:13.5911 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.637470 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:13.5913 UTC hyperparameters_optimizer.cc:582] [746/1100] Score: -0.63747 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:13.5929 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:13.5929 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:13.5931 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:13.5942 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.211225 train-accuracy:0.612469 valid-loss:1.173865 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:13.6688 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686449\n",
      "[INFO 24-02-22 07:38:13.6688 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:38:13.6689 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.686449 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:13.6690 UTC hyperparameters_optimizer.cc:582] [747/1100] Score: -0.686449 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:13.6710 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:13.6711 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:13.6714 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:13.6884 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157077 train-accuracy:0.776284 valid-loss:1.113755 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:38:13.8123 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643914\n",
      "[INFO 24-02-22 07:38:13.8124 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:13.8126 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.643914 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:13.8128 UTC hyperparameters_optimizer.cc:582] [748/1100] Score: -0.643914 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:13.8133 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:13.8133 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:13.8148 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:13.8508 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.032502 train-accuracy:0.856968 valid-loss:1.056394 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:13.9802 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648149\n",
      "[INFO 24-02-22 07:38:13.9822 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:13.9829 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.648149 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:13.9848 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:13.9848 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:13.9851 UTC hyperparameters_optimizer.cc:582] [749/1100] Score: -0.648149 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:13.9872 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:13.9964 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312213 train-accuracy:0.612469 valid-loss:1.271905 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:14.1717 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673298\n",
      "[INFO 24-02-22 07:38:14.1718 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:14.1719 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.673298 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:14.1724 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:14.1724 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:14.1727 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:14.1732 UTC hyperparameters_optimizer.cc:582] [750/1100] Score: -0.673298 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:14.1761 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.119238 train-accuracy:0.799511 valid-loss:1.087498 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:14.2913 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.713548\n",
      "[INFO 24-02-22 07:38:14.2914 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:14.2915 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.713548 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:14.2917 UTC hyperparameters_optimizer.cc:582] [751/1100] Score: -0.713548 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:14.2921 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:14.2921 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:14.2923 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:14.3256 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.044279 train-accuracy:0.856968 valid-loss:1.065054 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:14.5283 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692096\n",
      "[INFO 24-02-22 07:38:14.5283 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:14.5286 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:14.5287 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.692096 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:14.5289 UTC hyperparameters_optimizer.cc:582] [752/1100] Score: -0.692096 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:14.5294 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:14.5294 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:14.5298 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:14.5393 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122579 train-accuracy:0.839853 valid-loss:1.101068 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:14.5805 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673053\n",
      "[INFO 24-02-22 07:38:14.5806 UTC gradient_boosted_trees.cc:271] Truncates the model to 142 tree(s) i.e. 142  iteration(s).\n",
      "[INFO 24-02-22 07:38:14.5819 UTC gradient_boosted_trees.cc:334] Final model num-trees:142 valid-loss:0.673053 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:14.5843 UTC hyperparameters_optimizer.cc:582] [753/1100] Score: -0.673053 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:14.5854 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:14.5854 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:14.5884 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:14.6083 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184870 train-accuracy:0.612469 valid-loss:1.182682 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:15.0053 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.755086\n",
      "[INFO 24-02-22 07:38:15.0053 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:15.0056 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.755086 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:15.0059 UTC hyperparameters_optimizer.cc:582] [754/1100] Score: -0.755086 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:15.0068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:15.0069 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:15.0072 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:15.0344 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.061381 train-accuracy:0.834963 valid-loss:1.018808 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:15.1102 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68747\n",
      "[INFO 24-02-22 07:38:15.1102 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:15.1106 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.687470 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:15.1121 UTC hyperparameters_optimizer.cc:582] [755/1100] Score: -0.68747 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:15.1125 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:15.1125 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:15.1141 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:15.1430 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.054250 train-accuracy:0.826406 valid-loss:1.065592 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:15.5434 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.735615\n",
      "[INFO 24-02-22 07:38:15.5434 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:15.5439 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.735615 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:15.5457 UTC hyperparameters_optimizer.cc:582] [756/1100] Score: -0.735615 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:15.5465 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:15.5465 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:15.5468 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:15.5539 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084039 train-accuracy:0.858191 valid-loss:1.056810 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:15.7807 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.763704\n",
      "[INFO 24-02-22 07:38:15.7808 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:38:15.7826 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.763704 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:38:15.7859 UTC hyperparameters_optimizer.cc:582] [757/1100] Score: -0.763704 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:38:15.7870 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:15.7870 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:15.7885 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:15.8816 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655694\n",
      "[INFO 24-02-22 07:38:15.8817 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:15.8819 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.655694 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:15.8822 UTC hyperparameters_optimizer.cc:582] [758/1100] Score: -0.655694 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:15.8828 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:15.8828 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:15.8831 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:15.8873 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158888 train-accuracy:0.748166 valid-loss:1.123685 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:38:15.8967 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.769173\n",
      "[INFO 24-02-22 07:38:15.8970 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:15.9014 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:15.9014 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.769173 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:15.9022 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:15.9022 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:15.9025 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:15.9091 UTC hyperparameters_optimizer.cc:582] [759/1100] Score: -0.769173 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:15.9139 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.704728\n",
      "[INFO 24-02-22 07:38:15.9139 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:15.9145 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.704728 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:15.9149 UTC hyperparameters_optimizer.cc:582] [760/1100] Score: -0.704728 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:15.9164 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:15.9164 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:15.9167 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:15.9189 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.197560 train-accuracy:0.612469 valid-loss:1.156277 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:15.9449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.116979 train-accuracy:0.820293 valid-loss:1.129603 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:38:15.9637 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.054784 train-accuracy:0.927873 valid-loss:1.114437 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:16.0219 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691259\n",
      "[INFO 24-02-22 07:38:16.0219 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.0222 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.691259 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:16.0225 UTC hyperparameters_optimizer.cc:582] [761/1100] Score: -0.691259 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:16.0231 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.0231 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.0233 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.0247 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654743\n",
      "[INFO 24-02-22 07:38:16.0247 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.0248 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.654743 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:16.0250 UTC hyperparameters_optimizer.cc:582] [762/1100] Score: -0.654743 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:16.0292 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.0292 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.0295 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.0544 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279916 train-accuracy:0.612469 valid-loss:1.233352 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:16.0938 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673801\n",
      "[INFO 24-02-22 07:38:16.0938 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.0941 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.673801 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:16.0952 UTC hyperparameters_optimizer.cc:582] [763/1100] Score: -0.673801 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:16.0968 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.0968 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.0971 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.0991 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.125904 train-accuracy:0.815403 valid-loss:1.131260 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:16.1349 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.138746 train-accuracy:0.612469 valid-loss:1.148961 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:16.1694 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.758429\n",
      "[INFO 24-02-22 07:38:16.1694 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:16.1699 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:16.1699 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.758429 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:16.1710 UTC hyperparameters_optimizer.cc:582] [764/1100] Score: -0.758429 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:16.1715 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.1715 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.1720 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.1798 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67964\n",
      "[INFO 24-02-22 07:38:16.1799 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.1802 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.679640 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:16.1814 UTC hyperparameters_optimizer.cc:582] [765/1100] Score: -0.67964 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:16.1830 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.1831 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.1834 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.1920 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190870 train-accuracy:0.612469 valid-loss:1.142824 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:16.2143 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.127399 train-accuracy:0.806846 valid-loss:1.069071 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:16.2475 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680659\n",
      "[INFO 24-02-22 07:38:16.2486 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.2488 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.680659 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:16.2491 UTC hyperparameters_optimizer.cc:582] [766/1100] Score: -0.680659 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:16.2505 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.2505 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.2507 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.2837 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316314 train-accuracy:0.612469 valid-loss:1.273447 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:16.3044 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691433\n",
      "[INFO 24-02-22 07:38:16.3044 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:16.3046 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:16.3046 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.691433 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:16.3048 UTC hyperparameters_optimizer.cc:582] [767/1100] Score: -0.691433 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:16.3065 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.3065 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.3074 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.3107 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314004 train-accuracy:0.612469 valid-loss:1.273158 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:16.5361 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701578\n",
      "[INFO 24-02-22 07:38:16.5362 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.5365 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.701578 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:16.5369 UTC hyperparameters_optimizer.cc:582] [768/1100] Score: -0.701578 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:16.5383 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.5383 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.5386 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.5666 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.255641 train-accuracy:0.612469 valid-loss:1.213673 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:16.8608 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65681\n",
      "[INFO 24-02-22 07:38:16.8608 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.8611 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.656810 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:16.8622 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.8622 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.8625 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.8634 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225073 train-accuracy:0.612469 valid-loss:1.167497 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:16.8651 UTC hyperparameters_optimizer.cc:582] [769/1100] Score: -0.65681 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:16.9244 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690265\n",
      "[INFO 24-02-22 07:38:16.9244 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.9245 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.690265 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:16.9246 UTC hyperparameters_optimizer.cc:582] [770/1100] Score: -0.690265 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:16.9250 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.9250 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.9252 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.9316 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288056 train-accuracy:0.612469 valid-loss:1.243284 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:16.9489 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655389\n",
      "[INFO 24-02-22 07:38:16.9490 UTC gradient_boosted_trees.cc:271] Truncates the model to 163 tree(s) i.e. 163  iteration(s).\n",
      "[INFO 24-02-22 07:38:16.9492 UTC gradient_boosted_trees.cc:334] Final model num-trees:163 valid-loss:0.655389 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:16.9515 UTC hyperparameters_optimizer.cc:582] [771/1100] Score: -0.655389 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:16.9557 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:16.9557 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:16.9567 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:16.9771 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238770 train-accuracy:0.612469 valid-loss:1.187953 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:17.7168 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638385\n",
      "[INFO 24-02-22 07:38:17.7169 UTC gradient_boosted_trees.cc:271] Truncates the model to 78 tree(s) i.e. 78  iteration(s).\n",
      "[INFO 24-02-22 07:38:17.7170 UTC gradient_boosted_trees.cc:334] Final model num-trees:78 valid-loss:0.638385 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:17.7178 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:17.7180 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:17.7183 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:17.7217 UTC hyperparameters_optimizer.cc:582] [772/1100] Score: -0.638385 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:17.7251 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180383 train-accuracy:0.612469 valid-loss:1.137996 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:17.7542 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.744005\n",
      "[INFO 24-02-22 07:38:17.7543 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:17.7547 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.744005 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:17.7552 UTC hyperparameters_optimizer.cc:582] [773/1100] Score: -0.744005 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:17.7564 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:17.7568 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:17.7573 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:17.7603 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.125977 train-accuracy:0.767726 valid-loss:1.100383 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:17.8931 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.714907\n",
      "[INFO 24-02-22 07:38:17.8931 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:17.8937 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.714907 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:17.8942 UTC hyperparameters_optimizer.cc:582] [774/1100] Score: -0.714907 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:17.8958 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:17.8958 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:17.8962 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:17.9223 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701934\n",
      "[INFO 24-02-22 07:38:17.9224 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:17.9229 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:17.9229 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.701934 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:17.9234 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:17.9234 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:17.9236 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:17.9251 UTC hyperparameters_optimizer.cc:582] [775/1100] Score: -0.701934 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:17.9258 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201592 train-accuracy:0.612469 valid-loss:1.159582 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:18.0052 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674903\n",
      "[INFO 24-02-22 07:38:18.0060 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.0061 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.674903 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:18.0063 UTC hyperparameters_optimizer.cc:582] [776/1100] Score: -0.674903 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:18.0081 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.0083 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.0086 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.0113 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284460 train-accuracy:0.612469 valid-loss:1.246176 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:18.0173 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699568\n",
      "[INFO 24-02-22 07:38:18.0173 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.0175 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.699568 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:18.0177 UTC hyperparameters_optimizer.cc:582] [777/1100] Score: -0.699568 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:18.0182 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.0182 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.0220 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.0918 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:0.949080 train-accuracy:0.946210 valid-loss:1.080017 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:18.0966 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.113600 train-accuracy:0.783619 valid-loss:1.089586 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:18.1271 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.643866\n",
      "[INFO 24-02-22 07:38:18.1271 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.1272 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.643866 valid-accuracy:0.931507\n",
      "[INFO 24-02-22 07:38:18.1275 UTC hyperparameters_optimizer.cc:582] [778/1100] Score: -0.643866 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:18.1280 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.1280 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.1289 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.1370 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.183563 train-accuracy:0.612469 valid-loss:1.133384 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:18.2549 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667104\n",
      "[INFO 24-02-22 07:38:18.2549 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.2551 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.667104 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:18.2554 UTC hyperparameters_optimizer.cc:582] [779/1100] Score: -0.667104 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:18.2558 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.2558 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.2562 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.2812 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.088240 train-accuracy:0.833741 valid-loss:1.075576 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:18.2815 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668288\n",
      "[INFO 24-02-22 07:38:18.2815 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.2817 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.668288 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:18.2821 UTC hyperparameters_optimizer.cc:582] [780/1100] Score: -0.668288 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:18.2834 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.2834 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.2837 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.3341 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695426\n",
      "[INFO 24-02-22 07:38:18.3341 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.3343 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.695426 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:18.3353 UTC hyperparameters_optimizer.cc:582] [781/1100] Score: -0.695426 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:18.3357 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.3358 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.3360 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.3444 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.037221 train-accuracy:0.863081 valid-loss:0.994608 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:18.3730 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231192 train-accuracy:0.612469 valid-loss:1.183298 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:18.5858 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682794\n",
      "[INFO 24-02-22 07:38:18.5858 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.5860 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.682794 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:18.5863 UTC hyperparameters_optimizer.cc:582] [782/1100] Score: -0.682794 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:18.5870 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.5871 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.5874 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.6234 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.138746 train-accuracy:0.612469 valid-loss:1.148961 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:18.6897 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.752426\n",
      "[INFO 24-02-22 07:38:18.6898 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:18.6900 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:18.6900 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.752426 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:18.6903 UTC hyperparameters_optimizer.cc:582] [783/1100] Score: -0.752426 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:18.6910 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.6910 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.6912 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.6935 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.193480 train-accuracy:0.612469 valid-loss:1.158058 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:18.8262 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655866\n",
      "[INFO 24-02-22 07:38:18.8274 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.8276 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.655866 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:18.8281 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.8282 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.8284 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:18.8318 UTC hyperparameters_optimizer.cc:582] [784/1100] Score: -0.655866 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:18.8594 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279510 train-accuracy:0.612469 valid-loss:1.241778 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:18.9411 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679788\n",
      "[INFO 24-02-22 07:38:18.9411 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:38:18.9412 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.679788 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:18.9413 UTC hyperparameters_optimizer.cc:582] [785/1100] Score: -0.679788 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:18.9451 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:18.9451 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:18.9454 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:19.0296 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.127399 train-accuracy:0.806846 valid-loss:1.069071 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:19.1974 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679892\n",
      "[INFO 24-02-22 07:38:19.1974 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 07:38:19.1977 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.679892 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:19.1994 UTC hyperparameters_optimizer.cc:582] [786/1100] Score: -0.679892 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:19.2000 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:19.2000 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:19.2015 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:19.2394 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159014 train-accuracy:0.804401 valid-loss:1.134988 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:19.3343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669768\n",
      "[INFO 24-02-22 07:38:19.3343 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:19.3345 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.669768 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:19.3348 UTC hyperparameters_optimizer.cc:582] [787/1100] Score: -0.669768 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:19.3371 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:19.3371 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[[INFO 24-02-22 07:38:19.3374 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "INFO 24-02-22 07:38:19.3374 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.660289\n",
      "[INFO 24-02-22 07:38:19.3374 UTC gradient_boosted_trees.cc:271] Truncates the model to 80 tree(s) i.e. 80  iteration(s).\n",
      "[INFO 24-02-22 07:38:19.3380 UTC gradient_boosted_trees.cc:334] Final model num-trees:80 valid-loss:0.660289 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:19.3382 UTC hyperparameters_optimizer.cc:582] [788/1100] Score: -0.660289 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:19.3395 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:19.3395 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:19.3397 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:19.3400 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152751 train-accuracy:0.798289 valid-loss:1.085039 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:19.3420 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157167 train-accuracy:0.777506 valid-loss:1.103651 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:19.3439 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.764631\n",
      "[INFO 24-02-22 07:38:19.3441 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:19.3449 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.764631 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:19.3456 UTC hyperparameters_optimizer.cc:582] [789/1100] Score: -0.764631 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:19.3472 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:19.3473 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:19.3476 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:19.3723 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.192843 train-accuracy:0.612469 valid-loss:1.154871 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:19.5435 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656632\n",
      "[INFO 24-02-22 07:38:19.5436 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:38:19.5436 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.656632 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:19.5440 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:19.5440 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:19.5443 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:19.5451 UTC hyperparameters_optimizer.cc:582] [790/1100] Score: -0.656632 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:19.6129 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676155\n",
      "[INFO 24-02-22 07:38:19.6130 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 07:38:19.6130 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.676155 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:19.6132 UTC hyperparameters_optimizer.cc:582] [791/1100] Score: -0.676155 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:19.6136 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:19.6136 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:19.6138 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:19.6561 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.061566 train-accuracy:0.803178 valid-loss:1.056963 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:19.6841 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648053\n",
      "[INFO 24-02-22 07:38:19.6842 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:19.6844 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.648053 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:19.6847 UTC hyperparameters_optimizer.cc:582] [792/1100] Score: -0.648053 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:19.6853 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:19.6853 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:19.6857 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:19.7133 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.214520 train-accuracy:0.612469 valid-loss:1.184872 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:19.8168 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277948 train-accuracy:0.612469 valid-loss:1.240718 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:20.1616 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646491\n",
      "[INFO 24-02-22 07:38:20.1617 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 07:38:20.1618 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.646491 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:20.1624 UTC hyperparameters_optimizer.cc:582] [793/1100] Score: -0.646491 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:20.1630 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:20.1630 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:20.1638 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:20.1955 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.077236 train-accuracy:0.817848 valid-loss:1.063512 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:20.4317 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.714907\n",
      "[INFO 24-02-22 07:38:20.4317 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:20.4322 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.714907 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:20.4327 UTC hyperparameters_optimizer.cc:582] [794/1100] Score: -0.714907 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:20.4335 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:20.4335 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:20.4339 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:20.4583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.215904 train-accuracy:0.612469 valid-loss:1.188835 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:20.7526 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.658567\n",
      "[INFO 24-02-22 07:38:20.7526 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:38:20.7529 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.658567 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:20.7531 UTC hyperparameters_optimizer.cc:582] [795/1100] Score: -0.658567 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:20.7550 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:20.7551 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:20.7554 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:20.7807 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227117 train-accuracy:0.612469 valid-loss:1.185970 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:20.8429 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.696415\n",
      "[INFO 24-02-22 07:38:20.8429 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:20.8430 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.696415 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:20.8431 UTC hyperparameters_optimizer.cc:582] [796/1100] Score: -0.696415 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:20.8434 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:20.8434 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:20.8436 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:20.8743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102227 train-accuracy:0.809291 valid-loss:1.078449 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:21.0099 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.758082\n",
      "[INFO 24-02-22 07:38:21.0100 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:21.0102 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:21.0102 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.758082 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:21.0103 UTC hyperparameters_optimizer.cc:582] [797/1100] Score: -0.758082 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:21.0115 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:21.0116 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:21.0118 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:21.0169 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.078554 train-accuracy:0.819071 valid-loss:1.056216 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:21.2549 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684456\n",
      "[INFO 24-02-22 07:38:21.2549 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:21.2551 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.684456 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:21.2553 UTC hyperparameters_optimizer.cc:582] [798/1100] Score: -0.684456 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:21.2560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:21.2560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:21.2563 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:21.2764 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.072441 train-accuracy:0.817848 valid-loss:1.009272 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:21.2871 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679788\n",
      "[INFO 24-02-22 07:38:21.2871 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:38:21.2872 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.679788 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:21.2874 UTC hyperparameters_optimizer.cc:582] [799/1100] Score: -0.679788 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:21.2879 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:21.2879 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:21.2883 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:21.3143 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313932 train-accuracy:0.612469 valid-loss:1.274150 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:21.7302 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671013\n",
      "[INFO 24-02-22 07:38:21.7303 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:38:21.7307 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.671013 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:21.7310 UTC hyperparameters_optimizer.cc:582] [800/1100] Score: -0.671013 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:21.7325 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:21.7325 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:21.7328 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:21.7482 UTC [INFO 24-02-22 07:38:21.7483 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.148830 train-accuracy:0.756724 valid-loss:1.106989 valid-accuracy:0.753425\n",
      "early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670969\n",
      "[INFO 24-02-22 07:38:21.7486 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 07:38:21.7490 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.670969 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:21.7498 UTC hyperparameters_optimizer.cc:582] [801/1100] Score: -0.670969 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:21.7504 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:21.7504 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:21.7510 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:21.7712 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228941 train-accuracy:0.612469 valid-loss:1.192367 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:21.9981 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.69493\n",
      "[INFO 24-02-22 07:38:21.9982 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:21.9984 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.694930 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:21.9986 UTC hyperparameters_optimizer.cc:582] [802/1100] Score: -0.69493 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:21.9991 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:21.9991 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:21.9994 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.0034 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315877 train-accuracy:0.612469 valid-loss:1.272649 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:22.0155 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.724668\n",
      "[INFO 24-02-22 07:38:22.0155 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:22.0158 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.724668 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:22.0164 UTC hyperparameters_optimizer.cc:582] [803/1100] Score: -0.724668 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:22.0168 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.0169 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.0171 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.0855 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639077\n",
      "[INFO 24-02-22 07:38:22.0855 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:22.0860 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.639077 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:22.0866 UTC hyperparameters_optimizer.cc:582] [804/1100] Score: -0.639077 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:22.0919 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.0919 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.0922 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.0936 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.129664 train-accuracy:0.804401 valid-loss:1.086495 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:22.1125 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311506 train-accuracy:0.612469 valid-loss:1.272474 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:22.1614 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692489\n",
      "[INFO 24-02-22 07:38:22.1614 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:22.1615 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.692489 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:22.1616 UTC hyperparameters_optimizer.cc:582] [805/1100] Score: -0.692489 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:22.1624 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.1626 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.1631 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.1674 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317134 train-accuracy:0.612469 valid-loss:1.274258 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:22.1721 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674705\n",
      "[INFO 24-02-22 07:38:22.1721 UTC gradient_boosted_trees.cc:271] Truncates the model to 133 tree(s) i.e. 133  iteration(s).\n",
      "[INFO 24-02-22 07:38:22.1723 UTC gradient_boosted_trees.cc:334] Final model num-trees:133 valid-loss:0.674705 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:22.1737 UTC hyperparameters_optimizer.cc:582] [806/1100] Score: -0.674705 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:22.1741 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.1741 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.1752 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.1979 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.144848 train-accuracy:0.819071 valid-loss:1.093330 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:22.1993 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677312\n",
      "[INFO 24-02-22 07:38:22.1994 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:22.1996 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:22.1996 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.677312 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:22.2001 UTC hyperparameters_optimizer.cc:582] [807/1100] Score: -0.677312 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:22.2005 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.2005 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.2007 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.2044 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.109318 train-accuracy:0.798289 valid-loss:1.092332 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:22.4173 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639716\n",
      "[INFO 24-02-22 07:38:22.4173 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:22.4179 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.639716 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:22.4190 UTC hyperparameters_optimizer.cc:582] [808/1100] Score: -0.639716 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:22.4208 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.4208 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.4215 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.4459 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.159003 train-accuracy:0.612469 valid-loss:1.141967 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:22.6248 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.711153\n",
      "[INFO 24-02-22 07:38:22.6248 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:22.6249 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.711153 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:22.6251 UTC hyperparameters_optimizer.cc:582] [809/1100] Score: -0.711153 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:22.6255 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.6255 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.6258 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.6268 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152147 train-accuracy:0.800734 valid-loss:1.102328 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:22.7020 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659694\n",
      "[INFO 24-02-22 07:38:22.7021 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:38:22.7021 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.659694 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:22.7023 UTC hyperparameters_optimizer.cc:582] [810/1100] Score: -0.659694 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:22.7026 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.7026 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.7029 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.7616 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.077953 train-accuracy:0.856968 valid-loss:1.094977 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:22.8423 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677752\n",
      "[INFO 24-02-22 07:38:22.8423 UTC gradient_boosted_trees.cc:271] Truncates the model to 142 tree(s) i.e. 142  iteration(s).\n",
      "[INFO 24-02-22 07:38:22.8424 UTC gradient_boosted_trees.cc:334] Final model num-trees:142 valid-loss:0.677752 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:22.8428 UTC hyperparameters_optimizer.cc:582] [811/1100] Score: -0.677752 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:22.8447 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:22.8450 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:22.8453 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:22.8496 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233305 train-accuracy:0.612469 valid-loss:1.194152 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:23.0288 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674051\n",
      "[INFO 24-02-22 07:38:23.0289 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:23.0290 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.674051 valid-accuracy:0.904110\n",
      "[INFO[INFO 24-02-22 07:38:23.0297 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:23.0297 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:23.0300 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      " 24-02-22 07:38:23.0293 UTC hyperparameters_optimizer.cc:582] [812/1100] Score: -0.674051 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:23.0442 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653032\n",
      "[INFO 24-02-22 07:38:23.0442 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:38:23.0445 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.653032 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:23.0449 UTC hyperparameters_optimizer.cc:582] [813/1100] Score: -0.653032 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:23.0451 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289200 train-accuracy:0.612469 valid-loss:1.245456 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:23.0469 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:23.0469 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:23.0471 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:23.0534 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649844\n",
      "[INFO 24-02-22 07:38:23.0534 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 07:38:23.0535 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.649844 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:23.0540 UTC hyperparameters_optimizer.cc:582] [814/1100] Score: -0.649844 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:23.0548 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:23.0548 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:23.0551 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:23.0825 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223116 train-accuracy:0.612469 valid-loss:1.183044 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:23.0896 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.054578 train-accuracy:0.821516 valid-loss:1.044086 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:23.1798 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674277\n",
      "[INFO 24-02-22 07:38:23.1798 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:23.1802 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.674277 valid-accuracy:0.931507\n",
      "[INFO 24-02-22 07:38:23.1805 UTC hyperparameters_optimizer.cc:582] [815/1100] Score: -0.674277 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:23.1809 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:23.1809 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:23.1815 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:23.1998 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.268333 train-accuracy:0.612469 valid-loss:1.242138 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:23.2602 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654498\n",
      "[INFO 24-02-22 07:38:23.2602 UTC gradient_boosted_trees.cc:271] Truncates the model to 198 tree(s) i.e. 198  iteration(s).\n",
      "[INFO 24-02-22 07:38:23.2603 UTC gradient_boosted_trees.cc:334] Final model num-trees:198 valid-loss:0.654498 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:23.2610 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:23.2610 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:23.2610 UTC hyperparameters_optimizer.cc:582] [816/1100] Score: -0.654498 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:23.2623 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:23.2770 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.309756 train-accuracy:0.612469 valid-loss:1.269598 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:23.7752 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651186\n",
      "[INFO 24-02-22 07:38:23.7752 UTC gradient_boosted_trees.cc:271] Truncates the model to 168 tree(s) i.e. 168  iteration(s).\n",
      "[INFO 24-02-22 07:38:23.7753 UTC gradient_boosted_trees.cc:334] Final model num-trees:168 valid-loss:0.651186 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:23.7757 UTC hyperparameters_optimizer.cc:582] [817/1100] Score: -0.651186 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:23.7762 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:23.7762 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:23.7767 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:23.7875 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.207629 train-accuracy:0.612469 valid-loss:1.200181 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:23.9604 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.737109\n",
      "[INFO 24-02-22 07:38:23.9604 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 07:38:23.9625 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.737109 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:23.9687 UTC hyperparameters_optimizer.cc:582] [818/1100] Score: -0.737109 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:23.9850 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:23.9850 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:23.9854 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.1006 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176836 train-accuracy:0.612469 valid-loss:1.139890 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:24.1690 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688836\n",
      "[INFO 24-02-22 07:38:24.1690 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:24.1692 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.688836 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:24.1694 UTC hyperparameters_optimizer.cc:582] [819/1100] Score: -0.688836 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:24.1701 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:24.1701 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:24.1704 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.1736 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.057639 train-accuracy:0.822738 valid-loss:1.011875 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:24.1913 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.632042\n",
      "[INFO 24-02-22 07:38:24.1914 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 07:38:24.1917 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.632042 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:24.1922 UTC hyperparameters_optimizer.cc:582] [820/1100] Score: -0.632042 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:24.1954 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:24.1954 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:24.1956 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.2186 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.318012 train-accuracy:0.612469 valid-loss:1.275505 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:24.3116 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.707368\n",
      "[INFO 24-02-22 07:38:24.3119 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:24.3125 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.707368 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:24.3128 UTC hyperparameters_optimizer.cc:582] [821/1100] Score: -0.707368 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:24.3139 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:24.3140 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:24.3143 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.3251 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184179 train-accuracy:0.612469 valid-loss:1.143198 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:24.5651 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.633177\n",
      "[INFO 24-02-22 07:38:24.5651 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:24.5654 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.633177 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:24.5660 UTC hyperparameters_optimizer.cc:582] [822/1100] Score: -0.633177 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:24.5674 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:24.5674 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:24.5679 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.5892 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312888 train-accuracy:0.612469 valid-loss:1.274534 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:24.6088 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.616356\n",
      "[INFO 24-02-22 07:38:24.6088 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:38:24.6095 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.616356 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:38:24.6117 UTC hyperparameters_optimizer.cc:582] [823/1100] Score: -0.616356 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:38:24.6128 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:24.6128 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:24.6146 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.6336 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692194\n",
      "[INFO 24-02-22 07:38:24.6337 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:38:24.6347 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.692194 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:24.6376 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:24.6376 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:24.6379 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.6384 UTC hyperparameters_optimizer.cc:582] [824/1100] Score: -0.692194 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:24.7550 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280292 train-accuracy:0.612469 valid-loss:1.241835 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:24.7658 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.708122\n",
      "[INFO 24-02-22 07:38:24.7658 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:24.7660 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.708122 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:24.7662 UTC hyperparameters_optimizer.cc:582] [825/1100] Score: -0.708122 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:24.7665 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.099695 train-accuracy:0.797066 valid-loss:1.095038 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:24.7668 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:24.7668 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:24.7670 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.7777 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.172259 train-accuracy:0.787286 valid-loss:1.121365 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:24.8849 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652567\n",
      "[INFO 24-02-22 07:38:24.8850 UTC gradient_boosted_trees.cc:271] Truncates the model to 105 tree(s) i.e. 105  iteration(s).\n",
      "[INFO 24-02-22 07:38:24.8850 UTC gradient_boosted_trees.cc:334] Final model num-trees:105 valid-loss:0.652567 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:24.8853 UTC hyperparameters_optimizer.cc:582] [826/1100] Score: -0.652567 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:24.8869 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:24.8869 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:24.8871 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:24.9020 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.145527 train-accuracy:0.635697 valid-loss:1.085156 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:25.2636 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692521\n",
      "[INFO 24-02-22 07:38:25.2637 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:25.2637 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.692521 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:25.2641 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:25.2641 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:25.2643 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:25.2651 UTC hyperparameters_optimizer.cc:582] [827/1100] Score: -0.692521 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:25.2888 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.021327 train-accuracy:0.861858 valid-loss:1.040852 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:25.4835 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670436\n",
      "[INFO 24-02-22 07:38:25.4835 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 07:38:25.4842 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.670436 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:25.4861 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.711561\n",
      "[INFO 24-02-22 07:38:25.4861 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:25.4864 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.711561 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:25.4869 UTC hyperparameters_optimizer.cc:582] [828/1100] Score: -0.711561 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:25.4880 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:25.4882 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:25.4883 UTC hyperparameters_optimizer.cc:582] [829/1100] Score: -0.670436 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:25.4885 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:25.4940 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:25.4940 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:25.4942 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:25.5415 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.099106 train-accuracy:0.612469 valid-loss:1.145216 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:25.5772 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656746\n",
      "[INFO 24-02-22 07:38:25.5772 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 07:38:25.5774 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.656746 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:25.5798 UTC hyperparameters_optimizer.cc:582] [830/1100] Score: -0.656746 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:25.5803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156961 train-accuracy:0.612469 valid-loss:1.134400 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:25.5835 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:25.5836 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:25.5838 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:25.7347 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.020065 train-accuracy:0.844743 valid-loss:1.018873 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:25.8468 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.719984\n",
      "[INFO 24-02-22 07:38:25.8468 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:25.8483 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:25.8483 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.719984 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:25.8515 UTC hyperparameters_optimizer.cc:582] [831/1100] Score: -0.719984 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:25.8517 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.697818\n",
      "[INFO 24-02-22 07:38:25.8517 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:25.8520 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:25.8520 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:25.8525 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.697818 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:25.8526 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:25.8549 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:25.8550 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:25.8553 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:25.8584 UTC hyperparameters_optimizer.cc:582] [832/1100] Score: -0.697818 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:25.8795 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312755 train-accuracy:0.612469 valid-loss:1.273450 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:25.8833 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.106130 train-accuracy:0.798289 valid-loss:1.064177 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:25.9475 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695018\n",
      "[INFO 24-02-22 07:38:25.9475 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:38:25.9477 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.695018 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:25.9479 UTC hyperparameters_optimizer.cc:582] [833/1100] Score: -0.695018 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:25.9482 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:25.9482 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:25.9598 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:26.0082 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221708 train-accuracy:0.612469 valid-loss:1.182994 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:26.4030 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.702894\n",
      "[INFO 24-02-22 07:38:26.4030 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:26.4032 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:26.4032 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.702894 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:26.4034 UTC hyperparameters_optimizer.cc:582] [834/1100] Score: -0.702894 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:26.4040 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:26.4040 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:26.4043 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:26.4154 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314525 train-accuracy:0.612469 valid-loss:1.271146 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:26.7294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651924\n",
      "[INFO 24-02-22 07:38:26.7294 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:38:26.7296 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.651924 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:26.7301 UTC hyperparameters_optimizer.cc:582] [835/1100] Score: -0.651924 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:26.7318 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:26.7318 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:26.7320 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:26.8061 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302244 train-accuracy:0.612469 valid-loss:1.275046 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:27.5360 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672859\n",
      "[INFO 24-02-22 07:38:27.5360 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:38:27.5363 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.672859 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:27.5368 UTC hyperparameters_optimizer.cc:582] [836/1100] Score: -0.672859 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:27.5374 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:27.5374 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:27.5377 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:27.6576 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.273287 train-accuracy:0.612469 valid-loss:1.237775 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:27.7232 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636378\n",
      "[INFO 24-02-22 07:38:27.7232 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:38:27.7235 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.636378 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:27.7240 UTC hyperparameters_optimizer.cc:582] [837/1100] Score: -0.636378 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:27.7251 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:27.7251 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:27.7253 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:27.7923 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315176 train-accuracy:0.612469 valid-loss:1.275023 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:28.3496 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686549\n",
      "[INFO 24-02-22 07:38:28.3497 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:38:28.3501 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.686549 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:28.3509 UTC hyperparameters_optimizer.cc:582] [838/1100] Score: -0.686549 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:28.3518 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:28.3518 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:28.3522 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:28.3562 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.195395 train-accuracy:0.612469 valid-loss:1.164548 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:28.3611 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653692\n",
      "[INFO 24-02-22 07:38:28.3613 UTC gradient_boosted_trees.cc:271] Truncates the model to 165 tree(s) i.e. 165  iteration(s).\n",
      "[INFO 24-02-22 07:38:28.3617 UTC gradient_boosted_trees.cc:334] Final model num-trees:165 valid-loss:0.653692 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:28.3659 UTC hyperparameters_optimizer.cc:582] [839/1100] Score: -0.653692 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:28.3666 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:28.3666 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:28.3682 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:28.3846 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310203 train-accuracy:0.612469 valid-loss:1.275768 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:28.4277 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.766386\n",
      "[INFO 24-02-22 07:38:28.4277 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:28.4299 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:28.4299 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.766386 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:28.4317 UTC hyperparameters_optimizer.cc:582] [840/1100] Score: -0.766386 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:28.4347 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:28.4348 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:28.4350 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:28.4380 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.178454 train-accuracy:0.612469 valid-loss:1.147757 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:28.5269 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642487\n",
      "[INFO 24-02-22 07:38:28.5269 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:38:28.5274 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.642487 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:28.5277 UTC hyperparameters_optimizer.cc:582] [841/1100] Score: -0.642487 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:28.5280 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:28.5280 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:28.5282 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:28.5315 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317828 train-accuracy:0.612469 valid-loss:1.275805 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:28.5679 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.671471\n",
      "[INFO 24-02-22 07:38:28.5679 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:28.5682 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.671471 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:28.5686 UTC hyperparameters_optimizer.cc:582] [842/1100] Score: -0.671471 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:28.5695 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:28.5695 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:28.5699 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:28.6156 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.129536 train-accuracy:0.833741 valid-loss:1.060873 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:28.6684 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665528\n",
      "[INFO 24-02-22 07:38:28.6685 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 07:38:28.6686 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.665528 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:28.6707 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:28.6707 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:28.6709 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:28.6751 UTC hyperparameters_optimizer.cc:582] [843/1100] Score: -0.665528 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:28.7009 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.193850 train-accuracy:0.612469 valid-loss:1.153731 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:28.8340 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.746467\n",
      "[INFO 24-02-22 07:38:28.8340 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:28.8358 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.746467 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:28.8372 UTC hyperparameters_optimizer.cc:582] [844/1100] Score: -0.746467 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:28.8397 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:28.8397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:28.8406 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:28.8432 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155137 train-accuracy:0.735941 valid-loss:1.119243 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:28.9603 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635853\n",
      "[INFO 24-02-22 07:38:28.9603 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:28.9606 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.635853 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:28.9618 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:28.9618 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:28.9620 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:28.9621 UTC hyperparameters_optimizer.cc:582] [845/1100] Score: -0.635853 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:28.9668 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314544 train-accuracy:0.612469 valid-loss:1.274118 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:29.0145 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606302\n",
      "[INFO 24-02-22 07:38:29.0145 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:38:29.0147 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.606302 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:29.0191 UTC hyperparameters_optimizer.cc:582] [846/1100] Score: -0.606302 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:29.0192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:29.0192 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:29.0210 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:29.0399 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.040317 train-accuracy:0.837408 valid-loss:0.981783 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:29.1691 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645016\n",
      "[INFO 24-02-22 07:38:29.1692 UTC gradient_boosted_trees.cc:271] Truncates the model to 236 tree(s) i.e. 236  iteration(s).\n",
      "[INFO 24-02-22 07:38:29.1693 UTC gradient_boosted_trees.cc:334] Final model num-trees:236 valid-loss:0.645016 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:29.1703 UTC hyperparameters_optimizer.cc:582] [847/1100] Score: -0.645016 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:29.1728 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:29.1729 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:29.1731 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:29.1769 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.030964 train-accuracy:0.847188 valid-loss:1.023826 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:29.3519 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691585\n",
      "[INFO 24-02-22 07:38:29.3519 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:29.3523 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.691585 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:29.3531 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:29.3531 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:29.3534 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:29.3550 UTC hyperparameters_optimizer.cc:582] [848/1100] Score: -0.691585 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:29.3608 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.479863 train-accuracy:0.922983 valid-loss:0.637722 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:29.3618 UTC gradient_boosted_trees.cc:271] Truncates the model to 290 tree(s) i.e. 290  iteration(s).\n",
      "[INFO 24-02-22 07:38:29.3618 UTC gradient_boosted_trees.cc:334] Final model num-trees:290 valid-loss:0.636574 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:29.3636 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:29.3636 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:29.3638 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:29.3655 UTC hyperparameters_optimizer.cc:582] [849/1100] Score: -0.636574 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:29.3661 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280632 train-accuracy:0.612469 valid-loss:1.246853 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:29.3905 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280886 train-accuracy:0.612469 valid-loss:1.238834 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:29.4245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631784\n",
      "[INFO 24-02-22 07:38:29.4246 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:38:29.4249 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.631784 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:38:29.4260 UTC hyperparameters_optimizer.cc:582] [850/1100] Score: -0.631784 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:38:29.4264 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:29.4264 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:29.4269 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:29.4583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275799 train-accuracy:0.612469 valid-loss:1.240367 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:29.4978 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.727955\n",
      "[INFO 24-02-22 07:38:29.4978 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:29.4981 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.727955 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:29.4986 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:29.4987 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:29.4989 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:29.5018 UTC hyperparameters_optimizer.cc:582] [851/1100] Score: -0.727955 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:29.5081 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.256620 train-accuracy:0.612469 valid-loss:1.208295 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:29.9817 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648177\n",
      "[INFO 24-02-22 07:38:29.9818 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:38:29.9819 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.648177 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:29.9821 UTC hyperparameters_optimizer.cc:582] [852/1100] Score: -0.648177 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:29.9826 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:29.9826 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:29.9828 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:29.9844 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244467 train-accuracy:0.612469 valid-loss:1.202723 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.1266 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644106\n",
      "[INFO 24-02-22 07:38:30.1266 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.1267 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.644106 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:30.1269 UTC hyperparameters_optimizer.cc:582] [853/1100] Score: -0.644106 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:30.1279 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.1279 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.1282 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.1400 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312389 train-accuracy:0.612469 valid-loss:1.274191 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.2137 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.700164\n",
      "[INFO 24-02-22 07:38:30.2137 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:30.2140 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:30.2141 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.700164 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:30.2147 UTC hyperparameters_optimizer.cc:582] [854/1100] Score: -0.700164 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:30.2156 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.2156 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.2158 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.2269 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281978 train-accuracy:0.612469 valid-loss:1.243611 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.2650 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664869\n",
      "[INFO 24-02-22 07:38:30.2651 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.2653 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.664869 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:30.2659 UTC hyperparameters_optimizer.cc:582] [855/1100] Score: -0.664869 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:30.2671 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.2671 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.2674 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.2727 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313633 train-accuracy:0.612469 valid-loss:1.272373 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.3036 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662249\n",
      "[INFO 24-02-22 07:38:30.3036 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.3037 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.662249 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:30.3038 UTC hyperparameters_optimizer.cc:582] [856/1100] Score: -0.662249 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:30.3042 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.3043 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.3045 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.3087 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.211509 train-accuracy:0.612469 valid-loss:1.155222 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.4504 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683894\n",
      "[INFO 24-02-22 07:38:30.4504 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.4506 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.683894 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:30.4517 UTC hyperparameters_optimizer.cc:582] [857/1100] Score: -0.683894 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:30.4539 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.4539 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.4542 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.5402 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701683\n",
      "[INFO 24-02-22 07:38:30.5403 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.5404 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.701683 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:30.5405 UTC hyperparameters_optimizer.cc:582] [858/1100] Score: -0.701683 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:30.5409 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.5409 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.5412 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.5422 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321016 train-accuracy:0.612469 valid-loss:1.279095 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.5815 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223092 train-accuracy:0.612469 valid-loss:1.186030 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.6371 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670857\n",
      "[INFO 24-02-22 07:38:30.6371 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.6373 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.670857 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:30.6388 UTC hyperparameters_optimizer.cc:582] [859/1100] Score: -0.670857 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:30.6390 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.6390 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.6403 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.6446 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278969 train-accuracy:0.612469 valid-loss:1.243097 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.7824 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682602\n",
      "[INFO 24-02-22 07:38:30.7824 UTC gradient_boosted_trees.cc:271] Truncates the model to 131 tree(s) i.e. 131  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.7828 UTC gradient_boosted_trees.cc:334] Final model num-trees:131 valid-loss:0.682602 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:30.7857 UTC hyperparameters_optimizer.cc:582] [860/1100] Score: -0.682602 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:30.7866 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.7866 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.7887 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.8122 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279202 train-accuracy:0.612469 valid-loss:1.238228 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.8439 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.699770 train-accuracy:0.864303 valid-loss:0.671890 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:30.8439 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.8439 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.671863 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:30.8444 UTC hyperparameters_optimizer.cc:582] [861/1100] Score: -0.671863 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:30.8454 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.8455 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.8478 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:30.8570 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312218 train-accuracy:0.612469 valid-loss:1.273197 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:30.9830 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.628104\n",
      "[INFO 24-02-22 07:38:30.9830 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:30.9832 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.628104 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:30.9834 UTC hyperparameters_optimizer.cc:582] [862/1100] Score: -0.628104 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:30.9840 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:30.9841 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:30.9845 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.0144 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657078\n",
      "[INFO 24-02-22 07:38:31.0144 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.0146 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.657078 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:31.0153 UTC hyperparameters_optimizer.cc:582] [863/1100] Score: -0.657078 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:31.0166 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.0168 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.0174 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.0206 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683374\n",
      "[INFO 24-02-22 07:38:31.0206 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.0210 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.683374 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:31.0222 UTC hyperparameters_optimizer.cc:582] [864/1100] Score: -0.683374 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:31.0230 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.0230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.0240 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.0271 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.120500 train-accuracy:0.759169 valid-loss:1.089275 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:38:31.0288 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182596 train-accuracy:0.612469 valid-loss:1.157422 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:31.0930 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311931 train-accuracy:0.612469 valid-loss:1.272901 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:31.1083 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663269\n",
      "[INFO 24-02-22 07:38:31.1083 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.1087 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.663269 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:31.1098 UTC hyperparameters_optimizer.cc:582] [865/1100] Score: -0.663269 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:31.1108 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.1109 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.1113 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.1150 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.167099 train-accuracy:0.612469 valid-loss:1.146469 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:31.1506 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683306\n",
      "[INFO 24-02-22 07:38:31.1506 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:31.1508 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:31.1508 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.683306 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:31.1513 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.1513 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.1515 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.1518 UTC hyperparameters_optimizer.cc:582] [866/1100] Score: -0.683306 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:31.1614 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680353\n",
      "[INFO 24-02-22 07:38:31.1614 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:31.1645 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:31.1645 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.680353 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:31.1648 UTC hyperparameters_optimizer.cc:582] [867/1100] Score: -0.680353 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:31.1658 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.1658 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.1661 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.1729 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083733 train-accuracy:0.797066 valid-loss:1.068167 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:31.2577 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66019\n",
      "[INFO 24-02-22 07:38:31.2577 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.2580 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.660190 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:31.2617 UTC hyperparameters_optimizer.cc:582] [868/1100] Score: -0.66019 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:31.2637 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.2638 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.2640 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.2915 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.076742 train-accuracy:0.866748 valid-loss:1.111030 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:31.2965 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285298 train-accuracy:0.612469 valid-loss:1.243007 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:31.3200 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686058\n",
      "[INFO 24-02-22 07:38:31.3201 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.3203 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.686058 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:31.3206 UTC hyperparameters_optimizer.cc:582] [869/1100] Score: -0.686058 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:31.3220 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.3221 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.3223 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.4706 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.094133 train-accuracy:0.803178 valid-loss:1.095378 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:31.6191 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.656208 train-accuracy:0.887531 valid-loss:0.664236 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:31.6192 UTC gradient_boosted_trees.cc:271] Truncates the model to 288 tree(s) i.e. 288  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.6192 UTC gradient_boosted_trees.cc:334] Final model num-trees:288 valid-loss:0.660408 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:31.6196 UTC hyperparameters_optimizer.cc:582] [870/1100] Score: -0.660408 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:31.6206 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.6207 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.6209 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.6223 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.164020 train-accuracy:0.766504 valid-loss:1.121386 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:31.6390 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681123\n",
      "[INFO 24-02-22 07:38:31.6390 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.6393 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.681123 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:31.6397 UTC hyperparameters_optimizer.cc:582] [871/1100] Score: -0.681123 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:31.6405 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.6405 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.6407 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.6449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.211500 train-accuracy:0.612469 valid-loss:1.189103 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:31.7442 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662628\n",
      "[INFO 24-02-22 07:38:31.7442 UTC gradient_boosted_trees.cc:271] Truncates the model to 129 tree(s) i.e. 129  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.7446 UTC gradient_boosted_trees.cc:334] Final model num-trees:129 valid-loss:0.662628 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:31.7480 UTC hyperparameters_optimizer.cc:582] [872/1100] Score: -0.662628 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:31.7526 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.7527 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.7529 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.7558 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634196\n",
      "[INFO 24-02-22 07:38:31.7558 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.7559 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.634196 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:31.7563 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.7563 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.7565 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.7585 UTC hyperparameters_optimizer.cc:582] [873/1100] Score: -0.634196 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:31.7612 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312486 train-accuracy:0.612469 valid-loss:1.273370 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:31.7664 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310381 train-accuracy:0.612469 valid-loss:1.273931 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:31.9463 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653063\n",
      "[INFO 24-02-22 07:38:31.9463 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:31.9473 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.653063 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:31.9482 UTC hyperparameters_optimizer.cc:582] [874/1100] Score: -0.653063 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:31.9507 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:31.9507 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:31.9510 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:31.9534 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114018 train-accuracy:0.768949 valid-loss:1.094433 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:38:32.0801 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657573\n",
      "[INFO 24-02-22 07:38:32.0801 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:38:32.0804 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.657573 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:32.0810 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:32.0811 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:32.0813 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:32.0852 UTC hyperparameters_optimizer.cc:582] [875/1100] Score: -0.657573 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:32.0909 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.183794 train-accuracy:0.612469 valid-loss:1.148517 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:32.1171 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659363\n",
      "[INFO 24-02-22 07:38:32.1171 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:38:32.1173 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.659363 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:32.1179 UTC hyperparameters_optimizer.cc:582] [876/1100] Score: -0.659363 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:32.1189 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:32.1189 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:32.1192 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:32.1272 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.152425 train-accuracy:0.750611 valid-loss:1.109158 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:38:32.4776 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657929\n",
      "[INFO 24-02-22 07:38:32.4776 UTC gradient_boosted_trees.cc:271] Truncates the model to 154 tree(s) i.e. 154  iteration(s).\n",
      "[INFO 24-02-22 07:38:32.4779 UTC gradient_boosted_trees.cc:334] Final model num-trees:154 valid-loss:0.657929 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:32.4799 UTC hyperparameters_optimizer.cc:582] [877/1100] Score: -0.657929 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:32.4816 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:32.4817 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:32.4819 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:32.5061 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162827 train-accuracy:0.612469 valid-loss:1.140360 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:32.5285 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685613\n",
      "[INFO 24-02-22 07:38:32.5286 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:32.5287 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.685613 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:32.5289 UTC hyperparameters_optimizer.cc:582] [878/1100] Score: -0.685613 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:32.5294 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:32.5294 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:32.5296 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:32.5531 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295444 train-accuracy:0.612469 valid-loss:1.251749 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:32.5914 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661747\n",
      "[INFO 24-02-22 07:38:32.5914 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 07:38:32.5916 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.661747 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:32.5929 UTC hyperparameters_optimizer.cc:582] [879/1100] Score: -0.661747 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:32.5955 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:32.5961 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:32.5963 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:32.6254 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282788 train-accuracy:0.612469 valid-loss:1.248375 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:32.8736 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694411\n",
      "[INFO 24-02-22 07:38:32.8736 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:38:32.8741 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.694411 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:32.8757 UTC hyperparameters_optimizer.cc:582] [880/1100] Score: -0.694411 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:32.8803 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:32.8803 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:32.8806 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:32.8914 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.056709 train-accuracy:0.842298 valid-loss:0.998326 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:33.1547 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654979\n",
      "[INFO 24-02-22 07:38:33.1547 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 07:38:33.1550 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.654979 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:33.1569 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:33.1570 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:33.1572 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:33.1585 UTC hyperparameters_optimizer.cc:582] [881/1100] Score: -0.654979 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:33.1796 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315150 train-accuracy:0.612469 valid-loss:1.274251 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:33.1821 UTC gradient_boosted_trees.cc:1638] \tnum-trees:80 train-loss:0.334164 train-accuracy:0.958435 valid-loss:0.675071 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:33.2747 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639289\n",
      "[INFO 24-02-22 07:38:33.2747 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:38:33.2749 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.639289 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:33.2759 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:33.2759 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:33.2761 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:33.2768 UTC hyperparameters_optimizer.cc:582] [882/1100] Score: -0.639289 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:33.2809 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6481\n",
      "[INFO 24-02-22 07:38:33.2809 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:33.2811 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.648100 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:33.2816 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:33.2816 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:33.2850 UTC hyperparameters_optimizer.cc:582] [883/1100] Score: -0.6481 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:33.2853 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:33.2961 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.196864 train-accuracy:0.612469 valid-loss:1.133285 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:33.3226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.169470 train-accuracy:0.612469 valid-loss:1.132478 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:33.3295 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672565\n",
      "[INFO 24-02-22 07:38:33.3295 UTC gradient_boosted_trees.cc:271] Truncates the model to 130 tree(s) i.e. 130  iteration(s).\n",
      "[INFO 24-02-22 07:38:33.3299 UTC gradient_boosted_trees.cc:334] Final model num-trees:130 valid-loss:0.672565 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:33.3355 UTC hyperparameters_optimizer.cc:582] [884/1100] Score: -0.672565 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:33.3362 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:33.3362 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:33.3369 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:33.3439 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223871 train-accuracy:0.612469 valid-loss:1.189917 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:33.5604 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688735\n",
      "[INFO 24-02-22 07:38:33.5604 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:33.5610 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.688735 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:33.5621 UTC hyperparameters_optimizer.cc:582] [885/1100] Score: -0.688735 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:33.5633 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:33.5634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:33.5638 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:33.6024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.661403\n",
      "[INFO 24-02-22 07:38:33.6024 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:38:33.6026 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.661403 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:33.6035 UTC hyperparameters_optimizer.cc:582] [886/1100] Score: -0.661403 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:33.6039 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:33.6042 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:33.6067 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:33.6094 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.187054 train-accuracy:0.612469 valid-loss:1.120301 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:33.7217 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.115229 train-accuracy:0.612469 valid-loss:1.160310 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:33.7743 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.70388\n",
      "[INFO 24-02-22 07:38:33.7764 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:33.7765 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.703880 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:33.7768 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:33.7768 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:33.7771 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:33.7788 UTC hyperparameters_optimizer.cc:582] [887/1100] Score: -0.70388 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:33.7970 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242100 train-accuracy:0.612469 valid-loss:1.202878 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:33.8365 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62537\n",
      "[INFO 24-02-22 07:38:33.8365 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:38:33.8370 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.625370 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:33.8375 UTC hyperparameters_optimizer.cc:582] [888/1100] Score: -0.62537 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:33.8382 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:33.8382 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:33.8385 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:33.8615 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224653 train-accuracy:0.612469 valid-loss:1.186752 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:34.1456 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.64752\n",
      "[INFO 24-02-22 07:38:34.1456 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:38:34.1457 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.647520 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:34.1459 UTC hyperparameters_optimizer.cc:582] [889/1100] Score: -0.64752 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:34.1463 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:34.1463 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:34.1465 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:34.1496 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280514 train-accuracy:0.612469 valid-loss:1.244899 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:34.4419 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673281\n",
      "[INFO 24-02-22 07:38:34.4419 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 07:38:34.4422 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.673281 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:34.4431 UTC hyperparameters_optimizer.cc:582] [890/1100] Score: -0.673281 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:34.4445 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:34.4445 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:34.4447 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:34.4670 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224795 train-accuracy:0.612469 valid-loss:1.186161 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:34.6497 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682945\n",
      "[INFO 24-02-22 07:38:34.6497 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 07:38:34.6499 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.682945 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:34.6513 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:34.6513 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:34.6516 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:34.6520 UTC hyperparameters_optimizer.cc:582] [891/1100] Score: -0.682945 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:34.7750 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225431 train-accuracy:0.612469 valid-loss:1.196312 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:35.2239 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67033\n",
      "[INFO 24-02-22 07:38:35.2239 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.2240 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.670330 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:35.2245 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.2246 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.2248 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.2284 UTC hyperparameters_optimizer.cc:582] [892/1100] Score: -0.67033 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:35.2449 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.631146\n",
      "[INFO 24-02-22 07:38:35.2449 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.2452 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.631146 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:35.2457 UTC hyperparameters_optimizer.cc:582] [893/1100] Score: -0.631146 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:35.2464 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.2464 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.2467 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.2494 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.083472 train-accuracy:0.830073 valid-loss:1.053901 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:35.2708 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276587 train-accuracy:0.612469 valid-loss:1.239939 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:35.3629 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669263\n",
      "[INFO 24-02-22 07:38:35.3630 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.3633 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.669263 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:35.3637 UTC hyperparameters_optimizer.cc:582] [894/1100] Score: -0.669263 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:35.3644 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.3645 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.3649 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.3658 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.132927 train-accuracy:0.817848 valid-loss:1.059222 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:35.3815 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683539\n",
      "[INFO 24-02-22 07:38:35.3815 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.3817 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.683539 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:35.3826 UTC hyperparameters_optimizer.cc:582] [895/1100] Score: -0.683539 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:35.3830 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.3830 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.3832 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.4004 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692634\n",
      "[INFO 24-02-22 07:38:35.4004 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.4005 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.692634 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:35.4007 UTC hyperparameters_optimizer.cc:582] [896/1100] Score: -0.692634 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:35.4011 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.4012 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.4014 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.4046 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081877 train-accuracy:0.831296 valid-loss:1.087507 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:35.4608 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289311 train-accuracy:0.612469 valid-loss:1.241882 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:35.4916 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.606603\n",
      "[INFO 24-02-22 07:38:35.4917 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.4953 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.606603 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:35.4958 UTC hyperparameters_optimizer.cc:582] [897/1100] Score: -0.606603 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:35.4967 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.4967 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.4969 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.5169 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685053\n",
      "[INFO 24-02-22 07:38:35.5170 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.5173 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.685053 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:35.5175 UTC hyperparameters_optimizer.cc:582] [898/1100] Score: -0.685053 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:35.5180 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.5181 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.5182 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.5287 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.277596 train-accuracy:0.612469 valid-loss:1.240893 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:35.5394 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.082215 train-accuracy:0.814181 valid-loss:1.041764 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:35.7862 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.706874\n",
      "[INFO 24-02-22 07:38:35.7862 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.7866 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.706874 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:35.7870 UTC hyperparameters_optimizer.cc:582] [899/1100] Score: -0.706874 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:35.7891 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.7891 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.7895 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.8207 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.131920 train-accuracy:0.808068 valid-loss:1.113696 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:35.9357 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65062\n",
      "[INFO 24-02-22 07:38:35.9357 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:38:35.9359 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.650620 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:35.9363 UTC hyperparameters_optimizer.cc:582] [900/1100] Score: -0.65062 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:35.9373 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:35.9373 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:35.9383 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:35.9667 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.090412 train-accuracy:0.833741 valid-loss:1.065523 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:36.2203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677313\n",
      "[INFO 24-02-22 07:38:36.2203 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:38:36.2213 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.677313 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:36.2221 UTC hyperparameters_optimizer.cc:582] [901/1100] Score: -0.677313 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:36.2236 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:36.2236 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:36.2239 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:36.2260 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.103211 train-accuracy:0.827628 valid-loss:1.043230 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:36.3087 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.630616\n",
      "[INFO 24-02-22 07:38:36.3087 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:36.3089 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.630616 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:36.3090 UTC hyperparameters_optimizer.cc:582] [902/1100] Score: -0.630616 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:36.3102 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:36.3102 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:36.3104 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:36.3139 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248459 train-accuracy:0.612469 valid-loss:1.197104 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:36.5490 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668474\n",
      "[INFO 24-02-22 07:38:36.5490 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 07:38:36.5491 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.668474 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:36.5499 UTC hyperparameters_optimizer.cc:582] [903/1100] Score: -0.668474 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:36.5513 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:36.5513 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:36.5515 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:36.5596 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182469 train-accuracy:0.612469 valid-loss:1.139595 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:36.6009 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654295\n",
      "[INFO 24-02-22 07:38:36.6041 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 07:38:36.6042 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.654295 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:36.6044 UTC hyperparameters_optimizer.cc:582] [904/1100] Score: -0.654295 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:36.6047 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:36.6048 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:36.6050 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:36.6260 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.102590 train-accuracy:0.808068 valid-loss:1.058509 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:36.7628 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638679\n",
      "[INFO 24-02-22 07:38:36.7628 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:36.7631 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.638679 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:36.7633 UTC hyperparameters_optimizer.cc:582] [905/1100] Score: -0.638679 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:36.7638 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:36.7638 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:36.7641 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:36.7842 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228426 train-accuracy:0.612469 valid-loss:1.197587 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.0974 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639293\n",
      "[INFO 24-02-22 07:38:37.0975 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.0976 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.639293 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:37.0981 UTC hyperparameters_optimizer.cc:582] [906/1100] Score: -0.639293 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:37.0989 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.0989 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.0991 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.1100 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.308395 train-accuracy:0.612469 valid-loss:1.274020 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.2019 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689192\n",
      "[INFO 24-02-22 07:38:37.2019 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.2029 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.689192 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:37.2034 UTC hyperparameters_optimizer.cc:582] [907/1100] Score: -0.689192 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:37.2043 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.2043 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.2046 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.2078 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.220318 train-accuracy:0.612469 valid-loss:1.200595 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.2496 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.697127\n",
      "[INFO 24-02-22 07:38:37.2496 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:37.2501 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:37.2501 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.697127 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:37.2510 UTC hyperparameters_optimizer.cc:582] [908/1100] Score: -0.697127 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:37.2520 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.2520 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.2536 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.2648 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180044 train-accuracy:0.612469 valid-loss:1.150391 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.3107 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655169\n",
      "[INFO 24-02-22 07:38:37.3107 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:37.3110 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:37.3110 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.655169 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:37.3112 UTC hyperparameters_optimizer.cc:582] [909/1100] Score: -0.655169 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:37.3120 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.3121 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.3138 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.3635 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.163148 train-accuracy:0.783619 valid-loss:1.120976 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:37.3766 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.770671\n",
      "[INFO 24-02-22 07:38:37.3836 UTC gradient_boosted_trees.cc:271] Truncates the model to 88 tree(s) i.e. 88  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.3859 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67345\n",
      "[INFO 24-02-22 07:38:37.3859 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.3864 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.673450 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:37.3875 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.3875 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.3877 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.3879 UTC hyperparameters_optimizer.cc:582] [910/1100] Score: -0.67345 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:37.3909 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315132 train-accuracy:0.612469 valid-loss:1.275635 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.3918 UTC gradient_boosted_trees.cc:334] Final model num-trees:88 valid-loss:0.770671 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:37.4048 UTC hyperparameters_optimizer.cc:582] [911/1100] Score: -0.770671 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:37.4112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.4112 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.4114 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.4372 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222709 train-accuracy:0.612469 valid-loss:1.200309 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.5766 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691033\n",
      "[INFO 24-02-22 07:38:37.5767 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.5767 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.691033 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:37.5774 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.5775 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.5778 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.5784 UTC hyperparameters_optimizer.cc:582] [912/1100] Score: -0.691033 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:37.6048 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188409 train-accuracy:0.777506 valid-loss:1.137959 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:37.6278 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.605687\n",
      "[INFO 24-02-22 07:38:37.6278 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.6279 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.605687 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:37.6281 UTC hyperparameters_optimizer.cc:582] [913/1100] Score: -0.605687 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:37.6286 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.6287 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.6289 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.6379 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.131159 train-accuracy:0.783619 valid-loss:1.071551 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:37.6705 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675614\n",
      "[INFO 24-02-22 07:38:37.6705 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.6707 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.675614 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:37.6711 UTC hyperparameters_optimizer.cc:582] [914/1100] Score: -0.675614 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:37.6784 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.6785 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.6789 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.6827 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275659 train-accuracy:0.612469 valid-loss:1.242599 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.7729 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63905\n",
      "[INFO 24-02-22 07:38:37.7730 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.7732 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.639050 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:37.7737 UTC hyperparameters_optimizer.cc:582] [915/1100] Score: -0.63905 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:37.7742 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.7742 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.7767 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.7793 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.191695 train-accuracy:0.612469 valid-loss:1.144931 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.8169 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65897\n",
      "[INFO 24-02-22 07:38:37.8171 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.8173 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.658970 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:37.8176 UTC hyperparameters_optimizer.cc:582] [916/1100] Score: -0.65897 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:37.8181 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.8181 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.8183 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:37.8745 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314163 train-accuracy:0.612469 valid-loss:1.271480 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:37.9984 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666478\n",
      "[INFO 24-02-22 07:38:37.9984 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:37.9986 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.666478 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:37.9988 UTC hyperparameters_optimizer.cc:582] [917/1100] Score: -0.666478 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:37.9992 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:37.9993 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:37.9995 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:38.0048 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278922 train-accuracy:0.612469 valid-loss:1.224352 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:38.0364 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656182\n",
      "[INFO 24-02-22 07:38:38.0374 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:38.0376 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.656182 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:38.0378 UTC hyperparameters_optimizer.cc:582] [918/1100] Score: -0.656182 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:38.0383 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:38.0384 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:38.0387 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:38.0401 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670899\n",
      "[INFO 24-02-22 07:38:38.0401 UTC gradient_boosted_trees.cc:271] Truncates the model to 145 tree(s) i.e. 145  iteration(s).\n",
      "[INFO 24-02-22 07:38:38.0403 UTC gradient_boosted_trees.cc:334] Final model num-trees:145 valid-loss:0.670899 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:38.0417 UTC hyperparameters_optimizer.cc:582] [919/1100] Score: -0.670899 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:38.0424 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:38.0424 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:38.0438 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:38.0465 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.316440 train-accuracy:0.612469 valid-loss:1.276685 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:38.0692 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.186224 train-accuracy:0.612469 valid-loss:1.151012 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:38.1427 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.644569\n",
      "[INFO 24-02-22 07:38:38.1427 UTC gradient_boosted_trees.cc:271] Truncates the model to 258 tree(s) i.e. 258  iteration(s).\n",
      "[INFO 24-02-22 07:38:38.1428 UTC gradient_boosted_trees.cc:334] Final model num-trees:258 valid-loss:0.644569 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:38.1432 UTC hyperparameters_optimizer.cc:582] [920/1100] Score: -0.644569 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:38.1440 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:38.1440 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:38.1442 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:38.1486 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645696\n",
      "[INFO 24-02-22 07:38:38.1486 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 07:38:38.1492 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.645696 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:38.1504 UTC hyperparameters_optimizer.cc:582] [921/1100] Score: -0.645696 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:38.1515 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:38.1515 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:38.1617 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:38.1703 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.149654 train-accuracy:0.764059 valid-loss:1.122386 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:38.1966 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.043024 train-accuracy:0.817848 valid-loss:1.028312 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:38.6286 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649911\n",
      "[INFO 24-02-22 07:38:38.6287 UTC gradient_boosted_trees.cc:271] Truncates the model to 181 tree(s) i.e. 181  iteration(s).\n",
      "[INFO 24-02-22 07:38:38.6289 UTC gradient_boosted_trees.cc:334] Final model num-trees:181 valid-loss:0.649911 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:38.6304 UTC hyperparameters_optimizer.cc:582] [922/1100] Score: -0.649911 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:38.6325 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:38.6326 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:38.6328 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:38.6692 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.144453 train-accuracy:0.612469 valid-loss:1.144683 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:38.6837 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699229\n",
      "[INFO 24-02-22 07:38:38.6838 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 07:38:38.6844 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.699229 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:38:38.6865 UTC hyperparameters_optimizer.cc:582] [923/1100] Score: -0.699229 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }INFO 24-02-22 07:38:38.6866 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:38.6866 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:38.6868 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "\n",
      "[INFO 24-02-22 07:38:38.6926 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315233 train-accuracy:0.612469 valid-loss:1.275026 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:38.6992 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673119\n",
      "[INFO 24-02-22 07:38:38.6992 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:38:38.6993 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.673119 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:38.6996 UTC hyperparameters_optimizer.cc:582] [924/1100] Score: -0.673119 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:38.7002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:38.7004 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:38.7010 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:38.7372 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.166642 train-accuracy:0.612469 valid-loss:1.141964 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:38.8475 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.732892\n",
      "[INFO 24-02-22 07:38:38.8475 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:38.8479 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:38.8479 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.732892 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:38.8482 UTC hyperparameters_optimizer.cc:582] [925/1100] Score: -0.732892 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:38.8495 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:38.8496 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:38.8498 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:38.8584 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281027 train-accuracy:0.612469 valid-loss:1.240385 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:39.3309 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684201\n",
      "[INFO 24-02-22 07:38:39.3309 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:38:39.3314 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.684201 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:39.3326 UTC hyperparameters_optimizer.cc:582] [926/1100] Score: -0.684201 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:39.3336 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.3336 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.3347 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:39.3379 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.080610 train-accuracy:0.858191 valid-loss:1.067709 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:39.4593 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.620467\n",
      "[INFO 24-02-22 07:38:39.4593 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:39.4595 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:39.4595 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.620467 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:39.4598 UTC hyperparameters_optimizer.cc:582] [927/1100] Score: -0.620467 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:39.4603 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.4603 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.4606 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:39.5417 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279752 train-accuracy:0.612469 valid-loss:1.235942 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:39.6736 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680739\n",
      "[INFO 24-02-22 07:38:39.6736 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:38:39.6737 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.680739 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:39.6738 UTC hyperparameters_optimizer.cc:582] [928/1100] Score: -0.680739 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:39.6742 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.6743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.6744 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:39.6781 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647251\n",
      "[INFO 24-02-22 07:38:39.6781 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:38:39.6784 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.647251 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:39.6792 UTC hyperparameters_optimizer.cc:582] [929/1100] Score: -0.647251 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:39.6805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.6805 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.6808 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:39.6827 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313291 train-accuracy:0.612469 valid-loss:1.272116 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:39.6953 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283361 train-accuracy:0.612469 valid-loss:1.241114 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:39.7220 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675614\n",
      "[INFO 24-02-22 07:38:39.7220 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 07:38:39.7222 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.675614 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:39.7226 UTC hyperparameters_optimizer.cc:582] [930/1100] Score: -0.675614 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:39.7289 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.7290 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.7294 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:39.7640 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.075594 train-accuracy:0.821516 valid-loss:1.054257 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:39.7976 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655426\n",
      "[INFO 24-02-22 07:38:39.7998 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 07:38:39.7998 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.655426 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:39.8000 UTC hyperparameters_optimizer.cc:582] [931/1100] Score: -0.655426 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:39.8003 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.8003 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.8006 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:39.8123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312575 train-accuracy:0.612469 valid-loss:1.271427 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:39.8383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652319\n",
      "[INFO 24-02-22 07:38:39.8383 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 07:38:39.8390 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.652319 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:39.8450 UTC hyperparameters_optimizer.cc:582] [932/1100] Score: -0.652319 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:39.8520 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.8521 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.8523 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:39.8682 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.117520 train-accuracy:0.858191 valid-loss:1.072329 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:39.9191 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.647574\n",
      "[INFO 24-02-22 07:38:39.9191 UTC gradient_boosted_trees.cc:271] Truncates the model to 202 tree(s) i.e. 202  iteration(s).\n",
      "[INFO 24-02-22 07:38:39.9193 UTC gradient_boosted_trees.cc:334] Final model num-trees:202 valid-loss:0.647574 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:39.9206 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.9207 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.9208 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:39.9218 UTC hyperparameters_optimizer.cc:582] [933/1100] Score: -0.647574 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:39.9421 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654796\n",
      "[INFO 24-02-22 07:38:39.9421 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 07:38:39.9422 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.654796 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:39.9431 UTC hyperparameters_optimizer.cc:582] [934/1100] Score: -0.654796 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:39.9454 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:39.9454 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:39.9456 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.0083 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.271060 train-accuracy:0.612469 valid-loss:1.238906 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:40.0364 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.165003 train-accuracy:0.612469 valid-loss:1.133795 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:40.0543 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645655\n",
      "[INFO 24-02-22 07:38:40.0543 UTC gradient_boosted_trees.cc:271] Truncates the model to 174 tree(s) i.e. 174  iteration(s).\n",
      "[INFO 24-02-22 07:38:40.0544 UTC gradient_boosted_trees.cc:334] Final model num-trees:174 valid-loss:0.645655 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:40.0600 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.0600 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.0602 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.0617 UTC hyperparameters_optimizer.cc:582] [935/1100] Score: -0.645655 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:40.0678 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060311 train-accuracy:0.878973 valid-loss:1.072887 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:40.1751 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.651588\n",
      "[INFO 24-02-22 07:38:40.1751 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:40.1756 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.651588 valid-accuracy:0.863014\n",
      "[INFO[INFO 24-02-22 07:38:40.1793 UTC hyperparameters_optimizer.cc:582] [936/1100] Score: -0.651588 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      " 24-02-22 07:38:40.1799 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.1799 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.1802 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.3040 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.774872\n",
      "[INFO 24-02-22 07:38:40.3040 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:40.3043 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:40.3043 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.774872 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:40.3046 UTC hyperparameters_optimizer.cc:582] [937/1100] Score: -0.774872 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:40.3087 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.3087 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.3089 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.3169 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.084429 train-accuracy:0.848411 valid-loss:1.084440 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:40.3226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.314704 train-accuracy:0.612469 valid-loss:1.273359 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:40.4005 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.619479\n",
      "[INFO 24-02-22 07:38:40.4015 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:40.4022 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.619479 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:40.4034 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.4035 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.4037 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.4055 UTC hyperparameters_optimizer.cc:582] [938/1100] Score: -0.619479 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:40.4154 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313618 train-accuracy:0.612469 valid-loss:1.273501 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:40.6366 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680811\n",
      "[INFO 24-02-22 07:38:40.6366 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:40.6368 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.680811 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:40.6369 UTC hyperparameters_optimizer.cc:582] [939/1100] Score: -0.680811 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:40.6374 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.6374 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.6376 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.6485 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.054616 train-accuracy:0.821516 valid-loss:1.037007 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:40.7168 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669802\n",
      "[INFO 24-02-22 07:38:40.7170 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:40.7181 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.669802 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:40.7209 UTC hyperparameters_optimizer.cc:582] [940/1100] Score: -0.669802 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:40.7224 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.7226 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.7230 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.7361 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289806 train-accuracy:0.612469 valid-loss:1.244635 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:40.7705 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655947\n",
      "[INFO 24-02-22 07:38:40.7706 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 07:38:40.7709 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.655947 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:40.7716 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.7716 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.7717 UTC hyperparameters_optimizer.cc:582] [941/1100] Score: -0.655947 / -0.588907 HParams: [INFO 24-02-22 07:38:40.7718 UTC gradient_boosted_trees.cc:1261] fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }818\n",
      " examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.7850 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.62117\n",
      "[INFO 24-02-22 07:38:40.7853 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:40.7857 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.621170 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:40.7863 UTC hyperparameters_optimizer.cc:582] [942/1100] Score: -0.62117 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:40.7868 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.7868 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.7870 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.7923 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.172268 train-accuracy:0.612469 valid-loss:1.150993 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:40.7950 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.076663 train-accuracy:0.809291 valid-loss:1.053362 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:40.8817 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.716464\n",
      "[INFO 24-02-22 07:38:40.8817 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:40.8821 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.716464 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:40.8827 UTC hyperparameters_optimizer.cc:582] [943/1100] Score: -0.716464 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:40.8843 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:40.8843 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:40.8846 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:40.8872 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.188570 train-accuracy:0.612469 valid-loss:1.144203 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:41.0402 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682399\n",
      "[INFO 24-02-22 07:38:41.0402 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.0404 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.682399 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:41.0410 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.0410 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.0412 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.0417 UTC hyperparameters_optimizer.cc:582] [944/1100] Score: -0.682399 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:41.1247 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.171938 train-accuracy:0.612469 valid-loss:1.140761 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:41.1654 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675874\n",
      "[INFO 24-02-22 07:38:41.1654 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.1656 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.675874 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:41.1658 UTC hyperparameters_optimizer.cc:582] [945/1100] Score: -0.675874 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:41.1662 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.1662 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.1665 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.1762 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311511 train-accuracy:0.612469 valid-loss:1.272416 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:41.1928 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672434\n",
      "[INFO 24-02-22 07:38:41.1928 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:41.1932 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:41.1933 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.672434 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:41.1937 UTC hyperparameters_optimizer.cc:582] [946/1100] Score: -0.672434 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:41.1947 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.1947 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.1949 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.1997 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239491 train-accuracy:0.612469 valid-loss:1.204898 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:41.3902 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674504\n",
      "[INFO 24-02-22 07:38:41.3902 UTC gradient_boosted_trees.cc:271] Truncates the model to 129 tree(s) i.e. 129  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.3905 UTC gradient_boosted_trees.cc:334] Final model num-trees:129 valid-loss:0.674504 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:41.3921 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.3921 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.3924 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.3951 UTC hyperparameters_optimizer.cc:582] [947/1100] Score: -0.674504 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:41.4179 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.126738 train-accuracy:0.847188 valid-loss:1.103735 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:41.6534 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678173\n",
      "[INFO 24-02-22 07:38:41.6535 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.6536 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.678173 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:41.6540 UTC hyperparameters_optimizer.cc:582] [948/1100] Score: -0.678173 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:41.6558 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.6560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.6563 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.7614 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.202323 train-accuracy:0.612469 valid-loss:1.175224 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:41.7792 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675409\n",
      "[INFO 24-02-22 07:38:41.7792 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.7795 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.675409 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:41.7797 UTC hyperparameters_optimizer.cc:582] [949/1100] Score: -0.675409 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:41.7804 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.7804 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.7820 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.8104 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.110281 train-accuracy:0.833741 valid-loss:1.099847 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:41.8151 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664282\n",
      "[INFO 24-02-22 07:38:41.8151 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.8153 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.664282 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:41.8164 UTC hyperparameters_optimizer.cc:582] [950/1100] Score: -0.664282 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:41.8199 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.8200 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.8203 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.8299 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313039 train-accuracy:0.612469 valid-loss:1.272372 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:41.8619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.61983\n",
      "[INFO 24-02-22 07:38:41.8620 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.8622 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.619830 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:41.8627 UTC hyperparameters_optimizer.cc:582] [951/1100] Score: -0.61983 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:41.8638 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.8638 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.8641 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.8654 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122881 train-accuracy:0.748166 valid-loss:1.044707 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:38:41.8956 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645913\n",
      "[INFO 24-02-22 07:38:41.8958 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.8960 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.645913 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:41.8964 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.8964 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.8966 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.9018 UTC hyperparameters_optimizer.cc:582] [952/1100] Score: -0.645913 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:41.9085 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66104\n",
      "[INFO 24-02-22 07:38:41.9085 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 07:38:41.9086 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.661040 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:41.9097 UTC hyperparameters_optimizer.cc:582] [953/1100] Score: -0.66104 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:41.9102 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:41.9102 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:41.9111 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:41.9504 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.136694 train-accuracy:0.612469 valid-loss:1.144773 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:42.0212 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275702 train-accuracy:0.612469 valid-loss:1.237279 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:42.2009 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665821\n",
      "[INFO 24-02-22 07:38:42.2010 UTC gradient_boosted_trees.cc:271] Truncates the model to 84 tree(s) i.e. 84  iteration(s).\n",
      "[INFO 24-02-22 07:38:42.2010 UTC gradient_boosted_trees.cc:334] Final model num-trees:84 valid-loss:0.665821 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:42.2014 UTC hyperparameters_optimizer.cc:582] [954/1100] Score: -0.665821 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:42.2019 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:42.2019 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:42.2046 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:42.2211 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222180 train-accuracy:0.612469 valid-loss:1.181182 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:42.5957 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.731456\n",
      "[INFO 24-02-22 07:38:42.5957 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:42.5960 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.731456 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:42.5962 UTC hyperparameters_optimizer.cc:582] [955/1100] Score: -0.731456 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:42.5968 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:42.5968 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:42.5972 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:42.5993 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317838 train-accuracy:0.612469 valid-loss:1.276236 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:42.7196 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688795\n",
      "[INFO 24-02-22 07:38:42.7197 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:38:42.7201 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.688795 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:42.7205 UTC hyperparameters_optimizer.cc:582] [956/1100] Score: -0.688795 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:42.7216 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:42.7216 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:42.7218 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:42.7785 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.313771 train-accuracy:0.612469 valid-loss:1.273135 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:42.9966 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670887\n",
      "[INFO 24-02-22 07:38:42.9966 UTC gradient_boosted_trees.cc:271] Truncates the model to 179 tree(s) i.e. 179  iteration(s).\n",
      "[INFO 24-02-22 07:38:42.9968 UTC gradient_boosted_trees.cc:334] Final model num-trees:179 valid-loss:0.670887 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:42.9977 UTC hyperparameters_optimizer.cc:582] [957/1100] Score: -0.670887 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:42.9996 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:42.9996 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:43.0000 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:43.0539 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.156754 train-accuracy:0.753056 valid-loss:1.108821 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:43.2138 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672098\n",
      "[INFO 24-02-22 07:38:43.2139 UTC gradient_boosted_trees.cc:271] Truncates the model to 157 tree(s) i.e. 157  iteration(s).\n",
      "[INFO 24-02-22 07:38:43.2143 UTC gradient_boosted_trees.cc:334] Final model num-trees:157 valid-loss:0.672098 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:43.2165 UTC hyperparameters_optimizer.cc:582] [958/1100] Score: -0.672098 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:43.2179 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:43.2179 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:43.2183 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:43.2204 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.111227 train-accuracy:0.804401 valid-loss:1.063729 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:43.3567 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.710917\n",
      "[INFO 24-02-22 07:38:43.3567 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:43.3570 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:43.3570 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.710917 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:43.3573 UTC hyperparameters_optimizer.cc:582] [959/1100] Score: -0.710917 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:43.3578 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:43.3579 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:43.3583 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:43.3852 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648227\n",
      "[INFO 24-02-22 07:38:43.3852 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:38:43.3855 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.648227 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:43.3858 UTC hyperparameters_optimizer.cc:582] [960/1100] Score: -0.648227 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:43.3868 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:43.3869 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:43.3890 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:43.4005 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655689\n",
      "[INFO 24-02-22 07:38:43.4005 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 07:38:43.4008 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.655689 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:43.4027 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:43.4027 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[[INFO 24-02-22 07:38:43.4031 UTC hyperparameters_optimizer.cc:582] [961/1100] Score: -0.655689 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:38:43.4043 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:43.4255 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320471 train-accuracy:0.612469 valid-loss:1.278860 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:43.4564 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.035356 train-accuracy:0.935208 valid-loss:1.136178 valid-accuracy:0.794521\n",
      "[INFO 24-02-22 07:38:43.4961 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315066 train-accuracy:0.612469 valid-loss:1.272436 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:43.9920 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672749\n",
      "[INFO 24-02-22 07:38:43.9920 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:43.9925 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.672749 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:43.9934 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:43.9934 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:43.9936 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:43.9951 UTC hyperparameters_optimizer.cc:582] [962/1100] Score: -0.672749 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:44.0626 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060558 train-accuracy:0.848411 valid-loss:1.048488 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:44.3074 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.70975\n",
      "[INFO 24-02-22 07:38:44.3074 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:44.3081 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.709750 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:44.3094 UTC hyperparameters_optimizer.cc:582] [963/1100] Score: -0.70975 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:44.3128 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:44.3134 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:44.3136 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:44.3160 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684155\n",
      "[INFO 24-02-22 07:38:44.3160 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 07:38:44.3166 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.684155 valid-accuracy:0.890411\n",
      "[[INFO 24-02-22 07:38:44.3181 UTC hyperparameters_optimizer.cc:582] [964/1100] Score: -0.684155 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:38:44.3190 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:44.3190 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:44.3196 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:44.3282 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.131495 train-accuracy:0.784841 valid-loss:1.085842 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:38:44.3479 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291611 train-accuracy:0.612469 valid-loss:1.250350 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:44.7015 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.701746\n",
      "[INFO 24-02-22 07:38:44.7015 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:44.7017 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.701746 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:44.7020 UTC hyperparameters_optimizer.cc:582] [965/1100] Score: -0.701746 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:44.7055 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:44.7067 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:44.7070 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:44.7806 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.037033 train-accuracy:0.834963 valid-loss:1.062394 valid-accuracy:0.780822\n",
      "[INFO 24-02-22 07:38:45.5982 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654952\n",
      "[INFO 24-02-22 07:38:45.5982 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:45.5984 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.654952 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:45.5986 UTC hyperparameters_optimizer.cc:582] [966/1100] Score: -0.654952 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:45.5990 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:45.5990 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:45.5993 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:45.6316 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060241 train-accuracy:0.845966 valid-loss:1.080136 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:46.4774 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656644\n",
      "[INFO 24-02-22 07:38:46.4774 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:38:46.4778 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.656644 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:46.4784 UTC hyperparameters_optimizer.cc:582] [967/1100] Score: -0.656644 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:46.4800 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:46.4800 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:46.4803 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:46.4829 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230211 train-accuracy:0.612469 valid-loss:1.186879 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:46.5071 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.709873\n",
      "[INFO 24-02-22 07:38:46.5071 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:38:46.5074 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.709873 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:46.5078 UTC hyperparameters_optimizer.cc:582] [968/1100] Score: -0.709873 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:46.5087 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:46.5089 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:46.5094 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:46.5124 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315855 train-accuracy:0.612469 valid-loss:1.275307 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:46.6190 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.638237\n",
      "[INFO 24-02-22 07:38:46.6190 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 07:38:46.6194 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.638237 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:46.6202 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:46.6203 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:46.6205 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:46.6251 UTC hyperparameters_optimizer.cc:582] [969/1100] Score: -0.638237 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:46.6564 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184842 train-accuracy:0.612469 valid-loss:1.146088 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:46.7166 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655662\n",
      "[INFO 24-02-22 07:38:46.7166 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 07:38:46.7169 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.655662 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:46.7175 UTC hyperparameters_optimizer.cc:582] [970/1100] Score: -0.655662 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:46.7187 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:46.7188 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:46.7190 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:46.7291 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289602 train-accuracy:0.612469 valid-loss:1.248817 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:46.8101 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.697681\n",
      "[INFO 24-02-22 07:38:46.8102 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 07:38:46.8103 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.697681 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:46.8108 UTC hyperparameters_optimizer.cc:582] [971/1100] Score: -0.697681 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:46.8114 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:46.8114 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:46.8116 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:46.8139 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.200197 train-accuracy:0.612469 valid-loss:1.160860 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:46.9250 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653431\n",
      "[INFO 24-02-22 07:38:46.9276 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 07:38:46.9278 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.653431 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:46.9280 UTC hyperparameters_optimizer.cc:582] [972/1100] Score: -0.653431 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:46.9294 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:46.9294 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:46.9296 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:46.9435 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.178126 train-accuracy:0.612469 valid-loss:1.155673 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:47.0505 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.737237\n",
      "[INFO 24-02-22 07:38:47.0508 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.0511 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.737237 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:47.0514 UTC hyperparameters_optimizer.cc:582] [973/1100] Score: -0.737237 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:47.0530 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.0530 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.0532 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.0948 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.095297 train-accuracy:0.800734 valid-loss:1.053315 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:47.1441 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66966\n",
      "[INFO 24-02-22 07:38:47.1442 UTC gradient_boosted_trees.cc:271] Truncates the model to 165 tree(s) i.e. 165  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.1444 UTC gradient_boosted_trees.cc:334] Final model num-trees:165 valid-loss:0.669660 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:47.1459 UTC hyperparameters_optimizer.cc:582] [974/1100] Score: -0.66966 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:47.1482 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.1482 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.1484 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.2512 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222426 train-accuracy:0.612469 valid-loss:1.187001 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:47.2772 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639164\n",
      "[INFO 24-02-22 07:38:47.2772 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.2778 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.639164 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:47.2798 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.2798 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.2806 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.2819 UTC hyperparameters_optimizer.cc:582] [975/1100] Score: -0.639164 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:47.3025 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.260374 train-accuracy:0.612469 valid-loss:1.237375 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:47.4429 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.705458\n",
      "[INFO 24-02-22 07:38:47.4429 UTC gradient_boosted_trees.cc:271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.4432 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.705458 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:47.4435 UTC hyperparameters_optimizer.cc:582] [976/1100] Score: -0.705458 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:47.4444 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.4445 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.4448 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.4475 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.162365 train-accuracy:0.612469 valid-loss:1.126620 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:47.5659 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678476\n",
      "[INFO 24-02-22 07:38:47.5665 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.5669 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.678476 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:47.5673 UTC hyperparameters_optimizer.cc:582] [977/1100] Score: -0.678476 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:47.5679 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.642005\n",
      "[INFO 24-02-22 07:38:47.5679 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.5686 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.642005 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:47.5690 UTC hyperparameters_optimizer.cc:582] [978/1100] Score: -0.642005 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:47.5693 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.5693 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.5695 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.5699 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.5699 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.5701 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.5715 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.131620 train-accuracy:0.784841 valid-loss:1.081087 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:47.5733 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.061176 train-accuracy:0.860636 valid-loss:1.021415 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:47.6807 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652402\n",
      "[INFO 24-02-22 07:38:47.6813 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.6815 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.652402 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:47.6826 UTC hyperparameters_optimizer.cc:582] [979/1100] Score: -0.652402 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:47.6843 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.6844 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.6846 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.6881 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238228 train-accuracy:0.612469 valid-loss:1.196202 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:47.6888 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657093\n",
      "[INFO 24-02-22 07:38:47.6888 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.6890 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.657093 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:47.6893 UTC hyperparameters_optimizer.cc:582] [980/1100] Score: -0.657093 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:47.6953 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.6954 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.6956 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.7248 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.062396 train-accuracy:0.823961 valid-loss:1.056296 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:47.7344 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.714268\n",
      "[INFO 24-02-22 07:38:47.7345 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.7352 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.714268 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:47.7356 UTC hyperparameters_optimizer.cc:582] [981/1100] Score: -0.714268 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:47.7367 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.7368 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.7372 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.7410 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.317006 train-accuracy:0.612469 valid-loss:1.274310 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:47.8488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670199\n",
      "[INFO 24-02-22 07:38:47.8489 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 07:38:47.8490 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.670199 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:47.8492 UTC hyperparameters_optimizer.cc:582] [982/1100] Score: -0.670199 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:47.8497 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:47.8498 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:47.8500 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:47.8620 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.134055 train-accuracy:0.799511 valid-loss:1.078171 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:47.9962 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.847992\n",
      "[INFO 24-02-22 07:38:47.9962 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:47.9981 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:47.9981 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.847992 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:48.0006 UTC hyperparameters_optimizer.cc:582] [983/1100] Score: -0.847992 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:48.0045 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.0045 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.0053 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.0105 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.315214 train-accuracy:0.612469 valid-loss:1.275737 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:48.0176 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656468\n",
      "[INFO 24-02-22 07:38:48.0176 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:48.0178 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:48.0178 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.656468 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:48.0180 UTC hyperparameters_optimizer.cc:582] [984/1100] Score: -0.656468 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:48.0185 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.0185 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.0187 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.0430 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.015367 train-accuracy:0.871638 valid-loss:1.019849 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:48.2926 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.705341\n",
      "[INFO 24-02-22 07:38:48.2926 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 24-02-22 07:38:48.2928 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.705341 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:48.2942 UTC hyperparameters_optimizer.cc:582] [985/1100] Score: -0.705341 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:38:48.2949 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.2949 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.2959 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.2968 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321016 train-accuracy:0.612469 valid-loss:1.279095 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:48.3467 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646753\n",
      "[INFO 24-02-22 07:38:48.3474 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:48.3475 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.646753 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:48.3476 UTC hyperparameters_optimizer.cc:582] [986/1100] Score: -0.646753 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:48.3479 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.3479 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.3481 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.3509 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.154462 train-accuracy:0.727384 valid-loss:1.132506 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:38:48.4923 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664376\n",
      "[INFO 24-02-22 07:38:48.4923 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 07:38:48.4925 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.664376 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:48.4932 UTC hyperparameters_optimizer.cc:582] [987/1100] Score: -0.664376 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:48.4940 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.4940 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.4948 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.4979 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285517 train-accuracy:0.612469 valid-loss:1.249196 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:48.5469 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.635896\n",
      "[INFO 24-02-22 07:38:48.5469 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:48.5474 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.635896 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:48.5476 UTC hyperparameters_optimizer.cc:582] [988/1100] Score: -0.635896 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:48.5483 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.5483 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.5485 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.5626 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.038949 train-accuracy:0.847188 valid-loss:1.071694 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:48.6266 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676498\n",
      "[INFO 24-02-22 07:38:48.6285 UTC gradient_boosted_trees.cc:271] Truncates the model to 164 tree(s) i.e. 164  iteration(s).\n",
      "[INFO 24-02-22 07:38:48.6286 UTC gradient_boosted_trees.cc:334] Final model num-trees:164 valid-loss:0.676498 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:48.6290 UTC hyperparameters_optimizer.cc:582] [989/1100] Score: -0.676498 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:48.6295 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.6295 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.6299 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.6329 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.712329 train-accuracy:0.860636 valid-loss:0.684681 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:48.6330 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 07:38:48.6330 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.684681 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:48.6340 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.6341 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.6343 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.6351 UTC hyperparameters_optimizer.cc:582] [990/1100] Score: -0.684681 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:48.6617 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274613 train-accuracy:0.612469 valid-loss:1.238325 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:48.6755 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312544 train-accuracy:0.612469 valid-loss:1.273468 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:48.7431 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667135\n",
      "[INFO 24-02-22 07:38:48.7431 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 07:38:48.7433 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.667135 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:48.7439 UTC hyperparameters_optimizer.cc:582] [991/1100] Score: -0.667135 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:48.7445 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:48.7445 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:48.7449 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:48.7687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146450 train-accuracy:0.765281 valid-loss:1.111212 valid-accuracy:0.767123\n",
      "[INFO 24-02-22 07:38:49.0937 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675098\n",
      "[INFO 24-02-22 07:38:49.0938 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.0938 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.675098 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:49.0941 UTC hyperparameters_optimizer.cc:582] [992/1100] Score: -0.675098 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:49.0967 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.0971 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.0974 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.1075 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295889 train-accuracy:0.612469 valid-loss:1.250529 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:49.1484 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.653251\n",
      "[INFO 24-02-22 07:38:49.1484 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.1486 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.653251 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:49.1489 UTC hyperparameters_optimizer.cc:582] [993/1100] Score: -0.653251 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:49.1496 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.1496 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.1498 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.1514 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682387\n",
      "[INFO 24-02-22 07:38:49.1514 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:49.1518 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:49.1518 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.682387 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:49.1523 UTC hyperparameters_optimizer.cc:582] [994/1100] Score: -0.682387 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:49.1536 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.1536 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.1538 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.1563 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287773 train-accuracy:0.612469 valid-loss:1.250940 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:49.1784 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688526\n",
      "[INFO 24-02-22 07:38:49.1784 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.1787 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.688526 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:49.1793 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.1793 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.1795 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.1851 UTC hyperparameters_optimizer.cc:582] [995/1100] Score: -0.688526 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:49.1887 UTC gradient_boosted_trees.cc:[INFO1636] \tnum-trees:1 train-loss:1.077325 train-accuracy:0.892421 valid-loss:1.089701 valid-accuracy:0.835616\n",
      " 24-02-22 07:38:49.1897 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261760 train-accuracy:0.612469 valid-loss:1.236575 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:49.4289 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.739788\n",
      "[INFO 24-02-22 07:38:49.4289 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.4291 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.739788 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:49.4295 UTC hyperparameters_optimizer.cc:582] [996/1100] Score: -0.739788 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:49.4299 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.4299 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.4302 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.4369 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675595\n",
      "[INFO 24-02-22 07:38:49.4369 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.4371 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.675595 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:49.4375 UTC hyperparameters_optimizer.cc:582] [997/1100] Score: -0.675595 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:49.4384 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.4384 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.4387 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.4674 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.729033\n",
      "[INFO 24-02-22 07:38:49.4675 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:49.4691 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:49.4692 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.729033 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:49.4697 UTC hyperparameters_optimizer.cc:582] [998/1100] Score: -0.729033 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:49.4722 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.4723 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.4727 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.4747 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312290 train-accuracy:0.612469 valid-loss:1.270683 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:49.5058 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.201282 train-accuracy:0.612469 valid-loss:1.177208 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:49.5151 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.276739 train-accuracy:0.612469 valid-loss:1.235475 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:49.5581 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.652733\n",
      "[INFO 24-02-22 07:38:49.5581 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.5582 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.652733 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:49.5584 UTC hyperparameters_optimizer.cc:582] [999/1100] Score: -0.652733 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:49.5588 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.5588 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.5590 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.5710 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.072606 train-accuracy:0.784841 valid-loss:1.035056 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:49.6910 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657125\n",
      "[INFO 24-02-22 07:38:49.6910 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.6914 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.657125 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:49.6922 UTC hyperparameters_optimizer.cc:582] [1000/1100] Score: -0.657125 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:49.6956 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.6956 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.6959 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.7042 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114436 train-accuracy:0.784841 valid-loss:1.073793 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:49.7634 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.70865\n",
      "[INFO 24-02-22 07:38:49.7634 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.7648 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.708650 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:49.7731 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.7731 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.7733 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.7734 UTC hyperparameters_optimizer.cc:582] [1001/1100] Score: -0.70865 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:49.8286 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681844\n",
      "[INFO 24-02-22 07:38:49.8287 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.8297 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.681844 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:49.8317 UTC hyperparameters_optimizer.cc:582] [1002/1100] Score: -0.681844 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:49.8348 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.8348 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.8350 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:49.8531 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.114103 train-accuracy:0.787286 valid-loss:1.102217 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:49.8732 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310598 train-accuracy:0.612469 valid-loss:1.273347 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:49.9857 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.593484\n",
      "[INFO 24-02-22 07:38:49.9858 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:38:49.9860 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.593484 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:49.9863 UTC hyperparameters_optimizer.cc:582] [1003/1100] Score: -0.593484 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:49.9871 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:49.9872 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:49.9875 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:50.0002 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243514 train-accuracy:0.612469 valid-loss:1.204429 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:50.1585 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669422\n",
      "[INFO 24-02-22 07:38:50.1585 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:50.1587 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.669422 valid-accuracy:0.904110\n",
      "[[INFO 24-02-22 07:38:50.1593 UTC hyperparameters_optimizer.cc:582] [1004/1100] Score: -0.669422 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:38:50.1594 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:50.1594 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:50.1598 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:50.1640 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.062869 train-accuracy:0.869193 valid-loss:1.031590 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:50.3182 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67419\n",
      "[INFO 24-02-22 07:38:50.3182 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:50.3187 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:50.3187 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.674190 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:50.3195 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:50.3196 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:50.3198 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:50.3220 UTC hyperparameters_optimizer.cc:582] [1005/1100] Score: -0.67419 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:50.3337 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.032440 train-accuracy:0.864303 valid-loss:0.973397 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:50.5722 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68463\n",
      "[INFO 24-02-22 07:38:50.5723 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:50.5727 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.684630 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:50.5731 UTC hyperparameters_optimizer.cc:582] [1006/1100] Score: -0.68463 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:50.5743 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:50.5743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:50.5745 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:50.6036 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.110281 train-accuracy:0.833741 valid-loss:1.099847 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:50.7649 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681202\n",
      "[INFO 24-02-22 07:38:50.7649 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:50.7654 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:50.7655 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.681202 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:50.7660 UTC hyperparameters_optimizer.cc:582] [1007/1100] Score: -0.681202 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:50.7666 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:50.7668 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:50.7674 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:50.7863 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.040139 train-accuracy:0.834963 valid-loss:1.007116 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:50.8298 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.698015\n",
      "[INFO 24-02-22 07:38:50.8299 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 07:38:50.8299 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.698015 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:50.8302 UTC hyperparameters_optimizer.cc:582] [1008/1100] Score: -0.698015 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:50.8308 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:50.8308 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:50.8311 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:50.8413 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.715637\n",
      "[INFO 24-02-22 07:38:50.8413 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 07:38:50.8417 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.715637 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:50.8427 UTC hyperparameters_optimizer.cc:582] [1009/1100] Score: -0.715637 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:50.8447 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.007656 train-accuracy:0.855746 valid-loss:1.029944 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:50.8464 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:50.8464 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:50.8466 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:50.8494 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.140505 train-accuracy:0.810513 valid-loss:1.094803 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:51.0303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666134\n",
      "[INFO 24-02-22 07:38:51.0304 UTC gradient_boosted_trees.cc:271] Truncates the model to 195 tree(s) i.e. 195  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.0304 UTC gradient_boosted_trees.cc:334] Final model num-trees:195 valid-loss:0.666134 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:51.0310 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.0312 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.0315 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.0317 UTC hyperparameters_optimizer.cc:582] [1010/1100] Score: -0.666134 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:51.0350 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.079050 train-accuracy:0.855746 valid-loss:1.056688 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:51.0377 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670078\n",
      "[INFO 24-02-22 07:38:51.0377 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.0379 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.670078 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:51.0385 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.0385 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.0387 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.0402 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266932 train-accuracy:0.612469 valid-loss:1.222473 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:51.0417 UTC hyperparameters_optimizer.cc:582] [1011/1100] Score: -0.670078 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:51.1850 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.726057\n",
      "[INFO 24-02-22 07:38:51.1850 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.1854 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.726057 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:51.1857 UTC hyperparameters_optimizer.cc:582] [1012/1100] Score: -0.726057 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:51.1864 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.1864 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.1866 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.2279 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.645451\n",
      "[INFO 24-02-22 07:38:51.2279 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.2280 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.645451 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:51.2283 UTC hyperparameters_optimizer.cc:582] [1013/1100] Score: -0.645451 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:51.2296 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.2296 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.2299 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.2534 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.066602 train-accuracy:0.826406 valid-loss:1.061642 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:51.3413 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.258015 train-accuracy:0.612469 valid-loss:1.238814 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:51.4440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655846\n",
      "[INFO 24-02-22 07:38:51.4441 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:51.4444 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:51.4444 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.655846 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:51.4447 UTC hyperparameters_optimizer.cc:582] [1014/1100] Score: -0.655846 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:51.4458 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.4459 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.4462 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.4549 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.184615 train-accuracy:0.612469 valid-loss:1.130277 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:51.4936 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.679012 train-accuracy:0.854523 valid-loss:0.682122 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:51.4936 UTC gradient_boosted_trees.cc:271] Truncates the model to 278 tree(s) i.e. 278  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.4936 UTC gradient_boosted_trees.cc:334] Final model num-trees:278 valid-loss:0.681197 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:51.4941 UTC hyperparameters_optimizer.cc:582] [1015/1100] Score: -0.681197 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:51.4943 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.4943 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.4950 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.5035 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.318932 train-accuracy:0.612469 valid-loss:1.275604 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:51.5996 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.764985\n",
      "[INFO 24-02-22 07:38:51.5997 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.6001 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.732777\n",
      "[INFO 24-02-22 07:38:51.6002 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[WARNING 24-02-22 07:38:51.6003 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:51.6003 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.764985 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:51.6009 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.732777 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:51.6013 UTC hyperparameters_optimizer.cc:582] [1016/1100] Score: -0.764985 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:51.6018 UTC hyperparameters_optimizer.cc:582] [1017/1100] Score: -0.732777 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:51.6033 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.6034 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.6037 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.6043 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.6043 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.6048 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.6058 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321016 train-accuracy:0.612469 valid-loss:1.279095 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:51.6119 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.043402 train-accuracy:0.838631 valid-loss:1.039330 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:51.7647 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685987\n",
      "[INFO 24-02-22 07:38:51.7650 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.7654 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.685987 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:51.7662 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.7662 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.7665 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.7688 UTC hyperparameters_optimizer.cc:582] [1018/1100] Score: -0.685987 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:51.7711 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155227 train-accuracy:0.798289 valid-loss:1.082367 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:51.9208 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.698368\n",
      "[INFO 24-02-22 07:38:51.9237 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.9238 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.698368 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:51.9239 UTC hyperparameters_optimizer.cc:582] [1019/1100] Score: -0.698368 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:51.9260 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.9289 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.9291 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.9302 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665827\n",
      "[INFO 24-02-22 07:38:51.9302 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:51.9305 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.665827 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:51.9307 UTC hyperparameters_optimizer.cc:582] [1020/1100] Score: -0.665827 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:51.9314 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:51.9314 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:51.9316 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:51.9351 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.155557 train-accuracy:0.755501 valid-loss:1.099641 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:52.0054 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624941\n",
      "[INFO 24-02-22 07:38:52.0054 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:38:52.0056 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.624941 valid-accuracy:0.917808\n",
      "[INFO[ 24-02-22 07:38:52.0060 UTC hyperparameters_optimizer.cc:582] [1021/1100] Score: INFO-0.624941 / -0.588907 HParams:  24-02-22 07:38:52.0060 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.017338 train-accuracy:0.880196 valid-loss:1.078801 valid-accuracy:0.794521\n",
      "fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:52.0132 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:52.0132 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:52.0134 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:52.0301 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081033 train-accuracy:0.847188 valid-loss:1.071687 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:52.0412 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.704167 train-accuracy:0.864303 valid-loss:0.666272 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:52.0414 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 07:38:52.0417 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.666254 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:52.0423 UTC hyperparameters_optimizer.cc:582] [1022/1100] Score: -0.666254 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:52.0433 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:52.0435 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:52.0440 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:52.0470 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.127783 train-accuracy:0.793399 valid-loss:1.072010 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:52.2080 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65544\n",
      "[INFO 24-02-22 07:38:52.2101 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:38:52.2101 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.655440 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:52.2105 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:52.2105 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:52.2107 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:52.2124 UTC hyperparameters_optimizer.cc:582] [1023/1100] Score: -0.65544 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:52.2367 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234838 train-accuracy:0.612469 valid-loss:1.197245 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:52.2543 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.654921\n",
      "[INFO 24-02-22 07:38:52.2543 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:52.2544 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.654921 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:52.2548 UTC hyperparameters_optimizer.cc:582] [1024/1100] Score: -0.654921 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:52.2553 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:52.2553 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:52.2555 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:52.2655 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282926 train-accuracy:0.612469 valid-loss:1.243398 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:52.4569 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.723309\n",
      "[INFO 24-02-22 07:38:52.4570 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:52.4572 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.723309 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:52.4574 UTC hyperparameters_optimizer.cc:582] [1025/1100] Score: -0.723309 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:52.4578 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:52.4578 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:52.4583 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:52.4616 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.172089 train-accuracy:0.612469 valid-loss:1.136396 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:52.4972 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689993\n",
      "[INFO 24-02-22 07:38:52.4972 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:52.4974 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:52.4974 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.689993 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:52.4977 UTC hyperparameters_optimizer.cc:582] [1026/1100] Score: -0.689993 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:52.4991 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:52.4991 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:52.4994 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:52.5101 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.312325 train-accuracy:0.612469 valid-loss:1.271549 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:52.6727 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641392\n",
      "[INFO 24-02-22 07:38:52.6727 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:52.6731 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.641392 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:52.6736 UTC hyperparameters_optimizer.cc:582] [1027/1100] Score: -0.641392 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:52.6753 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:52.6754 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:52.6758 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:52.7050 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.221964 train-accuracy:0.612469 valid-loss:1.190724 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:53.2024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.704067\n",
      "[INFO 24-02-22 07:38:53.2024 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 07:38:53.2029 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.704067 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:53.2039 UTC hyperparameters_optimizer.cc:582] [1028/1100] Score: -0.704067 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:53.2060 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:53.2062 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:53.2065 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:53.3064 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.157202 train-accuracy:0.612469 valid-loss:1.111335 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:53.4926 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637933\n",
      "[INFO 24-02-22 07:38:53.4927 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 07:38:53.4931 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.637933 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:53.4941 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:53.4942 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:53.4944 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:53.4985 UTC hyperparameters_optimizer.cc:582] [1029/1100] Score: -0.637933 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:53.5016 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672026\n",
      "[INFO 24-02-22 07:38:53.5017 UTC gradient_boosted_trees.cc:271] Truncates the model to 208 tree(s) i.e. 208  iteration(s).\n",
      "[INFO 24-02-22 07:38:53.5017 UTC gradient_boosted_trees.cc:334] Final model num-trees:208 valid-loss:0.672026 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:53.5020 UTC hyperparameters_optimizer.cc:582] [1030/1100] Score: -0.672026 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:53.5024 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:53.5024 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:53.5029 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:53.5043 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.190048 train-accuracy:0.612469 valid-loss:1.132671 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:53.5086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669801\n",
      "[INFO 24-02-22 07:38:53.5086 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:38:53.5096 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.669801 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:53.5115 UTC hyperparameters_optimizer.cc:582] [1031/1100] Score: -0.669801 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:53.5162 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:53.5162 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:53.5165 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:53.5204 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.070587 train-accuracy:0.797066 valid-loss:1.057583 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:53.5424 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.65076\n",
      "[INFO 24-02-22 07:38:53.5425 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 07:38:53.5429 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.650760 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:53.5445 UTC hyperparameters_optimizer.cc:582] [1032/1100] Score: -0.65076 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:53.5464 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:53.5465 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:53.5469 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:53.5557 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.160585 train-accuracy:0.800734 valid-loss:1.117603 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:53.5698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224726 train-accuracy:0.612469 valid-loss:1.174721 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:53.6400 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670057\n",
      "[INFO 24-02-22 07:38:53.6433 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 07:38:53.6436 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.670057 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:53.6449 UTC hyperparameters_optimizer.cc:582] [1033/1100] Score: -0.670057 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:53.6455 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:53.6455 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:53.6468 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:53.6621 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223214 train-accuracy:0.612469 valid-loss:1.165339 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:53.7811 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.737745\n",
      "[INFO 24-02-22 07:38:53.7811 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:53.7813 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:53.7814 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.737745 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:53.7822 UTC hyperparameters_optimizer.cc:582] [1034/1100] Score: -0.737745 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:53.7834 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:53.7834 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:53.7837 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:53.8311 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.722938\n",
      "[INFO 24-02-22 07:38:53.8312 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 07:38:53.8313 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.722938 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:53.8314 UTC hyperparameters_optimizer.cc:582] [1035/1100] Score: -0.722938 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:53.8337 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:53.8352 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:53.8355 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:53.8877 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.004314 train-accuracy:0.892421 valid-loss:1.015815 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:53.9164 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281033 train-accuracy:0.612469 valid-loss:1.244665 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:54.1903 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655689\n",
      "[INFO 24-02-22 07:38:54.1903 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.1903 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.655689 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:54.1907 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.1907 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.1909 UTC hyperparameters_optimizer.cc:582] [1036/1100] Score: -0.655689 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:54.1912 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:54.2364 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.048702 train-accuracy:0.859413 valid-loss:1.079296 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:54.2697 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703669\n",
      "[INFO 24-02-22 07:38:54.2698 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.2699 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.703669 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:54.2702 UTC hyperparameters_optimizer.cc:582] [1037/1100] Score: -0.703669 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:54.2710 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.2713 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.2717 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:54.3233 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.174396 train-accuracy:0.612469 valid-loss:1.130360 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:54.3560 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667904\n",
      "[INFO 24-02-22 07:38:54.3561 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.3562 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.667904 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:54.3573 UTC hyperparameters_optimizer.cc:582] [1038/1100] Score: [INFO-0.667904 / -0.588907 HParams:  24-02-22 07:38:54.3573 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.3574 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:54.3583 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:54.3702 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.138819 train-accuracy:0.748166 valid-loss:1.105560 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:38:54.4777 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.641373\n",
      "[INFO 24-02-22 07:38:54.4780 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.4784 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.641373 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:54.4804 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.664976\n",
      "[INFO 24-02-22 07:38:54.4804 UTC gradient_boosted_trees.cc:271] Truncates the model to 152 tree(s) i.e. 152  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.4806 UTC gradient_boosted_trees.cc:334] Final model num-trees:152 valid-loss:0.664976 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:54.4810 UTC hyperparameters_optimizer.cc:582] [1039/1100] Score: -0.641373 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:54.4814 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.4814 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.4817 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO[INFO 24-02-22 07:38:54.4834 UTC hyperparameters_optimizer.cc:582] [1040/1100] Score: -0.664976 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      " 24-02-22 07:38:54.4865 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.4917 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.4947 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:54.5172 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.062286 train-accuracy:0.875306 valid-loss:1.064506 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:54.5195 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.267132 train-accuracy:0.612469 valid-loss:1.238450 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:54.5707 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.662511\n",
      "[INFO 24-02-22 07:38:54.5707 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.5711 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.662511 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:54.5748 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.5750 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.5754 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:54.5792 UTC hyperparameters_optimizer.cc:582] [1041/1100] Score: -0.662511 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:54.6383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.659051\n",
      "[INFO 24-02-22 07:38:54.6384 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.6390 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.659051 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:54.6402 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.6402 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.6404 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:54.6451 UTC hyperparameters_optimizer.cc:582] [1042/1100] Score: -0.659051 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:54.6501 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.180965 train-accuracy:0.612469 valid-loss:1.136062 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:54.6708 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.311476 train-accuracy:0.612469 valid-loss:1.274882 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:54.8804 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.636938\n",
      "[INFO 24-02-22 07:38:54.8805 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.8807 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.636938 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:54.8809 UTC hyperparameters_optimizer.cc:582] [1043/1100] Score: -0.636938 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:54.8814 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.8814 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.8816 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:54.9098 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280179 train-accuracy:0.612469 valid-loss:1.246158 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:54.9506 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.624838\n",
      "[INFO 24-02-22 07:38:54.9506 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.9506 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.624838 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:54.9510 UTC hyperparameters_optimizer.cc:582] [1044/1100] Score: -0.624838 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:54.9516 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.9517 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.9519 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:54.9820 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.111374 train-accuracy:0.841076 valid-loss:1.099107 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:54.9886 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683222\n",
      "[INFO 24-02-22 07:38:54.9887 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:54.9891 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.683222 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:38:54.9899 UTC hyperparameters_optimizer.cc:582] [1045/1100] Score: -0.683222 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "INFO 24-02-22 07:38:54.9900 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:54.9903 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:54.9908 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:55.0396 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.176968 train-accuracy:0.612469 valid-loss:1.154137 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:55.7672 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.663144\n",
      "[INFO 24-02-22 07:38:55.7673 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 07:38:55.7677 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.663144 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:55.7683 UTC hyperparameters_optimizer.cc:582] [1046/1100] Score: -0.663144 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:55.7696 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:55.7697 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:55.7700 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:55.7736 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.249016 train-accuracy:0.612469 valid-loss:1.203290 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:56.0178 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669932\n",
      "[INFO 24-02-22 07:38:56.0178 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 07:38:56.0179 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.669932 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:56.0185 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:56.0185 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:56.0187 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:56.0188 UTC hyperparameters_optimizer.cc:582] [1047/1100] Score: -0.669932 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:56.0264 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224133 train-accuracy:0.612469 valid-loss:1.185951 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:56.0923 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.59651\n",
      "[INFO 24-02-22 07:38:56.0923 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 07:38:56.0928 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.596510 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:56.0944 UTC hyperparameters_optimizer.cc:582] [1048/1100] Score: -0.59651 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:56.0972 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:56.0992 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:56.0995 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:56.1091 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.146048 train-accuracy:0.776284 valid-loss:1.104747 valid-accuracy:0.753425\n",
      "[INFO 24-02-22 07:38:56.2351 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.748912\n",
      "[INFO 24-02-22 07:38:56.2383 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:56.2387 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:56.2387 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.748912 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:56.2390 UTC hyperparameters_optimizer.cc:582] [1049/1100] Score: -0.748912 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:56.2412 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:56.2413 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:56.2415 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:56.2553 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.107130 train-accuracy:0.803178 valid-loss:1.069997 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:56.3677 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699393\n",
      "[INFO 24-02-22 07:38:56.3677 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:56.3681 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.699393 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:56.3687 UTC hyperparameters_optimizer.cc:582] [1050/1100] Score: -0.699393 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:56.3694 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:56.3712 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:56.3719 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:56.4035 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.060779 train-accuracy:0.882641 valid-loss:1.055075 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:56.5706 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.649336\n",
      "[INFO 24-02-22 07:38:56.5707 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:38:56.5709 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.649336 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:56.5714 UTC hyperparameters_optimizer.cc:582] [1051/1100] Score: -0.649336 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:56.5726 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:56.5726 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:56.5729 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:56.6182 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.278135 train-accuracy:0.612469 valid-loss:1.245547 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:56.6401 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.646208\n",
      "[INFO 24-02-22 07:38:56.6401 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 07:38:56.6415 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.646208 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:56.6420 UTC hyperparameters_optimizer.cc:582] [1052/1100] Score: -0.646208 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:56.6431 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:56.6431 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:56.6433 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:56.6587 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.034637 train-accuracy:0.858191 valid-loss:1.038089 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:38:56.6831 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.669448\n",
      "[INFO 24-02-22 07:38:56.6831 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 07:38:56.6834 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.669448 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:56.6837 UTC hyperparameters_optimizer.cc:582] [1053/1100] Score: -0.669448 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:56.6843 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:56.6843 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:56.6847 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:56.8377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310474 train-accuracy:0.612469 valid-loss:1.271936 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:56.9403 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.656379\n",
      "[INFO 24-02-22 07:38:56.9404 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 07:38:56.9408 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.656379 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:56.9418 UTC hyperparameters_optimizer.cc:582] [1054/1100] Score: -0.656379 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:56.9432 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:56.9434 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:56.9436 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:56.9750 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.213350 train-accuracy:0.612469 valid-loss:1.180617 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:57.0769 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.63025\n",
      "[INFO 24-02-22 07:38:57.0769 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:57.0772 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:57.0772 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.630250 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:57.0779 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:57.0780 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:57.0782 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:57.0786 UTC hyperparameters_optimizer.cc:582] [1055/1100] Score: -0.63025 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:57.1611 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283895 train-accuracy:0.612469 valid-loss:1.242045 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:57.2527 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.740681\n",
      "[INFO 24-02-22 07:38:57.2528 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:57.2531 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:57.2531 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.740681 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:57.2533 UTC hyperparameters_optimizer.cc:582] [1056/1100] Score: -0.740681 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:57.2540 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:57.2541 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:57.2544 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:57.3040 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.171520 train-accuracy:0.612469 valid-loss:1.152787 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:57.3074 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67467\n",
      "[INFO 24-02-22 07:38:57.3074 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 07:38:57.3075 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.674670 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:57.3082 UTC hyperparameters_optimizer.cc:582] [1057/1100] Score: -0.67467 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:57.3092 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:57.3095 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:57.3100 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:57.3446 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222145 train-accuracy:0.612469 valid-loss:1.183311 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:57.4076 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703108\n",
      "[INFO 24-02-22 07:38:57.4078 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 07:38:57.4088 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.703108 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:57.4104 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:57.4104 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:57.4106 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:57.4151 UTC hyperparameters_optimizer.cc:582] [1058/1100] Score: -0.703108 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:57.4163 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153367 train-accuracy:0.770171 valid-loss:1.110353 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:57.6302 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684304\n",
      "[INFO 24-02-22 07:38:57.6326 UTC gradient_boosted_trees.cc:271] Truncates the model to 13 tree(s) i.e. 13  iteration(s).\n",
      "[INFO 24-02-22 07:38:57.6328 UTC gradient_boosted_trees.cc:334] Final model num-trees:13 valid-loss:0.684304 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:57.6329 UTC hyperparameters_optimizer.cc:582] [1059/1100] Score: -0.684304 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:57.6357 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:57.6370 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:57.6373 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:57.6476 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.274696 train-accuracy:0.612469 valid-loss:1.238325 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:57.7293 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.625177\n",
      "[INFO 24-02-22 07:38:57.7293 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:38:57.7295 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.625177 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:57.7300 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:57.7301 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:57.7303 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:57.7335 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.182483 train-accuracy:0.612469 valid-loss:1.135658 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:57.7351 UTC hyperparameters_optimizer.cc:582] [1060/1100] Score: -0.625177 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:57.8282 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.708814\n",
      "[INFO 24-02-22 07:38:57.8296 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:57.8299 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.708814 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:57.8302 UTC hyperparameters_optimizer.cc:582] [1061/1100] Score: -0.708814 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:57.8308 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:57.8308 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:57.8310 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:57.8646 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226358 train-accuracy:0.612469 valid-loss:1.192881 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:57.9362 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674815\n",
      "[INFO 24-02-22 07:38:57.9362 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 07:38:57.9364 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.674815 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:57.9369 UTC hyperparameters_optimizer.cc:582] [1062/1100] Score: -0.674815 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:57.9375 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:57.9375 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:57.9379 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:57.9653 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226046 train-accuracy:0.612469 valid-loss:1.185639 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:58.1764 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683008\n",
      "[INFO 24-02-22 07:38:58.1764 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 07:38:58.1769 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.683008 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:58.1782 UTC hyperparameters_optimizer.cc:582] [1063/1100] Score: -0.683008 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:58.1792 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:58.1792 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:58.1804 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:58.2100 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225474 train-accuracy:0.612469 valid-loss:1.206833 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:58.4232 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.66484\n",
      "[INFO 24-02-22 07:38:58.4233 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 07:38:58.4236 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.664840 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:58.4243 UTC hyperparameters_optimizer.cc:582] [1064/1100] Score: -0.66484 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:58.4269 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:58.4269 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:58.4271 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:58.4351 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.158781 train-accuracy:0.777506 valid-loss:1.090465 valid-accuracy:0.808219\n",
      "[INFO 24-02-22 07:38:58.4736 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677269\n",
      "[INFO 24-02-22 07:38:58.4736 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 07:38:58.4740 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.677269 valid-accuracy:0.917808\n",
      "[INFO 24-02-22 07:38:58.4745 UTC hyperparameters_optimizer.cc:582] [1065/1100] Score: -0.677269 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:38:58.4755 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:58.4755 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:58.4759 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:58.4862 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.124682 train-accuracy:0.823961 valid-loss:1.064969 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:58.9413 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.634753\n",
      "[INFO 24-02-22 07:38:58.9414 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:38:58.9418 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.634753 valid-accuracy:0.876712\n",
      "[[INFO 24-02-22 07:38:58.9430 UTC hyperparameters_optimizer.cc:582] [1066/1100] Score: -0.634753 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "INFO 24-02-22 07:38:58.9432 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:58.9433 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:58.9437 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:58.9525 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.125996 train-accuracy:0.783619 valid-loss:1.109565 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:58.9828 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.657891\n",
      "[INFO 24-02-22 07:38:58.9828 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:58.9829 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.657891 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:58.9832 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:58.9832 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:58.9835 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:58.9851 UTC hyperparameters_optimizer.cc:582] [1067/1100] Score: -0.657891 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:59.0055 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222315 train-accuracy:0.612469 valid-loss:1.192031 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:59.0497 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672844\n",
      "[INFO 24-02-22 07:38:59.0497 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.0497 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.672844 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:59.0499 UTC hyperparameters_optimizer.cc:582] [1068/1100] Score: -0.672844 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:59.0519 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.0519 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.0521 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.1917 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.275562 train-accuracy:0.612469 valid-loss:1.239242 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:59.2096 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718681\n",
      "[INFO 24-02-22 07:38:59.2096 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.2098 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.718681 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:59.2102 UTC hyperparameters_optimizer.cc:582] [1069/1100] Score: -0.718681 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:59.2112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.2112 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.2115 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.2399 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.081844 train-accuracy:0.827628 valid-loss:1.079611 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:38:59.2546 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.6677\n",
      "[INFO 24-02-22 07:38:59.2546 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.2549 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.667700 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:59.2554 UTC hyperparameters_optimizer.cc:582] [1070/1100] Score: -0.6677 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:59.2560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.2560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.2566 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.2582 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682843\n",
      "[INFO 24-02-22 07:38:59.2582 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.2585 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.682843 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:59.2600 UTC hyperparameters_optimizer.cc:582] [1071/1100] Score: -0.682843 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:59.2614 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.2614 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.2617 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.2644 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225788 train-accuracy:0.612469 valid-loss:1.189141 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:59.2964 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.086735 train-accuracy:0.781174 valid-loss:1.061830 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:59.3250 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.670296\n",
      "[INFO 24-02-22 07:38:59.3251 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.3254 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.670296 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:38:59.3259 UTC hyperparameters_optimizer.cc:582] [1072/1100] Score: -0.670296 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:59.3267 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.712932\n",
      "[INFO 24-02-22 07:38:59.3267 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.3269 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.712932 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:59.3275 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.3275 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.3277 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.3317 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.3318 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.3324 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.3351 UTC hyperparameters_optimizer.cc:582] [1073/1100] Score: -0.712932 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:59.3466 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.175930 train-accuracy:0.612469 valid-loss:1.154964 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:59.4282 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.639886\n",
      "[INFO 24-02-22 07:38:59.4282 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.4285 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.639886 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:59.4288 UTC hyperparameters_optimizer.cc:582] [1074/1100] Score: -0.639886 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:38:59.4294 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.4294 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.4298 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.4579 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.034752 train-accuracy:0.852078 valid-loss:1.041145 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:38:59.4757 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238619 train-accuracy:0.612469 valid-loss:1.200663 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:59.4930 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689041\n",
      "[INFO 24-02-22 07:38:59.4930 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.4933 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.689041 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:59.4937 UTC hyperparameters_optimizer.cc:582] [1075/1100] Score: -0.689041 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:59.4943 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.4943 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.4948 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.4988 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228493 train-accuracy:0.612469 valid-loss:1.201310 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:59.7807 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.737327\n",
      "[INFO 24-02-22 07:38:59.7807 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:38:59.7810 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:38:59.7811 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.737327 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:59.7813 UTC hyperparameters_optimizer.cc:582] [1076/1100] Score: -0.737327 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.15 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:59.7822 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.7822 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.7828 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.7965 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.047344 train-accuracy:0.845966 valid-loss:1.022415 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:59.7995 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680556\n",
      "[INFO 24-02-22 07:38:59.7996 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.7999 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.680556 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:38:59.8004 UTC hyperparameters_optimizer.cc:582] [1077/1100] Score: -0.680556 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1 } }\n",
      "[INFO 24-02-22 07:38:59.8018 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.8018 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.8021 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.8285 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295170 train-accuracy:0.612469 valid-loss:1.255082 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:59.8968 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.720794\n",
      "[INFO 24-02-22 07:38:59.8969 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.8976 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.720794 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:38:59.8993 UTC hyperparameters_optimizer.cc:582] [1078/1100] Score: -0.720794 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:38:59.9022 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.9023 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.9026 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.9621 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.273138 train-accuracy:0.612469 valid-loss:1.243136 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:38:59.9823 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688151\n",
      "[INFO 24-02-22 07:38:59.9823 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 07:38:59.9826 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.688151 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:38:59.9844 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:38:59.9844 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:38:59.9847 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:38:59.9853 UTC hyperparameters_optimizer.cc:582] [1079/1100] Score: -0.688151 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:39:00.0201 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668341\n",
      "[INFO 24-02-22 07:39:00.0264 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 07:39:00.0278 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.668341 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:00.0288 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:39:00.0288 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:39:00.0290 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:39:00.0360 UTC hyperparameters_optimizer.cc:582] [1080/1100] Score: -0.668341 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:39:00.0718 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.310373 train-accuracy:0.612469 valid-loss:1.271984 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:39:00.0862 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.000061 train-accuracy:0.875306 valid-loss:1.011661 valid-accuracy:0.835616\n",
      "[INFO 24-02-22 07:39:00.2643 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672599\n",
      "[INFO 24-02-22 07:39:00.2667 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 07:39:00.2673 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.672599 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:00.2677 UTC hyperparameters_optimizer.cc:582] [1081/1100] Score: -0.672599 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:39:00.2682 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:39:00.2682 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:39:00.2686 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:39:00.2766 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.153167 train-accuracy:0.748166 valid-loss:1.129275 valid-accuracy:0.739726\n",
      "[INFO 24-02-22 07:39:00.3784 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.72251\n",
      "[INFO 24-02-22 07:39:00.3795 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 07:39:00.3797 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.722510 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:39:00.3801 UTC hyperparameters_optimizer.cc:582] [1082/1100] Score: -0.72251 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.2 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } }\n",
      "[INFO 24-02-22 07:39:00.3822 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:39:00.3822 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:39:00.3824 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:39:00.4326 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683026\n",
      "[INFO 24-02-22 07:39:00.4326 UTC gradient_boosted_trees.cc:271] Truncates the model to 129 tree(s) i.e. 129  iteration(s).\n",
      "[INFO 24-02-22 07:39:00.4331 UTC gradient_boosted_trees.cc:334] Final model num-trees:129 valid-loss:0.683026 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:39:00.4354 UTC hyperparameters_optimizer.cc:582] [1083/1100] Score: -0.683026 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:39:00.4408 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:39:00.4408 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:39:00.4411 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:39:00.4474 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242328 train-accuracy:0.612469 valid-loss:1.199228 valid-accuracy:0.657534\n",
      "[INFO 24-02-22 07:39:00.4514 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.050811 train-accuracy:0.838631 valid-loss:1.026199 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:39:00.4728 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.72143\n",
      "[INFO 24-02-22 07:39:00.4729 UTC gradient_boosted_trees.cc:271] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "[INFO 24-02-22 07:39:00.4731 UTC gradient_boosted_trees.cc:334] Final model num-trees:12 valid-loss:0.721430 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:00.4736 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 07:39:00.4736 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 891 example(s) and 10 feature(s).\n",
      "[INFO 24-02-22 07:39:00.4739 UTC gradient_boosted_trees.cc:1261] 818 examples used for training and 73 examples used for validation\n",
      "[INFO 24-02-22 07:39:00.4751 UTC hyperparameters_optimizer.cc:582] [1084/1100] Score: -0.72143 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:39:00.4814 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.122570 train-accuracy:0.784841 valid-loss:1.069284 valid-accuracy:0.821918\n",
      "[INFO 24-02-22 07:39:00.7417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.789001\n",
      "[INFO 24-02-22 07:39:00.7417 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 07:39:00.7420 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.789001 valid-accuracy:0.849315\n",
      "[INFO 24-02-22 07:39:00.7424 UTC hyperparameters_optimizer.cc:582] [1085/1100] Score: -0.789001 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:39:00.8256 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.655546\n",
      "[INFO 24-02-22 07:39:00.8258 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:39:00.8265 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO[INFO 24-02-22 07:39:00.8266 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss:  24-02-22 07:39:00.8266 UTC gradient_boosted_trees.cc0.674351\n",
      "[INFO: 24-02-22 07:39:00.8266 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.655546 valid-accuracy:0.890411271] Truncates the model to 14 tree(s) i.e. 14  iteration(s).\n",
      "[INFO 24-02-22 07:39:00.8277 UTC gradient_boosted_trees.cc:334] Final model num-trees:14 valid-loss:0.674351 valid-accuracy:0.904110\n",
      "\n",
      "[INFO 24-02-22 07:39:00.8310 UTC hyperparameters_optimizer.cc:582] [1086/1100] Score: -0.674351 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:39:00.8312 UTC hyperparameters_optimizer.cc:582] [1087/1100] Score: -0.655546 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.25 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:39:00.8618 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.666447\n",
      "[INFO 24-02-22 07:39:00.8618 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 07:39:00.8619 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.666447 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:00.8622 UTC hyperparameters_optimizer.cc:582] [1088/1100] Score: -0.666447 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 1.5 } }\n",
      "[INFO 24-02-22 07:39:01.8681 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684326\n",
      "[INFO 24-02-22 07:39:01.8681 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:39:01.8683 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.684326 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:39:01.8689 UTC hyperparameters_optimizer.cc:582] [1089/1100] Score: -0.684326 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:02.3955 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.708688\n",
      "[INFO 24-02-22 07:39:02.3955 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 07:39:02.3958 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.708688 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:02.3965 UTC hyperparameters_optimizer.cc:582] [1090/1100] Score: -0.708688 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:39:02.4323 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.637116\n",
      "[INFO 24-02-22 07:39:02.4323 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:39:02.4325 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:39:02.4325 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.637116 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:39:02.4331 UTC hyperparameters_optimizer.cc:582] [1091/1100] Score: -0.637116 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:02.7612 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.70124\n",
      "[INFO 24-02-22 07:39:02.7612 UTC gradient_boosted_trees.cc:271] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "[WARNING 24-02-22 07:39:02.7615 UTC gradient_boosted_trees.cc:292] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "[INFO 24-02-22 07:39:02.7615 UTC gradient_boosted_trees.cc:334] Final model num-trees:11 valid-loss:0.701240 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:39:02.7619 UTC hyperparameters_optimizer.cc:582] [1092/1100] Score: -0.70124 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:03.0809 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665322\n",
      "[INFO 24-02-22 07:39:03.0810 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 07:39:03.0811 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.665322 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:03.0821 UTC hyperparameters_optimizer.cc:582] [1093/1100] Score: -0.665322 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2 } }\n",
      "[INFO 24-02-22 07:39:03.1817 UTC gradient_boosted_trees.cc:1638] \tnum-trees:124 train-loss:0.628672 train-accuracy:0.878973 valid-loss:0.694819 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:03.3640 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.665721\n",
      "[INFO 24-02-22 07:39:03.3641 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 07:39:03.3642 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.665721 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:39:03.3644 UTC hyperparameters_optimizer.cc:582] [1094/1100] Score: -0.665721 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:03.9492 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67862\n",
      "[INFO 24-02-22 07:39:03.9493 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 07:39:03.9493 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.678620 valid-accuracy:0.904110\n",
      "[INFO 24-02-22 07:39:03.9497 UTC hyperparameters_optimizer.cc:582] [1095/1100] Score: -0.67862 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 21 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:04.5601 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.648346\n",
      "[INFO 24-02-22 07:39:04.5601 UTC gradient_boosted_trees.cc:271] Truncates the model to 56 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 24-02-22 07:39:04.5607 UTC gradient_boosted_trees.cc:334] Final model num-trees:56 valid-loss:0.648346 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:39:04.5620 UTC hyperparameters_optimizer.cc:582] [1096/1100] Score: -0.648346 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:04.6129 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.691138\n",
      "[INFO 24-02-22 07:39:04.6129 UTC gradient_boosted_trees.cc:271] Truncates the model to 153 tree(s) i.e. 153  iteration(s).\n",
      "[INFO 24-02-22 07:39:04.6129 UTC gradient_boosted_trees.cc:334] Final model num-trees:153 valid-loss:0.691138 valid-accuracy:0.890411\n",
      "[INFO 24-02-22 07:39:04.6131 UTC hyperparameters_optimizer.cc:582] [1097/1100] Score: -0.691138 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:04.6719 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676863\n",
      "[INFO 24-02-22 07:39:04.6719 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 07:39:04.6721 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.676863 valid-accuracy:0.863014\n",
      "[INFO 24-02-22 07:39:04.6741 UTC hyperparameters_optimizer.cc:582] [1098/1100] Score: -0.676863 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 2 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:06.9003 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.667922\n",
      "[INFO 24-02-22 07:39:06.9003 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 07:39:06.9005 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.667922 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:06.9013 UTC hyperparameters_optimizer.cc:582] [1099/1100] Score: -0.667922 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:09.4902 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679783\n",
      "[INFO 24-02-22 07:39:09.4902 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 07:39:09.4904 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.679783 valid-accuracy:0.876712\n",
      "[INFO 24-02-22 07:39:09.4918 UTC hyperparameters_optimizer.cc:582] [1100/1100] Score: -0.679783 / -0.588907 HParams: fields { name: \"min_examples\" value { integer: 14 } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 14 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } } fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"sparse_oblique_num_projections_exponent\" value { real: 2.5 } }\n",
      "[INFO 24-02-22 07:39:09.4966 UTC hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 5\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  value {\n",
      "    categorical: \"CART\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  value {\n",
      "    categorical: \"LOCAL\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  value {\n",
      "    integer: 6\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  value {\n",
      "    categorical: \"false\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  value {\n",
      "    real: 0.1\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  value {\n",
      "    real: 0.2\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  value {\n",
      "    categorical: \"SPARSE_OBLIQUE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_normalization\"\n",
      "  value {\n",
      "    categorical: \"STANDARD_DEVIATION\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_weights\"\n",
      "  value {\n",
      "    categorical: \"BINARY\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_num_projections_exponent\"\n",
      "  value {\n",
      "    real: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 07:39:09.5013 UTC kernel.cc:919] Export model in log directory: /tmp/tmpmzhz5c9s with prefix d29b5ea4ec334ecc\n",
      "[INFO 24-02-22 07:39:09.5071 UTC kernel.cc:937] Save model in resources\n",
      "[INFO 24-02-22 07:39:09.5103 UTC abstract_model.cc:881] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 0.588907\n",
      "\n",
      "Accuracy: 0.890411  CI95[W][0 1]\n",
      "ErrorRate: : 0.109589\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42   6\n",
      "2   2  23\n",
      "Total: 73\n",
      "\n",
      "\n",
      "[INFO 24-02-22 07:39:09.5241 UTC kernel.cc:1233] Loading model from path /tmp/tmpmzhz5c9s/model/ with prefix d29b5ea4ec334ecc\n",
      "[INFO 24-02-22 07:39:09.5348 UTC decision_forest.cc:660] Model loaded with 46 root(s), 1874 node(s), and 10 input feature(s).\n",
      "[INFO 24-02-22 07:39:09.5349 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-02-22 07:39:09.5349 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:02:36.372082\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x704aa2792660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x704aa2792660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x704ac09199d0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "tuned_model.fit(train_ds, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x704aa2793a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x704aa2793a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the TF-DF hyper-parameter tuner: 0.6388\n"
     ]
    }
   ],
   "source": [
    "tuned_model.compile([\"accuracy\"])\n",
    "tuned_test_accuracy = tuned_model.evaluate(test_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy with the TF-DF hyper-parameter tuner: {tuned_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpf8og66t6 as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-02-22 06:45:44.0102 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:45:44.0102 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:45:44.0102 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tensor examples:\n",
      "Features: {'Pclass': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'Age': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'Fare': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'People': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'Sex_female': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'Sex_male': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'Embarked_C': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>, 'Embarked_Q': <tf.Tensor 'data_7:0' shape=(None,) dtype=int64>, 'Embarked_S': <tf.Tensor 'data_8:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_9:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'Pclass': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Age': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Fare': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'People': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Sex_female': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'Sex_male': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'Embarked_C': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'Embarked_Q': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'Embarked_S': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>)}\n",
      "Training dataset read in 0:00:01.714312. Found 713 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-22 06:45:45.7465 UTC kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-02-22 06:45:45.7465 UTC kernel.cc:772] Collect training examples\n",
      "[INFO 24-02-22 06:45:45.7465 UTC kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7467 UTC kernel.cc:391] Number of batches: 1\n",
      "[INFO 24-02-22 06:45:45.7467 UTC kernel.cc:392] Number of examples: 713\n",
      "[INFO 24-02-22 06:45:45.7468 UTC kernel.cc:792] Training dataset:\n",
      "Number of records: 713\n",
      "Number of columns: 10\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 9 (90%)\n",
      "\tCATEGORICAL: 1 (10%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 9 (90%)\n",
      "\t0: \"Age\" NUMERICAL mean:28.8925 min:0.42 max:80 sd:13.0626\n",
      "\t1: \"Embarked_C\" NUMERICAL mean:0.187938 min:0 max:1 sd:0.390663\n",
      "\t2: \"Embarked_Q\" NUMERICAL mean:0.0869565 min:0 max:1 sd:0.281771\n",
      "\t3: \"Embarked_S\" NUMERICAL mean:0.725105 min:0 max:1 sd:0.446461\n",
      "\t4: \"Fare\" NUMERICAL mean:33.3333 min:0 max:512.329 sd:52.2398\n",
      "\t5: \"Pclass\" NUMERICAL mean:2.2777 min:1 max:3 sd:0.841604\n",
      "\t6: \"People\" NUMERICAL mean:1.85694 min:1 max:11 sd:1.56818\n",
      "\t7: \"Sex_female\" NUMERICAL mean:0.353436 min:0 max:1 sd:0.478037\n",
      "\t8: \"Sex_male\" NUMERICAL mean:0.646564 min:0 max:1 sd:0.478037\n",
      "\n",
      "CATEGORICAL: 1 (10%)\n",
      "\t9: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7469 UTC kernel.cc:808] Configure learner\n",
      "[WARNING 24-02-22 06:45:45.7471 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:45:45.7471 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-02-22 06:45:45.7471 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-02-22 06:45:45.7471 UTC kernel.cc:822] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Embarked_C$\"\n",
      "features: \"^Embarked_Q$\"\n",
      "features: \"^Embarked_S$\"\n",
      "features: \"^Fare$\"\n",
      "features: \"^Pclass$\"\n",
      "features: \"^People$\"\n",
      "features: \"^Sex_female$\"\n",
      "features: \"^Sex_male$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "    features: \"^Age$\"\n",
      "    features: \"^Embarked_C$\"\n",
      "    features: \"^Embarked_Q$\"\n",
      "    features: \"^Embarked_S$\"\n",
      "    features: \"^Fare$\"\n",
      "    features: \"^Pclass$\"\n",
      "    features: \"^People$\"\n",
      "    features: \"^Sex_female$\"\n",
      "    features: \"^Sex_male$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: CLASSIFICATION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 6\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: -1\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      shrinkage: 0.1\n",
      "      loss: DEFAULT\n",
      "      validation_set_ratio: 0.1\n",
      "      validation_interval_in_trees: 1\n",
      "      early_stopping: VALIDATION_LOSS_INCREASE\n",
      "      early_stopping_num_trees_look_ahead: 30\n",
      "      l2_regularization: 0\n",
      "      lambda_loss: 1\n",
      "      mart {\n",
      "      }\n",
      "      adapt_subsample_for_maximum_training_duration: false\n",
      "      l1_regularization: 0\n",
      "      use_hessian_gain: false\n",
      "      l2_regularization_categorical: 1\n",
      "      stochastic_gradient_boosting {\n",
      "        ratio: 1\n",
      "      }\n",
      "      apply_link_function: true\n",
      "      compute_permutation_variable_importance: false\n",
      "      binary_focal_loss_options {\n",
      "        misprediction_exponent: 2\n",
      "        positive_sample_coefficient: 0.5\n",
      "      }\n",
      "      early_stopping_initial_iteration: 10\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 500\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "  predefined_search_space {\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7474 UTC kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmp/tmpf8og66t6/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7475 UTC kernel.cc:887] Train model\n",
      "[INFO 24-02-22 06:45:45.7476 UTC hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_projection_density_factor\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"LOCAL\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"BEST_FIRST_GLOBAL\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_num_nodes\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 16\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 32\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 64\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 128\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 256\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 512\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"BEST_FIRST_GLOBAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_depth\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 6\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 8\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"LOCAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sampling_method\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"subsample\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 0.6\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 0.8\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 0.9\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"RANDOM\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.02\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.05\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 7\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 20\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"false\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.5\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.9\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:45:45.7479 UTC hyperparameters_optimizer.cc:500] Start local tuner with 16 thread(s)\n",
      "[INFO[INFO[INFO[INFO 24-02-22 06:45:45.7500 UTC gradient_boosted_trees.cc: 24-02-22 06:45:45.7500 UTC  24-02-22 06:45:45.7500 UTC gradient_boosted_trees.cc: 24-02-22 06:45:45.7500 UTC [591[INFOINFO] gradient_boosted_trees.cc591gradient_boosted_trees.cc] Default loss set to :BINOMIAL_LOG_LIKELIHOOD591\n",
      "] :Default loss set to  24-02-22 06:45:45.7501 UTC [INFOBINOMIAL_LOG_LIKELIHOOD 24-02-22 06:45:45.7501 UTC Default loss set to  24-02-22 06:45:45.7501 UTC gradient_boosted_trees.cc:\n",
      "[gradient_boosted_trees.cc:591] BINOMIAL_LOG_LIKELIHOOD\n",
      "591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "INFO[INFO 24-02-22 06:45:45.7501 UTC gradient_boosted_trees.cc:1218Default loss set to [ 24-02-22 06:45:45.7501 UTC gradient_boosted_trees.cc[INFO591INFO:591BINOMIAL_LOG_LIKELIHOOD] gradient_boosted_trees.ccDefault loss set to  24-02-22 06:45:45.7501 UTC :BINOMIAL_LOG_LIKELIHOOD1218\n",
      "] gradient_boosted_trees.cc:1218[] Training gradient boosted tree on INFO[]  24-02-22 06:45:45.7501 UTC Training gradient boosted tree on \n",
      "713] INFODefault loss set to 713 24-02-22 06:45:45.7501 UTC  24-02-22 06:45:45.7502 UTC  example(s) and 9gradient_boosted_trees.ccBINOMIAL_LOG_LIKELIHOOD:\n",
      " example(s) and 9 feature(s).gradient_boosted_trees.cc[\n",
      "1218INFO] [gradient_boosted_trees.cc feature(s).INFOTraining gradient boosted tree on 713 example(s) and Training gradient boosted tree on \n",
      " 24-02-22 06:45:45.7502 UTC  24-02-22 06:45:45.7502 UTC gradient_boosted_trees.ccgradient_boosted_trees.cc:7131218:1218:] 591]  example(s) and 9 feature(s).\n",
      "Default loss set to BINOMIAL_LOG_LIKELIHOODTraining gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      ":1218\n",
      "] Training gradient boosted tree on 713] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      " example(s) and 9 feature(s).\n",
      "[INFO[INFO 24-02-22 06:45:45.7502 UTC [INFO[INFO 24-02-22 06:45:45.7502 UTC gradient_boosted_trees.cc: 24-02-22 06:45:45.7502 UTC 591gradient_boosted_trees.ccgradient_boosted_trees.cc:1218]  24-02-22 06:45:45.7502 UTC gradient_boosted_trees.cc:] 591Default loss set to :591[Training gradient boosted tree on 713INFOBINOMIAL_LOG_LIKELIHOOD\n",
      "]  example(s) and 9 feature(s). 24-02-22 06:45:45.7503 UTC gradient_boosted_trees.cc:591] Default loss set to \n",
      "Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[BINOMIAL_LOG_LIKELIHOOD\n",
      "INFO[ 24-02-22 06:45:45.7503 UTC gradient_boosted_trees.cc:[[INFOINFO591]  24-02-22 06:45:45.7503 UTC 9 feature(s).\n",
      "gradient_boosted_trees.ccINFODefault loss set to : 24-02-22 06:45:45.7503 UTC BINOMIAL_LOG_LIKELIHOOD 24-02-22 06:45:45.7503 UTC gradient_boosted_trees.cc:1218] 1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "gradient_boosted_trees.ccTraining gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      ":1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:45.7503 UTC gradient_boosted_trees.cc:1261] 647[INFO[[INFO examples used for training and  24-02-22 06:45:45.7504 UTC gradient_boosted_trees.cc:\n",
      "INFO66 24-02-22 06:45:45.7504 UTC  24-02-22 06:45:45.7504 UTC gradient_boosted_trees.cc:591] Default loss set to [INFO1261] 647gradient_boosted_trees.ccBINOMIAL_LOG_LIKELIHOOD\n",
      ":1261 examples used for training and ] [[66 24-02-22 06:45:45.7504 UTC INFOINFO 24-02-22 06:45:45.7504 UTC Default loss set to  examples used for validationBINOMIAL_LOG_LIKELIHOOD examples used for validation\n",
      "\n",
      " 24-02-22 06:45:45.7504 UTC gradient_boosted_trees.cc] :1218] Training gradient boosted tree on gradient_boosted_trees.ccgradient_boosted_trees.cc:1218] 647[713[INFO examples used for training and 66 examples used for validation\n",
      "Training gradient boosted tree on 713: example(s) and 1261[ example(s) and ] INFO9\n",
      " feature(s).[647 examples used for training and 66 examples used for validation 24-02-22 06:45:45.7504 UTC \n",
      "gradient_boosted_trees.cc 24-02-22 06:45:45.7504 UTC gradient_boosted_trees.cc:\n",
      ":INFO12611261[] INFO]  24-02-22 06:45:45.7505 UTC 647 examples used for training and  24-02-22 06:45:45.7504 UTC 64766[ examples used for validation[INFOINFO examples used for training and  24-02-22 06:45:45.7505 UTC 66gradient_boosted_trees.cc examples used for validation:1261\n",
      " 24-02-22 06:45:45.7505 UTC gradient_boosted_trees.cc:\n",
      "591] [INFOgradient_boosted_trees.cc[INFODefault loss set to  24-02-22 06:45:45.7505 UTC ] gradient_boosted_trees.cc 24-02-22 06:45:45.7505 UTC :BINOMIAL_LOG_LIKELIHOOD\n",
      "1218[INFO]  24-02-22 06:45:45.7505 UTC 9gradient_boosted_trees.cc feature(s).\n",
      ":647gradient_boosted_trees.cc:591Training gradient boosted tree on 1261713]  example(s) and 647 examples used for training and gradient_boosted_trees.cc66::12611218] 9Training gradient boosted tree on 713] ] 647Default loss set to  examples used for training and BINOMIAL_LOG_LIKELIHOOD66\n",
      " examples used for validation examples used for training and  feature(s). example(s) and \n",
      "966 feature(s). examples used for validation\n",
      "\n",
      "\n",
      " examples used for validationINFO[[INFO\n",
      " 24-02-22 06:45:45.7505 UTC  24-02-22 06:45:45.7505 UTC gradient_boosted_trees.cc:gradient_boosted_trees.cc1261] 647 examples used for training and 66INFO examples used for validation\n",
      ": 24-02-22 06:45:45.7506 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:45.7506 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:45.7506 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:45.7507 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:45.7507 UTC gradient_boosted_trees.cc[INFO:1261]  24-02-22 06:45:45.7507 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 64766 examples used for validation\n",
      " examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:45.7566 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299102 train-accuracy:0.599691 valid-loss:1.281556 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7581 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.327167 train-accuracy:0.599691 valid-loss:1.303853 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7595 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248973 train-accuracy:0.599691 valid-loss:1.242635 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7598 UTC gradient_boosted_trees.cc:1638] \tnum-trees:2 train-loss:1.258656 train-accuracy:0.599691 valid-loss:1.252313 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7610 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246921 train-accuracy:0.599691 valid-loss:1.244506 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7636 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242535 train-accuracy:0.599691 valid-loss:1.239770 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7640 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238261 train-accuracy:0.599691 valid-loss:1.242172 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323255 train-accuracy:0.599691 valid-loss:1.301899 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7668 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284455 train-accuracy:0.599691 valid-loss:1.272638 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7696 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240513 train-accuracy:0.599691 valid-loss:1.236605 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325033 train-accuracy:0.599691 valid-loss:1.301812 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7723 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289820 train-accuracy:0.599691 valid-loss:1.273541 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286567 train-accuracy:0.599691 valid-loss:1.272373 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323071 train-accuracy:0.599691 valid-loss:1.301134 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7744 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295236 train-accuracy:0.599691 valid-loss:1.279608 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7767 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231723 train-accuracy:0.599691 valid-loss:1.247217 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:45.7881 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.219171 train-accuracy:0.599691 valid-loss:1.232235 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.0446 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.879663\n",
      "[INFO 24-02-22 06:45:46.0457 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.0458 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.879663 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:46.0461 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.0461 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.0462 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.0469 UTC hyperparameters_optimizer.cc:582] [1/500] Score: -0.879663 / -0.879663 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:46.0572 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326041 train-accuracy:0.599691 valid-loss:1.301055 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.1083 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.810702\n",
      "[INFO 24-02-22 06:45:46.1084 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.1085 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.810702 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:46.1089 UTC hyperparameters_optimizer.cc:582] [2/500] Score: -0.810702 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:46.1093 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.1093 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.1095 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.1189 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286585 train-accuracy:0.599691 valid-loss:1.271529 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.4318 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.813087\n",
      "[INFO 24-02-22 06:45:46.4319 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.4319 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.813087 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:46.4321 UTC hyperparameters_optimizer.cc:582] [3/500] Score: -0.813087 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.4325 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.4325 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.4326 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.4429 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320005 train-accuracy:0.599691 valid-loss:1.297612 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.6083 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846985\n",
      "[INFO 24-02-22 06:45:46.6085 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.6089 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.846985 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:46.6093 UTC hyperparameters_optimizer.cc:582] [4/500] Score: -0.846985 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:46.6100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.6102 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.6106 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.6287 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326903 train-accuracy:0.599691 valid-loss:1.302218 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.7098 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.821244\n",
      "[INFO 24-02-22 06:45:46.7098 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.7099 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.821244 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:46.7102 UTC hyperparameters_optimizer.cc:582] [5/500] Score: -0.821244 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.7107 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.7107 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.7109 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.7139 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.898714\n",
      "[INFO 24-02-22 06:45:46.7139 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.7142 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.898714 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:46.7150 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.7150 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.7152 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.7154 UTC hyperparameters_optimizer.cc:582] [6/500] Score: -0.898714 / -0.810702 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.7168 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329044 train-accuracy:0.599691 valid-loss:1.304259 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.7244 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323562 train-accuracy:0.599691 valid-loss:1.300765 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.8103 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.787401\n",
      "[INFO 24-02-22 06:45:46.8104 UTC gradient_boosted_trees.cc:271] Truncates the model to 183 tree(s) i.e. 183  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.8104 UTC gradient_boosted_trees.cc:334] Final model num-trees:183 valid-loss:0.787401 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:46.8110 UTC hyperparameters_optimizer.cc:582] [7/500] Score: -0.787401 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:46.8114 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.8114 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.8118 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.8193 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.877771\n",
      "[INFO 24-02-22 06:45:46.8193 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.8195 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.877771 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:46.8199 UTC hyperparameters_optimizer.cc:582] [8/500] Score: -0.877771 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.8208 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.8208 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.8210 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.8268 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232001 train-accuracy:0.599691 valid-loss:1.246278 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.8386 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223497 train-accuracy:0.599691 valid-loss:1.224562 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.8763 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851705\n",
      "[INFO 24-02-22 06:45:46.8763 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.8765 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.851705 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:46.8771 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.8771 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.8773 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.8820 UTC hyperparameters_optimizer.cc:582] [9/500] Score: -0.851705 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:46.8957 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282480 train-accuracy:0.599691 valid-loss:1.277844 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:46.9701 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.856374\n",
      "[INFO 24-02-22 06:45:46.9702 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:45:46.9704 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.856374 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:46.9710 UTC hyperparameters_optimizer.cc:582] [10/500] Score: -0.856374 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:46.9732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:46.9734 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:46.9736 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:46.9884 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321756 train-accuracy:0.599691 valid-loss:1.299039 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.0134 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862188\n",
      "[INFO 24-02-22 06:45:47.0134 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.0137 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.862188 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:47.0143 UTC hyperparameters_optimizer.cc:582] [11/500] Score: -0.862188 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:47.0158 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.0158 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.0160 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.0199 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846504\n",
      "[INFO 24-02-22 06:45:47.0201 UTC gradient_boosted_trees.cc:271] Truncates the model to 210 tree(s) i.e. 210  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.0202 UTC gradient_boosted_trees.cc:334] Final model num-trees:210 valid-loss:0.846504 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.0214 UTC hyperparameters_optimizer.cc:582] [12/500] Score: -0.846504 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:47.0234 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.0236 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.0239 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.0315 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322018 train-accuracy:0.599691 valid-loss:1.302492 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.0441 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319056 train-accuracy:0.599691 valid-loss:1.302298 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.0878 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876741\n",
      "[INFO 24-02-22 06:45:47.0879 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.0880 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.876741 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.0884 UTC hyperparameters_optimizer.cc:582] [13/500] Score: -0.876741 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:47.0896 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.0896 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.0897 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.0941 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266406 train-accuracy:0.599691 valid-loss:1.252495 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.5185 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89407\n",
      "[INFO 24-02-22 06:45:47.5186 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.5187 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.894070 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.5192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.5192 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.5194 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.5221 UTC hyperparameters_optimizer.cc:582] [14/500] Score: -0.89407 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:47.5321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225584 train-accuracy:0.599691 valid-loss:1.246779 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.5820 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875676\n",
      "[INFO 24-02-22 06:45:47.5820 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.5822 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.875676 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.5833 UTC hyperparameters_optimizer.cc:582] [15/500] Score: -0.875676 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:47.5855 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.5855 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.5857 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.6009 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285744 train-accuracy:0.599691 valid-loss:1.269879 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.6549 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86677\n",
      "[INFO 24-02-22 06:45:47.6549 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.6551 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.866770 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:47.6554 UTC hyperparameters_optimizer.cc:582] [16/500] Score: -0.86677 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:47.6561 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.6561 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.6563 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.6658 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297947 train-accuracy:0.599691 valid-loss:1.276181 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.7337 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.822231\n",
      "[INFO 24-02-22 06:45:47.7337 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.7338 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.822231 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:47.7340 UTC hyperparameters_optimizer.cc:582] [17/500] Score: -0.822231 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:47.7344 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.7344 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.7346 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.7480 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323394 train-accuracy:0.599691 valid-loss:1.300948 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.8691 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823503\n",
      "[INFO 24-02-22 06:45:47.8691 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.8693 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.823503 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.8698 UTC hyperparameters_optimizer.cc:582] [18/500] Score: -0.823503 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:47.8707 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.8708 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.8709 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.8878 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294626 train-accuracy:0.599691 valid-loss:1.274379 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.9052 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.833291\n",
      "[INFO 24-02-22 06:45:47.9053 UTC gradient_boosted_trees.cc:271] Truncates the model to 188 tree(s) i.e. 188  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.9055 UTC gradient_boosted_trees.cc:334] Final model num-trees:188 valid-loss:0.833291 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:47.9065 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.9066 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.9067 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.9087 UTC hyperparameters_optimizer.cc:582] [19/500] Score: -0.833291 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:47.9215 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322378 train-accuracy:0.599691 valid-loss:1.299599 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:47.9568 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872595\n",
      "[INFO 24-02-22 06:45:47.9568 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:45:47.9571 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.872595 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:47.9585 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:47.9585 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:47.9587 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:47.9587 UTC hyperparameters_optimizer.cc:582] [20/500] Score: -0.872595 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:47.9739 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227822 train-accuracy:0.599691 valid-loss:1.254822 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.1502 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858256\n",
      "[INFO 24-02-22 06:45:48.1502 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.1504 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.858256 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.1514 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.1514 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.1515 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.1521 UTC hyperparameters_optimizer.cc:582] [21/500] Score: -0.858256 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:48.1685 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238191 train-accuracy:0.599691 valid-loss:1.246720 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.1981 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.895892\n",
      "[INFO 24-02-22 06:45:48.1982 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.1984 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.895892 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:48.1992 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.1992 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.1994 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.2014 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324782 train-accuracy:0.599691 valid-loss:1.302546 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.2015 UTC hyperparameters_optimizer.cc:582] [22/500] Score: -0.895892 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:48.2182 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902587\n",
      "[INFO 24-02-22 06:45:48.2182 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.2185 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.902587 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:48.2188 UTC hyperparameters_optimizer.cc:582] [23/500] Score: -0.902587 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:48.2207 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.2209 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.2214 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.2283 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262533 train-accuracy:0.599691 valid-loss:1.263113 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.3251 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.898929\n",
      "[INFO 24-02-22 06:45:48.3252 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.3254 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.898929 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:48.3263 UTC hyperparameters_optimizer.cc:582] [24/500] Score: -0.898929 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:48.3273 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.3274 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.3277 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.3405 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324916 train-accuracy:0.599691 valid-loss:1.304121 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.3508 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81927\n",
      "[INFO 24-02-22 06:45:48.3510 UTC gradient_boosted_trees.cc:271] Truncates the model to 239 tree(s) i.e. 239  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.3511 UTC gradient_boosted_trees.cc:334] Final model num-trees:239 valid-loss:0.819270 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.3516 UTC hyperparameters_optimizer.cc:582] [25/500] Score: -0.81927 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:48.3519 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.3519 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.3521 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.3573 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263809 train-accuracy:0.599691 valid-loss:1.259300 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.6712 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838898\n",
      "[INFO 24-02-22 06:45:48.6712 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.6717 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.838898 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:48.6718 UTC hyperparameters_optimizer.cc:582] [26/500] Score: -0.838898 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:48.6722 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.6722 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.6724 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.6853 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294104 train-accuracy:0.599691 valid-loss:1.281722 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.7048 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834405\n",
      "[INFO 24-02-22 06:45:48.7048 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.7049 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.834405 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:48.7052 UTC hyperparameters_optimizer.cc:582] [27/500] Score: -0.834405 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:48.7056 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.7057 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.7060 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.7189 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880495\n",
      "[INFO 24-02-22 06:45:48.7190 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.7193 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.880495 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.7197 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238102 train-accuracy:0.599691 valid-loss:1.239705 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.7218 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.7219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.7221 UTC hyperparameters_optimizer.cc:582] [28/500] Score: -0.880495 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:48.7233 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.7380 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226669 train-accuracy:0.599691 valid-loss:1.233602 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.7445 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.612892 train-accuracy:0.893354 valid-loss:0.827650 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.7446 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.7447 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.827600 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:48.7453 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.7453 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.7455 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.7487 UTC hyperparameters_optimizer.cc:582] [29/500] Score: -0.8276 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:48.7647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285128 train-accuracy:0.599691 valid-loss:1.280545 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:48.8688 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89547\n",
      "[INFO 24-02-22 06:45:48.8688 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:48.8691 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.895470 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:48.8697 UTC hyperparameters_optimizer.cc:582] [30/500] Score: -0.89547 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:48.8702 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:48.8702 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:48.8707 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:48.8772 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261617 train-accuracy:0.599691 valid-loss:1.258390 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.0243 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860766\n",
      "[INFO 24-02-22 06:45:49.0243 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.0245 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.860766 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:49.0252 UTC hyperparameters_optimizer.cc:582] [31/500] Score: -0.860766 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.0266 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.0266 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.0268 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.0332 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328892 train-accuracy:0.599691 valid-loss:1.305558 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.1086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.803955\n",
      "[INFO 24-02-22 06:45:49.1086 UTC gradient_boosted_trees.cc:271] Truncates the model to 196 tree(s) i.e. 196  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.1087 UTC gradient_boosted_trees.cc:334] Final model num-trees:196 valid-loss:0.803955 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:49.1100 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.1100 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.1102 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.1122 UTC hyperparameters_optimizer.cc:582] [32/500] Score: -0.803955 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.1248 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322124 train-accuracy:0.599691 valid-loss:1.296306 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.2516 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.816475\n",
      "[INFO 24-02-22 06:45:49.2517 UTC gradient_boosted_trees.cc:271] Truncates the model to 133 tree(s) i.e. 133  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.2517 UTC gradient_boosted_trees.cc:334] Final model num-trees:133 valid-loss:0.816475 valid-accuracy:0.818182\n",
      "[[INFO 24-02-22 06:45:49.2523 UTC hyperparameters_optimizer.cc:582] [33/500] Score: -0.816475 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "INFO 24-02-22 06:45:49.2527 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.2527 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.2533 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.2695 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292946 train-accuracy:0.599691 valid-loss:1.274051 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.3222 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.841766\n",
      "[INFO 24-02-22 06:45:49.3223 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.3224 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.841766 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:49.3229 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.3229 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.3229 UTC hyperparameters_optimizer.cc:582] [34/500] Score: -0.841766 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.3254 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.3477 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297498 train-accuracy:0.599691 valid-loss:1.282897 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.4206 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.841924\n",
      "[INFO 24-02-22 06:45:49.4207 UTC gradient_boosted_trees.cc:271] Truncates the model to 56 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.4209 UTC gradient_boosted_trees.cc:334] Final model num-trees:56 valid-loss:0.841924 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:49.4213 UTC hyperparameters_optimizer.cc:582] [35/500] Score: -0.841924 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.4230 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.4230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.4232 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.4344 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.861837\n",
      "[INFO 24-02-22 06:45:49.4345 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.4347 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.861837 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:49.4351 UTC hyperparameters_optimizer.cc:582] [36/500] Score: -0.861837 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:49.4367 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.4371 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.4384 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.4429 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239855 train-accuracy:0.599691 valid-loss:1.255424 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.4569 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239919 train-accuracy:0.599691 valid-loss:1.240268 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.5893 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867645\n",
      "[INFO 24-02-22 06:45:49.5894 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.5896 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.867645 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:49.5907 UTC hyperparameters_optimizer.cc:582] [37/500] Score: -0.867645 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:49.5928 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.5928 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.5929 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.5969 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.300715 train-accuracy:0.599691 valid-loss:1.283338 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.6343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.816823\n",
      "[INFO 24-02-22 06:45:49.6343 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.6344 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.816823 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:49.6346 UTC hyperparameters_optimizer.cc:582] [38/500] Score: -0.816823 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:49.6351 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.6351 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.6354 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.6423 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328624 train-accuracy:0.599691 valid-loss:1.304430 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.8027 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85208\n",
      "[INFO 24-02-22 06:45:49.8027 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.8029 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.852080 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:49.8045 UTC hyperparameters_optimizer.cc:582] [39/500] Score: -0.85208 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:49.8059 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.8059 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.8069 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.8078 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261860 train-accuracy:0.599691 valid-loss:1.261429 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.8407 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845917\n",
      "[INFO 24-02-22 06:45:49.8408 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.8408 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.845917 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:49.8412 UTC hyperparameters_optimizer.cc:582] [40/500] Score: -0.845917 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:49.8417 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.8417 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.8420 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.8483 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326488 train-accuracy:0.599691 valid-loss:1.301378 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.8574 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866422\n",
      "[INFO 24-02-22 06:45:49.8574 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.8577 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.866422 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:49.8583 UTC hyperparameters_optimizer.cc:582] [41/500] Score: -0.866422 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:49.8592 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.8593 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.8599 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.8647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326360 train-accuracy:0.599691 valid-loss:1.302910 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.9391 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.853363\n",
      "[INFO 24-02-22 06:45:49.9391 UTC gradient_boosted_trees.cc:271] Truncates the model to 79 tree(s) i.e. 79  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.9392 UTC gradient_boosted_trees.cc:334] Final model num-trees:79 valid-loss:0.853363 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:49.9396 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.9396 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-22 06:45:49.9398 UTC hyperparameters_optimizer.cc:582] [42/500] Score: -0.853363 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "INFO 24-02-22 06:45:49.9401 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:49.9438 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263660 train-accuracy:0.599691 valid-loss:1.256220 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:49.9974 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.909584\n",
      "[INFO 24-02-22 06:45:49.9975 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:45:49.9977 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.909584 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:49.9985 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:49.9985 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:49.9986 UTC hyperparameters_optimizer.cc:582] [43/500] Score: -0.909584 / -0.787401 HParams: [INFO 24-02-22 06:45:49.9987 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      " examples used for validation\n",
      "[INFO 24-02-22 06:45:50.0113 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293281 train-accuracy:0.599691 valid-loss:1.277729 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.1343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836923\n",
      "[INFO 24-02-22 06:45:50.1347 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.1348 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.836923 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:50.1355 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.1356 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.1357 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.1381 UTC hyperparameters_optimizer.cc:582] [44/500] Score: -0.836923 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:50.1524 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286836 train-accuracy:0.599691 valid-loss:1.277966 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.1733 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848447\n",
      "[INFO 24-02-22 06:45:50.1734 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.1735 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.848447 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:50.1739 UTC hyperparameters_optimizer.cc:582] [45/500] Score: -0.848447 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:50.1743 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.1743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.1746 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.1868 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872035\n",
      "[INFO 24-02-22 06:45:50.1870 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.1873 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.872035 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.1890 UTC hyperparameters_optimizer.cc:582] [46/500] Score: -0.872035 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:50.1909 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.1910 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.1911 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.1949 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281181 train-accuracy:0.599691 valid-loss:1.280599 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.1992 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323041 train-accuracy:0.599691 valid-loss:1.298193 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.2724 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.853001\n",
      "[INFO 24-02-22 06:45:50.2724 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.2726 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.853001 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.2732 UTC hyperparameters_optimizer.cc:582] [47/500] Score: -0.853001 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:50.2744 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.2745 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.2748 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.2866 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235518 train-accuracy:0.599691 valid-loss:1.241700 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.3189 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851016\n",
      "[INFO 24-02-22 06:45:50.3190 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.3191 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.851016 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.3193 UTC hyperparameters_optimizer.cc:582] [48/500] Score: -0.851016 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:50.3196 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.3196 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.3198 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.3353 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321901 train-accuracy:0.599691 valid-loss:1.298070 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.4037 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.80436\n",
      "[INFO 24-02-22 06:45:50.4037 UTC gradient_boosted_trees.cc:271] Truncates the model to 93 tree(s) i.e. 93  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.4038 UTC gradient_boosted_trees.cc:334] Final model num-trees:93 valid-loss:0.804360 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.4040 UTC hyperparameters_optimizer.cc:582] [49/500] Score: -0.80436 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:50.4046 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.4046 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.4049 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.4081 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.818985\n",
      "[INFO 24-02-22 06:45:50.4081 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.4082 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.818985 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:50.4085 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304026 train-accuracy:0.599691 valid-loss:1.289701 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.4092 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.4092 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.4093 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.4120 UTC hyperparameters_optimizer.cc:582] [50/500] Score: -0.818985 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:50.4148 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326409 train-accuracy:0.599691 valid-loss:1.300988 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.4685 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824662\n",
      "[INFO 24-02-22 06:45:50.4685 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.4687 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.824662 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.4692 UTC hyperparameters_optimizer.cc:582] [51/500] Score: -0.824662 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:50.4699 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.4701 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.4705 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.4883 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236742 train-accuracy:0.599691 valid-loss:1.242617 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.6818 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86202\n",
      "[INFO 24-02-22 06:45:50.6818 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.6821 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.862020 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:50.6840 UTC hyperparameters_optimizer.cc:582] [52/500] Score: -0.86202 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:50.6847 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.6847 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.6864 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.6903 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.255817 train-accuracy:0.599691 valid-loss:1.241683 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.7593 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827896\n",
      "[INFO 24-02-22 06:45:50.7593 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.7595 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.827896 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:50.7599 UTC hyperparameters_optimizer.cc:582] [53/500] Score: -0.827896 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:50.7607 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.7607 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.7610 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.7697 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325228 train-accuracy:0.599691 valid-loss:1.302135 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.7828 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.895343\n",
      "[INFO 24-02-22 06:45:50.7861 UTC gradient_boosted_trees.cc:271] Truncates the model to 79 tree(s) i.e. 79  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.7862 UTC gradient_boosted_trees.cc:334] Final model num-trees:79 valid-loss:0.895343 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:50.7866 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.7867 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.7868 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.7921 UTC hyperparameters_optimizer.cc:582] [54/500] Score: -0.895343 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:50.8047 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292122 train-accuracy:0.599691 valid-loss:1.279078 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.8333 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.649951 train-accuracy:0.873261 valid-loss:0.862889 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:50.8333 UTC gradient_boosted_trees.cc:271] Truncates the model to 295 tree(s) i.e. 295  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.8333 UTC gradient_boosted_trees.cc:334] Final model num-trees:295 valid-loss:0.861282 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:50.8336 UTC hyperparameters_optimizer.cc:582] [55/500] Score: -0.861282 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:50.8343 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.8343 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.8345 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.8529 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323356 train-accuracy:0.599691 valid-loss:1.300296 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.9153 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.877363\n",
      "[INFO 24-02-22 06:45:50.9153 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.9155 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.877363 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:50.9158 UTC hyperparameters_optimizer.cc:582] [56/500] Score: -0.877363 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:50.9171 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.9171 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.9173 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.9322 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292667 train-accuracy:0.599691 valid-loss:1.277179 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.9755 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.847727\n",
      "[INFO 24-02-22 06:45:50.9755 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.9757 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.847727 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:50.9762 UTC hyperparameters_optimizer.cc:582] [57/500] Score: -0.847727 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:50.9769 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:50.9770 UTC gradient_boosted_trees.cc[INFO 24-02-22 06:45:50.9770 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842974\n",
      "[INFO 24-02-22 06:45:50.9770 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:45:50.9771 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.842974 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:50.9772 UTC hyperparameters_optimizer.cc:582] [58/500] Score: -0.842974 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      ":1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.9775 UTC gradient_boosted_trees.cc:1261] [INFO 24-02-22 06:45:50.9775 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.9777 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:50.9778 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:50.9863 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290440 train-accuracy:0.599691 valid-loss:1.280076 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:50.9926 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229263 train-accuracy:0.599691 valid-loss:1.215434 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.0850 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867761\n",
      "[INFO 24-02-22 06:45:51.0851 UTC gradient_boosted_trees.cc:271] Truncates the model to 105 tree(s) i.e. 105  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.0853 UTC gradient_boosted_trees.cc:334] Final model num-trees:105 valid-loss:0.867761 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:51.0866 UTC hyperparameters_optimizer.cc:582] [59/500] Score: -0.867761 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:51.0871 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.0871 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.0873 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.0987 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326501 train-accuracy:0.599691 valid-loss:1.301450 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.2619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843369\n",
      "[INFO 24-02-22 06:45:51.2619 UTC gradient_boosted_trees.cc:271] Truncates the model to 177 tree(s) i.e. 177  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.2627 UTC gradient_boosted_trees.cc:334] Final model num-trees:177 valid-loss:0.843369 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:51.2634 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.2634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.2636 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.2655 UTC hyperparameters_optimizer.cc:582] [60/500] Score: -0.843369 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:51.2701 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235285 train-accuracy:0.599691 valid-loss:1.228840 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.3009 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848051\n",
      "[INFO 24-02-22 06:45:51.3010 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.3012 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.848051 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:51.3016 UTC hyperparameters_optimizer.cc:582] [61/500] Score: -0.848051 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:51.3027 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.3028 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.3031 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.3126 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840029\n",
      "[INFO 24-02-22 06:45:51.3126 UTC gradient_boosted_trees.cc:271] Truncates the model to 261 tree(s) i.e. 261  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.3127 UTC gradient_boosted_trees.cc:334] Final model num-trees:261 valid-loss:0.840029 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:51.3133 UTC hyperparameters_optimizer.cc:582] [62/500] Score: -0.840029 / -0.787401 HParams: [INFO 24-02-22 06:45:51.3135 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.3135 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:51.3142 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.3206 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229674 train-accuracy:0.599691 valid-loss:1.231917 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.3271 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850837\n",
      "[INFO 24-02-22 06:45:51.3272 UTC gradient_boosted_trees.cc:271] Truncates the model to 164 tree(s) i.e. 164  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.3273 UTC gradient_boosted_trees.cc:334] Final model num-trees:164 valid-loss:0.850837 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:51.3277 UTC hyperparameters_optimizer.cc:582] [63/500] Score: -0.850837 / -0.787401 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:51.3285 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.3286 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.3288 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.3312 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286460 train-accuracy:0.599691 valid-loss:1.271635 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.3380 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299536 train-accuracy:0.599691 valid-loss:1.282935 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.4937 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.758798\n",
      "[INFO 24-02-22 06:45:51.4937 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.4939 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.758798 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:51.4944 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.4945 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.4945 UTC hyperparameters_optimizer.cc:582] [64/500] Score: -0.758798 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:51.4948 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.4953 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.909965\n",
      "[INFO 24-02-22 06:45:51.4953 UTC gradient_boosted_trees.cc:271] Truncates the model to 33 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.4958 UTC gradient_boosted_trees.cc:334] Final model num-trees:33 valid-loss:0.909965 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:51.4965 UTC hyperparameters_optimizer.cc:582] [65/500] Score: -0.909965 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:51.4979 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.4981 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.4983 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.4994 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328051 train-accuracy:0.599691 valid-loss:1.303930 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.5110 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321813 train-accuracy:0.599691 valid-loss:1.300878 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.5846 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.619778 train-accuracy:0.884080 valid-loss:0.850183 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:51.5847 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.5847 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.849889 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:51.5853 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.5853 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.5855 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.5887 UTC hyperparameters_optimizer.cc:582] [66/500] Score: -0.849889 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:51.6016 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842691\n",
      "[INFO 24-02-22 06:45:51.6016 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.6017 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.842691 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:51.6020 UTC hyperparameters_optimizer.cc:582] [67/500] Score: -0.842691 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:51.6022 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.6022 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.6025 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.6039 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243126 train-accuracy:0.599691 valid-loss:1.245450 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.6189 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321678 train-accuracy:0.599691 valid-loss:1.297279 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.6650 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838923\n",
      "[INFO 24-02-22 06:45:51.6651 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.6653 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.838923 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:51.6664 UTC hyperparameters_optimizer.cc:582] [68/500] Score: -0.838923 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:51.6671 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.6672 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.6679 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.6776 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248908 train-accuracy:0.599691 valid-loss:1.246901 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.7674 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872517\n",
      "[INFO 24-02-22 06:45:51.7675 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.7676 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.872517 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:51.7680 UTC hyperparameters_optimizer.cc:582] [69/500] Score: -0.872517 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:51.7685 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.7685 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.7686 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.7797 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288404 train-accuracy:0.599691 valid-loss:1.277787 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:51.8430 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866987\n",
      "[INFO 24-02-22 06:45:51.8431 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 06:45:51.8432 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.866987 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:51.8438 UTC hyperparameters_optimizer.cc:582] [70/500] Score: -0.866987 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:51.8441 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:51.8441 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:51.8449 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:51.8582 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324076 train-accuracy:0.599691 valid-loss:1.303412 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.1086 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876655\n",
      "[INFO 24-02-22 06:45:52.1090 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.1091 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.876655 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:52.1093 UTC hyperparameters_optimizer.cc:582] [71/500] Score: -0.876655 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:52.1103 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.1103 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.1104 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.1214 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851702\n",
      "[INFO 24-02-22 06:45:52.1214 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.1217 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.851702 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:52.1227 UTC hyperparameters_optimizer.cc:582] [72/500] Score: -0.851702 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:52.1239 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.1239 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.1240 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.1304 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236587 train-accuracy:0.599691 valid-loss:1.246619 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.1500 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321382 train-accuracy:0.599691 valid-loss:1.301534 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.1951 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834659\n",
      "[INFO 24-02-22 06:45:52.1951 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.1952 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.834659 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:52.1958 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.1958 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.1960 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.1987 UTC hyperparameters_optimizer.cc:582] [73/500] Score: -0.834659 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:52.2047 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286572 train-accuracy:0.599691 valid-loss:1.277108 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.2068 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.923587\n",
      "[INFO 24-02-22 06:45:52.2068 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.2072 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.923587 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:52.2084 UTC hyperparameters_optimizer.cc:582] [74/500] Score: -0.923587 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:52.2104 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.2106 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.2110 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.2241 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325547 train-accuracy:0.599691 valid-loss:1.302126 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.2644 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851685\n",
      "[INFO 24-02-22 06:45:52.2644 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.2645 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.851685 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:52.2650 UTC hyperparameters_optimizer.cc:582] [75/500] Score: -0.851685 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:52.2655 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.2655 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.2658 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.2688 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326290 train-accuracy:0.599691 valid-loss:1.303772 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.4845 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851117\n",
      "[INFO 24-02-22 06:45:52.4845 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.4847 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.851117 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:52.4852 UTC hyperparameters_optimizer.cc:582] [76/500] Score: -0.851117 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:52.4860 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.4860 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.4862 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.5004 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322180 train-accuracy:0.599691 valid-loss:1.298601 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.5132 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.906451\n",
      "[INFO 24-02-22 06:45:52.5133 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.5135 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.906451 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:52.5140 UTC hyperparameters_optimizer.cc:582] [77/500] Score: -0.906451 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:52.5142 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.5142 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.5210 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.5453 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321438 train-accuracy:0.599691 valid-loss:1.301863 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.7504 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.583254 train-accuracy:0.891808 valid-loss:0.852778 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:52.7504 UTC gradient_boosted_trees.cc:271] Truncates the model to 277 tree(s) i.e. 277  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.7504 UTC gradient_boosted_trees.cc:334] Final model num-trees:277 valid-loss:0.850376 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:52.7509 UTC hyperparameters_optimizer.cc:582] [78/500] Score: -0.850376 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:52.7513 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.7513 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.7518 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.7617 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321874 train-accuracy:0.599691 valid-loss:1.305339 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.8101 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832839\n",
      "[INFO 24-02-22 06:45:52.8101 UTC gradient_boosted_trees.cc:271] Truncates the model to 90 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.8102 UTC gradient_boosted_trees.cc:334] Final model num-trees:90 valid-loss:0.832839 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:52.8107 UTC hyperparameters_optimizer.cc:582] [79/500] Score: -0.832839 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:52.8112 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.8112 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.8116 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.8233 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322529 train-accuracy:0.599691 valid-loss:1.302170 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.8268 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89632\n",
      "[INFO 24-02-22 06:45:52.8269 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.8272 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.896320 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:52.8277 UTC hyperparameters_optimizer.cc:582] [80/500] Score: -0.89632 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:52.8291 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.8291 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.8293 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.8396 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323234 train-accuracy:0.599691 valid-loss:1.297781 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.8659 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850266\n",
      "[INFO 24-02-22 06:45:52.8660 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.8662 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.850266 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:52.8668 UTC hyperparameters_optimizer.cc:582] [81/500] Score: -0.850266 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:52.8673 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.8674 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.8680 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.8826 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.227562 train-accuracy:0.599691 valid-loss:1.229230 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:52.9265 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827327\n",
      "[INFO 24-02-22 06:45:52.9266 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:45:52.9267 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.827327 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:52.9271 UTC hyperparameters_optimizer.cc:582] [82/500] Score: -0.827327 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:52.9278 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:52.9279 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:52.9280 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:52.9425 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222877 train-accuracy:0.599691 valid-loss:1.224680 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.0650 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876295\n",
      "[INFO 24-02-22 06:45:53.0653 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.0656 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.876295 valid-accuracy:0.818182\n",
      "[[INFO 24-02-22 06:45:53.0664 UTC hyperparameters_optimizer.cc:582] [83/500] Score: -0.876295 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "INFO 24-02-22 06:45:53.0668 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.0669 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.0671 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.0796 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286184 train-accuracy:0.599691 valid-loss:1.275303 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.0892 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842445\n",
      "[INFO 24-02-22 06:45:53.0892 UTC gradient_boosted_trees.cc:271] Truncates the model to 203 tree(s) i.e. 203  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.0893 UTC gradient_boosted_trees.cc:334] Final model num-trees:203 valid-loss:0.842445 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:53.0899 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.0899 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.0900 UTC hyperparameters_optimizer.cc:582] [84/500] Score: -0.842445 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:53.0902 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.0949 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329622 train-accuracy:0.599691 valid-loss:1.303086 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.1827 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839654\n",
      "[INFO 24-02-22 06:45:53.1827 UTC gradient_boosted_trees.cc:271] Truncates the model to 225 tree(s) i.e. 225  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.1828 UTC gradient_boosted_trees.cc:334] Final model num-trees:225 valid-loss:0.839654 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:53.1832 UTC hyperparameters_optimizer.cc:582] [85/500] Score: -0.839654 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:53.1842 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.1842 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.1844 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.2070 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225415 train-accuracy:0.599691 valid-loss:1.238964 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.2616 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.900662\n",
      "[INFO 24-02-22 06:45:53.2616 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.2618 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.900662 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:53.2639 UTC hyperparameters_optimizer.cc:582] [86/500] Score: -0.900662 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:53.2647 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.2647 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.2649 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.2753 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326253 train-accuracy:0.599691 valid-loss:1.299680 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.6476 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.937712\n",
      "[INFO 24-02-22 06:45:53.6476 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.6479 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.937712 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:53.6484 UTC hyperparameters_optimizer.cc:582] [87/500] Score: -0.937712 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:53.6493 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.6493 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.6497 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.6604 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321537 train-accuracy:0.599691 valid-loss:1.299628 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:53.8431 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848033\n",
      "[INFO 24-02-22 06:45:53.8431 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:45:53.8433 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.848033 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:53.8437 UTC hyperparameters_optimizer.cc:582] [88/500] Score: -0.848033 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:53.8446 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:53.8446 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:53.8448 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:53.8584 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229778 train-accuracy:0.599691 valid-loss:1.261166 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.0087 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881817\n",
      "[INFO 24-02-22 06:45:54.0087 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.0089 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.881817 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.0092 UTC hyperparameters_optimizer.cc:582] [89/500] Score: -0.881817 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.0097 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.0097 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.0100 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.0235 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290843 train-accuracy:0.599691 valid-loss:1.274431 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.3646 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842427\n",
      "[INFO 24-02-22 06:45:54.3647 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.3649 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.842427 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.3655 UTC hyperparameters_optimizer.cc:582] [90/500] Score: -0.842427 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:54.3663 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.3666 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.3670 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.3731 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.882998\n",
      "[INFO 24-02-22 06:45:54.3733 UTC gradient_boosted_trees.cc:271] Truncates the model to 131 tree(s) i.e. 131  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.3738 UTC gradient_boosted_trees.cc:334] Final model num-trees:131 valid-loss:0.882998 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:54.3756 UTC hyperparameters_optimizer.cc:582] [91/500] Score: -0.882998 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:54.3796 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.3797 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.3798 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246865 train-accuracy:0.599691 valid-loss:1.240165 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.3801 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4015 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287206 train-accuracy:0.599691 valid-loss:1.282408 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.4048 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.884995\n",
      "[INFO 24-02-22 06:45:54.4049 UTC gradient_boosted_trees.cc:271] Truncates the model to 97 tree(s) i.e. 97  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.4052 UTC gradient_boosted_trees.cc:334] Final model num-trees:97 valid-loss:0.884995 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.4053 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875413\n",
      "[INFO 24-02-22 06:45:54.4053 UTC gradient_boosted_trees.cc:271] Truncates the model to 111 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.4056 UTC gradient_boosted_trees.cc:334] Final model num-trees:111 valid-loss:0.875413 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.4065 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.4066 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.4068 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4075 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.4075 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.4077 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4087 UTC hyperparameters_optimizer.cc:582] [92/500] Score: -0.884995 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.4093 UTC hyperparameters_optimizer.cc:582] [93/500] Score: -0.875413 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:54.4226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284457 train-accuracy:0.599691 valid-loss:1.274963 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.4252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321726 train-accuracy:0.599691 valid-loss:1.300783 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.4539 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873489\n",
      "[INFO 24-02-22 06:45:54.4539 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.4543 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.873489 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.4553 UTC hyperparameters_optimizer.cc:582] [94/500] Score: -0.873489 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.4557 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873904\n",
      "[INFO 24-02-22 06:45:54.4558 UTC gradient_boosted_trees.cc:271] Truncates the model to 113 tree(s) i.e. 113  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.4560 UTC gradient_boosted_trees.cc:334] Final model num-trees:113 valid-loss:0.873904 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.4560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.4560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.4568 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4573 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.4573 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.4575 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.4587 UTC hyperparameters_optimizer.cc:582] [95/500] Score: -0.873904 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:54.4765 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321857 train-accuracy:0.599691 valid-loss:1.299707 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.4768 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293400 train-accuracy:0.599691 valid-loss:1.278410 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.5096 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883627\n",
      "[INFO 24-02-22 06:45:54.5096 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.5098 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.883627 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.5103 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.5103 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.5105 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.5121 UTC hyperparameters_optimizer.cc:582] [96/500] Score: -0.883627 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.5286 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320953 train-accuracy:0.599691 valid-loss:1.300458 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.6652 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.818453\n",
      "[INFO 24-02-22 06:45:54.6653 UTC gradient_boosted_trees.cc:271] Truncates the model to 192 tree(s) i.e. 192  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.6653 UTC gradient_boosted_trees.cc:334] Final model num-trees:192 valid-loss:0.818453 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.6668 UTC hyperparameters_optimizer.cc:582] [97/500] Score: -0.818453 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:54.6678 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.6678 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.6680 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.6696 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.301557 train-accuracy:0.599691 valid-loss:1.290466 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.6942 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851904\n",
      "[INFO 24-02-22 06:45:54.6943 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.6946 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.851904 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:54.6959 UTC hyperparameters_optimizer.cc:582] [98/500] Score: -0.851904 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:54.6972 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.6972 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.6974 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.7104 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236315 train-accuracy:0.599691 valid-loss:1.244088 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.7184 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883665\n",
      "[INFO 24-02-22 06:45:54.7184 UTC gradient_boosted_trees.cc:271] Truncates the model to 69 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.7185 UTC gradient_boosted_trees.cc:334] Final model num-trees:69 valid-loss:0.883665 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.7190 UTC hyperparameters_optimizer.cc:582] [99/500] Score: -0.883665 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:54.7196 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.7197 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.7198 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.7365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321471 train-accuracy:0.599691 valid-loss:1.295724 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.7714 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858828\n",
      "[INFO 24-02-22 06:45:54.7715 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.7717 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.858828 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.7727 UTC hyperparameters_optimizer.cc:582] [100/500] Score: -0.858828 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:54.7734 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.7735 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.7743 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.7836 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.630140 train-accuracy:0.877898 valid-loss:0.835657 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:54.7836 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.7837 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.834202 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:54.7841 UTC hyperparameters_optimizer.cc:582] [101/500] Score: -0.834202 / -0.758798 HParams: [INFOfields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      " 24-02-22 06:45:54.7841 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.7841 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.7844 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.7906 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284991 train-accuracy:0.599691 valid-loss:1.283349 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.8013 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224230 train-accuracy:0.599691 valid-loss:1.230998 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:54.8587 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848704\n",
      "[INFO 24-02-22 06:45:54.8588 UTC gradient_boosted_trees.cc:271] Truncates the model to 168 tree(s) i.e. 168  iteration(s).\n",
      "[INFO 24-02-22 06:45:54.8590 UTC gradient_boosted_trees.cc:334] Final model num-trees:168 valid-loss:0.848704 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:54.8606 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:54.8606 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:54.8608 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:54.8624 UTC hyperparameters_optimizer.cc:582] [102/500] Score: -0.848704 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:54.8776 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240591 train-accuracy:0.599691 valid-loss:1.250737 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.1457 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823628\n",
      "[INFO 24-02-22 06:45:55.1458 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.1459 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.823628 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:55.1466 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.1466 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.1466 UTC hyperparameters_optimizer.cc:582] [103/500] Score: -0.823628 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:55.1470 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.1606 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241544 train-accuracy:0.599691 valid-loss:1.246401 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.3254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849427\n",
      "[INFO 24-02-22 06:45:55.3254 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.3256 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.849427 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.3262 UTC hyperparameters_optimizer.cc:582] [104/500] Score: -0.849427 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:55.3266 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.3267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.3272 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.3326 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326646 train-accuracy:0.599691 valid-loss:1.301765 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.3468 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.888552\n",
      "[INFO 24-02-22 06:45:55.3472 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.3478 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.888552 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:55.3493 UTC hyperparameters_optimizer.cc:582] [105/500] Score: -0.888552 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:55.3498 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.3499 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.3508 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.3599 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266087 train-accuracy:0.599691 valid-loss:1.262687 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.6215 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.894546\n",
      "[INFO 24-02-22 06:45:55.6215 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.6218 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.894546 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:55.6280 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.88059\n",
      "[INFO 24-02-22 06:45:55.6280 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.6296 UTC hyperparameters_optimizer.cc:582] [106/500] Score: -0.894546 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:55.6299 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.880590 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.6303 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.6303 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.6307 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.6307 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.6308 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.6309 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.6357 UTC hyperparameters_optimizer.cc:582] [107/500] Score: -0.88059 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:55.6381 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.256282 train-accuracy:0.599691 valid-loss:1.249756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.6450 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.327334 train-accuracy:0.599691 valid-loss:1.303216 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.7141 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855232\n",
      "[INFO 24-02-22 06:45:55.7141 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.7143 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.855232 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:55.7150 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.7150 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.7151 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.7187 UTC hyperparameters_optimizer.cc:582] [108/500] Score: -0.855232 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:55.7255 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324626 train-accuracy:0.599691 valid-loss:1.303213 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.7460 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.811014\n",
      "[INFO 24-02-22 06:45:55.7460 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.7462 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.811014 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.7465 UTC hyperparameters_optimizer.cc:582] [109/500] Score: -0.811014 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:55.7469 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.7469 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.7471 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.7648 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284398 train-accuracy:0.599691 valid-loss:1.286776 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.7717 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.476921 train-accuracy:0.924266 valid-loss:0.825049 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:55.7717 UTC gradient_boosted_trees.cc:271] Truncates the model to 281 tree(s) i.e. 281  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.7717 UTC gradient_boosted_trees.cc:334] Final model num-trees:281 valid-loss:0.824350 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.7725 UTC hyperparameters_optimizer.cc:582] [110/500] Score: -0.82435 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:55.7738 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.7738 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.7741 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.7874 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284343 train-accuracy:0.599691 valid-loss:1.271003 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.8541 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.90319\n",
      "[INFO 24-02-22 06:45:55.8541 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.8544 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.903190 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:55.8551 UTC hyperparameters_optimizer.cc:582] [111/500] Score: -0.90319 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:55.8556 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.8556 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.8559 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.8656 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323505 train-accuracy:0.599691 valid-loss:1.299270 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.8843 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.890846\n",
      "[INFO 24-02-22 06:45:55.8843 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.8855 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.890846 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.8887 UTC hyperparameters_optimizer.cc:582] [112/500] Score: -0.890846 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:55.8899 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.8899 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.8901 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.8991 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294888 train-accuracy:0.599691 valid-loss:1.280547 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:55.9444 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842825\n",
      "[INFO 24-02-22 06:45:55.9444 UTC gradient_boosted_trees.cc:271] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
      "[INFO 24-02-22 06:45:55.9446 UTC gradient_boosted_trees.cc:334] Final model num-trees:23 valid-loss:0.842825 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:55.9449 UTC hyperparameters_optimizer.cc:582] [113/500] Score: -0.842825 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:55.9452 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:55.9453 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:55.9459 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:55.9740 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.225948 train-accuracy:0.599691 valid-loss:1.241712 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.0807 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806746\n",
      "[INFO 24-02-22 06:45:56.0808 UTC gradient_boosted_trees.cc:271] Truncates the model to 124 tree(s) i.e. 124  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.0809 UTC gradient_boosted_trees.cc:334] Final model num-trees:124 valid-loss:0.806746 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:45:56.0811 UTC hyperparameters_optimizer.cc:582] [114/500] Score: -0.806746 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:56.0814 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.0814 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.0816 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.0993 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238274 train-accuracy:0.599691 valid-loss:1.234636 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.1823 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845586\n",
      "[INFO 24-02-22 06:45:56.1824 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.1826 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.845586 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:56.1833 UTC hyperparameters_optimizer.cc:582] [115/500] Score: -0.845586 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:56.1840 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.1840 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.1842 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.1942 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292518 train-accuracy:0.599691 valid-loss:1.276618 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.3668 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.894137\n",
      "[INFO 24-02-22 06:45:56.3669 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.3672 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.894137 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:56.3689 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.3690 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.3692 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.3694 UTC hyperparameters_optimizer.cc:582] [116/500] Score: -0.894137 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:56.3882 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324088 train-accuracy:0.599691 valid-loss:1.303607 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.3943 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836579\n",
      "[INFO 24-02-22 06:45:56.3943 UTC gradient_boosted_trees.cc:271] Truncates the model to 78 tree(s) i.e. 78  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.3943 UTC gradient_boosted_trees.cc:334] Final model num-trees:78 valid-loss:0.836579 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:56.3947 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.3947 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.3953 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.3987 UTC hyperparameters_optimizer.cc:582] [117/500] Score: -0.836579 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:56.4045 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247594 train-accuracy:0.599691 valid-loss:1.248466 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.4996 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849021\n",
      "[INFO 24-02-22 06:45:56.4996 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.4999 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.849021 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:56.5008 UTC hyperparameters_optimizer.cc:582] [118/500] Score: -0.849021 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:56.5030 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.5030 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.5032 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.5187 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234196 train-accuracy:0.599691 valid-loss:1.232174 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.7319 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880967\n",
      "[INFO 24-02-22 06:45:56.7319 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.7323 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.880967 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:56.7327 UTC hyperparameters_optimizer.cc:582] [119/500] Score: -0.880967 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:56.7337 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.7337 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.7340 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.7535 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282339 train-accuracy:0.599691 valid-loss:1.276376 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.8866 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839515\n",
      "[INFO 24-02-22 06:45:56.8866 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.8868 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.839515 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:56.8876 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.8876 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.8877 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.8893 UTC hyperparameters_optimizer.cc:582] [120/500] Score: -0.839515 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:56.8930 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246510 train-accuracy:0.599691 valid-loss:1.249096 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.9001 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871688\n",
      "[INFO 24-02-22 06:45:56.9001 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.9004 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.871688 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:56.9016 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.9017 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.9019 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:56.9054 UTC hyperparameters_optimizer.cc:582] [121/500] Score: -0.871688 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:56.9105 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236788 train-accuracy:0.599691 valid-loss:1.237309 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:56.9914 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852859\n",
      "[INFO 24-02-22 06:45:56.9914 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:45:56.9916 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.852859 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:56.9919 UTC hyperparameters_optimizer.cc:582] [122/500] Score: -0.852859 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:56.9924 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:56.9924 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:56.9927 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.0185 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226874 train-accuracy:0.599691 valid-loss:1.245509 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.0648 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.828724\n",
      "[INFO 24-02-22 06:45:57.0649 UTC gradient_boosted_trees.cc:271] Truncates the model to 250 tree(s) i.e. 250  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.0649 UTC gradient_boosted_trees.cc:334] Final model num-trees:250 valid-loss:0.828724 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:57.0654 UTC hyperparameters_optimizer.cc:582] [123/500] Score: -0.828724 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:57.0657 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.0657 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.0661 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.0761 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840335\n",
      "[INFO 24-02-22 06:45:57.0761 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.0762 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.840335 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.0768 UTC hyperparameters_optimizer.cc:582] [124/500] Score: -0.840335 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:57.0805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.0805 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.0807 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.0824 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288320 train-accuracy:0.599691 valid-loss:1.277649 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1084 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287834 train-accuracy:0.599691 valid-loss:1.277494 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1300 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.870566\n",
      "[INFO 24-02-22 06:45:57.1300 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.1303 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.870566 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:57.1308 UTC hyperparameters_optimizer.cc:582] [125/500] Score: -0.870566 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:57.1312 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.1312 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.1317 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.1489 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324613 train-accuracy:0.599691 valid-loss:1.299334 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1671 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.837656\n",
      "[INFO 24-02-22 06:45:57.1672 UTC gradient_boosted_trees.cc:271] Truncates the model to 258 tree(s) i.e. 258  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.1672 UTC gradient_boosted_trees.cc:334] Final model num-trees:258 valid-loss:0.837656 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.1678 UTC hyperparameters_optimizer.cc:582] [126/500] Score: -0.837656 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:57.1692 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.1693 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.1698 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.1849 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866406\n",
      "[INFO 24-02-22 06:45:57.1849 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.1850 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.866406 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.1855 UTC hyperparameters_optimizer.cc:582] [127/500] Score: -0.866406 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:57.1865 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.1865 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.1867 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.1877 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243688 train-accuracy:0.599691 valid-loss:1.255966 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1967 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322819 train-accuracy:0.599691 valid-loss:1.298133 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.1972 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881582\n",
      "[INFO 24-02-22 06:45:57.1972 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.1975 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.881582 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:57.1978 UTC hyperparameters_optimizer.cc:582] [128/500] Score: -0.881582 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:57.1983 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.1983 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.1987 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.2127 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325571 train-accuracy:0.599691 valid-loss:1.304232 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.3259 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858251\n",
      "[INFO 24-02-22 06:45:57.3259 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.3261 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.858251 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:57.3269 UTC hyperparameters_optimizer.cc:582] [129/500] Score: -0.858251 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:57.3276 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.3276 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.3278 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.3377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322770 train-accuracy:0.599691 valid-loss:1.298749 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.5135 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86566\n",
      "[INFO 24-02-22 06:45:57.5137 UTC gradient_boosted_trees.cc:271] Truncates the model to 131 tree(s) i.e. 131  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.5140 UTC gradient_boosted_trees.cc:334] Final model num-trees:131 valid-loss:0.865660 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:57.5147 UTC hyperparameters_optimizer.cc:582] [130/500] Score: -0.86566 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:57.5165 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.5165 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.5168 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.5252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298239 train-accuracy:0.599691 valid-loss:1.279649 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.5350 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844609\n",
      "[INFO 24-02-22 06:45:57.5351 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.5353 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.844609 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.5360 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.5361 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.5364 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.5387 UTC hyperparameters_optimizer.cc:582] [131/500] Score: -0.844609 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:57.5457 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232166 train-accuracy:0.599691 valid-loss:1.245184 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.5472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868087\n",
      "[INFO 24-02-22 06:45:57.5473 UTC gradient_boosted_trees.cc:271] Truncates the model to 151 tree(s) i.e. 151  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.5475 UTC gradient_boosted_trees.cc:334] Final model num-trees:151 valid-loss:0.868087 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:57.5489 UTC hyperparameters_optimizer.cc:582] [132/500] Score: -0.868087 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:57.5503 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.5505 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.5509 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.5646 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232204 train-accuracy:0.599691 valid-loss:1.237812 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.6116 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.821189\n",
      "[INFO 24-02-22 06:45:57.6116 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.6120 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.821189 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:57.6126 UTC hyperparameters_optimizer.cc:582] [133/500] Score: -0.821189 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:57.6128 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.6128 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.6130 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.6226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323450 train-accuracy:0.599691 valid-loss:1.297224 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.7260 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842676\n",
      "[INFO 24-02-22 06:45:57.7260 UTC gradient_boosted_trees.cc:271] Truncates the model to 151 tree(s) i.e. 151  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.7261 UTC gradient_boosted_trees.cc:334] Final model num-trees:151 valid-loss:0.842676 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:45:57.7271 UTC hyperparameters_optimizer.cc:582] [134/500] Score: -0.842676 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:57.7277 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.7277 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.7286 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.7433 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324091 train-accuracy:0.599691 valid-loss:1.296394 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.7812 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845881\n",
      "[INFO 24-02-22 06:45:57.7812 UTC gradient_boosted_trees.cc:271] Truncates the model to 140 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.7815 UTC gradient_boosted_trees.cc:334] Final model num-trees:140 valid-loss:0.845881 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:57.7828 UTC hyperparameters_optimizer.cc:582] [135/500] Score: -0.845881 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:57.7842 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.7842 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.7844 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.7958 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324051 train-accuracy:0.599691 valid-loss:1.302081 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:57.9601 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.899409\n",
      "[INFO 24-02-22 06:45:57.9601 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:45:57.9604 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.899409 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:45:57.9609 UTC hyperparameters_optimizer.cc:582] [136/500] Score: -0.899409 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:57.9614 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:57.9614 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:57.9616 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:57.9712 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323619 train-accuracy:0.599691 valid-loss:1.302112 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.0054 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891364\n",
      "[INFO 24-02-22 06:45:58.0054 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.0056 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.891364 valid-accuracy:0.772727\n",
      "[[INFO 24-02-22 06:45:58.0061 UTC hyperparameters_optimizer.cc:582] [137/500] Score: -0.891364 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "INFO 24-02-22 06:45:58.0062 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.0062 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.0067 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.0192 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229498 train-accuracy:0.599691 valid-loss:1.245338 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.1479 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859885\n",
      "[INFO 24-02-22 06:45:58.1479 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.1481 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.859885 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.1508 UTC gradient_boosted_trees.cc:[INFO 24-02-22 06:45:58.1524 UTC hyperparameters_optimizer.cc:582] 591] Default loss set to [138/BINOMIAL_LOG_LIKELIHOOD\n",
      "500] Score: -0.859885 / -0.758798 HParams: [INFO 24-02-22 06:45:58.1525 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.1530 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.1694 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231566 train-accuracy:0.599691 valid-loss:1.242215 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.1879 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846067\n",
      "[INFO 24-02-22 06:45:58.1880 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.1882 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.846067 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:58.1891 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.1891 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.1892 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.1919 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328953 train-accuracy:0.599691 valid-loss:1.304642 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.1921 UTC hyperparameters_optimizer.cc:582] [139/500] Score: -0.846067 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.2933 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.830987\n",
      "[INFO 24-02-22 06:45:58.2934 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.2936 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.830987 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:58.2939 UTC hyperparameters_optimizer.cc:582] [140/500] Score: -0.830987 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:58.2962 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.2963 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.2965 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.3056 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290789 train-accuracy:0.599691 valid-loss:1.277578 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.4010 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834941\n",
      "[INFO 24-02-22 06:45:58.4010 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.4011 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.834941 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:58.4013 UTC hyperparameters_optimizer.cc:582] [141/500] Score: -0.834941 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.4024 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.4026 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.4029 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.4170 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321871 train-accuracy:0.599691 valid-loss:1.303112 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.5752 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845996\n",
      "[INFO 24-02-22 06:45:58.5752 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.5753 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.845996 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.5757 UTC hyperparameters_optimizer.cc:582] [142/500] Score: -0.845996 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:58.5761 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.5761 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.5765 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.5800 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.88359\n",
      "[INFO 24-02-22 06:45:58.5800 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.5803 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.883590 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.5811 UTC hyperparameters_optimizer.cc:582] [143/500] Score: -0.88359 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.5827 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.5828 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.5830 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.5845 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.249482 train-accuracy:0.599691 valid-loss:1.259961 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.6072 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222709 train-accuracy:0.599691 valid-loss:1.245217 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.7198 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867383\n",
      "[INFO 24-02-22 06:45:58.7198 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.7200 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.867383 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.7205 UTC hyperparameters_optimizer.cc:582] [144/500] Score: -0.867383 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.7211 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.7211 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.7214 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.7251 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299191 train-accuracy:0.599691 valid-loss:1.287499 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.9340 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867043\n",
      "[INFO 24-02-22 06:45:58.9341 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.9343 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.867043 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.9347 UTC hyperparameters_optimizer.cc:582] [145/500] Score: -0.867043 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:58.9356 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.9356 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.9359 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:58.9452 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286003 train-accuracy:0.599691 valid-loss:1.269670 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:58.9801 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868128\n",
      "[INFO 24-02-22 06:45:58.9802 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:45:58.9804 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.868128 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:58.9810 UTC hyperparameters_optimizer.cc:582] [146/500] Score: -0.868128 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:58.9821 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:58.9821 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:58.9824 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.0007 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292728 train-accuracy:0.599691 valid-loss:1.278734 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.1461 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.665948 train-accuracy:0.877898 valid-loss:0.862057 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.1461 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.1480 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.862057 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.1485 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.1485 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.1486 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.1524 UTC hyperparameters_optimizer.cc:582] [147/500] Score: -0.862057 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.1655 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288129 train-accuracy:0.599691 valid-loss:1.269813 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.1941 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.8915\n",
      "[INFO 24-02-22 06:45:59.1942 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.1946 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.891500 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:59.1972 UTC hyperparameters_optimizer.cc:582] [148/500] Score: -0.8915 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.2002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.2003 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.2006 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.2160 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.250557 train-accuracy:0.599691 valid-loss:1.250360 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.3566 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.841222\n",
      "[INFO 24-02-22 06:45:59.3566 UTC gradient_boosted_trees.cc:271] Truncates the model to 110 tree(s) i.e. 110  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.3569 UTC gradient_boosted_trees.cc:334] Final model num-trees:110 valid-loss:0.841222 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:59.3578 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.3578 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.3580 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.3587 UTC hyperparameters_optimizer.cc:582] [149/500] Score: -0.841222 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.3743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240513 train-accuracy:0.599691 valid-loss:1.236605 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.4124 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839641\n",
      "[INFO 24-02-22 06:45:59.4125 UTC gradient_boosted_trees.cc:271] Truncates the model to 154 tree(s) i.e. 154  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.4125 UTC gradient_boosted_trees.cc:334] Final model num-trees:154 valid-loss:0.839641 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.4129 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.4130 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.4130 UTC hyperparameters_optimizer.cc:582] [150/500] Score: -0.839641 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:59.4133 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.4359 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.280830 train-accuracy:0.599691 valid-loss:1.269141 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.4762 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.828555\n",
      "[INFO 24-02-22 06:45:59.4762 UTC gradient_boosted_trees.cc:271] Truncates the model to 75 tree(s) i.e. 75  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.4763 UTC gradient_boosted_trees.cc:334] Final model num-trees:75 valid-loss:0.828555 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.4765 UTC hyperparameters_optimizer.cc:582] [151/500] Score: -0.828555 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.4769 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.4770 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.4772 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.4903 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243165 train-accuracy:0.599691 valid-loss:1.253930 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5050 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849009\n",
      "[INFO 24-02-22 06:45:59.5050 UTC gradient_boosted_trees.cc:271] Truncates the model to 158 tree(s) i.e. 158  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5051 UTC gradient_boosted_trees.cc:334] Final model num-trees:158 valid-loss:0.849009 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:59.5064 UTC hyperparameters_optimizer.cc:582] [152/500] Score: -0.849009 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:45:59.5069 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5070 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.5076 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.5111 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849079\n",
      "[INFO 24-02-22 06:45:59.5112 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5113 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.849079 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.5119 UTC hyperparameters_optimizer.cc:582] [153/500] Score: -0.849079 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:45:59.5127 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5127 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.5129 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.5159 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867116\n",
      "[INFO 24-02-22 06:45:59.5159 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5161 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.867116 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:45:59.5169 UTC hyperparameters_optimizer.cc:582] [154/500] Score: -0.867116 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:59.5172 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.909698\n",
      "[INFO 24-02-22 06:45:59.5172 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5174 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.909698 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.5175 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302074 train-accuracy:0.599691 valid-loss:1.284614 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5180 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5180 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.5181 UTC hyperparameters_optimizer.cc:582] [155/500] Score: -0.909698 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.5184 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5184 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.5185 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.5186 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.5251 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.303281 train-accuracy:0.599691 valid-loss:1.286197 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5299 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236326 train-accuracy:0.599691 valid-loss:1.239036 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5405 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321382 train-accuracy:0.599691 valid-loss:1.301534 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.5965 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881148\n",
      "[INFO 24-02-22 06:45:59.5966 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.5968 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.881148 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:45:59.5976 UTC hyperparameters_optimizer.cc:582] [156/500] Score: -0.881148 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:45:59.5982 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.5982 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.6004 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.6205 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291178 train-accuracy:0.599691 valid-loss:1.279230 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.7239 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.886151\n",
      "[INFO 24-02-22 06:45:59.7239 UTC gradient_boosted_trees.cc:271] Truncates the model to 178 tree(s) i.e. 178  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.7241 UTC gradient_boosted_trees.cc:334] Final model num-trees:178 valid-loss:0.886151 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.7253 UTC hyperparameters_optimizer.cc:582] [157/500] Score: -0.886151 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:59.7279 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.7279 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.7288 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.7431 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324904 train-accuracy:0.599691 valid-loss:1.300962 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:45:59.8839 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866793\n",
      "[INFO 24-02-22 06:45:59.8839 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:45:59.8842 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.866793 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:45:59.8849 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:45:59.8849 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:45:59.8851 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:45:59.8879 UTC hyperparameters_optimizer.cc:582] [158/500] Score: -0.866793 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:45:59.8970 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323661 train-accuracy:0.599691 valid-loss:1.300292 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.1692 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846071\n",
      "[INFO 24-02-22 06:46:00.1692 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.1694 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.846071 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:00.1702 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.1702 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.1704 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.1707 UTC hyperparameters_optimizer.cc:582] [159/500] Score: -0.846071 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:00.1818 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234480 train-accuracy:0.599691 valid-loss:1.239550 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.2073 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844673\n",
      "[INFO 24-02-22 06:46:00.2073 UTC gradient_boosted_trees.cc:271] Truncates the model to 165 tree(s) i.e. 165  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.2075 UTC gradient_boosted_trees.cc:334] Final model num-trees:165 valid-loss:0.844673 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:00.2091 UTC hyperparameters_optimizer.cc:582] [160/500] Score: -0.844673 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.2106 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.2108 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.2113 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.2258 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290114 train-accuracy:0.599691 valid-loss:1.275710 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.2793 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832439\n",
      "[INFO 24-02-22 06:46:00.2793 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.2793 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.832439 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:00.2795 UTC hyperparameters_optimizer.cc:582] [161/500] Score: -0.832439 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:00.2798 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.2798 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.2800 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.2809 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.812552\n",
      "[INFO 24-02-22 06:46:00.2809 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.2810 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.812552 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:00.2813 UTC hyperparameters_optimizer.cc:582] [162/500] Score: -0.812552 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.2818 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.2820 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.2824 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.2828 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883554\n",
      "[INFO 24-02-22 06:46:00.2828 UTC gradient_boosted_trees.cc:271] Truncates the model to 129 tree(s) i.e. 129  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.2830 UTC gradient_boosted_trees.cc:334] Final model num-trees:129 valid-loss:0.883554 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:00.2845 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.2845 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.2847 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.2854 UTC hyperparameters_optimizer.cc:582] [163/500] Score: -0.883554 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.2911 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246292 train-accuracy:0.599691 valid-loss:1.253693 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.2980 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320625 train-accuracy:0.599691 valid-loss:1.301433 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.2984 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.267449 train-accuracy:0.599691 valid-loss:1.260474 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.3297 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.79449\n",
      "[INFO 24-02-22 06:46:00.3298 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.3299 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.794490 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:00.3302 UTC hyperparameters_optimizer.cc:582] [164/500] Score: -0.79449 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.3306 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.3306 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.3309 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.3363 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.250811 train-accuracy:0.599691 valid-loss:1.251427 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.3933 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836357\n",
      "[INFO 24-02-22 06:46:00.3933 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.3935 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.836357 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:00.3941 UTC hyperparameters_optimizer.cc:582] [165/500] Score: -0.836357 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:00.3952 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.3955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.3960 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.3990 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262917 train-accuracy:0.599691 valid-loss:1.255451 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.4302 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855804\n",
      "[INFO 24-02-22 06:46:00.4302 UTC gradient_boosted_trees.cc:271] Truncates the model to 163 tree(s) i.e. 163  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.4304 UTC gradient_boosted_trees.cc:334] Final model num-trees:163 valid-loss:0.855804 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:00.4314 UTC hyperparameters_optimizer.cc:582] [166/500] Score: -0.855804 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:00.4318 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.4318 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.4326 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.4509 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292517 train-accuracy:0.599691 valid-loss:1.282027 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.5316 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.816336\n",
      "[INFO 24-02-22 06:46:00.5316 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.5318 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.816336 valid-accuracy:0.833333\n",
      "[[INFO 24-02-22 06:46:00.5324 UTC hyperparameters_optimizer.cc:582] [167/500] Score: -0.816336 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "INFO 24-02-22 06:46:00.5327 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.5327 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.5330 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.5505 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226879 train-accuracy:0.599691 valid-loss:1.241126 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.7037 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.858464\n",
      "[INFO 24-02-22 06:46:00.7038 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.7038 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.858464 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:00.7042 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.7042 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.7044 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.7054 UTC hyperparameters_optimizer.cc:582] [168/500] Score: -0.858464 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:00.7149 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235176 train-accuracy:0.599691 valid-loss:1.223951 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.7425 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850947\n",
      "[INFO 24-02-22 06:46:00.7426 UTC gradient_boosted_trees.cc:271] Truncates the model to 62 tree(s) i.e. 62  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.7427 UTC gradient_boosted_trees.cc:334] Final model num-trees:62 valid-loss:0.850947 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:00.7431 UTC hyperparameters_optimizer.cc:582] [169/500] Score: -0.850947 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:00.7434 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.7434 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.7438 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:00.7497 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324958 train-accuracy:0.599691 valid-loss:1.301035 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:00.9318 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.821383\n",
      "[INFO 24-02-22 06:46:00.9319 UTC gradient_boosted_trees.cc:271] Truncates the model to 257 tree(s) i.e. 257  iteration(s).\n",
      "[INFO 24-02-22 06:46:00.9319 UTC gradient_boosted_trees.cc:334] Final model num-trees:257 valid-loss:0.821383 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:00.9322 UTC hyperparameters_optimizer.cc:582] [170/500] Score: -0.821383 / -0.758798 HParams: [INFO 24-02-22 06:46:00.9324 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:00.9324 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:00.9326 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:00.9435 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323168 train-accuracy:0.599691 valid-loss:1.304000 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.0035 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.915345\n",
      "[INFO 24-02-22 06:46:01.0035 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.0038 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.915345 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:01.0043 UTC hyperparameters_optimizer.cc:582] [171/500] Score: -0.915345 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:01.0049 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.0049 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.0055 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.0239 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230135 train-accuracy:0.599691 valid-loss:1.238685 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.0655 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855706\n",
      "[INFO 24-02-22 06:46:01.0656 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.0658 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.855706 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:01.0661 UTC hyperparameters_optimizer.cc:582] [172/500] Score: -0.855706 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.0669 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.0669 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.0671 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.0800 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233363 train-accuracy:0.599691 valid-loss:1.234657 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.1778 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.828484\n",
      "[INFO 24-02-22 06:46:01.1778 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.1779 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.828484 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:01.1782 UTC hyperparameters_optimizer.cc:582] [173/500] Score: -0.828484 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:01.1786 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.1786 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.1788 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.1907 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284759 train-accuracy:0.599691 valid-loss:1.269787 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.2326 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.812656\n",
      "[INFO 24-02-22 06:46:01.2326 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.2328 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.812656 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.2333 UTC hyperparameters_optimizer.cc:582] [174/500] Score: -0.812656 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:01.2337 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.2337 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.2340 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.2343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.802782\n",
      "[INFO 24-02-22 06:46:01.2343 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.2343 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.802782 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:01.2346 UTC hyperparameters_optimizer.cc:582] [175/500] Score: -0.802782 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.2350 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.2350 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.2353 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.2447 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291651 train-accuracy:0.599691 valid-loss:1.274528 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.2448 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293438 train-accuracy:0.599691 valid-loss:1.270533 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.2628 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838958\n",
      "[INFO 24-02-22 06:46:01.2634 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.2636 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.838958 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.2641 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.2641 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.2643 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.2675 UTC hyperparameters_optimizer.cc:582] [176/500] Score: -0.838958 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.2774 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325116 train-accuracy:0.599691 valid-loss:1.300908 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.3058 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.892219\n",
      "[INFO 24-02-22 06:46:01.3059 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.3061 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.892219 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.3074 UTC hyperparameters_optimizer.cc:582] [177/500] Score: -0.892219 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.3086 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.3087 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.3089 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.3176 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296573 train-accuracy:0.599691 valid-loss:1.279891 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.4113 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850301\n",
      "[INFO 24-02-22 06:46:01.4116 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.4118 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.850301 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:01.4120 UTC hyperparameters_optimizer.cc:582] [178/500] Score: -0.850301 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:01.4143 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.4143 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.4145 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.4298 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323628 train-accuracy:0.599691 valid-loss:1.301374 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.5122 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.87215\n",
      "[INFO 24-02-22 06:46:01.5123 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.5124 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.872150 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.5128 UTC hyperparameters_optimizer.cc:582] [179/500] Score: -0.87215 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:01.5139 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.5139 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.5141 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.5314 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224710 train-accuracy:0.599691 valid-loss:1.241904 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.5915 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86204\n",
      "[INFO 24-02-22 06:46:01.5915 UTC gradient_boosted_trees.cc:271] Truncates the model to 130 tree(s) i.e. 130  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.5917 UTC gradient_boosted_trees.cc:334] Final model num-trees:130 valid-loss:0.862040 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:01.5925 UTC hyperparameters_optimizer.cc:582] [180/500] Score: -0.86204 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:01.5944 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.5944 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.5946 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.6005 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.250313 train-accuracy:0.599691 valid-loss:1.234948 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.6836 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.87804\n",
      "[INFO 24-02-22 06:46:01.6836 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.6838 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.878040 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:01.6843 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.6843 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.6845 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.6846 UTC hyperparameters_optimizer.cc:582] [181/500] Score: -0.87804 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:01.6865 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297247 train-accuracy:0.599691 valid-loss:1.291178 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.7245 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850297\n",
      "[INFO 24-02-22 06:46:01.7245 UTC gradient_boosted_trees.cc:271] Truncates the model to 137 tree(s) i.e. 137  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.7246 UTC gradient_boosted_trees.cc:334] Final model num-trees:137 valid-loss:0.850297 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:01.7255 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.7255 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.7257 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.7287 UTC hyperparameters_optimizer.cc:582] [182/500] Score: -0.850297 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:01.7471 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321078 train-accuracy:0.599691 valid-loss:1.300097 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:01.7875 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859761\n",
      "[INFO 24-02-22 06:46:01.7902 UTC gradient_boosted_trees.cc:271] Truncates the model to 102 tree(s) i.e. 102  iteration(s).\n",
      "[INFO 24-02-22 06:46:01.7903 UTC gradient_boosted_trees.cc:334] Final model num-trees:102 valid-loss:0.859761 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:01.7908 UTC hyperparameters_optimizer.cc:582] [183/500] Score: -0.859761 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:01.7924 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:01.7924 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:01.7926 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:01.8035 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325976 train-accuracy:0.599691 valid-loss:1.303840 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.0154 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.84785\n",
      "[INFO 24-02-22 06:46:02.0154 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.0155 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.847850 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.0159 UTC hyperparameters_optimizer.cc:582] [184/500] Score: -0.84785 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.0165 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.0165 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.0167 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.0220 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263445 train-accuracy:0.599691 valid-loss:1.257060 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.0619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875343\n",
      "[INFO 24-02-22 06:46:02.0619 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.0625 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.875343 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.0628 UTC hyperparameters_optimizer.cc:582] [185/500] Score: -0.875343 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:02.0634 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.0634 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.0635 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.0792 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322625 train-accuracy:0.599691 valid-loss:1.298635 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.1166 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.84172\n",
      "[INFO 24-02-22 06:46:02.1166 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.1168 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.841720 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.1171 UTC hyperparameters_optimizer.cc:582] [186/500] Score: -0.84172 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:02.1174 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.1174 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.1176 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.1288 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326067 train-accuracy:0.599691 valid-loss:1.300447 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.1316 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864405\n",
      "[INFO 24-02-22 06:46:02.1316 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.1318 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.864405 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:02.1326 UTC hyperparameters_optimizer.cc:582] [187/500] Score: -0.864405 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.1331 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.1332 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.1338 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.1387 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257049 train-accuracy:0.599691 valid-loss:1.251756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.2045 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838905\n",
      "[INFO 24-02-22 06:46:02.2045 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.2047 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.838905 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:02.2054 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.2054 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.2056 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.2087 UTC hyperparameters_optimizer.cc:582] [188/500] Score: -0.838905 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:02.2142 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852657\n",
      "[INFO 24-02-22 06:46:02.2142 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.2144 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.852657 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.2147 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244933 train-accuracy:0.599691 valid-loss:1.249263 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.2149 UTC hyperparameters_optimizer.cc:582] [189/500] Score: -0.852657 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.2218 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.2219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.2222 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.2355 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237601 train-accuracy:0.599691 valid-loss:1.224684 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.2439 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875839\n",
      "[INFO 24-02-22 06:46:02.2442 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.2447 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.875839 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.2452 UTC hyperparameters_optimizer.cc:582] [190/500] Score: -0.875839 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:02.2461 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.2462 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.2466 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.2583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242063 train-accuracy:0.599691 valid-loss:1.247574 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.3636 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873904\n",
      "[INFO 24-02-22 06:46:02.3636 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.3638 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.873904 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.3648 UTC hyperparameters_optimizer.cc:582] [191/500] Score: -0.873904 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.3672 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.3673 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.3676 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.3728 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326447 train-accuracy:0.599691 valid-loss:1.300664 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.4263 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859907\n",
      "[INFO 24-02-22 06:46:02.4263 UTC gradient_boosted_trees.cc:271] Truncates the model to 91 tree(s) i.e. 91  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.4264 UTC gradient_boosted_trees.cc:334] Final model num-trees:91 valid-loss:0.859907 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.4269 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.4269 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.4271 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.4276 UTC hyperparameters_optimizer.cc:582] [192/500] Score: -0.859907 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:02.4367 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238566 train-accuracy:0.599691 valid-loss:1.238345 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.5500 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.870194\n",
      "[INFO 24-02-22 06:46:02.5500 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.5503 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.870194 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.5509 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.5509 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.5511 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.5521 UTC hyperparameters_optimizer.cc:582] [193/500] Score: -0.870194 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:02.5604 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290180 train-accuracy:0.599691 valid-loss:1.273954 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.5886 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851558\n",
      "[INFO 24-02-22 06:46:02.5886 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.5886 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.851558 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:02.5889 UTC hyperparameters_optimizer.cc:582] [194/500] Score: -0.851558 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.5892 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.5892 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.5894 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.5984 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326388 train-accuracy:0.599691 valid-loss:1.303335 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.7303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.822583\n",
      "[INFO 24-02-22 06:46:02.7303 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.7303 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.822583 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:02.7305 UTC hyperparameters_optimizer.cc:582] [195/500] Score: -0.822583 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.7309 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.7309 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.7311 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.7484 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322536 train-accuracy:0.599691 valid-loss:1.298201 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.8320 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.853052\n",
      "[INFO 24-02-22 06:46:02.8320 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.8322 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.853052 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:02.8326 UTC hyperparameters_optimizer.cc:582] [196/500] Score: -0.853052 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.8339 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.8341 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.8343 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.8472 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325359 train-accuracy:0.599691 valid-loss:1.302685 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.9511 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.893887\n",
      "[INFO 24-02-22 06:46:02.9511 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.9513 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.893887 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:02.9517 UTC hyperparameters_optimizer.cc:582] [197/500] Score: -0.893887 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:02.9522 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.9523 UTC gradient_boosted_trees.cc:[INFO1218] Training gradient boosted tree on 713 example(s) and 9 feature(s). 24-02-22 06:46:02.9524 UTC \n",
      "[INFO 24-02-22 06:46:02.9528 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845838\n",
      "[INFO 24-02-22 06:46:02.9531 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:02.9533 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.845838 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:02.9536 UTC hyperparameters_optimizer.cc:582] [198/500] Score: -0.845838 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:02.9540 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:02.9541 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:02.9542 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:02.9642 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288404 train-accuracy:0.599691 valid-loss:1.274297 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:02.9650 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288797 train-accuracy:0.599691 valid-loss:1.279459 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.0098 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85871\n",
      "[INFO 24-02-22 06:46:03.0098 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.0102 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.858710 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:03.0116 UTC hyperparameters_optimizer.cc:582] [199/500] Score: -0.85871 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:03.0130 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.0130 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.0133 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.0252 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234473 train-accuracy:0.599691 valid-loss:1.214245 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.0814 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.896019\n",
      "[INFO 24-02-22 06:46:03.0814 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.0815 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.896019 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.0818 UTC hyperparameters_optimizer.cc:582] [200/500] Score: -0.896019 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:03.0826 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.0826 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.0829 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.0955 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322473 train-accuracy:0.599691 valid-loss:1.302628 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.3211 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.885119\n",
      "[INFO 24-02-22 06:46:03.3214 UTC gradient_boosted_trees.cc:271] Truncates the model to 43 tree(s) i.e. 43  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.3216 UTC gradient_boosted_trees.cc:334] Final model num-trees:43 valid-loss:0.885119 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:03.3221 UTC hyperparameters_optimizer.cc:582] [201/500] Score: -0.885119 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:03.3232 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.3234 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.3237 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.3390 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866671\n",
      "[INFO 24-02-22 06:46:03.3391 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.3393 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.866671 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.3411 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.3412 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.3413 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.3423 UTC hyperparameters_optimizer.cc:582] [202/500] Score: -0.866671 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:03.3510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322796 train-accuracy:0.599691 valid-loss:1.300515 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.3617 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292385 train-accuracy:0.599691 valid-loss:1.278833 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.5250 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838083\n",
      "[INFO 24-02-22 06:46:03.5250 UTC gradient_boosted_trees.cc:271] Truncates the model to 196 tree(s) i.e. 196  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.5251 UTC gradient_boosted_trees.cc:334] Final model num-trees:196 valid-loss:0.838083 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:03.5254 UTC hyperparameters_optimizer.cc:582] [203/500] Score: -0.838083 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:03.5263 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.5263 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.5271 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.5312 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295128 train-accuracy:0.599691 valid-loss:1.281679 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.6199 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.829883\n",
      "[INFO 24-02-22 06:46:03.6199 UTC gradient_boosted_trees.cc:271] Truncates the model to 163 tree(s) i.e. 163  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.6201 UTC gradient_boosted_trees.cc:334] Final model num-trees:163 valid-loss:0.829883 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:03.6208 UTC hyperparameters_optimizer.cc:582] [204/500] Score: -0.829883 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:03.6211 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.6219 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.6226 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.6289 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.261358 train-accuracy:0.599691 valid-loss:1.251163 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.7815 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843416\n",
      "[INFO 24-02-22 06:46:03.7815 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.7817 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.843416 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.7825 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.7825 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.7827 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.7854 UTC hyperparameters_optimizer.cc:582] [205/500] Score: -0.843416 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:03.7886 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302953 train-accuracy:0.599691 valid-loss:1.288614 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.9383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845857\n",
      "[INFO 24-02-22 06:46:03.9386 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.9387 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.845857 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.9388 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865152\n",
      "[INFO 24-02-22 06:46:03.9388 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:46:03.9389 UTC hyperparameters_optimizer.cc:582] [206/500] Score: -0.845857 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:03.9390 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.865152 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:03.9394 UTC hyperparameters_optimizer.cc:582] [207/500] Score: -0.865152 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:03.9406 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.9406 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.9408 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.9421 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:03.9436 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:03.9438 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:03.9547 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246865 train-accuracy:0.599691 valid-loss:1.231841 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:03.9564 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247269 train-accuracy:0.599691 valid-loss:1.237954 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.0689 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843644\n",
      "[INFO 24-02-22 06:46:04.0690 UTC gradient_boosted_trees.cc:271] Truncates the model to 207 tree(s) i.e. 207  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.0691 UTC gradient_boosted_trees.cc:334] Final model num-trees:207 valid-loss:0.843644 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:04.0707 UTC hyperparameters_optimizer.cc:582] [208/500] Score: -0.843644 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:04.0732 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.0732 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.0734 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.0854 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322168 train-accuracy:0.599691 valid-loss:1.301637 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.1871 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86079\n",
      "[INFO 24-02-22 06:46:04.1871 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.1872 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.860790 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:04.1874 UTC hyperparameters_optimizer.cc:582] [209/500] Score: -0.86079 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:04.1879 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.1879 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.1882 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.1908 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86558\n",
      "[INFO 24-02-22 06:46:04.1908 UTC gradient_boosted_trees.cc:271] Truncates the model to 153 tree(s) i.e. 153  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.1909 UTC gradient_boosted_trees.cc:334] Final model num-trees:153 valid-loss:0.865580 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:04.1913 UTC hyperparameters_optimizer.cc:582] [210/500] Score: -0.86558 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:04.1920 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.1921 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.1924 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.1929 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262566 train-accuracy:0.599691 valid-loss:1.251289 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.2203 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839867\n",
      "[INFO 24-02-22 06:46:04.2204 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.2206 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.839867 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:04.2214 UTC hyperparameters_optimizer.cc:582] [211/500] Score: -0.839867 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:04.2239 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.2239 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.2241 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.2323 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281334 train-accuracy:0.599691 valid-loss:1.279522 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.2426 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235015 train-accuracy:0.599691 valid-loss:1.221871 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.2991 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.890413\n",
      "[INFO 24-02-22 06:46:04.2992 UTC gradient_boosted_trees.cc:271] Truncates the model to 92 tree(s) i.e. 92  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.2994 UTC gradient_boosted_trees.cc:334] Final model num-trees:92 valid-loss:0.890413 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:04.3004 UTC hyperparameters_optimizer.cc:582] [212/500] Score: -0.890413 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:04.3031 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.3031 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.3033 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.3146 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325544 train-accuracy:0.599691 valid-loss:1.300727 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.4796 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.809691\n",
      "[INFO 24-02-22 06:46:04.4796 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.4797 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.809691 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:04.4799 UTC hyperparameters_optimizer.cc:582] [213/500] Score: -0.809691 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:04.4805 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.4805 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.4806 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.4874 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237323 train-accuracy:0.599691 valid-loss:1.232162 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.5692 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859307\n",
      "[INFO 24-02-22 06:46:04.5693 UTC gradient_boosted_trees.cc:271] Truncates the model to 172 tree(s) i.e. 172  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.5695 UTC gradient_boosted_trees.cc:334] Final model num-trees:172 valid-loss:0.859307 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:04.5707 UTC hyperparameters_optimizer.cc:582] [214/500] Score: -0.859307 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:04.5712 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.5712 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.5723 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.5910 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279918 train-accuracy:0.599691 valid-loss:1.273780 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.6118 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852731\n",
      "[INFO 24-02-22 06:46:04.6118 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.6120 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.852731 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:04.6125 UTC hyperparameters_optimizer.cc:582] [215/500] Score: -0.852731 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:04.6131 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.6132 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.6134 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.6270 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323972 train-accuracy:0.599691 valid-loss:1.299657 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.6432 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.818836\n",
      "[INFO 24-02-22 06:46:04.6432 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.6434 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.818836 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:04.6440 UTC hyperparameters_optimizer.cc:582] [216/500] Score: -0.818836 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:04.6457 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.6457 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.6459 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.6627 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238784 train-accuracy:0.599691 valid-loss:1.240684 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.6723 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.807477\n",
      "[INFO 24-02-22 06:46:04.6723 UTC gradient_boosted_trees.cc:271] Truncates the model to 192 tree(s) i.e. 192  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.6724 UTC gradient_boosted_trees.cc:334] Final model num-trees:192 valid-loss:0.807477 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:04.6736 UTC hyperparameters_optimizer.cc:582] [217/500] Score: -0.807477 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:04.6743 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.6744 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.6751 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.6767 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825382\n",
      "[INFO 24-02-22 06:46:04.6767 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.6768 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.825382 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:04.6773 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.6773 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.6775 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.6787 UTC hyperparameters_optimizer.cc:582] [218/500] Score: -0.825382 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:04.6838 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329031 train-accuracy:0.599691 valid-loss:1.305317 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.6910 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322495 train-accuracy:0.599691 valid-loss:1.299464 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.7063 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.856445\n",
      "[INFO 24-02-22 06:46:04.7064 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.7067 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.856445 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:04.7071 UTC hyperparameters_optimizer.cc:582] [219/500] Score: -0.856445 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:04.7078 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.7080 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.7085 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.7214 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286585 train-accuracy:0.599691 valid-loss:1.271529 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.9661 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.863366\n",
      "[INFO 24-02-22 06:46:04.9661 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.9663 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.863366 valid-accuracy:0.803030\n",
      "[[INFO 24-02-22 06:46:04.9668 UTC hyperparameters_optimizer.cc:582] [220/500] Score: -0.863366 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "INFO 24-02-22 06:46:04.9670 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.9671 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.9673 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:04.9759 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248951 train-accuracy:0.599691 valid-loss:1.244663 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:04.9955 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850757\n",
      "[INFO 24-02-22 06:46:04.9957 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 06:46:04.9957 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.850757 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:04.9959 UTC hyperparameters_optimizer.cc:582] [221/500] Score: -0.850757 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:04.9964 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:04.9964 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:04.9966 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.0111 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246771 train-accuracy:0.599691 valid-loss:1.245844 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.0678 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867971\n",
      "[INFO 24-02-22 06:46:05.0678 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.0681 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.867971 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:05.0692 UTC hyperparameters_optimizer.cc:582] [222/500] Score: -0.867971 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:05.0714 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.0714 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.0716 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.0847 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286886 train-accuracy:0.599691 valid-loss:1.275457 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.2246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864505\n",
      "[INFO 24-02-22 06:46:05.2246 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.2249 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.864505 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:05.2266 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.2268 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.2271 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.2274 UTC hyperparameters_optimizer.cc:582] [223/500] Score: -0.864505 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:05.2416 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322900 train-accuracy:0.599691 valid-loss:1.298998 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.3313 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.829992\n",
      "[INFO 24-02-22 06:46:05.3314 UTC gradient_boosted_trees.cc:271] Truncates the model to 158 tree(s) i.e. 158  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.3315 UTC gradient_boosted_trees.cc:334] Final model num-trees:158 valid-loss:0.829992 valid-accuracy:0.803030\n",
      "[INFO[INFO 24-02-22 06:46:05.3328 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      " 24-02-22 06:46:05.3328 UTC hyperparameters_optimizer.cc:[582] [224/INFO500 24-02-22 06:46:05.3329 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713] Score:  example(s) and 9 feature(s).\n",
      "-0.829992 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:05.3337 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.3437 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325154 train-accuracy:0.599691 valid-loss:1.303593 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.5202 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85535\n",
      "[INFO 24-02-22 06:46:05.5202 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.5203 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.855350 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:05.5208 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.5208 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.5210 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.5220 UTC hyperparameters_optimizer.cc:582] [225/500] Score: -0.85535 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:05.5262 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328930 train-accuracy:0.599691 valid-loss:1.305670 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.5589 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.877662\n",
      "[INFO 24-02-22 06:46:05.5589 UTC gradient_boosted_trees.cc:271] Truncates the model to 106 tree(s) i.e. 106  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.5592 UTC gradient_boosted_trees.cc:334] Final model num-trees:106 valid-loss:0.877662 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:05.5609 UTC hyperparameters_optimizer.cc:582] [226/500] Score: -0.877662 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:05.5635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.5637 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.5640 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.5722 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329552 train-accuracy:0.599691 valid-loss:1.303615 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.6370 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860485\n",
      "[INFO 24-02-22 06:46:05.6370 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.6373 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.860485 valid-accuracy:0.818182\n",
      "[[INFO 24-02-22 06:46:05.6383 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.6383 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.6385 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "INFO 24-02-22 06:46:05.6420 UTC hyperparameters_optimizer.cc:582] [227/500] Score: -0.860485 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:05.6515 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245420 train-accuracy:0.599691 valid-loss:1.247387 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.6926 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862188\n",
      "[INFO 24-02-22 06:46:05.6927 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.6929 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.862188 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:05.6936 UTC hyperparameters_optimizer.cc:582] [228/500] Score: -0.862188 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:05.6953 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.6955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.6958 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.7102 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292511 train-accuracy:0.599691 valid-loss:1.274700 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.8047 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851912\n",
      "[INFO 24-02-22 06:46:05.8047 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.8049 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.851912 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:05.8054 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.8054 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.8054 UTC hyperparameters_optimizer.cc:582] [229/500] Score: -0.851912 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:05.8058 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.8149 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296740 train-accuracy:0.599691 valid-loss:1.286736 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:05.9596 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838981\n",
      "[INFO 24-02-22 06:46:05.9596 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:05.9598 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.838981 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:05.9603 UTC hyperparameters_optimizer.cc:582] [230/500] Score: -0.838981 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:05.9611 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:05.9612 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:05.9613 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:05.9748 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245440 train-accuracy:0.599691 valid-loss:1.241328 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.0173 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.661777 train-accuracy:0.870170 valid-loss:0.842121 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:06.0173 UTC gradient_boosted_trees.cc:271] Truncates the model to 279 tree(s) i.e. 279  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.0174 UTC gradient_boosted_trees.cc:334] Final model num-trees:279 valid-loss:0.838642 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:06.0177 UTC hyperparameters_optimizer.cc:582] [231/500] Score: -0.838642 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:06.0179 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.0179 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.0191 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.0279 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.889677\n",
      "[INFO 24-02-22 06:46:06.0279 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.0282 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.889677 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:06.0294 UTC hyperparameters_optimizer.cc:582] [232/500] Score: -0.889677 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:06.0322 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.0322 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.0327 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.0363 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322583 train-accuracy:0.599691 valid-loss:1.297591 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.0443 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287503 train-accuracy:0.599691 valid-loss:1.279301 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.1627 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866232\n",
      "[INFO 24-02-22 06:46:06.1627 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.1630 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.866232 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:06.1645 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.1646 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.1649 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.1654 UTC hyperparameters_optimizer.cc:582] [233/500] Score: -0.866232 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:06.1716 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298153 train-accuracy:0.599691 valid-loss:1.278018 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.4805 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.854953\n",
      "[INFO 24-02-22 06:46:06.4805 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.4806 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.854953 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:06.4809 UTC hyperparameters_optimizer.cc:582] [234/500] Score: -0.854953 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:06.4812 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.4812 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.4815 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.4975 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288895 train-accuracy:0.599691 valid-loss:1.277117 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.5177 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876373\n",
      "[INFO 24-02-22 06:46:06.5177 UTC gradient_boosted_trees.cc:271] Truncates the model to 167 tree(s) i.e. 167  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.5181 UTC gradient_boosted_trees.cc:334] Final model num-trees:167 valid-loss:0.876373 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:06.5194 UTC hyperparameters_optimizer.cc:582] [235/500] Score: -0.876373 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:06.5215 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.5217 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.5220 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.5365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237479 train-accuracy:0.599691 valid-loss:1.234575 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.5830 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876528\n",
      "[INFO 24-02-22 06:46:06.5830 UTC gradient_boosted_trees.cc:271] Truncates the model to 82 tree(s) i.e. 82  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.5832 UTC gradient_boosted_trees.cc:334] Final model num-trees:82 valid-loss:0.876528 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:06.5845 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.5845 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.5847 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.5854 UTC hyperparameters_optimizer.cc:582] [236/500] Score: -0.876528 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:06.6000 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.222966 train-accuracy:0.599691 valid-loss:1.246790 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.6276 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873442\n",
      "[INFO 24-02-22 06:46:06.6277 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.6279 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.873442 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:06.6294 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.6294 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.6296 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.6323 UTC hyperparameters_optimizer.cc:582] [237/500] Score: -0.873442 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:06.6456 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.235615 train-accuracy:0.599691 valid-loss:1.237404 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.6570 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860329\n",
      "[INFO 24-02-22 06:46:06.6571 UTC gradient_boosted_trees.cc:271] Truncates the model to 150 tree(s) i.e. 150  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.6572 UTC gradient_boosted_trees.cc:334] Final model num-trees:150 valid-loss:0.860329 valid-accuracy:0.803030\n",
      "[INFO[INFO 24-02-22 06:46:06.6585 UTC hyperparameters_optimizer.cc:582] [238/500] Score:  24-02-22 06:46:06.6585 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "-0.860329 / -0.758798 HParams: [INFO 24-02-22 06:46:06.6586 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:06.6590 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.6811 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286899 train-accuracy:0.599691 valid-loss:1.272996 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.6949 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845889\n",
      "[INFO 24-02-22 06:46:06.6950 UTC gradient_boosted_trees.cc:271] Truncates the model to 252 tree(s) i.e. 252  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.6950 UTC gradient_boosted_trees.cc:334] Final model num-trees:252 valid-loss:0.845889 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:06.6957 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.6965 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.6971 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.6987 UTC hyperparameters_optimizer.cc:582] [239/500] Score: -0.845889 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:06.7126 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241522 train-accuracy:0.599691 valid-loss:1.258464 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.7548 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.831642\n",
      "[INFO 24-02-22 06:46:06.7548 UTC gradient_boosted_trees.cc:271] Truncates the model to 77 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.7549 UTC gradient_boosted_trees.cc:334] Final model num-trees:77 valid-loss:0.831642 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:06.7554 UTC hyperparameters_optimizer.cc:582] [240/500] Score: -0.831642 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:06.7560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.7560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.7563 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.7658 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326161 train-accuracy:0.599691 valid-loss:1.300731 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.8487 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.87982\n",
      "[INFO 24-02-22 06:46:06.8487 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.8491 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.879820 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:06.8501 UTC hyperparameters_optimizer.cc:582] [241/500] Score: -0.87982 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:06.8508 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.8508 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.8518 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.8650 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324468 train-accuracy:0.599691 valid-loss:1.301262 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:06.9173 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.900699\n",
      "[INFO 24-02-22 06:46:06.9173 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:06.9175 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.900699 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:06.9180 UTC hyperparameters_optimizer.cc:582] [242/500] Score: -0.900699 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:06.9188 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:06.9188 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:06.9192 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:06.9285 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292518 train-accuracy:0.599691 valid-loss:1.275395 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.0136 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832069\n",
      "[INFO 24-02-22 06:46:07.0136 UTC gradient_boosted_trees.cc:271] Truncates the model to 105 tree(s) i.e. 105  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.0137 UTC gradient_boosted_trees.cc:334] Final model num-trees:105 valid-loss:0.832069 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:07.0145 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.0145 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.0147 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.0188 UTC hyperparameters_optimizer.cc:582] [243/500] Score: -0.832069 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:07.0320 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226622 train-accuracy:0.599691 valid-loss:1.237185 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.0554 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859188\n",
      "[INFO 24-02-22 06:46:07.0554 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.0558 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.859188 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:07.0565 UTC hyperparameters_optimizer.cc:582] [244/500] Score: -0.859188 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:07.0578 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.0578 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.0580 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.0604 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.628379 train-accuracy:0.879444 valid-loss:0.831342 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:07.0605 UTC gradient_boosted_trees.cc:271] Truncates the model to 283 tree(s) i.e. 283  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.0607 UTC gradient_boosted_trees.cc:334] Final model num-trees:283 valid-loss:0.828854 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:07.0610 UTC hyperparameters_optimizer.cc:582] [245/500] Score: -0.828854 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:07.0618 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.0620 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.0622 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.0703 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325515 train-accuracy:0.599691 valid-loss:1.298934 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.0778 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.228902 train-accuracy:0.599691 valid-loss:1.229746 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.1417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.826073\n",
      "[INFO 24-02-22 06:46:07.1418 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.1419 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.826073 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:07.1455 UTC hyperparameters_optimizer.cc:582] [246/500] Score: -0.826073 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:07.1460 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.1460 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.1463 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.1543 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325921 train-accuracy:0.599691 valid-loss:1.302890 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.2254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.928827\n",
      "[INFO 24-02-22 06:46:07.2254 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.2257 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.928827 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:07.2266 UTC hyperparameters_optimizer.cc:582] [247/500] Score: -0.928827 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:07.2270 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.2270 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.2274 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.2436 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321405 train-accuracy:0.599691 valid-loss:1.298983 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.3254 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872076\n",
      "[INFO 24-02-22 06:46:07.3256 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.3261 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.872076 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:07.3271 UTC hyperparameters_optimizer.cc:582] [248/500] Score: -0.872076 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:07.3298 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.3299 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.3301 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.3569 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324738 train-accuracy:0.599691 valid-loss:1.301937 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.4007 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832025\n",
      "[INFO 24-02-22 06:46:07.4007 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.4009 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.832025 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:07.4017 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.4017 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.4019 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.4055 UTC hyperparameters_optimizer.cc:582] [249/500] Score: -0.832025 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:07.4133 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848385\n",
      "[INFO 24-02-22 06:46:07.4134 UTC gradient_boosted_trees.cc:271] Truncates the model to 171 tree(s) i.e. 171  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.4135 UTC gradient_boosted_trees.cc:334] Final model num-trees:171 valid-loss:0.848385 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:07.4144 UTC hyperparameters_optimizer.cc:582] [250/500] Score: -0.848385 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:07.4166 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.4167 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.4169 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.4202 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285471 train-accuracy:0.599691 valid-loss:1.269148 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.4294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876855\n",
      "[INFO 24-02-22 06:46:07.4295 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.4296 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.876855 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:07.4298 UTC hyperparameters_optimizer.cc:582] [251/500] Score: -0.876855 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:07.4302 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.4302 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.4307 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.4322 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286526 train-accuracy:0.599691 valid-loss:1.282790 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.4419 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323554 train-accuracy:0.599691 valid-loss:1.301333 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.5219 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.863857\n",
      "[INFO 24-02-22 06:46:07.5219 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.5221 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.863857 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:07.5224 UTC hyperparameters_optimizer.cc:582] [252/500] Score: -0.863857 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:07.5229 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.5230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.5234 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.5318 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248003 train-accuracy:0.599691 valid-loss:1.239043 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:07.9130 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.830535\n",
      "[INFO 24-02-22 06:46:07.9131 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:07.9133 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.830535 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:07.9137 UTC hyperparameters_optimizer.cc:582] [253/500] Score: -0.830535 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:07.9145 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:07.9145 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:07.9147 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:07.9229 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233637 train-accuracy:0.599691 valid-loss:1.235401 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.0282 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852118\n",
      "[INFO 24-02-22 06:46:08.0282 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.0285 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.852118 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.0291 UTC hyperparameters_optimizer.cc:582] [254/500] Score: -0.852118 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:08.0300 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.0300 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.0303 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.0418 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325674 train-accuracy:0.599691 valid-loss:1.304057 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.0693 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871876\n",
      "[INFO 24-02-22 06:46:08.0693 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.0711 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.871876 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.0735 UTC hyperparameters_optimizer.cc:582] [255/500] Score: -0.871876 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.0737 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.0737 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.0739 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.0796 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.300954 train-accuracy:0.599691 valid-loss:1.284301 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.1174 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.882252\n",
      "[INFO 24-02-22 06:46:08.1174 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.1177 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.882252 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:08.1182 UTC hyperparameters_optimizer.cc:582] [256/500] Score: -0.882252 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:08.1212 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.1212 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.1214 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.1321 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326067 train-accuracy:0.599691 valid-loss:1.300447 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.1374 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867302\n",
      "[INFO 24-02-22 06:46:08.1374 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.1377 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.867302 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:08.1382 UTC hyperparameters_optimizer.cc:582] [257/500] Score: -0.867302 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:08.1393 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.1393 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.1395 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.1429 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880944\n",
      "[INFO 24-02-22 06:46:08.1430 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.1433 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.880944 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:08.1445 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.1446 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.1447 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.1453 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.251238 train-accuracy:0.599691 valid-loss:1.251439 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.1487 UTC hyperparameters_optimizer.cc:582] [258/500] Score: -0.880944 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.1569 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266269 train-accuracy:0.599691 valid-loss:1.261001 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.4817 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840626\n",
      "[INFO 24-02-22 06:46:08.4817 UTC gradient_boosted_trees.cc:271] Truncates the model to 231 tree(s) i.e. 231  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.4818 UTC gradient_boosted_trees.cc:334] Final model num-trees:231 valid-loss:0.840626 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.4824 UTC hyperparameters_optimizer.cc:582] [259/500] Score: -0.840626 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:08.4830 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.4830 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.4834 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.5028 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321840 train-accuracy:0.599691 valid-loss:1.303972 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.5297 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859662\n",
      "[INFO 24-02-22 06:46:08.5297 UTC gradient_boosted_trees.cc:271] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.5299 UTC gradient_boosted_trees.cc:334] Final model num-trees:30 valid-loss:0.859662 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.5302 UTC hyperparameters_optimizer.cc:582] [260/500] Score: -0.859662 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.5324 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.5327 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.5330 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.5449 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234676 train-accuracy:0.599691 valid-loss:1.239601 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.5853 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845099\n",
      "[INFO 24-02-22 06:46:08.5854 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.5857 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.845099 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.5869 UTC hyperparameters_optimizer.cc:582] [261/500] Score: -0.845099 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.5892 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.5892 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.5894 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.6076 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850324\n",
      "[INFO 24-02-22 06:46:08.6077 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.6079 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.850324 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.6084 UTC hyperparameters_optimizer.cc:582] [262/500] Score: -0.850324 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:08.6090 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.6090 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.6094 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.6120 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321870 train-accuracy:0.599691 valid-loss:1.296363 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.6258 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305521 train-accuracy:0.599691 valid-loss:1.290511 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.6385 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.870874\n",
      "[INFO 24-02-22 06:46:08.6385 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.6388 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.870874 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.6397 UTC hyperparameters_optimizer.cc:582] [263/500] Score: -0.870874 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:08.6413 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.6416 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.6417 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.6583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320908 train-accuracy:0.599691 valid-loss:1.298668 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.6789 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.819528\n",
      "[INFO 24-02-22 06:46:08.6790 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.6792 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.819528 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.6798 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.6800 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.6803 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.6820 UTC hyperparameters_optimizer.cc:582] [264/500] Score: -0.819528 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:08.6971 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321313 train-accuracy:0.599691 valid-loss:1.301700 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.8113 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.817027\n",
      "[INFO 24-02-22 06:46:08.8113 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.8113 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.817027 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.8115 UTC hyperparameters_optimizer.cc:582] [265/500] Score: -0.817027 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:08.8119 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.8119 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.8155 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.8406 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295592 train-accuracy:0.599691 valid-loss:1.280203 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.8551 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838496\n",
      "[INFO 24-02-22 06:46:08.8551 UTC gradient_boosted_trees.cc:271] Truncates the model to 180 tree(s) i.e. 180  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.8552 UTC gradient_boosted_trees.cc:334] Final model num-trees:180 valid-loss:0.838496 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:08.8562 UTC hyperparameters_optimizer.cc:582] [266/500] Score: -0.838496 / -0.758798 HParams: [INFO 24-02-22 06:46:08.8564 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.8564 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.8566 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:08.8626 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.301723 train-accuracy:0.599691 valid-loss:1.284914 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:08.9681 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876352\n",
      "[INFO 24-02-22 06:46:08.9681 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 06:46:08.9683 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.876352 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:08.9713 UTC hyperparameters_optimizer.cc:582] [267/500] Score: -0.876352 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:08.9728 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:08.9729 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:08.9731 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:08.9803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305073 train-accuracy:0.599691 valid-loss:1.288816 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.0725 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.819336\n",
      "[INFO 24-02-22 06:46:09.0726 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.0727 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.819336 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:09.0731 UTC hyperparameters_optimizer.cc:582] [268/500] Score: -0.819336 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:09.0741 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.0741 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.0742 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.0839 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325710 train-accuracy:0.599691 valid-loss:1.302621 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.1358 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.909216\n",
      "[INFO 24-02-22 06:46:09.1358 UTC gradient_boosted_trees.cc:271] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.1362 UTC gradient_boosted_trees.cc:334] Final model num-trees:16 valid-loss:0.909216 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:09.1375 UTC hyperparameters_optimizer.cc:582] [269/500] Score: -0.909216 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:09.1396 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.1398 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.1401 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.1408 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862655\n",
      "[INFO 24-02-22 06:46:09.1409 UTC gradient_boosted_trees.cc:271] Truncates the model to 130 tree(s) i.e. 130  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.1410 UTC gradient_boosted_trees.cc:334] Final model num-trees:130 valid-loss:0.862655 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:09.1420 UTC hyperparameters_optimizer.cc:582] [270/500] Score: -0.862655 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:09.1447 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.1447 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.1449 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.1509 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324348 train-accuracy:0.599691 valid-loss:1.301131 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.1510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304974 train-accuracy:0.599691 valid-loss:1.287256 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.5470 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864952\n",
      "[INFO 24-02-22 06:46:09.5470 UTC gradient_boosted_trees.cc:271] Truncates the model to 72 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.5470 UTC gradient_boosted_trees.cc:334] Final model num-trees:72 valid-loss:0.864952 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:09.5472 UTC hyperparameters_optimizer.cc:582] [271/500] Score: -0.864952 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:09.5475 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.5476 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.5477 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.5690 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288655 train-accuracy:0.599691 valid-loss:1.273381 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.6038 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.910278\n",
      "[INFO 24-02-22 06:46:09.6038 UTC gradient_boosted_trees.cc:271] Truncates the model to 108 tree(s) i.e. 108  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.6041 UTC gradient_boosted_trees.cc:334] Final model num-trees:108 valid-loss:0.910278 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:09.6053 UTC hyperparameters_optimizer.cc:582] [272/500] Score: -0.910278 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:09.6076 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.6077 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.6080 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.6103 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855391\n",
      "[INFO 24-02-22 06:46:09.6104 UTC gradient_boosted_trees.cc:271] Truncates the model to 155 tree(s) i.e. 155  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.6114 UTC gradient_boosted_trees.cc:334] Final model num-trees:155 valid-loss:0.855391 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:09.6124 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.6125 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.6127 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.6154 UTC hyperparameters_optimizer.cc:582] [273/500] Score: -0.855391 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:09.6185 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287649 train-accuracy:0.599691 valid-loss:1.277522 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.6330 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286742 train-accuracy:0.599691 valid-loss:1.277768 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:09.6440 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872668\n",
      "[INFO 24-02-22 06:46:09.6441 UTC gradient_boosted_trees.cc:271] Truncates the model to 117 tree(s) i.e. 117  iteration(s).\n",
      "[INFO 24-02-22 06:46:09.6441 UTC gradient_boosted_trees.cc:334] Final model num-trees:117 valid-loss:0.872668 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:09.6444 UTC hyperparameters_optimizer.cc:582] [274/500] Score: -0.872668 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:09.6449 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:09.6449 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:09.6451 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:09.6507 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.300742 train-accuracy:0.599691 valid-loss:1.283290 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.0027 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864656\n",
      "[INFO 24-02-22 06:46:10.0027 UTC gradient_boosted_trees.cc:271] Truncates the model to 128 tree(s) i.e. 128  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.0029 UTC gradient_boosted_trees.cc:334] Final model num-trees:128 valid-loss:0.864656 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:10.0045 UTC hyperparameters_optimizer.cc:582] [275/500] Score: -0.864656 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.0063 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.0063 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.0066 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.0174 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242955 train-accuracy:0.599691 valid-loss:1.248737 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.3411 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823306\n",
      "[INFO 24-02-22 06:46:10.3411 UTC gradient_boosted_trees.cc:271] Truncates the model to 213 tree(s) i.e. 213  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.3411 UTC gradient_boosted_trees.cc:334] Final model num-trees:213 valid-loss:0.823306 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:10.3414 UTC hyperparameters_optimizer.cc:582] [276/500] Score: -0.823306 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:10.3421 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.3421 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.3423 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.3490 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296139 train-accuracy:0.599691 valid-loss:1.280746 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.3589 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824332\n",
      "[INFO 24-02-22 06:46:10.3589 UTC gradient_boosted_trees.cc:271] Truncates the model to 166 tree(s) i.e. 166  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.3590 UTC gradient_boosted_trees.cc:334] Final model num-trees:166 valid-loss:0.824332 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:10.3593 UTC hyperparameters_optimizer.cc:582] [277/500] Score: -0.824332 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.3597 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.3597 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.3600 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.3687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326301 train-accuracy:0.599691 valid-loss:1.301626 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.3951 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844423\n",
      "[INFO 24-02-22 06:46:10.3984 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.4001 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.844423 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:10.4004 UTC hyperparameters_optimizer.cc:582] [278/500] Score: -0.844423 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.4009 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.4009 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.4013 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.4059 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263216 train-accuracy:0.599691 valid-loss:1.259980 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.4596 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.802028\n",
      "[INFO 24-02-22 06:46:10.4597 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.4599 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.802028 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:10.4603 UTC hyperparameters_optimizer.cc:582] [279/500] Score: -0.802028 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:10.4609 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.4609 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.4613 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.4814 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226188 train-accuracy:0.599691 valid-loss:1.237855 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.6322 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881\n",
      "[INFO 24-02-22 06:46:10.6322 UTC gradient_boosted_trees.cc:271] Truncates the model to 28 tree(s) i.e. 28  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.6323 UTC gradient_boosted_trees.cc:334] Final model num-trees:28 valid-loss:0.881000 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:10.6326 UTC hyperparameters_optimizer.cc:582] [280/500] Score: -0.881 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.6332 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.6332 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.6334 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.6455 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245692 train-accuracy:0.599691 valid-loss:1.240063 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.6889 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824926\n",
      "[INFO 24-02-22 06:46:10.6889 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.6890 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.824926 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:10.6892 UTC hyperparameters_optimizer.cc:582] [281/500] Score: -0.824926 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:10.6896 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.6896 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.6903 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.6960 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.305820 train-accuracy:0.599691 valid-loss:1.287657 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.8056 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.83236\n",
      "[INFO 24-02-22 06:46:10.8056 UTC gradient_boosted_trees.cc:271] Truncates the model to 193 tree(s) i.e. 193  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.8057 UTC gradient_boosted_trees.cc:334] Final model num-trees:193 valid-loss:0.832360 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:10.8067 UTC hyperparameters_optimizer.cc:582] [282/500] Score: -0.83236 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:10.8096 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.8096 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.8099 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.8197 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293968 train-accuracy:0.599691 valid-loss:1.275316 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.8693 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842824\n",
      "[INFO 24-02-22 06:46:10.8694 UTC gradient_boosted_trees.cc:271] Truncates the model to 176 tree(s) i.e. 176  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.8695 UTC gradient_boosted_trees.cc:334] Final model num-trees:176 valid-loss:0.842824 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:10.8704 UTC hyperparameters_optimizer.cc:582] [283/500] Score: -0.842824 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.8720 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.8720 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.8722 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.8803 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291077 train-accuracy:0.599691 valid-loss:1.278862 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:10.8818 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867523\n",
      "[INFO 24-02-22 06:46:10.8818 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:10.8820 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.867523 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:10.8824 UTC hyperparameters_optimizer.cc:582] [284/500] Score: -0.867523 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:10.8833 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:10.8834 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:10.8835 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:10.8947 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284775 train-accuracy:0.599691 valid-loss:1.278194 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.0825 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.802925\n",
      "[INFO 24-02-22 06:46:11.0826 UTC gradient_boosted_trees.cc:271] Truncates the model to 193 tree(s) i.e. 193  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.0826 UTC gradient_boosted_trees.cc:334] Final model num-trees:193 valid-loss:0.802925 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:11.0835 UTC hyperparameters_optimizer.cc:582] [285/500] Score: -0.802925 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:11.0845 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.0846 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.0854 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.0875 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262917 train-accuracy:0.599691 valid-loss:1.255451 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.0963 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.830561\n",
      "[INFO 24-02-22 06:46:11.0964 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.0964 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.830561 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.0967 UTC hyperparameters_optimizer.cc:582] [286/500] Score: -0.830561 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.0977 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.0977 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.0979 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.1148 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246352 train-accuracy:0.599691 valid-loss:1.244529 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.2288 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.420433 train-accuracy:0.930448 valid-loss:0.801530 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.2288 UTC gradient_boosted_trees.cc:271] Truncates the model to 271 tree(s) i.e. 271  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.2291 UTC gradient_boosted_trees.cc:334] Final model num-trees:271 valid-loss:0.793794 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.2306 UTC hyperparameters_optimizer.cc:582] [287/500] Score: -0.793794 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.2310 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.2310 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.2311 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.2427 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233539 train-accuracy:0.599691 valid-loss:1.239797 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.3198 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846757\n",
      "[INFO 24-02-22 06:46:11.3198 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.3199 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.846757 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.3201 UTC hyperparameters_optimizer.cc:582] [288/500] Score: -0.846757 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.3205 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.3205 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.3207 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.3266 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296664 train-accuracy:0.599691 valid-loss:1.276545 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.4127 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.931659\n",
      "[INFO 24-02-22 06:46:11.4127 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.4129 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.931659 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.4133 UTC hyperparameters_optimizer.cc:582] [289/500] Score: -0.931659 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:11.4147 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.4148 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.4150 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.4203 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.248183 train-accuracy:0.599691 valid-loss:1.249650 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.4294 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855735\n",
      "[INFO 24-02-22 06:46:11.4296 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.4298 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.855735 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.4310 UTC hyperparameters_optimizer.cc:582] [290/500] Score: -0.855735 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.4321 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.4383 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.4385 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.4535 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288545 train-accuracy:0.599691 valid-loss:1.277084 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.6303 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.835988\n",
      "[INFO 24-02-22 06:46:11.6303 UTC gradient_boosted_trees.cc:271] Truncates the model to 63 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.6305 UTC gradient_boosted_trees.cc:334] Final model num-trees:63 valid-loss:0.835988 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.6314 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.6315 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.6316 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.6320 UTC hyperparameters_optimizer.cc:582] [291/500] Score: -0.835988 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:11.6485 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.282687 train-accuracy:0.599691 valid-loss:1.275411 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.6513 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824072\n",
      "[INFO 24-02-22 06:46:11.6513 UTC gradient_boosted_trees.cc:271] Truncates the model to 211 tree(s) i.e. 211  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.6515 UTC gradient_boosted_trees.cc:334] Final model num-trees:211 valid-loss:0.824072 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.6529 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.6530 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.6531 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.6533 UTC hyperparameters_optimizer.cc:582] [292/500] Score: -0.824072 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:11.6550 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859561\n",
      "[INFO 24-02-22 06:46:11.6550 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.6553 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.859561 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.6560 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.6560 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.6562 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.6590 UTC hyperparameters_optimizer.cc:582] [293/500] Score: -0.859561 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:11.6687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324331 train-accuracy:0.599691 valid-loss:1.300421 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.6718 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323661 train-accuracy:0.599691 valid-loss:1.300292 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.7024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843953\n",
      "[INFO 24-02-22 06:46:11.7024 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.7030 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.843953 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.7036 UTC hyperparameters_optimizer.cc:582] [294/500] Score: -0.843953 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.7053 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.7054 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.7056 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.7180 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.234389 train-accuracy:0.599691 valid-loss:1.229050 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.8065 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865345\n",
      "[INFO 24-02-22 06:46:11.8065 UTC gradient_boosted_trees.cc:271] Truncates the model to 132 tree(s) i.e. 132  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.8067 UTC gradient_boosted_trees.cc:334] Final model num-trees:132 valid-loss:0.865345 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:11.8079 UTC hyperparameters_optimizer.cc:582] [295/500] Score: -0.865345 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:11.8085 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.8085 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.8096 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.8233 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324068 train-accuracy:0.599691 valid-loss:1.300491 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.8520 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855365\n",
      "[INFO 24-02-22 06:46:11.8520 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.8524 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.855365 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:11.8529 UTC hyperparameters_optimizer.cc:582] [296/500] Score: -0.855365 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:11.8536 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.8536 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.8538 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.8713 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288569 train-accuracy:0.599691 valid-loss:1.274876 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.8735 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.835406\n",
      "[INFO 24-02-22 06:46:11.8735 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.8736 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.835406 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:11.8740 UTC hyperparameters_optimizer.cc:582] [297/500] Score: -0.835406 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:11.8745 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.8745 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.8748 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.8786 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263192 train-accuracy:0.599691 valid-loss:1.259511 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:11.9024 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.890069\n",
      "[INFO 24-02-22 06:46:11.9025 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:11.9028 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.890069 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:11.9036 UTC hyperparameters_optimizer.cc:582] [298/500] Score: -0.890069 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:11.9045 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:11.9045 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:11.9047 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:11.9135 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.253553 train-accuracy:0.599691 valid-loss:1.250270 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.0138 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862767\n",
      "[INFO 24-02-22 06:46:12.0138 UTC gradient_boosted_trees.cc:271] Truncates the model to 165 tree(s) i.e. 165  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.0140 UTC gradient_boosted_trees.cc:334] Final model num-trees:165 valid-loss:0.862767 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:12.0221 UTC hyperparameters_optimizer.cc:582] [299/500] Score: -0.862767 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:12.0259 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.0259 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.0271 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.0487 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322590 train-accuracy:0.599691 valid-loss:1.299636 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.0701 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855295\n",
      "[INFO 24-02-22 06:46:12.0701 UTC gradient_boosted_trees.cc:271] Truncates the model to 83 tree(s) i.e. 83  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.0702 UTC gradient_boosted_trees.cc:334] Final model num-trees:83 valid-loss:0.855295 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.0707 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.0707 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.0708 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.0754 UTC hyperparameters_optimizer.cc:582] [300/500] Score: -0.855295 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:12.0879 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283832 train-accuracy:0.599691 valid-loss:1.274965 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.1001 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.835615\n",
      "[INFO 24-02-22 06:46:12.1001 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.1003 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.835615 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.1007 UTC hyperparameters_optimizer.cc:582] [301/500] Score: -0.835615 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:12.1012 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.1013 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.1015 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.1132 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295079 train-accuracy:0.599691 valid-loss:1.272891 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.2854 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.872935\n",
      "[INFO 24-02-22 06:46:12.2854 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.2856 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.872935 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:12.2877 UTC hyperparameters_optimizer.cc:582] [302/500] Score: -0.872935 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:12.2882 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.2883 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.2887 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.3081 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322844 train-accuracy:0.599691 valid-loss:1.298466 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.3300 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.914054\n",
      "[INFO 24-02-22 06:46:12.3300 UTC gradient_boosted_trees.cc:271] Truncates the model to 19 tree(s) i.e. 19  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.3309 UTC gradient_boosted_trees.cc:334] Final model num-trees:19 valid-loss:0.914054 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.3312 UTC hyperparameters_optimizer.cc:582] [303/500] Score: -0.914054 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:12.3320 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.3320 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.3323 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.3514 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325281 train-accuracy:0.599691 valid-loss:1.302328 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.4242 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824073\n",
      "[INFO 24-02-22 06:46:12.4242 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.4242 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.824073 valid-accuracy:0.818182\n",
      "[INFO[INFO 24-02-22 06:46:12.4246 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.4246 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      " 24-02-22 06:46:12.4246 UTC hyperparameters_optimizer.cc:582] [304/500] Score: -0.824073 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:12.4248 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.4365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323142 train-accuracy:0.599691 valid-loss:1.300930 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.4482 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.837316\n",
      "[INFO 24-02-22 06:46:12.4483 UTC gradient_boosted_trees.cc:271] Truncates the model to 193 tree(s) i.e. 193  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.4483 UTC gradient_boosted_trees.cc:334] Final model num-trees:193 valid-loss:0.837316 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.4489 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.4489 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.4490 UTC hyperparameters_optimizer.cc:582] [305/500] Score: -0.837316 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:12.4492 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.4685 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291529 train-accuracy:0.599691 valid-loss:1.273217 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.4978 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865235\n",
      "[INFO 24-02-22 06:46:12.4978 UTC gradient_boosted_trees.cc:271] Truncates the model to 161 tree(s) i.e. 161  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.4980 UTC gradient_boosted_trees.cc:334] Final model num-trees:161 valid-loss:0.865235 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:12.4996 UTC hyperparameters_optimizer.cc:582] [306/500] Score: -0.865235 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:12.5024 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.5024 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.5026 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.5095 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.303854 train-accuracy:0.599691 valid-loss:1.286242 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.5452 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.820399\n",
      "[INFO 24-02-22 06:46:12.5452 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.5453 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.820399 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:12.5459 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.5459 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.5461 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.5487 UTC hyperparameters_optimizer.cc:582] [307/500] Score: -0.820399 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:12.5516 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295802 train-accuracy:0.599691 valid-loss:1.281844 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.5744 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.878092\n",
      "[INFO 24-02-22 06:46:12.5744 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.5747 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.878092 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:12.5752 UTC hyperparameters_optimizer.cc:582] [308/500] Score: -0.878092 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:12.5762 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.5762 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.5765 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.5825 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285704 train-accuracy:0.599691 valid-loss:1.267563 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.9061 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.813012\n",
      "[INFO 24-02-22 06:46:12.9061 UTC gradient_boosted_trees.cc:271] Truncates the model to 245 tree(s) i.e. 245  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.9062 UTC gradient_boosted_trees.cc:334] Final model num-trees:245 valid-loss:0.813012 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:12.9066 UTC hyperparameters_optimizer.cc:582] [309/500] Score: -0.813012 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:12.9071 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.9071 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:12.9076 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:12.9226 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281316 train-accuracy:0.599691 valid-loss:1.266753 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:12.9972 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.888231\n",
      "[INFO 24-02-22 06:46:12.9973 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:12.9976 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.888231 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:12.9982 UTC hyperparameters_optimizer.cc:582] [310/500] Score: -0.888231 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:12.9995 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:12.9998 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.0003 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.0313 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230236 train-accuracy:0.599691 valid-loss:1.233078 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.0619 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871961\n",
      "[INFO 24-02-22 06:46:13.0619 UTC gradient_boosted_trees.cc:271] Truncates the model to 45 tree(s) i.e. 45  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.0621 UTC gradient_boosted_trees.cc:334] Final model num-trees:45 valid-loss:0.871961 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.0625 UTC hyperparameters_optimizer.cc:582] [311/500] Score: -0.871961 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:13.0635 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.0635 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.0637 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.0671 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.327149 train-accuracy:0.599691 valid-loss:1.304756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.1252 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.870963\n",
      "[INFO 24-02-22 06:46:13.1252 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.1254 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.870963 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.1260 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.1260 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.1262 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.1263 UTC hyperparameters_optimizer.cc:582] [312/500] Score: -0.870963 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:13.1296 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329289 train-accuracy:0.599691 valid-loss:1.304668 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.3109 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.893574\n",
      "[INFO 24-02-22 06:46:13.3110 UTC gradient_boosted_trees.cc:271] Truncates the model to 42 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.3112 UTC gradient_boosted_trees.cc:334] Final model num-trees:42 valid-loss:0.893574 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:13.3115 UTC hyperparameters_optimizer.cc:582] [313/500] Score: -0.893574 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:13.3120 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.3121 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.3124 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.3302 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321295 train-accuracy:0.599691 valid-loss:1.300440 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.3946 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.811453\n",
      "[INFO 24-02-22 06:46:13.3946 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.3948 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.811453 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:13.3951 UTC hyperparameters_optimizer.cc:582] [314/500] Score: -0.811453 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:13.3960 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.3960 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.3963 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.4052 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.249042 train-accuracy:0.599691 valid-loss:1.252849 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.7578 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860244\n",
      "[INFO 24-02-22 06:46:13.7578 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.7581 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.860244 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.7599 UTC hyperparameters_optimizer.cc:582] [315/500] Score: -0.860244 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:13.7611 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85953\n",
      "[INFO 24-02-22 06:46:13.7613 UTC gradient_boosted_trees.cc:271] Truncates the model to 120 tree(s) i.e. 120  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.7616 UTC gradient_boosted_trees.cc:334] Final model num-trees:120 valid-loss:0.859530 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.7620 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.7620 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.7622 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.7626 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.7626 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.7628 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.7687 UTC hyperparameters_optimizer.cc:582] [316/500] Score: -0.85953 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:13.7707 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288577 train-accuracy:0.599691 valid-loss:1.272806 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.7763 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283980 train-accuracy:0.599691 valid-loss:1.276469 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.8481 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891767\n",
      "[INFO 24-02-22 06:46:13.8481 UTC gradient_boosted_trees.cc:271] Truncates the model to 88 tree(s) i.e. 88  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.8484 UTC gradient_boosted_trees.cc:334] Final model num-trees:88 valid-loss:0.891767 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.8493 UTC hyperparameters_optimizer.cc:582] [317/500] Score: -0.891767 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:13.8506 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.8506 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.8509 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:13.8657 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241020 train-accuracy:0.599691 valid-loss:1.240876 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:13.9897 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806646\n",
      "[INFO 24-02-22 06:46:13.9900 UTC gradient_boosted_trees.cc:271] Truncates the model to 178 tree(s) i.e. 178  iteration(s).\n",
      "[INFO 24-02-22 06:46:13.9904 UTC gradient_boosted_trees.cc:334] Final model num-trees:178 valid-loss:0.806646 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:13.9908 UTC hyperparameters_optimizer.cc:582] [318/500] Score: -0.806646 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:13.9915 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:13.9916 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:13.9920 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.0019 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834984\n",
      "[INFO 24-02-22 06:46:14.0019 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.0022 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.834984 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:14.0033 UTC hyperparameters_optimizer.cc:582] [319/500] Score: -0.834984 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.0049 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.0049 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.0052 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.0061 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.662497 train-accuracy:0.871716 valid-loss:0.865441 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.0061 UTC gradient_boosted_trees.cc:271] Truncates the model to 284 tree(s) i.e. 284  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.0061 UTC gradient_boosted_trees.cc:334] Final model num-trees:284 valid-loss:0.863688 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.0064 UTC hyperparameters_optimizer.cc:582] [320/500] Score: -0.863688 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:14.0068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.0068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.0071 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.0076 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844125\n",
      "[INFO 24-02-22 06:46:14.0076 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.0077 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.844125 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.0079 UTC hyperparameters_optimizer.cc:582] [321/500] Score: -0.844125 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.0083 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.0083 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.0085 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.0096 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324808 train-accuracy:0.599691 valid-loss:1.303621 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.0104 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298894 train-accuracy:0.599691 valid-loss:1.278034 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.0203 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284248 train-accuracy:0.599691 valid-loss:1.267679 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.0367 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292111 train-accuracy:0.599691 valid-loss:1.273172 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.0974 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.648473 train-accuracy:0.879444 valid-loss:0.841110 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.0974 UTC gradient_boosted_trees.cc:271] Truncates the model to 299 tree(s) i.e. 299  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.0974 UTC gradient_boosted_trees.cc:334] Final model num-trees:299 valid-loss:0.840642 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.1023 UTC hyperparameters_optimizer.cc:582] [322/500] Score: -0.840642 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:14.1041 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.1041 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.1048 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.1196 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.249250 train-accuracy:0.599691 valid-loss:1.254290 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.1374 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.908148\n",
      "[INFO 24-02-22 06:46:14.1375 UTC gradient_boosted_trees.cc:271] Truncates the model to 39 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.1378 UTC gradient_boosted_trees.cc:334] Final model num-trees:39 valid-loss:0.908148 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.1387 UTC hyperparameters_optimizer.cc:582] [323/500] Score: -0.908148 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.1400 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.1400 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.1402 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.1639 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321696 train-accuracy:0.599691 valid-loss:1.299578 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.1811 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864405\n",
      "[INFO 24-02-22 06:46:14.1811 UTC gradient_boosted_trees.cc:271] Truncates the model to 146 tree(s) i.e. 146  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.1813 UTC gradient_boosted_trees.cc:334] Final model num-trees:146 valid-loss:0.864405 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.1825 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.1826 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[[INFO 24-02-22 06:46:14.1828 UTC hyperparameters_optimizer.cc:582] [324/500] Score: -0.864405 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "INFO 24-02-22 06:46:14.1837 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.1895 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302857 train-accuracy:0.599691 valid-loss:1.282740 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.3177 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849398\n",
      "[INFO 24-02-22 06:46:14.3177 UTC gradient_boosted_trees.cc:271] Truncates the model to 138 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.3179 UTC gradient_boosted_trees.cc:334] Final model num-trees:138 valid-loss:0.849398 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.3192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.3192 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.3194 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.3195 UTC hyperparameters_optimizer.cc:582] [325/500] Score: -0.849398 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:14.3223 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.291512 train-accuracy:0.599691 valid-loss:1.276446 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.4102 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902137\n",
      "[INFO 24-02-22 06:46:14.4105 UTC gradient_boosted_trees.cc:271] Truncates the model to 94 tree(s) i.e. 94  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.4123 UTC gradient_boosted_trees.cc:334] Final model num-trees:94 valid-loss:0.902137 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.4136 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.4136 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.4137 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.4155 UTC hyperparameters_optimizer.cc:582] [326/500] Score: -0.902137 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:14.4257 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231591 train-accuracy:0.599691 valid-loss:1.249238 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.4305 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.835538\n",
      "[INFO 24-02-22 06:46:14.4305 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.4307 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.835538 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.4311 UTC hyperparameters_optimizer.cc:582] [327/500] Score: -0.835538 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:14.4319 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.4319 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.4321 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.4594 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322788 train-accuracy:0.599691 valid-loss:1.300967 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.6495 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874074\n",
      "[INFO 24-02-22 06:46:14.6496 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.6497 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.874074 valid-accuracy:0.803030\n",
      "[[INFO 24-02-22 06:46:14.6504 UTC hyperparameters_optimizer.cc:582] [328/500] Score: -0.874074 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "INFO 24-02-22 06:46:14.6506 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.6507 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.6510 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.6643 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322687 train-accuracy:0.599691 valid-loss:1.300945 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.6756 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.839348\n",
      "[INFO 24-02-22 06:46:14.6756 UTC gradient_boosted_trees.cc:271] Truncates the model to 115 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.6757 UTC gradient_boosted_trees.cc:334] Final model num-trees:115 valid-loss:0.839348 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.6763 UTC hyperparameters_optimizer.cc:582] [329/500] Score: -0.839348 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.6774 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.6774 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.6776 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.6999 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287789 train-accuracy:0.599691 valid-loss:1.278768 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.7918 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881485\n",
      "[INFO 24-02-22 06:46:14.7919 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.7925 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.881485 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:14.7944 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.7945 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.7948 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.7954 UTC hyperparameters_optimizer.cc:582] [330/500] Score: -0.881485 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:14.7994 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297296 train-accuracy:0.599691 valid-loss:1.281059 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.8389 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.879958\n",
      "[INFO 24-02-22 06:46:14.8390 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.8392 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.879958 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:14.8397 UTC hyperparameters_optimizer.cc:582] [331/500] Score: -0.879958 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:14.8402 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.8402 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.8407 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.8510 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322431 train-accuracy:0.599691 valid-loss:1.298795 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.8539 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.886162\n",
      "[INFO 24-02-22 06:46:14.8540 UTC gradient_boosted_trees.cc:271] Truncates the model to 87 tree(s) i.e. 87  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.8541 UTC gradient_boosted_trees.cc:334] Final model num-trees:87 valid-loss:0.886162 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:14.8547 UTC hyperparameters_optimizer.cc:582] [332/500] Score: -0.886162 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:14.8554 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.8554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.8558 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.8691 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806861\n",
      "[INFO 24-02-22 06:46:14.8691 UTC gradient_boosted_trees.cc:271] Truncates the model to 84 tree(s) i.e. 84  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.8693 UTC gradient_boosted_trees.cc:334] Final model num-trees:84 valid-loss:0.806861 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:14.8699 UTC hyperparameters_optimizer.cc:582] [333/500] Score: -0.806861 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.8708 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.8709 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.8711 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.8818 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.218532 train-accuracy:0.599691 valid-loss:1.229182 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.8925 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241439 train-accuracy:0.599691 valid-loss:1.257340 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:14.9606 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840271\n",
      "[INFO 24-02-22 06:46:14.9606 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:46:14.9607 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.840271 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:14.9611 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:14.9611 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:14.9613 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:14.9621 UTC hyperparameters_optimizer.cc:582] [334/500] Score: -0.840271 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:14.9728 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322631 train-accuracy:0.599691 valid-loss:1.299350 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.0575 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876965\n",
      "[INFO 24-02-22 06:46:15.0575 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.0577 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.876965 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:15.0577 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823232\n",
      "[INFO 24-02-22 06:46:15.0577 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.0578 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.823232 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:15.0580 UTC hyperparameters_optimizer.cc:582] [335/500] Score: -0.823232 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:15.0582 UTC hyperparameters_optimizer.cc:582] [336/[INFO 24-02-22 06:46:15.0582 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.0582 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.0584 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.0585 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.0585 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "500] Score: -0.876965 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:15.0591 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.0716 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324931 train-accuracy:0.599691 valid-loss:1.300968 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.0743 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230097 train-accuracy:0.599691 valid-loss:1.233376 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.1579 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868958\n",
      "[INFO 24-02-22 06:46:15.1579 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.1582 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.868958 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:15.1589 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.1589 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.1594 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.1621 UTC hyperparameters_optimizer.cc:582] [337/500] Score: -0.868958 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:15.1784 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239919 train-accuracy:0.599691 valid-loss:1.240268 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.4469 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845635\n",
      "[INFO 24-02-22 06:46:15.4469 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.4470 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.845635 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:15.4473 UTC hyperparameters_optimizer.cc:582] [338/500] Score: -0.845635 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:15.4476 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.4477 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.4480 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.4532 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329081 train-accuracy:0.599691 valid-loss:1.304597 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.7611 UTC gradient_boosted_trees.cc:1638] \tnum-trees:69 train-loss:0.846107 train-accuracy:0.843895 valid-loss:0.943233 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:15.8052 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874903\n",
      "[INFO 24-02-22 06:46:15.8052 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.8055 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.874903 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:15.8061 UTC hyperparameters_optimizer.cc:582] [339/500] Score: -0.874903 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:15.8069 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.8070 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.8073 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:15.8127 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.252365 train-accuracy:0.599691 valid-loss:1.253688 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:15.9884 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.869719\n",
      "[INFO 24-02-22 06:46:15.9885 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:15.9887 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.869719 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:15.9892 UTC hyperparameters_optimizer.cc:582] [340/500] Score: -0.869719 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:15.9904 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:15.9906 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:15.9909 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.0123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.279918 train-accuracy:0.599691 valid-loss:1.273780 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.0465 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862051\n",
      "[INFO 24-02-22 06:46:16.0465 UTC gradient_boosted_trees.cc:271] Truncates the model to 230 tree(s) i.e. 230  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.0467 UTC gradient_boosted_trees.cc:334] Final model num-trees:230 valid-loss:0.862051 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.0480 UTC hyperparameters_optimizer.cc:582] [341/500] Score: -0.862051 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:16.0483 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.0483 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.0485 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.0638 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290790 train-accuracy:0.599691 valid-loss:1.276983 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.0842 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.851016\n",
      "[INFO 24-02-22 06:46:16.0844 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.0846 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.851016 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.0850 UTC hyperparameters_optimizer.cc:582] [342/500] Score: -0.851016 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:16.0855 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.0855 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.0857 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.1029 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323030 train-accuracy:0.599691 valid-loss:1.297347 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.1059 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824155\n",
      "[INFO 24-02-22 06:46:16.1059 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.1062 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.824155 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:16.1067 UTC hyperparameters_optimizer.cc:582] [343/500] Score: -0.824155 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:16.1073 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.1073 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.1081 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.1140 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.878121\n",
      "[INFO 24-02-22 06:46:16.1141 UTC gradient_boosted_trees.cc:271] Truncates the model to 20 tree(s) i.e. 20  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.1144 UTC gradient_boosted_trees.cc:334] Final model num-trees:20 valid-loss:0.878121 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.1147 UTC hyperparameters_optimizer.cc:582] [344/500] Score: -0.878121 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:16.1157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.1158 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.1160 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.1189 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321390 train-accuracy:0.599691 valid-loss:1.296705 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.1337 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324406 train-accuracy:0.599691 valid-loss:1.301194 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.2482 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874139\n",
      "[INFO 24-02-22 06:46:16.2482 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.2483 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.874139 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:16.2484 UTC hyperparameters_optimizer.cc:582] [345/500] Score: -0.874139 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:16.2488 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.2488 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.2489 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.2526 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298632 train-accuracy:0.599691 valid-loss:1.275730 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.3965 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.871411\n",
      "[INFO 24-02-22 06:46:16.3965 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.3968 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.871411 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.3980 UTC hyperparameters_optimizer.cc:582] [346/500] Score: -0.871411 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:16.4002 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.4002 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.4004 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.4099 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324156 train-accuracy:0.599691 valid-loss:1.301589 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.5706 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.875705\n",
      "[INFO 24-02-22 06:46:16.5707 UTC gradient_boosted_trees.cc:271] Truncates the model to 121 tree(s) i.e. 121  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.5709 UTC gradient_boosted_trees.cc:334] Final model num-trees:121 valid-loss:0.875705 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.5720 UTC hyperparameters_optimizer.cc:582] [347/500] Score: -0.875705 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:16.5739 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.5739 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.5740 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.5843 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287035 train-accuracy:0.599691 valid-loss:1.274595 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.6693 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.811636\n",
      "[INFO 24-02-22 06:46:16.6693 UTC gradient_boosted_trees.cc:271] Truncates the model to 210 tree(s) i.e. 210  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.6695 UTC gradient_boosted_trees.cc:334] Final model num-trees:210 valid-loss:0.811636 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.6708 UTC hyperparameters_optimizer.cc:582] [348/500] Score: -0.811636 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:16.6733 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.6733 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.6735 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.6933 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288220 train-accuracy:0.599691 valid-loss:1.275597 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.7518 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.844084\n",
      "[INFO 24-02-22 06:46:16.7519 UTC gradient_boosted_trees.cc:271] Truncates the model to 104 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.7519 UTC gradient_boosted_trees.cc:334] Final model num-trees:104 valid-loss:0.844084 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.7525 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.7525 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.7527 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.7587 UTC hyperparameters_optimizer.cc:582] [349/500] Score: -0.844084 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:16.7641 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323341 train-accuracy:0.599691 valid-loss:1.301286 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.7876 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.628221 train-accuracy:0.868624 valid-loss:0.833106 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.7876 UTC gradient_boosted_trees.cc:271] Truncates the model to 296 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.7877 UTC gradient_boosted_trees.cc:334] Final model num-trees:296 valid-loss:0.832464 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.7880 UTC hyperparameters_optimizer.cc:582] [350/500] Score: -0.832464 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:16.7887 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.7887 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.7888 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.8030 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322808 train-accuracy:0.599691 valid-loss:1.303474 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.8952 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.83767\n",
      "[INFO 24-02-22 06:46:16.8953 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.8955 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.837670 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:16.8965 UTC hyperparameters_optimizer.cc:582] [351/500] Score: -0.83767 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:16.8983 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.8983 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.8985 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.9160 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323189 train-accuracy:0.599691 valid-loss:1.301968 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:16.9905 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881786\n",
      "[INFO 24-02-22 06:46:16.9905 UTC gradient_boosted_trees.cc:271] Truncates the model to 135 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 24-02-22 06:46:16.9908 UTC gradient_boosted_trees.cc:334] Final model num-trees:135 valid-loss:0.881786 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:16.9921 UTC hyperparameters_optimizer.cc:582] [352/500] Score: -0.881786 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:16.9945 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:16.9946 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:16.9948 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:16.9986 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.264080 train-accuracy:0.599691 valid-loss:1.259534 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.0217 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857238\n",
      "[INFO 24-02-22 06:46:17.0217 UTC gradient_boosted_trees.cc:271] Truncates the model to 149 tree(s) i.e. 149  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.0218 UTC gradient_boosted_trees.cc:334] Final model num-trees:149 valid-loss:0.857238 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:17.0228 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.0230 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.0233 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.0254 UTC hyperparameters_optimizer.cc:582] [353/500] Score: -0.857238 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:17.0281 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859625\n",
      "[INFO 24-02-22 06:46:17.0284 UTC gradient_boosted_trees.cc:271] Truncates the model to 154 tree(s) i.e. 154  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.0288 UTC gradient_boosted_trees.cc:334] Final model num-trees:154 valid-loss:0.859625 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:17.0297 UTC hyperparameters_optimizer.cc:582] [354/500] Score: -0.859625 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:17.0316 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.0317 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.0321 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.0353 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326163 train-accuracy:0.599691 valid-loss:1.303270 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.0432 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325445 train-accuracy:0.599691 valid-loss:1.301339 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.3157 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.859246\n",
      "[INFO 24-02-22 06:46:17.3157 UTC gradient_boosted_trees.cc:271] Truncates the model to 139 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.3160 UTC gradient_boosted_trees.cc:334] Final model num-trees:139 valid-loss:0.859246 valid-accuracy:0.803030\n",
      "[INFO[INFO 24-02-22 06:46:17.3177 UTC hyperparameters_optimizer.cc:582] [355/500] Score: -0.859246 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      " 24-02-22 06:46:17.3177 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.3181 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.3226 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.3400 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322551 train-accuracy:0.599691 valid-loss:1.301024 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.4794 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838753\n",
      "[INFO 24-02-22 06:46:17.4794 UTC gradient_boosted_trees.cc:271] Truncates the model to 71 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.4796 UTC gradient_boosted_trees.cc:334] Final model num-trees:71 valid-loss:0.838753 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:17.4802 UTC hyperparameters_optimizer.cc:582] [356/500] Score: -0.838753 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:17.4807 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.4807 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.4812 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.4821 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880835\n",
      "[INFO 24-02-22 06:46:17.4822 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.4824 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.880835 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:17.4832 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.4832 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.4833 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.4852 UTC hyperparameters_optimizer.cc:582] [357/500] Score: -0.880835 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:17.4915 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239646 train-accuracy:0.599691 valid-loss:1.237198 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.5001 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230207 train-accuracy:0.599691 valid-loss:1.240547 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.6028 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902397\n",
      "[INFO 24-02-22 06:46:17.6028 UTC gradient_boosted_trees.cc:271] Truncates the model to 97 tree(s) i.e. 97  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.6030 UTC gradient_boosted_trees.cc:334] Final model num-trees:97 valid-loss:0.902397 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:17.6040 UTC hyperparameters_optimizer.cc:582] [358/500] Score: -0.902397 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:17.6046 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.6046 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.6061 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.6095 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328171 train-accuracy:0.599691 valid-loss:1.303988 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.6458 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.885739\n",
      "[INFO 24-02-22 06:46:17.6458 UTC gradient_boosted_trees.cc:271] Truncates the model to 99 tree(s) i.e. 99  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.6460 UTC gradient_boosted_trees.cc:334] Final model num-trees:99 valid-loss:0.885739 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:17.6468 UTC hyperparameters_optimizer.cc:582] [359/500] Score: -0.885739 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:17.6479 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.6479 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.6486 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.6670 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.830544\n",
      "[INFO 24-02-22 06:46:17.6671 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.6671 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.830544 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:17.6674 UTC hyperparameters_optimizer.cc:582] [360/500] Score: -0.830544 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:17.6679 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.6679 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.6682 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.6683 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.223510 train-accuracy:0.599691 valid-loss:1.244706 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.6754 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.264934 train-accuracy:0.599691 valid-loss:1.259652 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:17.7150 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866232\n",
      "[INFO 24-02-22 06:46:17.7151 UTC gradient_boosted_trees.cc:271] Truncates the model to 53 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 24-02-22 06:46:17.7153 UTC gradient_boosted_trees.cc:334] Final model num-trees:53 valid-loss:0.866232 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:17.7162 UTC hyperparameters_optimizer.cc:582] [361/500] Score: -0.866232 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:17.7163 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:17.7163 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:17.7169 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:17.7316 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245019 train-accuracy:0.599691 valid-loss:1.242678 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.0477 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.84578\n",
      "[INFO 24-02-22 06:46:18.0478 UTC gradient_boosted_trees.cc:271] Truncates the model to 84 tree(s) i.e. 84  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.0478 UTC gradient_boosted_trees.cc:334] Final model num-trees:84 valid-loss:0.845780 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.0481 UTC hyperparameters_optimizer.cc:582] [362/500] Score: -0.84578 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:18.0500 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.0500 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.0508 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.0735 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285256 train-accuracy:0.599691 valid-loss:1.265318 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.2835 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.833452\n",
      "[INFO 24-02-22 06:46:18.2836 UTC gradient_boosted_trees.cc:271] Truncates the model to 64 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.2839 UTC gradient_boosted_trees.cc:334] Final model num-trees:64 valid-loss:0.833452 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:18.2844 UTC hyperparameters_optimizer.cc:582] [363/500] Score: -0.833452 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:18.2858 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.2858 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.2861 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.2884 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.302732 train-accuracy:0.599691 valid-loss:1.286804 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.3187 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.792538\n",
      "[INFO 24-02-22 06:46:18.3188 UTC gradient_boosted_trees.cc:271] Truncates the model to 214 tree(s) i.e. 214  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.3189 UTC gradient_boosted_trees.cc:334] Final model num-trees:214 valid-loss:0.792538 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.3202 UTC hyperparameters_optimizer.cc:582] [364/500] Score: -0.792538 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:18.3207 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.3207 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.3218 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.3286 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.252630 train-accuracy:0.599691 valid-loss:1.251546 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.3318 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.877442\n",
      "[INFO 24-02-22 06:46:18.3319 UTC gradient_boosted_trees.cc:271] Truncates the model to 15 tree(s) i.e. 15  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.3323 UTC gradient_boosted_trees.cc:334] Final model num-trees:15 valid-loss:0.877442 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:18.3325 UTC hyperparameters_optimizer.cc:582] [365/500] Score: -0.877442 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:18.3329 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.3329 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.3334 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.3415 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299160 train-accuracy:0.599691 valid-loss:1.282474 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.3472 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.894494\n",
      "[INFO 24-02-22 06:46:18.3472 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.3473 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.894494 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.3479 UTC hyperparameters_optimizer.cc:582] [366/500] Score: -0.894494 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:18.3493 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.3495 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.3512 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.3698 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295236 train-accuracy:0.599691 valid-loss:1.279608 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.4066 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825456\n",
      "[INFO 24-02-22 06:46:18.4066 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.4069 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.825456 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.4085 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.4088 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.4094 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.4123 UTC hyperparameters_optimizer.cc:582] [367/500] Score: -0.825456 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:18.4161 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326971 train-accuracy:0.599691 valid-loss:1.301426 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.4337 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.879201\n",
      "[INFO 24-02-22 06:46:18.4338 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.4343 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.879201 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:18.4359 UTC hyperparameters_optimizer.cc:582] [368/500] Score: -0.879201 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:18.4369 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.4369 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.4371 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.4441 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.328662 train-accuracy:0.599691 valid-loss:1.305328 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.4509 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.876821\n",
      "[INFO 24-02-22 06:46:18.4510 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.4513 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.876821 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:18.4517 UTC hyperparameters_optimizer.cc:582] [369/500] Score: -0.876821 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:18.4522 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.4522 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.4526 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.4707 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288248 train-accuracy:0.599691 valid-loss:1.286268 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.6493 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902616\n",
      "[INFO 24-02-22 06:46:18.6493 UTC gradient_boosted_trees.cc:271] Truncates the model to 17 tree(s) i.e. 17  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.6497 UTC gradient_boosted_trees.cc:334] Final model num-trees:17 valid-loss:0.902616 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:18.6500 UTC hyperparameters_optimizer.cc:582] [370/500] Score: -0.902616 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:18.6507 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.6507 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.6508 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.6605 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298123 train-accuracy:0.599691 valid-loss:1.282281 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.6962 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.624892 train-accuracy:0.873261 valid-loss:0.833572 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.6963 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.6963 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.833572 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.6967 UTC hyperparameters_optimizer.cc:582] [371/500] Score: -0.833572 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:18.6975 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.6976 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.6978 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.7042 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247753 train-accuracy:0.599691 valid-loss:1.252946 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.7295 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865795\n",
      "[INFO 24-02-22 06:46:18.7295 UTC gradient_boosted_trees.cc:271] Truncates the model to 118 tree(s) i.e. 118  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.7297 UTC gradient_boosted_trees.cc:334] Final model num-trees:118 valid-loss:0.865795 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.7354 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.7355 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.7357 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.7388 UTC hyperparameters_optimizer.cc:582] [372/500] Score: -0.865795 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:18.7464 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.265835 train-accuracy:0.599691 valid-loss:1.259168 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:18.9211 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827191\n",
      "[INFO 24-02-22 06:46:18.9211 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:18.9212 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.827191 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:18.9215 UTC hyperparameters_optimizer.cc:582] [373/500] Score: -0.827191 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:18.9219 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:18.9233 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:18.9239 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:18.9408 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285470 train-accuracy:0.599691 valid-loss:1.280667 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.0810 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842725\n",
      "[INFO 24-02-22 06:46:19.0810 UTC gradient_boosted_trees.cc:271] Truncates the model to 153 tree(s) i.e. 153  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.0811 UTC gradient_boosted_trees.cc:334] Final model num-trees:153 valid-loss:0.842725 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:19.0823 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.0823 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.0825 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.0854 UTC hyperparameters_optimizer.cc:582] [374/500] Score: -0.842725 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:19.0907 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322655 train-accuracy:0.599691 valid-loss:1.298650 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.1786 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.831007\n",
      "[INFO 24-02-22 06:46:19.1789 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.1798 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.831007 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:19.1802 UTC hyperparameters_optimizer.cc:582] [375/500] Score: -0.831007 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:19.1808 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.1808 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.1811 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.1901 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.241142 train-accuracy:0.599691 valid-loss:1.227674 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.3059 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825049\n",
      "[INFO 24-02-22 06:46:19.3060 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.3061 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.825049 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:19.3066 UTC hyperparameters_optimizer.cc:582] [376/500] Score: -0.825049 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:19.3068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.3068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.3071 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.3201 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321941 train-accuracy:0.599691 valid-loss:1.298497 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.4405 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.813229\n",
      "[INFO 24-02-22 06:46:19.4406 UTC gradient_boosted_trees.cc:271] Truncates the model to 102 tree(s) i.e. 102  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.4406 UTC gradient_boosted_trees.cc:334] Final model num-trees:102 valid-loss:0.813229 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:19.4408 UTC hyperparameters_optimizer.cc:582] [377/500] Score: -0.813229 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:19.4413 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.4413 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.4415 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.4424 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.329393 train-accuracy:0.599691 valid-loss:1.305255 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.5023 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.840959\n",
      "[INFO 24-02-22 06:46:19.5023 UTC gradient_boosted_trees.cc:271] Truncates the model to 151 tree(s) i.e. 151  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.5026 UTC gradient_boosted_trees.cc:334] Final model num-trees:151 valid-loss:0.840959 valid-accuracy:0.787879\n",
      "[[INFO 24-02-22 06:46:19.5047 UTC hyperparameters_optimizer.cc:582] [378/500] Score: -0.840959 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "INFO 24-02-22 06:46:19.5048 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.5054 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.5060 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.5168 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.296846 train-accuracy:0.599691 valid-loss:1.282393 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.5856 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.715470 train-accuracy:0.851623 valid-loss:0.874445 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:19.5856 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.5856 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.873263 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:19.5859 UTC hyperparameters_optimizer.cc:582] [379/500] Score: -0.873263 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:19.5874 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.5874 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.5878 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.6124 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322317 train-accuracy:0.599691 valid-loss:1.299272 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.6553 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.828491\n",
      "[INFO 24-02-22 06:46:19.6553 UTC gradient_boosted_trees.cc:271] Truncates the model to 221 tree(s) i.e. 221  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.6554 UTC gradient_boosted_trees.cc:334] Final model num-trees:221 valid-loss:0.828491 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:19.6562 UTC hyperparameters_optimizer.cc:582] [380/500] Score: -0.828491 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:19.6581 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.6581 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.6583 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.6709 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293467 train-accuracy:0.599691 valid-loss:1.278218 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.7256 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.806593\n",
      "[INFO 24-02-22 06:46:19.7257 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.7259 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.806593 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:19.7267 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.7267 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.7268 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.7280 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.831233\n",
      "[INFO 24-02-22 06:46:19.7281 UTC gradient_boosted_trees.cc:271] Truncates the model to 164 tree(s) i.e. 164  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.7281 UTC gradient_boosted_trees.cc:334] Final model num-trees:164 valid-loss:0.831233 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:19.7286 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.7286 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.7287 UTC hyperparameters_optimizer.cc:582] [381/500] Score: -0.806593 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:19.7291 UTC hyperparameters_optimizer.cc:582] [382/500] Score: -0.831233 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:19.7305 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.7375 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321594 train-accuracy:0.599691 valid-loss:1.299985 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.7409 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324193 train-accuracy:0.599691 valid-loss:1.302485 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.8852 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834233\n",
      "[INFO 24-02-22 06:46:19.8852 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.8853 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.834233 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:19.8855 UTC hyperparameters_optimizer.cc:582] [383/500] Score: -0.834233 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:19.8862 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.8862 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.8864 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.8900 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.902774\n",
      "[INFO 24-02-22 06:46:19.8900 UTC gradient_boosted_trees.cc:271] Truncates the model to 148 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 24-02-22 06:46:19.8902 UTC gradient_boosted_trees.cc:334] Final model num-trees:148 valid-loss:0.902774 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:19.8918 UTC hyperparameters_optimizer.cc:582] [384/500] Score: -0.902774 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:19.8955 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:19.8955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:19.8958 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:19.8998 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326739 train-accuracy:0.599691 valid-loss:1.300533 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:19.9050 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226218 train-accuracy:0.599691 valid-loss:1.237393 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.0426 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.823503\n",
      "[INFO 24-02-22 06:46:20.0426 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.0429 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.823503 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.0445 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.0446 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.0447 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.0454 UTC hyperparameters_optimizer.cc:582] [385/500] Score: -0.823503 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.0496 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326783 train-accuracy:0.599691 valid-loss:1.302539 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.0519 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.786696\n",
      "[INFO 24-02-22 06:46:20.0519 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.0521 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.786696 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.0527 UTC hyperparameters_optimizer.cc:582] [386/500] Score: -0.786696 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.0531 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.0531 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.0533 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.0742 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321941 train-accuracy:0.599691 valid-loss:1.298165 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.1443 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.866231\n",
      "[INFO 24-02-22 06:46:20.1443 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.1446 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.866231 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.1452 UTC hyperparameters_optimizer.cc:582] [387/500] Score: -0.866231 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.1458 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.1458 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.1464 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.1546 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.900502\n",
      "[INFO 24-02-22 06:46:20.1546 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.1549 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.900502 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:20.1558 UTC hyperparameters_optimizer.cc:582] [388/500] Score: -0.900502 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:20.1582 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.1583 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.1584 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.1620 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288385 train-accuracy:0.599691 valid-loss:1.271633 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.1733 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.229096 train-accuracy:0.599691 valid-loss:1.246819 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.1855 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857059\n",
      "[INFO 24-02-22 06:46:20.1855 UTC gradient_boosted_trees.cc:271] Truncates the model to 132 tree(s) i.e. 132  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.1858 UTC gradient_boosted_trees.cc:334] Final model num-trees:132 valid-loss:0.857059 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.1866 UTC hyperparameters_optimizer.cc:582] [389/500] Score: -0.857059 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:20.1870 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.1870 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.1877 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.1911 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825327\n",
      "[INFO 24-02-22 06:46:20.1911 UTC gradient_boosted_trees.cc:271] Truncates the model to 169 tree(s) i.e. 169  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.1915 UTC gradient_boosted_trees.cc:334] Final model num-trees:169 valid-loss:0.825327 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:20.1935 UTC hyperparameters_optimizer.cc:582] [390/500] Score: -0.825327 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.1954 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.1955 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.1959 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.2085 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319999 train-accuracy:0.599691 valid-loss:1.298808 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.2164 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236396 train-accuracy:0.599691 valid-loss:1.248073 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.2636 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852652\n",
      "[INFO 24-02-22 06:46:20.2636 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.2638 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.852652 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.2646 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.2646 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.2648 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.2652 UTC hyperparameters_optimizer.cc:582] [391/500] Score: -0.852652 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:20.2706 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.262147 train-accuracy:0.599691 valid-loss:1.259999 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.4671 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.654482 train-accuracy:0.873261 valid-loss:0.824180 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:20.4673 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.4676 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.824180 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:20.4689 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.4689 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.4691 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.4719 UTC hyperparameters_optimizer.cc:582] [392/500] Score: -0.82418 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:20.4863 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237808 train-accuracy:0.599691 valid-loss:1.252180 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.7984 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832637\n",
      "[INFO 24-02-22 06:46:20.7985 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.7985 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.832637 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:20.7990 UTC hyperparameters_optimizer.cc:582] [393/500] Score: -0.832637 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:20.8004 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.8006 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.8013 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.8144 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289524 train-accuracy:0.599691 valid-loss:1.275626 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:20.9586 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.826534\n",
      "[INFO 24-02-22 06:46:20.9586 UTC gradient_boosted_trees.cc:271] Truncates the model to 67 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 24-02-22 06:46:20.9587 UTC gradient_boosted_trees.cc:334] Final model num-trees:67 valid-loss:0.826534 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:20.9593 UTC hyperparameters_optimizer.cc:582] [394/500] Score: -0.826534 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:20.9597 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:20.9597 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:20.9602 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:20.9654 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.266406 train-accuracy:0.599691 valid-loss:1.252495 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.0836 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836621\n",
      "[INFO 24-02-22 06:46:21.0836 UTC gradient_boosted_trees.cc:271] Truncates the model to 253 tree(s) i.e. 253  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.0837 UTC gradient_boosted_trees.cc:334] Final model num-trees:253 valid-loss:0.836621 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:21.0851 UTC hyperparameters_optimizer.cc:582] [395/500] Score: -0.836621 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.0883 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.0891 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.0893 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.1156 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285809 train-accuracy:0.599691 valid-loss:1.278593 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.1219 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880037\n",
      "[INFO 24-02-22 06:46:21.1219 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.1221 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.880037 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.1226 UTC hyperparameters_optimizer.cc:582] [396/500] Score: -0.880037 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.1233 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.1235 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.1237 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.1367 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230668 train-accuracy:0.599691 valid-loss:1.244447 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.1560 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.795838\n",
      "[INFO 24-02-22 06:46:21.1561 UTC gradient_boosted_trees.cc:271] Truncates the model to 119 tree(s) i.e. 119  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.1561 UTC gradient_boosted_trees.cc:334] Final model num-trees:119 valid-loss:0.795838 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.1563 UTC hyperparameters_optimizer.cc:582] [397/500] Score: -0.795838 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:21.1568 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.1568 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.1570 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.1745 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.319552 train-accuracy:0.599691 valid-loss:1.299159 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.1877 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850958\n",
      "[INFO 24-02-22 06:46:21.1877 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.1880 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.850958 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.1885 UTC hyperparameters_optimizer.cc:582] [398/500] Score: -0.850958 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:21.1896 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.1896 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.1897 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.1976 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325568 train-accuracy:0.599691 valid-loss:1.304047 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.2467 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.86593\n",
      "[INFO 24-02-22 06:46:21.2467 UTC gradient_boosted_trees.cc:271] Truncates the model to 125 tree(s) i.e. 125  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.2471 UTC gradient_boosted_trees.cc:334] Final model num-trees:125 valid-loss:0.865930 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.2484 UTC hyperparameters_optimizer.cc:582] [399/500] Score: -0.86593 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:21.2536 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.2566 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.2568 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.2681 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.231959 train-accuracy:0.599691 valid-loss:1.246595 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.3297 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857582\n",
      "[INFO 24-02-22 06:46:21.3298 UTC gradient_boosted_trees.cc:271] Truncates the model to 107 tree(s) i.e. 107  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.3299 UTC gradient_boosted_trees.cc:334] Final model num-trees:107 valid-loss:0.857582 valid-accuracy:0.818182\n",
      "[INFO[INFO 24-02-22 06:46:21.3327 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.3327 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.3329 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      " 24-02-22 06:46:21.3357 UTC hyperparameters_optimizer.cc:582] [400/500] Score: -0.857582 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.3533 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233756 train-accuracy:0.599691 valid-loss:1.240359 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.4477 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.883494\n",
      "[INFO 24-02-22 06:46:21.4486 UTC gradient_boosted_trees.cc:271] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.4488 UTC gradient_boosted_trees.cc:334] Final model num-trees:26 valid-loss:0.883494 valid-accuracy:0.803030\n",
      "[INFO[ 24-02-22 06:46:21.4511 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "INFO[INFO 24-02-22 06:46:21.4511 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      " 24-02-22 06:46:21.4511 UTC hyperparameters_optimizer.cc:582] [401/500] Score: -0.883494 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.4518 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.4522 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.534927 train-accuracy:0.908810 valid-loss:0.849025 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.4522 UTC gradient_boosted_trees.cc:271] Truncates the model to 298 tree(s) i.e. 298  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.4522 UTC gradient_boosted_trees.cc:334] Final model num-trees:298 valid-loss:0.848618 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.4528 UTC hyperparameters_optimizer.cc:582] [402/500] Score: -0.848618 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:21.4532 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.4532 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.4537 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.4616 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.246449 train-accuracy:0.599691 valid-loss:1.243552 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.4785 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321153 train-accuracy:0.599691 valid-loss:1.300486 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.5138 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.887463\n",
      "[INFO 24-02-22 06:46:21.5138 UTC gradient_boosted_trees.cc:271] Truncates the model to 34 tree(s) i.e. 34  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.5142 UTC gradient_boosted_trees.cc:334] Final model num-trees:34 valid-loss:0.887463 valid-accuracy:0.787879\n",
      "[[INFO 24-02-22 06:46:21.5154 UTC hyperparameters_optimizer.cc:582] [403/500] Score: -0.887463 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "INFO 24-02-22 06:46:21.5157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.5157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.5163 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.5366 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240764 train-accuracy:0.599691 valid-loss:1.243603 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.5528 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.821433\n",
      "[INFO 24-02-22 06:46:21.5529 UTC gradient_boosted_trees.cc:271] Truncates the model to 70 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.5529 UTC gradient_boosted_trees.cc:334] Final model num-trees:70 valid-loss:0.821433 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:21.5532 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.5533 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.5534 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.5555 UTC hyperparameters_optimizer.cc:582] [404/500] Score: -0.821433 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.5687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.244959 train-accuracy:0.599691 valid-loss:1.238667 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.6488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.898132\n",
      "[INFO 24-02-22 06:46:21.6496 UTC gradient_boosted_trees.cc:271] Truncates the model to 114 tree(s) i.e. 114  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.6500 UTC gradient_boosted_trees.cc:334] Final model num-trees:114 valid-loss:0.898132 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.6509 UTC hyperparameters_optimizer.cc:582] [405/500] Score: -0.898132 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.6553 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.6554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.6556 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.6595 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242661 train-accuracy:0.599691 valid-loss:1.244442 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.7142 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891879\n",
      "[INFO 24-02-22 06:46:21.7142 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.7144 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.891879 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.7187 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.7187 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.7188 UTC hyperparameters_optimizer.cc:582] [406/500] Score: -0.891879 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.7189 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.7271 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297469 train-accuracy:0.599691 valid-loss:1.277336 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.8221 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873443\n",
      "[INFO 24-02-22 06:46:21.8247 UTC gradient_boosted_trees.cc:271] Truncates the model to 52 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.8250 UTC gradient_boosted_trees.cc:334] Final model num-trees:52 valid-loss:0.873443 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.8257 UTC hyperparameters_optimizer.cc:582] [407/500] Score: -0.873443 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:21.8299 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.8300 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.8302 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.8555 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.289101 train-accuracy:0.599691 valid-loss:1.272415 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.8571 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.885702\n",
      "[INFO 24-02-22 06:46:21.8571 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.8573 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.885702 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:21.8576 UTC hyperparameters_optimizer.cc:582] [408/500] Score: -0.885702 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.8583 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.8584 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.8585 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.8647 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.298066 train-accuracy:0.599691 valid-loss:1.275231 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.9242 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.853916\n",
      "[INFO 24-02-22 06:46:21.9243 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.9245 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.853916 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:21.9251 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.9251 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.9252 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.9255 UTC hyperparameters_optimizer.cc:582] [409/500] Score: -0.853916 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:21.9377 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297151 train-accuracy:0.599691 valid-loss:1.283573 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:21.9761 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.878809\n",
      "[INFO 24-02-22 06:46:21.9761 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:21.9764 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.878809 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:21.9766 UTC hyperparameters_optimizer.cc:582] [410/500] Score: -0.878809 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:21.9773 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:21.9773 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:21.9775 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:21.9852 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.251805 train-accuracy:0.599691 valid-loss:1.258704 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.3630 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867171\n",
      "[INFO 24-02-22 06:46:22.3631 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.3632 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.867171 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:22.3635 UTC hyperparameters_optimizer.cc:582] [411/500] Score: -0.867171 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:22.3638 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.3638 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.3640 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.3727 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848085\n",
      "[INFO 24-02-22 06:46:22.3727 UTC gradient_boosted_trees.cc:271] Truncates the model to 68 tree(s) i.e. 68  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.3728 UTC gradient_boosted_trees.cc:334] Final model num-trees:68 valid-loss:0.848085 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:22.3731 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238693 train-accuracy:0.599691 valid-loss:1.229094 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.3733 UTC hyperparameters_optimizer.cc:582] [412/500] Score: -0.848085 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.3742 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.3743 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.3745 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.3833 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286572 train-accuracy:0.599691 valid-loss:1.277108 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.4666 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.800145\n",
      "[INFO 24-02-22 06:46:22.4666 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.4667 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.800145 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:22.4670 UTC hyperparameters_optimizer.cc:582] [413/500] Score: -0.800145 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.4675 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.4675 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.4677 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.4770 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322770 train-accuracy:0.599691 valid-loss:1.298749 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.6330 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825449\n",
      "[INFO 24-02-22 06:46:22.6330 UTC gradient_boosted_trees.cc:271] Truncates the model to 101 tree(s) i.e. 101  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.6332 UTC gradient_boosted_trees.cc:334] Final model num-trees:101 valid-loss:0.825449 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:22.6336 UTC hyperparameters_optimizer.cc:582] [414/500] Score: -0.825449 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:22.6340 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.6340 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.6345 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.6387 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81754\n",
      "[INFO 24-02-22 06:46:22.6388 UTC gradient_boosted_trees.cc:271] Truncates the model to 36 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.6389 UTC gradient_boosted_trees.cc:334] Final model num-trees:36 valid-loss:0.817540 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:22.6392 UTC hyperparameters_optimizer.cc:582] [415/500] Score: -0.81754 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.6397 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.6397 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.6399 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.6479 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292776 train-accuracy:0.599691 valid-loss:1.281058 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.6619 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.232047 train-accuracy:0.599691 valid-loss:1.246513 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.7635 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.833198\n",
      "[INFO 24-02-22 06:46:22.7635 UTC gradient_boosted_trees.cc:271] Truncates the model to 112 tree(s) i.e. 112  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.7636 UTC gradient_boosted_trees.cc:334] Final model num-trees:112 valid-loss:0.833198 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:22.7639 UTC hyperparameters_optimizer.cc:582] [416/500] Score: -0.833198 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:22.7642 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.7643 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.7646 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.7748 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.237687 train-accuracy:0.599691 valid-loss:1.245790 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.8380 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85852\n",
      "[INFO 24-02-22 06:46:22.8381 UTC gradient_boosted_trees.cc:271] Truncates the model to 157 tree(s) i.e. 157  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.8382 UTC gradient_boosted_trees.cc:334] Final model num-trees:157 valid-loss:0.858520 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:22.8393 UTC hyperparameters_optimizer.cc:582] [417/500] Score: -0.85852 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.8399 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.8399 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.8409 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.8654 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224034 train-accuracy:0.599691 valid-loss:1.254949 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:22.9304 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.794096\n",
      "[INFO 24-02-22 06:46:22.9305 UTC gradient_boosted_trees.cc:271] Truncates the model to 31 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 24-02-22 06:46:22.9306 UTC gradient_boosted_trees.cc:334] Final model num-trees:31 valid-loss:0.794096 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:22.9309 UTC hyperparameters_optimizer.cc:582] [418/500] Score: -0.794096 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:22.9358 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:22.9358 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:22.9360 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:22.9664 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.281505 train-accuracy:0.599691 valid-loss:1.273863 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.0148 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.838417\n",
      "[INFO 24-02-22 06:46:23.0148 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.0150 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.838417 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:23.0153 UTC hyperparameters_optimizer.cc:582] [419/500] Score: -0.838417 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:23.0157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.0157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.0159 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.0328 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.238188 train-accuracy:0.599691 valid-loss:1.241760 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.0373 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874696\n",
      "[INFO 24-02-22 06:46:23.0373 UTC gradient_boosted_trees.cc:271] Truncates the model to 99 tree(s) i.e. 99  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.0375 UTC gradient_boosted_trees.cc:334] Final model num-trees:99 valid-loss:0.874696 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:23.0387 UTC hyperparameters_optimizer.cc:582] [420/500] Score: -0.874696 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:23.0393 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.0393 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.0403 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.0606 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.89632\n",
      "[INFO 24-02-22 06:46:23.0607 UTC gradient_boosted_trees.cc:271] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.0609 UTC gradient_boosted_trees.cc:334] Final model num-trees:50 valid-loss:0.896320 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:23.0614 UTC hyperparameters_optimizer.cc:582] [421/500] Score: -0.89632 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:23.0624 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.0625 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.0626 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.0657 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288667 train-accuracy:0.599691 valid-loss:1.278169 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.0713 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286981 train-accuracy:0.599691 valid-loss:1.278010 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.1125 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.861326\n",
      "[INFO 24-02-22 06:46:23.1126 UTC gradient_boosted_trees.cc:271] Truncates the model to 49 tree(s) i.e. 49  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.1130 UTC gradient_boosted_trees.cc:334] Final model num-trees:49 valid-loss:0.861326 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:23.1141 UTC hyperparameters_optimizer.cc:582] [422/500] Score: -0.861326 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.1157 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.1157 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.1159 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.1206 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.253101 train-accuracy:0.599691 valid-loss:1.259169 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.2247 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81219\n",
      "[INFO 24-02-22 06:46:23.2247 UTC gradient_boosted_trees.cc:271] Truncates the model to 147 tree(s) i.e. 147  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.2248 UTC gradient_boosted_trees.cc:334] Final model num-trees:147 valid-loss:0.812190 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:23.2253 UTC hyperparameters_optimizer.cc:582] [423/500] Score: -0.81219 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:23.2257 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.2257 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.2262 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.2365 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324982 train-accuracy:0.599691 valid-loss:1.301121 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.4051 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843925\n",
      "[INFO 24-02-22 06:46:23.4051 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.4053 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.843925 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.4057 UTC hyperparameters_optimizer.cc:582] [424/500] Score: -0.843925 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:23.4068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.4068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.4081 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.4314 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285247 train-accuracy:0.599691 valid-loss:1.279247 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.4810 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864816\n",
      "[INFO 24-02-22 06:46:23.4810 UTC gradient_boosted_trees.cc:271] Truncates the model to 98 tree(s) i.e. 98  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.4813 UTC gradient_boosted_trees.cc:334] Final model num-trees:98 valid-loss:0.864816 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:23.4827 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.4827 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.4829 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.4856 UTC hyperparameters_optimizer.cc:582] [425/500] Score: -0.864816 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:23.5016 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287991 train-accuracy:0.599691 valid-loss:1.271756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.5707 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.841302\n",
      "[INFO 24-02-22 06:46:23.5716 UTC gradient_boosted_trees.cc:271] Truncates the model to 74 tree(s) i.e. 74  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.5717 UTC gradient_boosted_trees.cc:334] Final model num-trees:74 valid-loss:0.841302 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.5720 UTC hyperparameters_optimizer.cc:582] [426/500] Score: -0.841302 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.5726 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.5726 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.5728 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.5827 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325438 train-accuracy:0.599691 valid-loss:1.298811 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.6417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.824109\n",
      "[INFO 24-02-22 06:46:23.6417 UTC gradient_boosted_trees.cc:271] Truncates the model to 195 tree(s) i.e. 195  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.6420 UTC gradient_boosted_trees.cc:334] Final model num-trees:195 valid-loss:0.824109 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.6436 UTC hyperparameters_optimizer.cc:582] [427/500] Score: -0.824109 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:23.6451 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.6454 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.6514 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.6683 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.236242 train-accuracy:0.599691 valid-loss:1.237008 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.6811 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.893199\n",
      "[INFO 24-02-22 06:46:23.6811 UTC gradient_boosted_trees.cc:271] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.6814 UTC gradient_boosted_trees.cc:334] Final model num-trees:116 valid-loss:0.893199 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.6837 UTC hyperparameters_optimizer.cc:582] [428/500] Score: -0.893199 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:23.6851 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.6851 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.6865 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.6957 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326845 train-accuracy:0.599691 valid-loss:1.303097 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.7177 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.854581\n",
      "[INFO 24-02-22 06:46:23.7177 UTC gradient_boosted_trees.cc:271] Truncates the model to 65 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.7179 UTC gradient_boosted_trees.cc:334] Final model num-trees:65 valid-loss:0.854581 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:23.7199 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.7200 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.7203 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.7221 UTC hyperparameters_optimizer.cc:582] [429/500] Score: -0.854581 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:23.7583 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322730 train-accuracy:0.599691 valid-loss:1.301670 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.7773 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864495\n",
      "[INFO 24-02-22 06:46:23.7773 UTC gradient_boosted_trees.cc:271] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.7776 UTC gradient_boosted_trees.cc:334] Final model num-trees:27 valid-loss:0.864495 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.7779 UTC hyperparameters_optimizer.cc:582] [430/500] Score: -0.864495 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.7782 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.7782 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.7785 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.7854 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.891506\n",
      "[INFO 24-02-22 06:46:23.7856 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.7859 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.891506 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:23.7868 UTC hyperparameters_optimizer.cc:582] [431/500] Score: -0.891506 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.7875 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.7875 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.7877 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.7980 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240787 train-accuracy:0.599691 valid-loss:1.236858 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.8078 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242117 train-accuracy:0.599691 valid-loss:1.256775 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:23.9564 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.861981\n",
      "[INFO 24-02-22 06:46:23.9564 UTC gradient_boosted_trees.cc:271] Truncates the model to 38 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 24-02-22 06:46:23.9565 UTC gradient_boosted_trees.cc:334] Final model num-trees:38 valid-loss:0.861981 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:23.9569 UTC hyperparameters_optimizer.cc:582] [432/500] Score: -0.861981 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:23.9575 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:23.9575 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:23.9578 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:23.9732 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284100 train-accuracy:0.599691 valid-loss:1.273701 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.1422 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.863748\n",
      "[INFO 24-02-22 06:46:24.1422 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.1429 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.863748 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.1432 UTC hyperparameters_optimizer.cc:582] [433/500] Score: -0.863748 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:24.1436 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.1436 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.1438 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.1563 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.243992 train-accuracy:0.599691 valid-loss:1.223522 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.1708 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.901162\n",
      "[INFO 24-02-22 06:46:24.1708 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.1711 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.901162 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:24.1713 UTC hyperparameters_optimizer.cc:582] [434/500] Score: -0.901162 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:24.1719 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.1719 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.1723 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.1818 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324823 train-accuracy:0.599691 valid-loss:1.300802 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.3383 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881871\n",
      "[INFO 24-02-22 06:46:24.3383 UTC gradient_boosted_trees.cc:271] Truncates the model to 21 tree(s) i.e. 21  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.3392 UTC gradient_boosted_trees.cc:334] Final model num-trees:21 valid-loss:0.881871 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:24.3398 UTC hyperparameters_optimizer.cc:582] [435/500] Score: -0.881871 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:24.3407 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.3407 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.3409 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.3603 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322295 train-accuracy:0.599691 valid-loss:1.301339 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.3890 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.8915\n",
      "[INFO 24-02-22 06:46:24.3890 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.3893 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.891500 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.3907 UTC hyperparameters_optimizer.cc:582] [436/500] Score: -0.8915 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:24.3945 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.3945 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.3948 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.4123 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292122 train-accuracy:0.599691 valid-loss:1.279078 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.4747 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842558\n",
      "[INFO 24-02-22 06:46:24.4747 UTC gradient_boosted_trees.cc:271] Truncates the model to 40 tree(s) i.e. 40  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.4749 UTC gradient_boosted_trees.cc:334] Final model num-trees:40 valid-loss:0.842558 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.4751 UTC hyperparameters_optimizer.cc:582] [437/500] Score: -0.842558 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:24.4758 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.4758 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.4760 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.4871 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.239358 train-accuracy:0.599691 valid-loss:1.238617 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.5395 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.889452\n",
      "[INFO 24-02-22 06:46:24.5398 UTC gradient_boosted_trees.cc:271] Truncates the model to 89 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.5403 UTC gradient_boosted_trees.cc:334] Final model num-trees:89 valid-loss:0.889452 valid-accuracy:0.803030\n",
      "[[INFO 24-02-22 06:46:24.5446 UTC hyperparameters_optimizer.cc:582] [438/500] Score: -0.889452 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "INFO 24-02-22 06:46:24.5457 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.5459 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.5474 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.5837 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.325090 train-accuracy:0.599691 valid-loss:1.301567 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.7716 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865291\n",
      "[INFO 24-02-22 06:46:24.7717 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.7719 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.865291 valid-accuracy:0.818182\n",
      "[[INFO 24-02-22 06:46:24.7730 UTC hyperparameters_optimizer.cc:582] [439/500] Score: -0.865291 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "INFO 24-02-22 06:46:24.7735 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.7736 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.7741 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.7851 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321913 train-accuracy:0.599691 valid-loss:1.298923 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.8323 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.829923\n",
      "[INFO 24-02-22 06:46:24.8323 UTC gradient_boosted_trees.cc:271] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.8326 UTC gradient_boosted_trees.cc:334] Final model num-trees:41 valid-loss:0.829923 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:24.8335 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.8335 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.8341 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.8349 UTC hyperparameters_optimizer.cc:582] [440/500] Score: -0.829923 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:24.8556 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.242171 train-accuracy:0.599691 valid-loss:1.255534 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.9141 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836829\n",
      "[INFO 24-02-22 06:46:24.9141 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.9142 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.836829 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.9145 UTC hyperparameters_optimizer.cc:582] [441/500] Score: -0.836829 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:24.9151 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.9152 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.9153 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.9214 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.257563 train-accuracy:0.599691 valid-loss:1.251756 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:24.9743 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836194\n",
      "[INFO 24-02-22 06:46:24.9745 UTC gradient_boosted_trees.cc:271] Truncates the model to 35 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 24-02-22 06:46:24.9746 UTC gradient_boosted_trees.cc:334] Final model num-trees:35 valid-loss:0.836194 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:24.9751 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:24.9751 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:24.9753 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:24.9787 UTC hyperparameters_optimizer.cc:582] [442/500] Score: -0.836194 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:24.9924 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.233687 train-accuracy:0.599691 valid-loss:1.242509 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.0363 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849935\n",
      "[INFO 24-02-22 06:46:25.0363 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.0365 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.849935 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.0371 UTC hyperparameters_optimizer.cc:582] [443/500] Score: -0.849935 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:25.0383 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.0383 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.0386 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.0509 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.286755 train-accuracy:0.599691 valid-loss:1.285917 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.1218 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85228\n",
      "[INFO 24-02-22 06:46:25.1218 UTC gradient_boosted_trees.cc:271] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.1220 UTC gradient_boosted_trees.cc:334] Final model num-trees:54 valid-loss:0.852280 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.1227 UTC hyperparameters_optimizer.cc:582] [444/500] Score: -0.85228 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:25.1232 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.1232 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.1237 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.1343 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.326922 train-accuracy:0.599691 valid-loss:1.300154 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.1385 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.848336\n",
      "[INFO 24-02-22 06:46:25.1387 UTC gradient_boosted_trees.cc:271] Truncates the model to 25 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.1392 UTC gradient_boosted_trees.cc:334] Final model num-trees:25 valid-loss:0.848336 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:25.1396 UTC hyperparameters_optimizer.cc:582] [445/500] Score: -0.848336 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:25.1402 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.1404 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.1409 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.1828 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.284817 train-accuracy:0.599691 valid-loss:1.274918 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.2947 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.856491\n",
      "[INFO 24-02-22 06:46:25.2947 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.2949 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.856491 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:25.2953 UTC hyperparameters_optimizer.cc:582] [446/500] Score: -0.856491 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:25.2959 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.2960 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.2966 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.3094 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288903 train-accuracy:0.599691 valid-loss:1.276387 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.7421 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.892933\n",
      "[INFO 24-02-22 06:46:25.7422 UTC gradient_boosted_trees.cc:271] Truncates the model to 24 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.7424 UTC gradient_boosted_trees.cc:334] Final model num-trees:24 valid-loss:0.892933 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.7427 UTC hyperparameters_optimizer.cc:582] [447/500] Score: -0.892933 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:25.7437 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.7438 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.7440 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.7631 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320679 train-accuracy:0.599691 valid-loss:1.300279 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.7836 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855831\n",
      "[INFO 24-02-22 06:46:25.7837 UTC gradient_boosted_trees.cc:271] Truncates the model to 134 tree(s) i.e. 134  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.7840 UTC gradient_boosted_trees.cc:334] Final model num-trees:134 valid-loss:0.855831 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:25.7848 UTC hyperparameters_optimizer.cc:582] [448/500] Score: -0.855831 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:25.7854 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.7854 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.7861 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.7959 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288772 train-accuracy:0.599691 valid-loss:1.266201 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.8007 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.855176\n",
      "[INFO 24-02-22 06:46:25.8007 UTC gradient_boosted_trees.cc:271] Truncates the model to 188 tree(s) i.e. 188  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.8008 UTC gradient_boosted_trees.cc:334] Final model num-trees:188 valid-loss:0.855176 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.8016 UTC hyperparameters_optimizer.cc:582] [449/500] Score: -0.855176 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:25.8031 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.8032 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.8034 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.8139 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293512 train-accuracy:0.599691 valid-loss:1.280251 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.9333 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.892938\n",
      "[INFO 24-02-22 06:46:25.9337 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.9343 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.892938 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:25.9349 UTC hyperparameters_optimizer.cc:582] [450/500] Score: -0.892938 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:25.9361 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.9363 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.9368 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.9486 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.80558\n",
      "[INFO 24-02-22 06:46:25.9486 UTC gradient_boosted_trees.cc:271] Truncates the model to 141 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 24-02-22 06:46:25.9486 UTC gradient_boosted_trees.cc:334] Final model num-trees:141 valid-loss:0.805580 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:25.9488 UTC hyperparameters_optimizer.cc:582] [451/500] Score: -0.80558 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:25.9494 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:25.9494 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:25.9499 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:25.9577 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283808 train-accuracy:0.599691 valid-loss:1.277540 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:25.9581 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288613 train-accuracy:0.599691 valid-loss:1.275549 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.1126 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.845328\n",
      "[INFO 24-02-22 06:46:26.1126 UTC gradient_boosted_trees.cc:271] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.1128 UTC gradient_boosted_trees.cc:334] Final model num-trees:29 valid-loss:0.845328 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:26.1131 UTC hyperparameters_optimizer.cc:582] [452/500] Score: -0.845328 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:26.1136 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.1136 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.1139 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.1381 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.321220 train-accuracy:0.599691 valid-loss:1.299968 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.1719 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868953\n",
      "[INFO 24-02-22 06:46:26.1720 UTC gradient_boosted_trees.cc:271] Truncates the model to 170 tree(s) i.e. 170  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.1722 UTC gradient_boosted_trees.cc:334] Final model num-trees:170 valid-loss:0.868953 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:26.1740 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.1741 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.1743 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.1754 UTC hyperparameters_optimizer.cc:582] [453/500] Score: -0.868953 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:26.1946 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.283893 train-accuracy:0.599691 valid-loss:1.284861 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.2176 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827858\n",
      "[INFO 24-02-22 06:46:26.2176 UTC gradient_boosted_trees.cc:271] Truncates the model to 222 tree(s) i.e. 222  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.2177 UTC gradient_boosted_trees.cc:334] Final model num-trees:222 valid-loss:0.827858 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:26.2188 UTC hyperparameters_optimizer.cc:582] [454/500] Score: -0.827858 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:26.2192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.2192 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.2203 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.2355 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.245432 train-accuracy:0.599691 valid-loss:1.245759 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.3612 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.880723\n",
      "[INFO 24-02-22 06:46:26.3612 UTC gradient_boosted_trees.cc:271] Truncates the model to 85 tree(s) i.e. 85  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.3614 UTC gradient_boosted_trees.cc:334] Final model num-trees:85 valid-loss:0.880723 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:26.3622 UTC hyperparameters_optimizer.cc:582] [455/500] Score: -0.880723 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:26.3640 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.3640 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.3642 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.3788 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293177 train-accuracy:0.599691 valid-loss:1.277127 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.4582 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.846272\n",
      "[INFO 24-02-22 06:46:26.4601 UTC gradient_boosted_trees.cc:271] Truncates the model to 55 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.4603 UTC gradient_boosted_trees.cc:334] Final model num-trees:55 valid-loss:0.846272 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:26.4607 UTC hyperparameters_optimizer.cc:582] [456/500] Score: -0.846272 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:26.4613 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.4613 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.4616 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.4806 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.322742 train-accuracy:0.599691 valid-loss:1.297766 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.5734 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.862691\n",
      "[INFO 24-02-22 06:46:26.5734 UTC gradient_boosted_trees.cc:271] Truncates the model to 123 tree(s) i.e. 123  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.5736 UTC gradient_boosted_trees.cc:334] Final model num-trees:123 valid-loss:0.862691 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:26.5748 UTC hyperparameters_optimizer.cc:582] [457/500] Score: -0.862691 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:26.5781 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.5781 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.5783 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.5868 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.247157 train-accuracy:0.599691 valid-loss:1.239475 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.5902 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836121\n",
      "[INFO 24-02-22 06:46:26.5902 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.5903 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.836121 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:26.5904 UTC hyperparameters_optimizer.cc:582] [458/500] Score: -0.836121 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:26.5908 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.5908 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.5909 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.6109 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290028 train-accuracy:0.599691 valid-loss:1.274383 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.6593 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.842044\n",
      "[INFO 24-02-22 06:46:26.6595 UTC gradient_boosted_trees.cc:271] Truncates the model to 57 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.6597 UTC gradient_boosted_trees.cc:334] Final model num-trees:57 valid-loss:0.842044 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:26.6601 UTC hyperparameters_optimizer.cc:582] [459/500] Score: -0.842044 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:26.6605 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.6606 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.6609 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.6832 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.240245 train-accuracy:0.599691 valid-loss:1.246634 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.7165 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864741\n",
      "[INFO 24-02-22 06:46:26.7166 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.7169 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.864741 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:26.7179 UTC hyperparameters_optimizer.cc:582] [460/500] Score: -0.864741 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:26.7192 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.7193 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.7196 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.7347 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.832839\n",
      "[INFO 24-02-22 06:46:26.7349 UTC gradient_boosted_trees.cc:271] Truncates the model to 90 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.7350 UTC gradient_boosted_trees.cc:334] Final model num-trees:90 valid-loss:0.832839 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:26.7356 UTC hyperparameters_optimizer.cc:582] [461/500] Score: -0.832839 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:26.7363 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.7363 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.7365 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:26.7374 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.224136 train-accuracy:0.599691 valid-loss:1.226326 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.7542 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285819 train-accuracy:0.599691 valid-loss:1.270400 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:26.9847 UTC gradient_boosted_trees.cc:1636] \tnum-trees:300 train-loss:0.476155 train-accuracy:0.935085 valid-loss:0.851135 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:26.9847 UTC gradient_boosted_trees.cc:271] Truncates the model to 300 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 24-02-22 06:46:26.9848 UTC gradient_boosted_trees.cc:334] Final model num-trees:300 valid-loss:0.851135 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:26.9854 UTC hyperparameters_optimizer.cc:582] [462/500] Score: -0.851135 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:26.9858 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:26.9858 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:26.9866 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.0076 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320010 train-accuracy:0.599691 valid-loss:1.299249 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.1606 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.825564\n",
      "[INFO 24-02-22 06:46:27.1606 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.1607 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.825564 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:27.1619 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.1619 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.1621 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.1625 UTC hyperparameters_optimizer.cc:582] [463/500] Score: -0.825564 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.1746 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290290 train-accuracy:0.599691 valid-loss:1.279000 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.2646 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.827447\n",
      "[INFO 24-02-22 06:46:27.2646 UTC gradient_boosted_trees.cc:271] Truncates the model to 32 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.2648 UTC gradient_boosted_trees.cc:334] Final model num-trees:32 valid-loss:0.827447 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.2653 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.2653 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.2656 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO[INFO 24-02-22 06:46:27.2687 UTC hyperparameters_optimizer.cc:582] [464/500] Score:  24-02-22 06:46:27.2687 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.258473 train-accuracy:0.599691 valid-loss:1.257301 valid-accuracy:0.636364\n",
      "-0.827447 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.4488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.881123\n",
      "[INFO 24-02-22 06:46:27.4489 UTC gradient_boosted_trees.cc:271] Truncates the model to 44 tree(s) i.e. 44  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.4492 UTC gradient_boosted_trees.cc:334] Final model num-trees:44 valid-loss:0.881123 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:27.4498 UTC hyperparameters_optimizer.cc:582] [465/500] Score: -0.881123 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.4510 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.4510 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.4513 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.4677 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323012 train-accuracy:0.599691 valid-loss:1.297698 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.4995 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.836968\n",
      "[INFO 24-02-22 06:46:27.4996 UTC gradient_boosted_trees.cc:271] Truncates the model to 46 tree(s) i.e. 46  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.5001 UTC gradient_boosted_trees.cc:334] Final model num-trees:46 valid-loss:0.836968 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.5008 UTC hyperparameters_optimizer.cc:582] [466/500] Score: -0.836968 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:27.5021 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.5021 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.5023 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.5109 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.290443 train-accuracy:0.599691 valid-loss:1.269418 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.5417 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.905929\n",
      "[INFO 24-02-22 06:46:27.5418 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.5423 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.905929 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:27.5433 UTC hyperparameters_optimizer.cc:582] [467/500] Score: -0.905929 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.5437 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.5437 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.5440 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.5543 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295290 train-accuracy:0.599691 valid-loss:1.283301 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.6998 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.873533\n",
      "[INFO 24-02-22 06:46:27.6998 UTC gradient_boosted_trees.cc:271] Truncates the model to 22 tree(s) i.e. 22  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.7000 UTC gradient_boosted_trees.cc:334] Final model num-trees:22 valid-loss:0.873533 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.7003 UTC hyperparameters_optimizer.cc:582] [468/500] Score: -0.873533 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.7008 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.7008 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.7045 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.7077 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.304326 train-accuracy:0.599691 valid-loss:1.288304 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.7097 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.780587\n",
      "[INFO 24-02-22 06:46:27.7098 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.7099 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.780587 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:27.7103 UTC hyperparameters_optimizer.cc:582] [469/500] Score: -0.780587 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:27.7110 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.7110 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.7112 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.7222 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.895371\n",
      "[INFO 24-02-22 06:46:27.7223 UTC gradient_boosted_trees.cc:271] Truncates the model to 73 tree(s) i.e. 73  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.7225 UTC gradient_boosted_trees.cc:334] Final model num-trees:73 valid-loss:0.895371 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:27.7235 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.7236 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.7238 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.7254 UTC hyperparameters_optimizer.cc:582] [470/500] Score: -0.895371 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:27.7283 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.299755 train-accuracy:0.599691 valid-loss:1.287562 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.7324 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323426 train-accuracy:0.599691 valid-loss:1.299440 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.7659 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.804027\n",
      "[INFO 24-02-22 06:46:27.7659 UTC gradient_boosted_trees.cc:271] Truncates the model to 95 tree(s) i.e. 95  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.7659 UTC gradient_boosted_trees.cc:334] Final model num-trees:95 valid-loss:0.804027 valid-accuracy:0.848485\n",
      "[INFO 24-02-22 06:46:27.7661 UTC hyperparameters_optimizer.cc:582] [471/500] Score: -0.804027 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:27.7665 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.7665 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.7667 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.7730 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.263929 train-accuracy:0.599691 valid-loss:1.260704 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.8360 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.849266\n",
      "[INFO 24-02-22 06:46:27.8360 UTC gradient_boosted_trees.cc:271] Truncates the model to 143 tree(s) i.e. 143  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.8362 UTC gradient_boosted_trees.cc:334] Final model num-trees:143 valid-loss:0.849266 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.8372 UTC hyperparameters_optimizer.cc:582] [472/500] Score: -0.849266 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:27.8390 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.8390 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.8392 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.8613 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.323587 train-accuracy:0.599691 valid-loss:1.297065 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:27.8774 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.865638\n",
      "[INFO 24-02-22 06:46:27.8775 UTC gradient_boosted_trees.cc:271] Truncates the model to 66 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 24-02-22 06:46:27.8776 UTC gradient_boosted_trees.cc:334] Final model num-trees:66 valid-loss:0.865638 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:27.8783 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:27.8783 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:27.8784 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:27.8787 UTC hyperparameters_optimizer.cc:582] [473/500] Score: -0.865638 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:27.8964 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.320758 train-accuracy:0.599691 valid-loss:1.297540 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.0078 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.831037\n",
      "[INFO 24-02-22 06:46:28.0078 UTC gradient_boosted_trees.cc:271] Truncates the model to 51 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.0080 UTC gradient_boosted_trees.cc:334] Final model num-trees:51 valid-loss:0.831037 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.0084 UTC hyperparameters_optimizer.cc:582] [474/500] Score: -0.831037 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:28.0097 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.0097 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.0099 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.0158 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.297254 train-accuracy:0.599691 valid-loss:1.282973 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.0660 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.868684\n",
      "[INFO 24-02-22 06:46:28.0661 UTC gradient_boosted_trees.cc:271] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.0662 UTC gradient_boosted_trees.cc:334] Final model num-trees:48 valid-loss:0.868684 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:28.0668 UTC hyperparameters_optimizer.cc:582] [475/500] Score: -0.868684 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:28.0679 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.0679 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.0681 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.0821 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.285197 train-accuracy:0.599691 valid-loss:1.273829 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.0859 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.894032\n",
      "[INFO 24-02-22 06:46:28.0859 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.0863 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.894032 valid-accuracy:0.772727\n",
      "[[INFO 24-02-22 06:46:28.0873 UTC hyperparameters_optimizer.cc:582] [476/500] Score: -0.894032 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "INFO 24-02-22 06:46:28.0879 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.0879 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.0886 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.0975 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.292784 train-accuracy:0.599691 valid-loss:1.277535 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.4533 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.861533\n",
      "[INFO 24-02-22 06:46:28.4534 UTC gradient_boosted_trees.cc:271] Truncates the model to 58 tree(s) i.e. 58  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.4535 UTC gradient_boosted_trees.cc:334] Final model num-trees:58 valid-loss:0.861533 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.4550 UTC hyperparameters_optimizer.cc:582] [477/500] Score: -0.861533 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:28.4554 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.4554 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.4558 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.4702 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.324074 train-accuracy:0.599691 valid-loss:1.301806 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.4887 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.850325\n",
      "[INFO 24-02-22 06:46:28.4887 UTC gradient_boosted_trees.cc:271] Truncates the model to 86 tree(s) i.e. 86  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.4888 UTC gradient_boosted_trees.cc:334] Final model num-trees:86 valid-loss:0.850325 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.4897 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.4897 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.4900 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.4921 UTC hyperparameters_optimizer.cc:582] [478/500] Score: -0.850325 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:28.5008 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.295223 train-accuracy:0.599691 valid-loss:1.273200 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.5063 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.82017\n",
      "[INFO 24-02-22 06:46:28.5063 UTC gradient_boosted_trees.cc:271] Truncates the model to 232 tree(s) i.e. 232  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.5063 UTC gradient_boosted_trees.cc:334] Final model num-trees:232 valid-loss:0.820170 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:28.5068 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.5068 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.5070 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.5087 UTC hyperparameters_optimizer.cc:582] [479/500] Score: -0.82017 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:28.5201 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.294247 train-accuracy:0.599691 valid-loss:1.275443 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.5890 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.847658\n",
      "[INFO 24-02-22 06:46:28.5890 UTC gradient_boosted_trees.cc:271] Truncates the model to 156 tree(s) i.e. 156  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.5891 UTC gradient_boosted_trees.cc:334] Final model num-trees:156 valid-loss:0.847658 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.5894 UTC hyperparameters_optimizer.cc:582] [480/500] Score: -0.847658 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:28.5905 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.5906 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.5907 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.6066 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.230309 train-accuracy:0.599691 valid-loss:1.246516 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:28.9206 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.874587\n",
      "[INFO 24-02-22 06:46:28.9220 UTC gradient_boosted_trees.cc:271] Truncates the model to 109 tree(s) i.e. 109  iteration(s).\n",
      "[INFO 24-02-22 06:46:28.9222 UTC gradient_boosted_trees.cc:334] Final model num-trees:109 valid-loss:0.874587 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:28.9233 UTC hyperparameters_optimizer.cc:582] [481/500] Score: -0.874587 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:28.9270 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:28.9271 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:28.9273 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:28.9501 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.226547 train-accuracy:0.599691 valid-loss:1.244866 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:29.0542 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.88806\n",
      "[INFO 24-02-22 06:46:29.0543 UTC gradient_boosted_trees.cc:271] Truncates the model to 94 tree(s) i.e. 94  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.0547 UTC gradient_boosted_trees.cc:334] Final model num-trees:94 valid-loss:0.888060 valid-accuracy:0.772727\n",
      "[INFO 24-02-22 06:46:29.0560 UTC hyperparameters_optimizer.cc:582] [482/500] Score: -0.88806 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:29.0576 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:29.0577 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:29.0581 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:29.0589 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.797545\n",
      "[INFO 24-02-22 06:46:29.0589 UTC gradient_boosted_trees.cc:271] Truncates the model to 144 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.0589 UTC gradient_boosted_trees.cc:334] Final model num-trees:144 valid-loss:0.797545 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:29.0594 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:29.0594 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:29.0595 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:29.0621 UTC hyperparameters_optimizer.cc:582] [483/500] Score: -0.797545 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:29.0710 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.288085 train-accuracy:0.599691 valid-loss:1.281139 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:29.0804 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.293229 train-accuracy:0.599691 valid-loss:1.288878 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:29.1884 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.852276\n",
      "[INFO 24-02-22 06:46:29.1885 UTC gradient_boosted_trees.cc:271] Truncates the model to 76 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.1886 UTC gradient_boosted_trees.cc:334] Final model num-trees:76 valid-loss:0.852276 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:29.1891 UTC hyperparameters_optimizer.cc:582] [484/500] Score: -0.852276 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:29.1913 UTC gradient_boosted_trees.cc:591] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 24-02-22 06:46:29.1914 UTC gradient_boosted_trees.cc:1218] Training gradient boosted tree on 713 example(s) and 9 feature(s).\n",
      "[INFO 24-02-22 06:46:29.1917 UTC gradient_boosted_trees.cc:1261] 647 examples used for training and 66 examples used for validation\n",
      "[INFO 24-02-22 06:46:29.2071 UTC gradient_boosted_trees.cc:1636] \tnum-trees:1 train-loss:1.287935 train-accuracy:0.599691 valid-loss:1.279650 valid-accuracy:0.636364\n",
      "[INFO 24-02-22 06:46:29.2286 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.857383\n",
      "[INFO 24-02-22 06:46:29.2286 UTC gradient_boosted_trees.cc:271] Truncates the model to 103 tree(s) i.e. 103  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.2289 UTC gradient_boosted_trees.cc:334] Final model num-trees:103 valid-loss:0.857383 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:29.2299 UTC hyperparameters_optimizer.cc:582] [485/500] Score: -0.857383 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:29.3029 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864463\n",
      "[INFO 24-02-22 06:46:29.3029 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.3031 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.864463 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:29.3039 UTC hyperparameters_optimizer.cc:582] [486/500] Score: -0.864463 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:29.4366 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.916912\n",
      "[INFO 24-02-22 06:46:29.4366 UTC gradient_boosted_trees.cc:271] Truncates the model to 37 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.4368 UTC gradient_boosted_trees.cc:334] Final model num-trees:37 valid-loss:0.916912 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:29.4372 UTC hyperparameters_optimizer.cc:582] [487/500] Score: -0.916912 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:29.6237 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.797799\n",
      "[INFO 24-02-22 06:46:29.6237 UTC gradient_boosted_trees.cc:271] Truncates the model to 223 tree(s) i.e. 223  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.6238 UTC gradient_boosted_trees.cc:334] Final model num-trees:223 valid-loss:0.797799 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:29.6247 UTC hyperparameters_optimizer.cc:582] [488/500] Score: -0.797799 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:29.7488 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.81823\n",
      "[INFO 24-02-22 06:46:29.7489 UTC gradient_boosted_trees.cc:271] Truncates the model to 93 tree(s) i.e. 93  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.7491 UTC gradient_boosted_trees.cc:334] Final model num-trees:93 valid-loss:0.818230 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:29.7496 UTC hyperparameters_optimizer.cc:582] [489/500] Score: -0.81823 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:29.7574 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.843279\n",
      "[INFO 24-02-22 06:46:29.7575 UTC gradient_boosted_trees.cc:271] Truncates the model to 60 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.7576 UTC gradient_boosted_trees.cc:334] Final model num-trees:60 valid-loss:0.843279 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:29.7580 UTC hyperparameters_optimizer.cc:582] [490/500] Score: -0.843279 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:29.8056 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.869204\n",
      "[INFO 24-02-22 06:46:29.8056 UTC gradient_boosted_trees.cc:271] Truncates the model to 88 tree(s) i.e. 88  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.8059 UTC gradient_boosted_trees.cc:334] Final model num-trees:88 valid-loss:0.869204 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:29.8068 UTC hyperparameters_optimizer.cc:582] [491/500] Score: -0.869204 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:29.8870 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.869227\n",
      "[INFO 24-02-22 06:46:29.8870 UTC gradient_boosted_trees.cc:271] Truncates the model to 18 tree(s) i.e. 18  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.8872 UTC gradient_boosted_trees.cc:334] Final model num-trees:18 valid-loss:0.869227 valid-accuracy:0.787879\n",
      "[INFO 24-02-22 06:46:29.8873 UTC hyperparameters_optimizer.cc:582] [492/500] Score: -0.869227 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:29.9372 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.867664\n",
      "[INFO 24-02-22 06:46:29.9372 UTC gradient_boosted_trees.cc:271] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
      "[INFO 24-02-22 06:46:29.9376 UTC gradient_boosted_trees.cc:334] Final model num-trees:136 valid-loss:0.867664 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:29.9387 UTC hyperparameters_optimizer.cc:582] [493/500] Score: -0.867664 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:30.1014 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.826458\n",
      "[INFO 24-02-22 06:46:30.1014 UTC gradient_boosted_trees.cc:271] Truncates the model to 47 tree(s) i.e. 47  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.1015 UTC gradient_boosted_trees.cc:334] Final model num-trees:47 valid-loss:0.826458 valid-accuracy:0.833333\n",
      "[INFO 24-02-22 06:46:30.1018 UTC hyperparameters_optimizer.cc:582] [494/500] Score: -0.826458 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 24-02-22 06:46:30.1414 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864924\n",
      "[INFO 24-02-22 06:46:30.1415 UTC gradient_boosted_trees.cc:271] Truncates the model to 126 tree(s) i.e. 126  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.1418 UTC gradient_boosted_trees.cc:334] Final model num-trees:126 valid-loss:0.864924 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:30.1428 UTC hyperparameters_optimizer.cc:582] [495/500] Score: -0.864924 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:30.1910 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.897969\n",
      "[INFO 24-02-22 06:46:30.1910 UTC gradient_boosted_trees.cc:271] Truncates the model to 59 tree(s) i.e. 59  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.1913 UTC gradient_boosted_trees.cc:334] Final model num-trees:59 valid-loss:0.897969 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:30.1917 UTC hyperparameters_optimizer.cc:582] [496/500] Score: -0.897969 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:30.2421 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.864362\n",
      "[INFO 24-02-22 06:46:30.2421 UTC gradient_boosted_trees.cc:271] Truncates the model to 61 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.2422 UTC gradient_boosted_trees.cc:334] Final model num-trees:61 valid-loss:0.864362 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:30.2426 UTC hyperparameters_optimizer.cc:582] [497/500] Score: -0.864362 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:30.3246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.834547\n",
      "[INFO 24-02-22 06:46:30.3247 UTC gradient_boosted_trees.cc:271] Truncates the model to 127 tree(s) i.e. 127  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.3249 UTC gradient_boosted_trees.cc:334] Final model num-trees:127 valid-loss:0.834547 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:30.3258 UTC hyperparameters_optimizer.cc:582] [498/500] Score: -0.834547 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 24-02-22 06:46:30.6013 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.85364\n",
      "[INFO 24-02-22 06:46:30.6013 UTC gradient_boosted_trees.cc:271] Truncates the model to 122 tree(s) i.e. 122  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.6014 UTC gradient_boosted_trees.cc:334] Final model num-trees:122 valid-loss:0.853640 valid-accuracy:0.818182\n",
      "[INFO 24-02-22 06:46:30.6020 UTC hyperparameters_optimizer.cc:582] [499/500] Score: -0.85364 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 24-02-22 06:46:30.9567 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.829806\n",
      "[INFO 24-02-22 06:46:30.9568 UTC gradient_boosted_trees.cc:271] Truncates the model to 174 tree(s) i.e. 174  iteration(s).\n",
      "[INFO 24-02-22 06:46:30.9569 UTC gradient_boosted_trees.cc:334] Final model num-trees:174 valid-loss:0.829806 valid-accuracy:0.803030\n",
      "[INFO 24-02-22 06:46:30.9578 UTC hyperparameters_optimizer.cc:582] [500/500] Score: -0.829806 / -0.758798 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 24-02-22 06:46:30.9639 UTC hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  value {\n",
      "    categorical: \"SPARSE_OBLIQUE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_projection_density_factor\"\n",
      "  value {\n",
      "    real: 3\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_normalization\"\n",
      "  value {\n",
      "    categorical: \"NONE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_weights\"\n",
      "  value {\n",
      "    categorical: \"BINARY\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  value {\n",
      "    categorical: \"CART\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  value {\n",
      "    categorical: \"BEST_FIRST_GLOBAL\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_num_nodes\"\n",
      "  value {\n",
      "    integer: 32\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sampling_method\"\n",
      "  value {\n",
      "    categorical: \"RANDOM\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"subsample\"\n",
      "  value {\n",
      "    real: 0.6\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  value {\n",
      "    real: 0.1\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 5\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  value {\n",
      "    categorical: \"true\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  value {\n",
      "    real: 0.5\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 24-02-22 06:46:30.9662 UTC kernel.cc:919] Export model in log directory: /tmp/tmpf8og66t6 with prefix 99a97f2c4fb549ac\n",
      "[INFO 24-02-22 06:46:30.9695 UTC kernel.cc:937] Save model in resources\n",
      "[INFO 24-02-22 06:46:30.9733 UTC abstract_model.cc:881] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 0.758798\n",
      "\n",
      "Accuracy: 0.818182  CI95[W][0 1]\n",
      "ErrorRate: : 0.181818\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36   6\n",
      "2   6  18\n",
      "Total: 66\n",
      "\n",
      "\n",
      "[INFO 24-02-22 06:46:30.9830 UTC kernel.cc:1233] Loading model from path /tmp/tmpf8og66t6/model/ with prefix 99a97f2c4fb549ac\n",
      "[INFO 24-02-22 06:46:30.9871 UTC decision_forest.cc:660] Model loaded with 21 root(s), 1167 node(s), and 9 input feature(s).\n",
      "[INFO 24-02-22 06:46:30.9871 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-02-22 06:46:30.9871 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:45.245856\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x704c301cf910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner2 = tfdf.tuner.RandomSearch(num_trials=500, use_predefined_hps=True)\n",
    "\n",
    "# Define and train the model.\n",
    "tuned_model2 = tfdf.keras.GradientBoostedTreesModel(tuner=tuner2)\n",
    "tuned_model2.fit(train_ds, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the TF-DF hyper-parameter tuner: 0.7978\n"
     ]
    }
   ],
   "source": [
    "tuned_model2.compile([\"accuracy\"])\n",
    "tuned_test_accuracy2 = tuned_model2.evaluate(test_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy with the TF-DF hyper-parameter tuner: {tuned_test_accuracy2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_rfm = tuned_model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('titanic/test.csv')\n",
    "answer = pd.DataFrame({\"PassengerId\" : t[\"PassengerId\"], \"Survived\":np.round(predictions_rfm,0).astype('int').ravel()})\n",
    "answer.to_csv('titanic/predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1 (1.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (9):\n",
      "\tAge\n",
      "\tEmbarked_C\n",
      "\tEmbarked_Q\n",
      "\tEmbarked_S\n",
      "\tFare\n",
      "\tPclass\n",
      "\tPeople\n",
      "\tSex_female\n",
      "\tSex_male\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.        \"Age\"  0.480781 ################\n",
      "    2.       \"Fare\"  0.233748 ##\n",
      "    3. \"Embarked_C\"  0.229072 ##\n",
      "    4. \"Embarked_Q\"  0.212467 #\n",
      "    5.     \"Pclass\"  0.204518 #\n",
      "    6. \"Embarked_S\"  0.203581 #\n",
      "    7. \"Sex_female\"  0.190493 \n",
      "    8.   \"Sex_male\"  0.187266 \n",
      "    9.     \"People\"  0.184621 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.        \"Age\" 40.000000 ################\n",
      "    2.       \"Fare\"  9.000000 ##\n",
      "    3. \"Embarked_C\"  7.000000 #\n",
      "    4.     \"Pclass\"  7.000000 #\n",
      "    5. \"Sex_female\"  6.000000 \n",
      "    6. \"Embarked_Q\"  5.000000 \n",
      "    7. \"Embarked_S\"  4.000000 \n",
      "    8.   \"Sex_male\"  4.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.        \"Age\" 576.000000 ################\n",
      "    2.       \"Fare\" 150.000000 ###\n",
      "    3. \"Embarked_C\" 143.000000 ###\n",
      "    4. \"Embarked_Q\" 91.000000 ##\n",
      "    5. \"Embarked_S\" 83.000000 ##\n",
      "    6.     \"Pclass\" 35.000000 \n",
      "    7.     \"People\" 26.000000 \n",
      "    8. \"Sex_female\" 11.000000 \n",
      "    9.   \"Sex_male\"  9.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.        \"Age\" 704597.971906 ################\n",
      "    2. \"Sex_female\" 449054.584518 #########\n",
      "    3. \"Embarked_C\" 369300.695390 ########\n",
      "    4.       \"Fare\" 178456.741431 ###\n",
      "    5.     \"Pclass\" 160581.892920 ###\n",
      "    6. \"Embarked_Q\" 130410.905733 ##\n",
      "    7.   \"Sex_male\" 113611.533708 ##\n",
      "    8. \"Embarked_S\" 82894.168039 #\n",
      "    9.     \"People\" 24160.364469 \n",
      "\n",
      "\n",
      "Hyperparameter optimizer:\n",
      "\n",
      "Best parameters: min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5\n",
      "Num steps: 1100\n",
      "Best score: -0.481402\n",
      "\n",
      "Step #0 score:-0.645815 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #1 score:-0.585609 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #2 score:-0.599763 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #3 score:-0.568930 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #4 score:-0.634661 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #5 score:-0.615607 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #6 score:-0.601437 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #7 score:-0.664715 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #8 score:-0.714605 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #9 score:-0.629326 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #10 score:-0.643946 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #11 score:-0.503908 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #12 score:-0.653731 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #13 score:-0.677357 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #14 score:-0.676131 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #15 score:-0.586386 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #16 score:-0.593186 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #17 score:-0.617288 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #18 score:-0.637020 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #19 score:-0.606755 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #20 score:-0.566428 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #21 score:-0.642750 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #22 score:-0.602530 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #23 score:-0.631400 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #24 score:-0.618578 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #25 score:-0.693484 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #26 score:-0.593831 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #27 score:-0.662786 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #28 score:-0.584920 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #29 score:-0.588046 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #30 score:-0.639925 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #31 score:-0.559566 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #32 score:-0.613429 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #33 score:-0.643561 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #34 score:-0.640006 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #35 score:-0.631039 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #36 score:-0.661270 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #37 score:-0.640317 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #38 score:-0.666041 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #39 score:-0.598319 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #40 score:-0.646619 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #41 score:-0.649778 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #42 score:-0.662044 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #43 score:-0.612097 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #44 score:-0.666539 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #45 score:-0.766761 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #46 score:-0.620427 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #47 score:-0.715716 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #48 score:-0.664302 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #49 score:-0.664295 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #50 score:-0.608074 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #51 score:-0.651693 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #52 score:-0.805334 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #53 score:-0.640271 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #54 score:-0.676364 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #55 score:-0.589980 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #56 score:-0.552127 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #57 score:-0.603467 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #58 score:-0.717200 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #59 score:-0.606969 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #60 score:-0.651592 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #61 score:-0.638965 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #62 score:-0.598334 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #63 score:-0.629838 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #64 score:-0.646786 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #65 score:-0.641507 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #66 score:-0.602530 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #67 score:-0.559765 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #68 score:-0.679317 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #69 score:-0.554702 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #70 score:-0.643361 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #71 score:-0.686589 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #72 score:-0.627231 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #73 score:-0.596326 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #74 score:-0.561884 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #75 score:-0.656476 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #76 score:-0.662947 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #77 score:-0.579348 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #78 score:-0.641401 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #79 score:-0.599048 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #80 score:-0.636102 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #81 score:-0.640009 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #82 score:-0.588897 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #83 score:-0.711419 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #84 score:-0.666699 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #85 score:-0.655131 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #86 score:-0.640531 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #87 score:-0.638013 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #88 score:-0.681733 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #89 score:-0.587596 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #90 score:-0.579884 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #91 score:-0.647353 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #92 score:-0.656947 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #93 score:-0.610321 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #94 score:-0.593423 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #95 score:-0.605527 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #96 score:-0.624682 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #97 score:-0.598807 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #98 score:-0.671101 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #99 score:-0.603022 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #100 score:-0.637813 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #101 score:-0.677585 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #102 score:-0.595298 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #103 score:-0.656367 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #104 score:-0.575557 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #105 score:-0.684891 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #106 score:-0.640009 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #107 score:-0.661047 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #108 score:-0.571258 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #109 score:-0.631749 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #110 score:-0.645773 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #111 score:-0.549677 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #112 score:-0.582806 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #113 score:-0.669472 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #114 score:-0.639900 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #115 score:-0.564717 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #116 score:-0.629376 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #117 score:-0.658020 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #118 score:-0.627014 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #119 score:-0.613530 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #120 score:-0.822489 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #121 score:-0.581505 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #122 score:-0.620094 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #123 score:-0.652279 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #124 score:-0.655113 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #125 score:-0.553490 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #126 score:-0.642726 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #127 score:-0.626014 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #128 score:-0.671986 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #129 score:-0.639237 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #130 score:-0.646227 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #131 score:-0.484448 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #132 score:-0.626700 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #133 score:-0.627543 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #134 score:-0.642666 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #135 score:-0.680645 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #136 score:-0.633698 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #137 score:-0.614333 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #138 score:-0.597476 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #139 score:-0.594182 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #140 score:-0.619649 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #141 score:-0.631588 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #142 score:-0.634664 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #143 score:-0.655209 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #144 score:-0.653877 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #145 score:-0.627401 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #146 score:-0.598999 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #147 score:-0.622344 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #148 score:-0.630440 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #149 score:-0.663697 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #150 score:-0.690625 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #151 score:-0.633112 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #152 score:-0.622736 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #153 score:-0.644741 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #154 score:-0.684591 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #155 score:-0.628030 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #156 score:-0.665994 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #157 score:-0.669680 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #158 score:-0.591658 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #159 score:-0.645021 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #160 score:-0.615304 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #161 score:-0.665059 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #162 score:-0.674371 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #163 score:-0.682262 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #164 score:-0.700419 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #165 score:-0.607977 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #166 score:-0.621692 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #167 score:-0.662283 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #168 score:-0.648901 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #169 score:-0.677989 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #170 score:-0.595065 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #171 score:-0.649326 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #172 score:-0.622477 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #173 score:-0.663058 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #174 score:-0.643666 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #175 score:-0.676862 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #176 score:-0.644350 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #177 score:-0.623624 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #178 score:-0.675383 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #179 score:-0.584911 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #180 score:-0.651041 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #181 score:-0.624666 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #182 score:-0.543816 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #183 score:-0.646839 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #184 score:-0.560026 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #185 score:-0.586447 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #186 score:-0.653785 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #187 score:-0.629333 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #188 score:-0.576655 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #189 score:-0.649184 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #190 score:-0.639879 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #191 score:-0.634097 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #192 score:-0.638393 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #193 score:-0.634816 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #194 score:-0.619892 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #195 score:-0.576481 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #196 score:-0.556867 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #197 score:-0.624300 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #198 score:-0.605375 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #199 score:-0.570653 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #200 score:-0.621858 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #201 score:-0.631691 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #202 score:-0.637541 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #203 score:-0.634937 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #204 score:-0.601864 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #205 score:-0.683953 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #206 score:-0.642792 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #207 score:-0.638097 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #208 score:-0.590543 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #209 score:-0.646519 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #210 score:-0.676301 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #211 score:-0.634097 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #212 score:-0.604342 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #213 score:-0.609086 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #214 score:-0.640701 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #215 score:-0.661219 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #216 score:-0.690635 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #217 score:-0.643361 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #218 score:-0.593643 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #219 score:-0.653081 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #220 score:-0.638097 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #221 score:-0.619375 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #222 score:-0.548150 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #223 score:-0.635861 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #224 score:-0.581865 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #225 score:-0.705775 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #226 score:-0.561038 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #227 score:-0.640669 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #228 score:-0.645628 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #229 score:-0.620100 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #230 score:-0.664239 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #231 score:-0.567090 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #232 score:-0.647355 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #233 score:-0.704299 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #234 score:-0.668482 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #235 score:-0.636488 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #236 score:-0.599953 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #237 score:-0.639398 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #238 score:-0.632438 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #239 score:-0.553541 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #240 score:-0.649065 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #241 score:-0.575577 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #242 score:-0.547343 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #243 score:-0.548625 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #244 score:-0.630608 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #245 score:-0.602836 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #246 score:-0.650486 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #247 score:-0.716784 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #248 score:-0.587780 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #249 score:-0.576442 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #250 score:-0.716255 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #251 score:-0.657890 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #252 score:-0.643030 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #253 score:-0.577275 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #254 score:-0.730107 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #255 score:-0.525454 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #256 score:-0.574905 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #257 score:-0.611073 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #258 score:-0.566698 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #259 score:-0.655736 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #260 score:-0.646468 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #261 score:-0.635395 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #262 score:-0.655862 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #263 score:-0.617232 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #264 score:-0.648661 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #265 score:-0.601573 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #266 score:-0.638922 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #267 score:-0.686185 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #268 score:-0.571873 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #269 score:-0.600764 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #270 score:-0.660915 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #271 score:-0.589818 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #272 score:-0.749716 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #273 score:-0.651127 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #274 score:-0.622065 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #275 score:-0.654726 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #276 score:-0.847052 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #277 score:-0.649589 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #278 score:-0.624791 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #279 score:-0.619533 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #280 score:-0.640886 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #281 score:-0.643775 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #282 score:-0.685192 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #283 score:-0.681752 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #284 score:-0.629114 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #285 score:-0.648945 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #286 score:-0.646662 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #287 score:-0.632866 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #288 score:-0.633866 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #289 score:-0.636323 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #290 score:-0.642619 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #291 score:-0.647414 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #292 score:-0.610210 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #293 score:-0.660354 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #294 score:-0.699986 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #295 score:-0.551815 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #296 score:-0.636490 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #297 score:-0.626416 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #298 score:-0.571546 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #299 score:-0.655346 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #300 score:-0.739866 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #301 score:-0.601420 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #302 score:-0.614684 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #303 score:-0.602668 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #304 score:-0.613454 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #305 score:-0.645295 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #306 score:-0.674591 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #307 score:-0.644853 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #308 score:-0.588574 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #309 score:-0.637641 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #310 score:-0.648206 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #311 score:-0.682810 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #312 score:-0.624847 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #313 score:-0.676403 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #314 score:-0.597307 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #315 score:-0.632512 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #316 score:-0.621407 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #317 score:-0.619798 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #318 score:-0.635511 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #319 score:-0.658055 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #320 score:-0.670339 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #321 score:-0.641970 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #322 score:-0.581195 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #323 score:-0.643179 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #324 score:-0.643617 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #325 score:-0.721029 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #326 score:-0.665115 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #327 score:-0.660770 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #328 score:-0.585931 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #329 score:-0.681982 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #330 score:-0.669408 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #331 score:-0.600919 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #332 score:-0.678578 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #333 score:-0.606689 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #334 score:-0.661819 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #335 score:-0.597063 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #336 score:-0.603301 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #337 score:-0.607654 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #338 score:-0.660747 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #339 score:-0.673941 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #340 score:-0.591906 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #341 score:-0.639281 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #342 score:-0.660360 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #343 score:-0.597921 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #344 score:-0.508148 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #345 score:-0.603391 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #346 score:-0.623886 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #347 score:-0.632352 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #348 score:-0.638393 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #349 score:-0.561060 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #350 score:-0.644097 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #351 score:-0.660188 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #352 score:-0.642909 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #353 score:-0.691353 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #354 score:-0.619076 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #355 score:-0.666967 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #356 score:-0.601603 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #357 score:-0.639534 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #358 score:-0.640095 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #359 score:-0.589210 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #360 score:-0.666243 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #361 score:-0.593871 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #362 score:-0.588897 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #363 score:-0.599618 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #364 score:-0.610989 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #365 score:-0.660734 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #366 score:-0.571491 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #367 score:-0.611401 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #368 score:-0.656066 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #369 score:-0.645746 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #370 score:-0.582241 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #371 score:-0.657438 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #372 score:-0.603737 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #373 score:-0.601927 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #374 score:-0.616415 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #375 score:-0.661219 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #376 score:-0.574196 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #377 score:-0.615418 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #378 score:-0.567367 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #379 score:-0.659832 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #380 score:-0.622333 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #381 score:-0.626599 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #382 score:-0.639241 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #383 score:-0.662834 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #384 score:-0.641816 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #385 score:-0.630030 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #386 score:-0.615004 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #387 score:-0.649211 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #388 score:-0.646081 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #389 score:-0.600869 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #390 score:-0.651144 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #391 score:-0.632075 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #392 score:-0.617728 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #393 score:-0.614473 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #394 score:-0.652409 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #395 score:-0.665398 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #396 score:-0.710151 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #397 score:-0.618336 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #398 score:-0.678976 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #399 score:-0.623125 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #400 score:-0.660087 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #401 score:-0.637671 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #402 score:-0.523470 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #403 score:-0.634506 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #404 score:-0.569205 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #405 score:-0.592396 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #406 score:-0.609601 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #407 score:-0.629034 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #408 score:-0.582871 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #409 score:-0.561494 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #410 score:-0.614571 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #411 score:-0.637383 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #412 score:-0.621387 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #413 score:-0.610151 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #414 score:-0.640554 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #415 score:-0.596103 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #416 score:-0.585172 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #417 score:-0.631661 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #418 score:-0.661939 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #419 score:-0.817640 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #420 score:-0.631426 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #421 score:-0.692347 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #422 score:-0.621795 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #423 score:-0.615357 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #424 score:-0.764579 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #425 score:-0.618467 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #426 score:-0.673177 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #427 score:-0.664885 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #428 score:-0.597427 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #429 score:-0.634404 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #430 score:-0.708706 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #431 score:-0.636596 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #432 score:-0.569890 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #433 score:-0.599368 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #434 score:-0.598749 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #435 score:-0.606046 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #436 score:-0.641375 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #437 score:-0.577672 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #438 score:-0.653734 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #439 score:-0.575536 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #440 score:-0.638409 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #441 score:-0.640886 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #442 score:-0.567182 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #443 score:-0.643922 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #444 score:-0.629708 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #445 score:-0.617541 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #446 score:-0.653450 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #447 score:-0.580403 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #448 score:-0.638751 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #449 score:-0.683639 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #450 score:-0.639249 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #451 score:-0.678140 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #452 score:-0.657731 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #453 score:-0.643030 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #454 score:-0.667432 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #455 score:-0.600541 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #456 score:-0.673468 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #457 score:-0.608508 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #458 score:-0.648956 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #459 score:-0.616620 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #460 score:-0.642907 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #461 score:-0.637673 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #462 score:-0.658727 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #463 score:-0.587321 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #464 score:-0.682391 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #465 score:-0.621788 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #466 score:-0.608194 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #467 score:-0.611209 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #468 score:-0.655213 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #469 score:-0.636416 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #470 score:-0.655561 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #471 score:-0.619365 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #472 score:-0.597554 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #473 score:-0.648704 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #474 score:-0.634986 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #475 score:-0.649550 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #476 score:-0.572552 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #477 score:-0.702981 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #478 score:-0.517357 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #479 score:-0.614790 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #480 score:-0.566319 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #481 score:-0.659726 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #482 score:-0.600724 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #483 score:-0.604731 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #484 score:-0.656628 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #485 score:-0.601433 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #486 score:-0.618026 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #487 score:-0.690008 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #488 score:-0.535468 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #489 score:-0.575657 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #490 score:-0.547564 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #491 score:-0.625140 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #492 score:-0.665489 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #493 score:-0.591289 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #494 score:-0.621864 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #495 score:-0.714661 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #496 score:-0.680486 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #497 score:-0.640995 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #498 score:-0.604440 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #499 score:-0.624447 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #500 score:-0.676862 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #501 score:-0.591978 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #502 score:-0.605113 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #503 score:-0.638401 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #504 score:-0.663456 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #505 score:-0.662825 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #506 score:-0.579477 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #507 score:-0.623886 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #508 score:-0.591658 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #509 score:-0.650253 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #510 score:-0.669607 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #511 score:-0.672941 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #512 score:-0.639627 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #513 score:-0.730090 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #514 score:-0.629708 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #515 score:-0.624099 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #516 score:-0.547283 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #517 score:-0.589741 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #518 score:-0.643197 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #519 score:-0.625585 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #520 score:-0.641545 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #521 score:-0.640699 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #522 score:-0.547948 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #523 score:-0.615724 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #524 score:-0.624178 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #525 score:-0.727425 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #526 score:-0.656405 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #527 score:-0.603579 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #528 score:-0.658692 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #529 score:-0.663261 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #530 score:-0.551459 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #531 score:-0.596463 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #532 score:-0.650258 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #533 score:-0.644689 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #534 score:-0.643836 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #535 score:-0.563896 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #536 score:-0.631821 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #537 score:-0.635631 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #538 score:-0.661081 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #539 score:-0.546416 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #540 score:-0.612443 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #541 score:-0.661479 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #542 score:-0.679750 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #543 score:-0.633696 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #544 score:-0.650205 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #545 score:-0.627399 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #546 score:-0.666310 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #547 score:-0.635165 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #548 score:-0.671350 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #549 score:-0.613555 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #550 score:-0.655105 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #551 score:-0.658331 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #552 score:-0.634724 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #553 score:-0.617883 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #554 score:-0.703046 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #555 score:-0.588103 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #556 score:-0.634766 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #557 score:-0.612952 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #558 score:-0.695149 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #559 score:-0.602696 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #560 score:-0.665872 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #561 score:-0.640793 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #562 score:-0.639922 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #563 score:-0.623847 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #564 score:-0.649907 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #565 score:-0.690968 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #566 score:-0.662439 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #567 score:-0.642792 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #568 score:-0.643138 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #569 score:-0.661270 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #570 score:-0.662366 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #571 score:-0.634094 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #572 score:-0.607645 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #573 score:-0.620179 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #574 score:-0.668840 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #575 score:-0.656220 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #576 score:-0.664522 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #577 score:-0.589856 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #578 score:-0.593831 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #579 score:-0.616387 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #580 score:-0.611109 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #581 score:-0.636420 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #582 score:-0.579875 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #583 score:-0.565065 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #584 score:-0.570157 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #585 score:-0.628178 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #586 score:-0.653854 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #587 score:-0.595105 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #588 score:-0.627781 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #589 score:-0.588892 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #590 score:-0.664239 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #591 score:-0.675400 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #592 score:-0.628187 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #593 score:-0.634435 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #594 score:-0.691012 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #595 score:-0.650358 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #596 score:-0.693503 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #597 score:-0.657524 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #598 score:-0.602075 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #599 score:-0.551543 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #600 score:-0.657561 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #601 score:-0.671777 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #602 score:-0.668702 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #603 score:-0.647332 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #604 score:-0.659361 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #605 score:-0.585768 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #606 score:-0.698570 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #607 score:-0.636737 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #608 score:-0.662741 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #609 score:-0.668881 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #610 score:-0.589455 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #611 score:-0.647472 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #612 score:-0.635053 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #613 score:-0.688051 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #614 score:-0.559779 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #615 score:-0.651994 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #616 score:-0.636622 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #617 score:-0.576061 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #618 score:-0.618477 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #619 score:-0.609881 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #620 score:-0.589388 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #621 score:-0.691002 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #622 score:-0.627280 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #623 score:-0.590418 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #624 score:-0.607595 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #625 score:-0.639876 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #626 score:-0.586990 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #627 score:-0.724531 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #628 score:-0.668436 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #629 score:-0.669067 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #630 score:-0.664653 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #631 score:-0.660747 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #632 score:-0.650722 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #633 score:-0.568745 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #634 score:-0.625430 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #635 score:-0.583309 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #636 score:-0.630449 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #637 score:-0.614498 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #638 score:-0.623497 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #639 score:-0.625106 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #640 score:-0.656461 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #641 score:-0.559341 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #642 score:-0.655659 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #643 score:-0.658285 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #644 score:-0.553680 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #645 score:-0.680024 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #646 score:-0.690968 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #647 score:-0.609881 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #648 score:-0.731155 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #649 score:-0.601053 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #650 score:-0.631164 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #651 score:-0.609421 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #652 score:-0.581865 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #653 score:-0.632934 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #654 score:-0.570676 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #655 score:-0.639253 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #656 score:-0.629674 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #657 score:-0.684463 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #658 score:-0.654251 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #659 score:-0.623714 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #660 score:-0.637217 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #661 score:-0.651592 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #662 score:-0.648162 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #663 score:-0.630623 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #664 score:-0.641919 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #665 score:-0.625713 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #666 score:-0.624330 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #667 score:-0.665070 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #668 score:-0.675074 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #669 score:-0.645853 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #670 score:-0.623746 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #671 score:-0.606261 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #672 score:-0.615179 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #673 score:-0.605468 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #674 score:-0.666531 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #675 score:-0.638950 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #676 score:-0.655120 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #677 score:-0.647038 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #678 score:-0.650948 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #679 score:-0.648889 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #680 score:-0.607590 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #681 score:-0.587246 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #682 score:-0.587565 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #683 score:-0.581697 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #684 score:-0.663598 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #685 score:-0.592926 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #686 score:-0.600592 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #687 score:-0.622084 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #688 score:-0.484448 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #689 score:-0.650069 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #690 score:-0.628294 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #691 score:-0.586584 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #692 score:-0.635929 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #693 score:-0.604459 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #694 score:-0.639342 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #695 score:-0.648496 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #696 score:-0.754995 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #697 score:-0.603171 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #698 score:-0.687956 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #699 score:-0.619008 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #700 score:-0.638575 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #701 score:-0.654559 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #702 score:-0.771647 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #703 score:-0.615858 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #704 score:-0.651664 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #705 score:-0.652192 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #706 score:-0.519662 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #707 score:-0.609388 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #708 score:-0.633525 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #709 score:-0.793429 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #710 score:-0.575933 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #711 score:-0.729906 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #712 score:-0.653208 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #713 score:-0.646601 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #714 score:-0.651407 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #715 score:-0.624585 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #716 score:-0.660907 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #717 score:-0.682098 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #718 score:-0.646656 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #719 score:-0.642331 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #720 score:-0.619145 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #721 score:-0.606001 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #722 score:-0.690626 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #723 score:-0.625828 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #724 score:-0.605913 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #725 score:-0.621973 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #726 score:-0.613162 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #727 score:-0.563055 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #728 score:-0.643030 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #729 score:-0.507723 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #730 score:-0.659862 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #731 score:-0.637590 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #732 score:-0.608549 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #733 score:-0.661164 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #734 score:-0.627252 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #735 score:-0.660427 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #736 score:-0.641974 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #737 score:-0.574737 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #738 score:-0.630790 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #739 score:-0.634525 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #740 score:-0.663994 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #741 score:-0.560613 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #742 score:-0.607983 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #743 score:-0.655537 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #744 score:-0.641305 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #745 score:-0.634285 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #746 score:-0.609876 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #747 score:-0.578330 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #748 score:-0.634077 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #749 score:-0.564254 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #750 score:-0.617401 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #751 score:-0.622671 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #752 score:-0.642788 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #753 score:-0.680656 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #754 score:-0.481402 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #755 score:-0.604728 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #756 score:-0.621926 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #757 score:-0.737159 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #758 score:-0.713302 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #759 score:-0.707871 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #760 score:-0.600541 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #761 score:-0.709763 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #762 score:-0.718559 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #763 score:-0.556556 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #764 score:-0.621274 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #765 score:-0.593470 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #766 score:-0.644082 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #767 score:-0.629357 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #768 score:-0.660196 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #769 score:-0.675322 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #770 score:-0.636812 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #771 score:-0.633670 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #772 score:-0.628455 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #773 score:-0.593571 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #774 score:-0.611397 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #775 score:-0.665330 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #776 score:-0.639266 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #777 score:-0.662370 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #778 score:-0.648728 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #779 score:-0.599979 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #780 score:-0.578492 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #781 score:-0.696114 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #782 score:-0.630018 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #783 score:-0.651840 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #784 score:-0.561321 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #785 score:-0.624857 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #786 score:-0.628146 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #787 score:-0.617147 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #788 score:-0.717160 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #789 score:-0.617970 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #790 score:-0.633670 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #791 score:-0.618998 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #792 score:-0.636812 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #793 score:-0.650378 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #794 score:-0.640209 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #795 score:-0.634980 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #796 score:-0.634641 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #797 score:-0.647896 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #798 score:-0.752259 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #799 score:-0.651699 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #800 score:-0.631100 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #801 score:-0.603324 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #802 score:-0.643403 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #803 score:-0.646431 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #804 score:-0.650588 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #805 score:-0.542954 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #806 score:-0.648895 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #807 score:-0.715122 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #808 score:-0.627934 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #809 score:-0.543437 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #810 score:-0.649260 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #811 score:-0.622366 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #812 score:-0.614506 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #813 score:-0.564959 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #814 score:-0.632556 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #815 score:-0.675593 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #816 score:-0.646431 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #817 score:-0.658887 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #818 score:-0.646917 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #819 score:-0.650800 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #820 score:-0.554313 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #821 score:-0.624079 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #822 score:-0.779099 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #823 score:-0.683377 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #824 score:-0.576180 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #825 score:-0.585286 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #826 score:-0.665495 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #827 score:-0.706890 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #828 score:-0.589427 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #829 score:-0.674140 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #830 score:-0.594471 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #831 score:-0.644627 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #832 score:-0.654425 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #833 score:-0.624516 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #834 score:-0.699899 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #835 score:-0.597897 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #836 score:-0.657811 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #837 score:-0.633303 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #838 score:-0.621417 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #839 score:-0.630343 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #840 score:-0.604880 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #841 score:-0.733535 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #842 score:-0.612045 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #843 score:-0.599615 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #844 score:-0.565572 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #845 score:-0.632934 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #846 score:-0.577642 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #847 score:-0.603841 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #848 score:-0.643047 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #849 score:-0.617235 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #850 score:-0.672246 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #851 score:-0.621085 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #852 score:-0.626741 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #853 score:-0.609986 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #854 score:-0.651549 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #855 score:-0.612569 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #856 score:-0.615793 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #857 score:-0.626154 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #858 score:-0.646433 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #859 score:-0.682565 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #860 score:-0.612897 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #861 score:-0.645648 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #862 score:-0.625026 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #863 score:-0.660381 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #864 score:-0.558592 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #865 score:-0.616040 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #866 score:-0.668718 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #867 score:-0.633792 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #868 score:-0.670276 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #869 score:-0.542653 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #870 score:-0.637074 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #871 score:-0.648425 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #872 score:-0.560651 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #873 score:-0.604277 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #874 score:-0.619332 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #875 score:-0.624744 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #876 score:-0.650509 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #877 score:-0.582781 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #878 score:-0.620580 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #879 score:-0.646437 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #880 score:-0.633112 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #881 score:-0.632272 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #882 score:-0.589102 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #883 score:-0.641430 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #884 score:-0.659935 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #885 score:-0.624847 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #886 score:-0.674441 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #887 score:-0.648800 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #888 score:-0.650588 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #889 score:-0.608344 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #890 score:-0.651580 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #891 score:-0.633549 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #892 score:-0.666309 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #893 score:-0.569784 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #894 score:-0.632866 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #895 score:-0.654252 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #896 score:-0.633345 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #897 score:-0.569665 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #898 score:-0.695451 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #899 score:-0.638143 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #900 score:-0.620617 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #901 score:-0.659240 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #902 score:-0.615278 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #903 score:-0.627705 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #904 score:-0.671806 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #905 score:-0.639346 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #906 score:-0.598363 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #907 score:-0.686776 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #908 score:-0.628075 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #909 score:-0.622671 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #910 score:-0.724639 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #911 score:-0.650286 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #912 score:-0.586661 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #913 score:-0.605011 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #914 score:-0.595870 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #915 score:-0.638601 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #916 score:-0.600711 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #917 score:-0.655788 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #918 score:-0.609618 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:AXIS_ALIGNED }\n",
      "Step #919 score:-0.638916 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #920 score:-0.602409 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #921 score:-0.709057 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #922 score:-0.634318 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #923 score:-0.634986 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #924 score:-0.639155 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #925 score:-0.620669 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #926 score:-0.646207 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #927 score:-0.688085 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #928 score:-0.665951 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #929 score:-0.622182 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #930 score:-0.661942 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #931 score:-0.632795 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #932 score:-0.538434 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #933 score:-0.624919 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #934 score:-0.565415 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #935 score:-0.668482 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #936 score:-0.574429 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #937 score:-0.625739 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #938 score:-0.643582 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #939 score:-0.578004 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #940 score:-0.592761 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #941 score:-0.662782 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #942 score:-0.651768 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #943 score:-0.631825 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #944 score:-0.671325 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #945 score:-0.675709 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #946 score:-0.639241 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #947 score:-0.655652 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #948 score:-0.581735 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #949 score:-0.615674 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #950 score:-0.673735 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #951 score:-0.632698 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #952 score:-0.599325 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #953 score:-0.674776 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #954 score:-0.629865 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #955 score:-0.633365 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #956 score:-0.678636 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #957 score:-0.645969 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #958 score:-0.622473 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #959 score:-0.515327 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #960 score:-0.656845 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #961 score:-0.611060 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #962 score:-0.592400 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #963 score:-0.625523 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #964 score:-0.667361 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #965 score:-0.647782 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #966 score:-0.632376 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #967 score:-0.601005 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:AXIS_ALIGNED }\n",
      "Step #968 score:-0.649887 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #969 score:-0.648190 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #970 score:-0.665807 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:AXIS_ALIGNED }\n",
      "Step #971 score:-0.609553 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #972 score:-0.642933 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #973 score:-0.630544 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #974 score:-0.684891 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #975 score:-0.581592 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #976 score:-0.733343 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #977 score:-0.601035 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #978 score:-0.680696 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #979 score:-0.707047 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #980 score:-0.635759 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #981 score:-0.601542 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #982 score:-0.690722 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #983 score:-0.671112 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #984 score:-0.690196 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #985 score:-0.615573 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #986 score:-0.714483 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #987 score:-0.556892 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #988 score:-0.639476 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #989 score:-0.650073 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #990 score:-0.681858 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #991 score:-0.610086 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #992 score:-0.621417 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #993 score:-0.636313 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #994 score:-0.675323 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #995 score:-0.684289 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #996 score:-0.635281 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #997 score:-0.669302 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #998 score:-0.637258 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #999 score:-0.649522 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1000 score:-0.617197 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1001 score:-0.658049 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1002 score:-0.664568 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1003 score:-0.522856 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1004 score:-0.679006 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1005 score:-0.648079 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1006 score:-0.631424 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1007 score:-0.691297 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1008 score:-0.635562 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1009 score:-0.663696 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1010 score:-0.679546 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1011 score:-0.619382 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1012 score:-0.660165 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1013 score:-0.694163 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1014 score:-0.732395 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1015 score:-0.651572 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1016 score:-0.640926 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1017 score:-0.655405 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1018 score:-0.656602 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1019 score:-0.608399 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1020 score:-0.680279 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1021 score:-0.629210 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1022 score:-0.631446 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1023 score:-0.629275 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1024 score:-0.574241 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1025 score:-0.688345 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1026 score:-0.596278 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1027 score:-0.617850 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1028 score:-0.634650 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1029 score:-0.646249 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1030 score:-0.648426 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1031 score:-0.605278 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1032 score:-0.696710 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1033 score:-0.651958 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1034 score:-0.603750 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1035 score:-0.660203 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1036 score:-0.631210 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1037 score:-0.579912 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:4 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1038 score:-0.655094 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1039 score:-0.599897 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1040 score:-0.566341 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1041 score:-0.609728 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1042 score:-0.671655 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1043 score:-0.683510 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1044 score:-0.559248 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1045 score:-0.651177 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1046 score:-0.611864 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1047 score:-0.595714 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:4 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1048 score:-0.600869 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1049 score:-0.647179 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1050 score:-0.635304 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1051 score:-0.638244 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:6 use_hessian_gain:false shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1052 score:-0.659034 parameters:{ min_examples:21 categorical_algorithm:CART growing_strategy:LOCAL max_depth:14 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1053 score:-0.666694 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1054 score:-0.652707 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1055 score:-0.649608 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1056 score:-0.534674 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1057 score:-0.588889 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1058 score:-0.665817 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1059 score:-0.681593 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1060 score:-0.611919 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1061 score:-0.614729 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1062 score:-0.700034 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1063 score:-0.641797 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1064 score:-0.635315 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1065 score:-0.646568 parameters:{ min_examples:10 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1066 score:-0.620043 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1067 score:-0.636212 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1068 score:-0.610658 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1069 score:-0.596326 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1070 score:-0.666790 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1071 score:-0.657965 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1072 score:-0.656367 parameters:{ min_examples:5 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1073 score:-0.624528 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:6 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1074 score:-0.631913 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1075 score:-0.656996 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:true shrinkage:0.15 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1076 score:-0.640239 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:8 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1077 score:-0.616124 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1 }\n",
      "Step #1078 score:-0.608347 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1079 score:-0.648678 parameters:{ min_examples:7 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1080 score:-0.641283 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:512 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1081 score:-0.621317 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.2 num_candidate_attributes_ratio:1 split_axis:AXIS_ALIGNED }\n",
      "Step #1082 score:-0.617094 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:256 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1083 score:-0.579914 parameters:{ min_examples:7 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1084 score:-0.633088 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1085 score:-0.609867 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.25 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1086 score:-0.657624 parameters:{ min_examples:10 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.02 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1087 score:-0.605766 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:5 use_hessian_gain:false shrinkage:0.1 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:1.5 }\n",
      "Step #1088 score:-0.598086 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1089 score:-0.637899 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1090 score:-0.574272 parameters:{ min_examples:14 categorical_algorithm:CART growing_strategy:LOCAL max_depth:10 use_hessian_gain:false shrinkage:0.25 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1091 score:-0.676926 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1092 score:-0.723972 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:128 use_hessian_gain:true shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1093 score:-0.665822 parameters:{ min_examples:5 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:16 use_hessian_gain:true shrinkage:0.1 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1094 score:-0.558984 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:false shrinkage:0.3 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:NONE sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1095 score:-0.629045 parameters:{ min_examples:21 categorical_algorithm:RANDOM growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:64 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1096 score:-0.669062 parameters:{ min_examples:2 categorical_algorithm:CART growing_strategy:BEST_FIRST_GLOBAL max_num_nodes:32 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:1 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:STANDARD_DEVIATION sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2 }\n",
      "Step #1097 score:-0.639493 parameters:{ min_examples:2 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:3 use_hessian_gain:true shrinkage:0.05 num_candidate_attributes_ratio:0.2 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:BINARY sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1098 score:-0.623052 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:12 use_hessian_gain:false shrinkage:0.05 num_candidate_attributes_ratio:0.5 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "Step #1099 score:-0.632966 parameters:{ min_examples:14 categorical_algorithm:RANDOM growing_strategy:LOCAL max_depth:14 use_hessian_gain:true shrinkage:0.02 num_candidate_attributes_ratio:0.9 split_axis:SPARSE_OBLIQUE sparse_oblique_normalization:MIN_MAX sparse_oblique_weights:CONTINUOUS sparse_oblique_num_projections_exponent:2.5 }\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 0.481402\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 82\n",
      "Total number of nodes: 2330\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 82 Average: 28.4146 StdDev: 4.43366\n",
      "Min: 17 Max: 31 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 17, 18)  2   2.44%   2.44%\n",
      "[ 18, 19)  0   0.00%   2.44%\n",
      "[ 19, 20)  6   7.32%   9.76% #\n",
      "[ 20, 21)  0   0.00%   9.76%\n",
      "[ 21, 22)  4   4.88%  14.63% #\n",
      "[ 22, 23)  0   0.00%  14.63%\n",
      "[ 23, 24)  6   7.32%  21.95% #\n",
      "[ 24, 25)  0   0.00%  21.95%\n",
      "[ 25, 26)  3   3.66%  25.61% #\n",
      "[ 26, 27)  0   0.00%  25.61%\n",
      "[ 27, 28)  0   0.00%  25.61%\n",
      "[ 28, 29)  0   0.00%  25.61%\n",
      "[ 29, 30)  3   3.66%  29.27% #\n",
      "[ 30, 31)  0   0.00%  29.27%\n",
      "[ 31, 31] 58  70.73% 100.00% ##########\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 1206 Average: 4.60116 StdDev: 1.36746\n",
      "Min: 1 Max: 6 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)  21   1.74%   1.74%\n",
      "[ 2, 3)  75   6.22%   7.96% ##\n",
      "[ 3, 4) 180  14.93%  22.89% ####\n",
      "[ 4, 5) 264  21.89%  44.78% ######\n",
      "[ 5, 6) 214  17.74%  62.52% #####\n",
      "[ 6, 6] 452  37.48% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 1206 Average: 0 StdDev: 0\n",
      "Min: 0 Max: 0 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 0, 0] 1206 100.00% 100.00% ##########\n",
      "\n",
      "Attribute in nodes:\n",
      "\t576 : Age [NUMERICAL]\n",
      "\t150 : Fare [NUMERICAL]\n",
      "\t143 : Embarked_C [NUMERICAL]\n",
      "\t91 : Embarked_Q [NUMERICAL]\n",
      "\t83 : Embarked_S [NUMERICAL]\n",
      "\t35 : Pclass [NUMERICAL]\n",
      "\t26 : People [NUMERICAL]\n",
      "\t11 : Sex_female [NUMERICAL]\n",
      "\t9 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t40 : Age [NUMERICAL]\n",
      "\t9 : Fare [NUMERICAL]\n",
      "\t7 : Pclass [NUMERICAL]\n",
      "\t7 : Embarked_C [NUMERICAL]\n",
      "\t6 : Sex_female [NUMERICAL]\n",
      "\t5 : Embarked_Q [NUMERICAL]\n",
      "\t4 : Sex_male [NUMERICAL]\n",
      "\t4 : Embarked_S [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t120 : Age [NUMERICAL]\n",
      "\t29 : Fare [NUMERICAL]\n",
      "\t25 : Embarked_C [NUMERICAL]\n",
      "\t15 : Pclass [NUMERICAL]\n",
      "\t13 : Embarked_S [NUMERICAL]\n",
      "\t12 : Embarked_Q [NUMERICAL]\n",
      "\t6 : Sex_female [NUMERICAL]\n",
      "\t4 : Sex_male [NUMERICAL]\n",
      "\t1 : People [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t229 : Age [NUMERICAL]\n",
      "\t55 : Fare [NUMERICAL]\n",
      "\t52 : Embarked_C [NUMERICAL]\n",
      "\t34 : Embarked_Q [NUMERICAL]\n",
      "\t26 : Embarked_S [NUMERICAL]\n",
      "\t18 : Pclass [NUMERICAL]\n",
      "\t9 : People [NUMERICAL]\n",
      "\t7 : Sex_female [NUMERICAL]\n",
      "\t6 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t345 : Age [NUMERICAL]\n",
      "\t92 : Embarked_C [NUMERICAL]\n",
      "\t87 : Fare [NUMERICAL]\n",
      "\t54 : Embarked_Q [NUMERICAL]\n",
      "\t48 : Embarked_S [NUMERICAL]\n",
      "\t22 : Pclass [NUMERICAL]\n",
      "\t15 : People [NUMERICAL]\n",
      "\t9 : Sex_female [NUMERICAL]\n",
      "\t6 : Sex_male [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t576 : Age [NUMERICAL]\n",
      "\t150 : Fare [NUMERICAL]\n",
      "\t143 : Embarked_C [NUMERICAL]\n",
      "\t91 : Embarked_Q [NUMERICAL]\n",
      "\t83 : Embarked_S [NUMERICAL]\n",
      "\t35 : Pclass [NUMERICAL]\n",
      "\t26 : People [NUMERICAL]\n",
      "\t11 : Sex_female [NUMERICAL]\n",
      "\t9 : Sex_male [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t1124 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t82 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t225 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t436 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t678 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t1124 : ObliqueCondition\n",
      "\n",
      "Training logs:\n",
      "Number of iteration to final model: 82\n",
      "\tIter:1 train-loss:1.163775 valid-loss:1.131190  train-accuracy:0.757946 valid-accuracy:0.767123\n",
      "\tIter:2 train-loss:1.043927 valid-loss:1.002614  train-accuracy:0.804401 valid-accuracy:0.808219\n",
      "\tIter:3 train-loss:0.959685 valid-loss:0.905966  train-accuracy:0.834963 valid-accuracy:0.863014\n",
      "\tIter:4 train-loss:0.898672 valid-loss:0.836608  train-accuracy:0.843521 valid-accuracy:0.890411\n",
      "\tIter:5 train-loss:0.848150 valid-loss:0.790985  train-accuracy:0.849633 valid-accuracy:0.904110\n",
      "\tIter:6 train-loss:0.811976 valid-loss:0.761388  train-accuracy:0.849633 valid-accuracy:0.904110\n",
      "\tIter:16 train-loss:0.611618 valid-loss:0.595033  train-accuracy:0.888753 valid-accuracy:0.890411\n",
      "\tIter:26 train-loss:0.492851 valid-loss:0.518746  train-accuracy:0.910758 valid-accuracy:0.917808\n",
      "\tIter:36 train-loss:0.413215 valid-loss:0.504503  train-accuracy:0.938875 valid-accuracy:0.917808\n",
      "\tIter:46 train-loss:0.352192 valid-loss:0.514836  train-accuracy:0.949878 valid-accuracy:0.904110\n",
      "\tIter:56 train-loss:0.307182 valid-loss:0.505045  train-accuracy:0.962103 valid-accuracy:0.904110\n",
      "\tIter:66 train-loss:0.264389 valid-loss:0.491744  train-accuracy:0.968215 valid-accuracy:0.904110\n",
      "\tIter:76 train-loss:0.238156 valid-loss:0.492671  train-accuracy:0.974328 valid-accuracy:0.904110\n",
      "\tIter:86 train-loss:0.213843 valid-loss:0.497076  train-accuracy:0.975550 valid-accuracy:0.904110\n",
      "\tIter:96 train-loss:0.187752 valid-loss:0.511678  train-accuracy:0.979218 valid-accuracy:0.890411\n",
      "\tIter:106 train-loss:0.169169 valid-loss:0.526256  train-accuracy:0.979218 valid-accuracy:0.890411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
